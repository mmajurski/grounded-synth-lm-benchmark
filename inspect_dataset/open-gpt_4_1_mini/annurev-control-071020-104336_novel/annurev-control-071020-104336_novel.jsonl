[
  {
    "context": "## 4.1. Decoding Algorithms\nThe clinical standard for RPH control is based on the use of two sEMG channels, with the electrodes placed superficially on antagonist muscles. The envelope of the signal is extracted so that the user can control the closing and opening of the RPH by modulating the amplitude of their muscle contraction. When the amplitude exceeds a certain threshold, the RPH will move depending on which muscle was activated. Companies are offering more DOFs, using cocontraction to\n\ncycle through different types of grasps (e.g., Ottobock's Michelangelo hand). However, this type of control is highly nonintuitive and gives only low dexterity to the user. An alternative to this direct control approach is based on pattern recognition methods, extracting hand-crafted features to characterize the signal in a discriminative way (e.g., the signal root mean square, wavelength, and zero crossing) and classify the type of grasp intended by the user. This solution has become robust enough to reach the market (the Coapt system and Ottobock's Myo Plus). Using 2-12 bipolar sEMG electrodes makes it possible to obtain good classification rates for different kinds of grasps, with 90-95% accuracy for 4-12 classes and up to 75% for 50 classes (68-72).\n\nUsing a similar electrode disposition and classification method, other groups showed the possibility of decoding single-finger movement using the classification of flexion or extension (73, 74). Recently, Bhagwat &amp; Mukherji (75) showed single- and multifinger classification of 15 different movements with 99.79% accuracy. Researchers are also working on proportional control instead of classification, which makes it possible to decode several DOFs (e.g., wrist and finger movements) simultaneously and proportionally (76, 77). This type of control offers continuous position control. Several studies have also shown that single-finger proportional control is feasible, with good results (78, 79).\n\nAs an alternative, nonbiomimetic EMG decoders have been developed that rely on the subject learning inverse maps to relate motor outputs to arbitrary control variables (80). Using an abstract decoding cursor control space, subjects can learn to modulate their EMG activity to reach different targets arranged in a center-out task in order to trigger various grasping movements (81). Dyson et al. (82) recently validated these results on amputee participants; they showed that after training, the difficulty of the tasks could be increased, improving the possibilities for robotic hand control.\n\nWith only a few electrodes placed on muscles of interest, the accurate positioning of the electrodes requires anatomical knowledge; indeed, the type of amputation (congenital or traumatic), the surgical procedure, and the time since amputation (83) could influence the muscle anatomy and make the placement of the electrode tedious and specific to individual subjects. Moreover, a small shift in electrode placement can disrupt the pattern recognition algorithm (84). T o tackle these issues, several authors have proposed HD-sEMG, which consists of a grid of closely spaced electrodes, as an alternative solution. The large number of electrodes allows information to be recorded from a large part of the subject's forearm.\n\nHD-sEMG signals offer high spatial resolution, and recorded signals can be interpreted as spatial images of EMG activity. Using this image representation of EMG data, HD-sEMG is robust to small electrode shifts (85). Boschmann &amp; Platzner (85) used a structural similarity index, borrowed from the computer vision field, on HD-sEMG images combined with a simple one-against-one nearest-neighbor classifier to decode wrist and hand motions. Similarly, Stango et al. (86) used a variogram of images (a measure of the degree of spatial correlation, used mainly in geostatistics) to classify wrist movements. Both groups showed that their methods, which use spatial information from the images, performed better or similarly to the classic feature extraction approach. Moreover, their strategies improved the robustness to electrode shift and electrode number. The use of several spatially close electrodes makes it possible to decompose the EMG signal into its constituent motor unit action potential (50, 87). Kapelner et al. (88) investigated this approach, decomposing EMG signals to extract motor unit activity from forearm muscles during wrist motions. Recently, Dai &amp; Hu (89) showed that an approach consisting of finger joint angle estimation, combining classification for finger selection with EMG decomposition into motor unit activity, outperforms a standard amplitude-based approach.\n\nWe observe a paradigm shift from feature engineering to feature learning using raw data as input for deep neural networks. Studies have shown that combining this deep learning approach with HD-sEMG offers better performance than hand-crafted features in both grasp classification\n\n(90) and simultaneous single-finger and wrist movement classification (91). Deep learning has also shown good results with a smaller number of electrodes for grasp classification (72) and regression of arm or wrist motions (92, 93).\n\nThis approach permits both high dexterity and robustness, with unprecedented performance. However,one of the major difficulties of the deep learning approach is that it requires an extensive data set for training. For example, the deep learning used for the ImageNet challenge in 2012 used 1.2 million images for training on 1,000 categories (94). In the context of hand gesture recognition, generating tens of thousands of examples for a subject is not a viable option.\n\nA possible solution could use domain adaptation [often called transfer learning in the EMG literature (95, 96)], by leveraging data acquired from several subjects to enhance and accelerate training for a new user. Indeed, the aim is to use information from a database of several source domains and adapt it to a target domain (the end user) with a small number of samples. Authors generally apply deep domain adaptation (domain adaptation combined with deep learning) by pretraining a deep neural network and fine-tuning it with a few repetitions of movements by a target subject. The main idea is that gathering the recordings of several participants can meet the necessary conditions to learn a general mapping of all users' sEMG signals.\n\nUsing this idea, C\u00f4t\u00e9-Allard et al. (97) showed that their deep model was able to learn the features and significantly enhance the performance of deep networks on out-of-sample gestures. Using HD-sEMG and deep learning, Du et al. (98) also showed an unsupervised deep domain adaptation method that incrementally learns from data during a new session without explicit calibration of gestures. Consequently, deep learning offers a particularly attractive context from which to develop deep domain adaptation algorithms to leverage interuser data. This approach can increase decoding performance, improve robustness to electrode shift, and reduce the number of repetitions needed during training (99).\n\nAs seen in this section, the search for new EMG decoding algorithms that go beyond thresholdbased detection is an active field of research. Phinyomark &amp; Scheme (100) and Khamparia &amp; Singh (101) have reviewed recent research in EMG pattern recognition methods.\n\nMachine learning in the field of computer vision and object recognition has shown outstanding results using deep learning and is already used commercially by many companies. Some deep learning algorithms based on a pretrained network are now usable without any fine-tuning (e.g., self-driving cars). However, bio-signals are intrinsically different from images and need adaptation. More important, the amount of labeled EMG data available to effectively train deep networks might not be sufficient to capture the evolution of the signal over time (electrode displacement, skin impedance changes, etc.). Therefore, if model architectures and data processing are tailored for bio-signal applications and take into consideration signal evolution with time, deep learning can become a solution for more robust motor intention decoding.\n",
    "topic": "The principles and limitations of traditional threshold-based sEMG control using two channels for robotic prosthetic hand operation.",
    "response": "<document_analysis>\nThe provided context discusses various decoding algorithms for robotic prosthetic hand (RPH) control based on surface electromyography (sEMG). It contrasts the traditional clinical standard using two sEMG channels for threshold-based control with advanced pattern recognition, proportional control, high-density sEMG (HD-sEMG), and deep learning methods. The traditional method involves placing two electrodes on antagonist muscles, extracting the envelope of the signal, and using amplitude thresholds to trigger opening or closing the prosthetic hand. While simple and clinically standard, this approach is limited by low dexterity, nonintuitive control, and sensitivity to electrode placement. The threshold method offers only binary or discrete control of muscle activation amplitude, limiting the number of degrees of freedom (DOFs) and types of grasps achievable. In contrast, pattern recognition and proportional control allow classification of multiple grasps or continuous multi-DOF control, respectively, but require more electrodes and computational complexity. The context emphasizes that the threshold method's reliance on two channels and amplitude thresholds constrains user control to basic open/close functions, lacks intuitive multi-grasp selection, and is vulnerable to electrode placement variability.\n\nThe question should challenge experts to articulate the fundamental operational principles of threshold-based sEMG control and critically analyze its inherent limitations regarding dexterity, intuitiveness, and robustness. It should stimulate reflection on why this method remains the clinical standard despite these shortcomings and how these limitations motivate the development of more advanced decoding algorithms.\n\nDifficulty rating: 8/10, as the question requires detailed technical understanding of sEMG signal processing, prosthetic control paradigms, and practical clinical considerations.\n\nThe question invites critical engagement with the balance between simplicity and functionality in prosthetic control, encouraging experts to synthesize knowledge about signal acquisition, control logic, and user experience in threshold-based systems.\n\nNo irrelevant or bogus information is present; the context is coherent, technical, and educationally rich.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the fundamental operational principles of the traditional two-channel threshold-based sEMG control method for robotic prosthetic hands, and what inherent limitations of this approach restrict its dexterity, intuitiveness, and robustness in clinical applications?\n\nExplanation: The traditional two-channel threshold-based sEMG control method relies on placing electrodes over antagonist muscles to extract the amplitude envelope of muscle contractions; when the signal amplitude exceeds a preset threshold, it triggers a discrete prosthetic movement (e.g., opening or closing the hand) depending on which muscle is activated. This method inherently limits control to simple binary commands without enabling multi-degree-of-freedom or proportional control, resulting in low dexterity and nonintuitive user experience. Additionally, its performance is highly sensitive to precise electrode placement, making it vulnerable to variability in muscle anatomy and electrode shifts, which diminishes robustness and reliability in clinical use.\n\nCorrect Answer: It uses amplitude thresholds from two antagonist muscle sEMG channels to trigger discrete hand opening or closing, but is limited by low dexterity, nonintuitive control, and sensitivity to electrode placement variability.\n</output_format>",
    "question": "What are the fundamental operational principles of the traditional two-channel threshold-based sEMG control method for robotic prosthetic hands, and what inherent limitations of this approach restrict its dexterity, intuitiveness, and robustness in clinical applications?",
    "answer": "It uses amplitude thresholds from two antagonist muscle sEMG channels to trigger discrete hand opening or closing, but is limited by low dexterity, nonintuitive control, and sensitivity to electrode placement variability.",
    "explanation": "The traditional two-channel threshold-based sEMG control method relies on placing electrodes over antagonist muscles to extract the amplitude envelope of muscle contractions; when the signal amplitude exceeds a preset threshold, it triggers a discrete prosthetic movement (e.g., opening or closing the hand) depending on which muscle is activated. This method inherently limits control to simple binary commands without enabling multi-degree-of-freedom or proportional control, resulting in low dexterity and nonintuitive user experience. Additionally, its performance is highly sensitive to precise electrode placement, making it vulnerable to variability in muscle anatomy and electrode shifts, which diminishes robustness and reliability in clinical use.",
    "question_token_count": 46,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 41
  },
  {
    "context": "## 5.4. Sensory Feedback\nIn basic myoelectric or body-powered prostheses, feedback is delivered mainly by visually inspecting the movements of the prosthesis and by the physical interaction between the device and the user (126), as with hook prostheses. Clearly, the goal of a modern RPH is to deliver richer information more intuitively.\n\nSensory feedback strategies are characterized by their precision and the coherence between the evoked sensation and the desired one in terms of timing (synchronicity), position (somatotopy), and modality (i.e., touch, vibration, and temperature). Feedback techniques encode sensor values to stimulation parameters, which in turn are strongly tied to the chosen stimulation interface ( Table 2 ). Here, we focus mainly on electrical interfaces for feedback, but we also briefly discuss the mechanical interfaces.\n\nNoninvasive feedback strategies are attractive approaches since they do not necessitate surgical interventions ( Figure 2 a ). Starting with the Boston Arm, which Mann &amp; Reimers (127) used to demonstrate that position feedback was needed for precise reaching movements, these techniques have improved in both mechanical and electrical interfaces with the user. Indeed, the intact mechanoreceptors in the skin of the arm can be stimulated with small linear (128) or vibrating (129) motors that vary in their driving amplitude and frequency. On the other hand, mechanical stimulation brings an unavoidable delay of approximately 400 ms in the delivery of the sensation (130), and the integration and miniaturization of mechanoreceptors are challenging. The miniaturization of noninvasive feedback approaches is also challenging.\n",
    "topic": "The differences between basic myoelectric/body-powered prostheses and modern robotic prosthetic hands in terms of sensory feedback delivery.",
    "response": "<document_analysis>\nThe context contrasts basic myoelectric or body-powered prostheses with modern robotic prosthetic hands (RPH) regarding sensory feedback delivery. The fundamental difference lies in the richness and intuitiveness of the feedback: basic prostheses rely primarily on visual inspection and physical interaction, while modern RPH aim to provide richer, more intuitive sensory information. The text highlights key parameters defining sensory feedback\u2014precision, synchronicity, somatotopy, and modality\u2014and emphasizes the importance of coherence between the evoked and desired sensations. It also notes various feedback strategies, focusing on electrical stimulation interfaces and briefly mentioning mechanical ones. Noninvasive techniques stimulate intact skin mechanoreceptors but suffer from delays (~400 ms) and miniaturization challenges. This analysis reveals the conceptual and technical evolution from rudimentary feedback reliant on indirect cues to advanced, direct, and multimodal sensory feedback systems in modern prosthetics. The question can probe understanding of these nuanced differences, the technological challenges, and implications for user experience and control precision.\n\nDifficulty rating: 9/10, as it requires synthesis of detailed sensory feedback principles, comparative technological understanding, and implications for prosthesis design.\n\nThe question should encourage deep reflection on how sensory feedback mechanisms impact prosthesis functionality and user integration, challenging experts to articulate the technical and functional distinctions without oversimplification.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do sensory feedback delivery methods in basic myoelectric or body-powered prostheses fundamentally differ from those in modern robotic prosthetic hands, particularly regarding the precision, intuitiveness, and modalities of the feedback provided?\n\nExplanation: Basic myoelectric or body-powered prostheses primarily rely on indirect sensory feedback through visual monitoring and physical device interaction, lacking precise, modality-specific sensory information. In contrast, modern robotic prosthetic hands employ advanced feedback strategies that emphasize high precision, coherent timing (synchronicity), accurate spatial mapping (somatotopy), and multiple sensory modalities (touch, vibration, temperature), often using electrical stimulation interfaces to evoke more intuitive and natural sensations, thereby enhancing user control and embodiment.\n\nCorrect Answer: Basic prostheses use mainly visual and physical interaction cues, while modern robotic hands deliver precise, multimodal, and somatotopically coherent sensory feedback via advanced electrical stimulation for more intuitive control.\n</output_format>",
    "question": "How do sensory feedback delivery methods in basic myoelectric or body-powered prostheses fundamentally differ from those in modern robotic prosthetic hands, particularly regarding the precision, intuitiveness, and modalities of the feedback provided?",
    "answer": "Basic prostheses use mainly visual and physical interaction cues, while modern robotic hands deliver precise, multimodal, and somatotopically coherent sensory feedback via advanced electrical stimulation for more intuitive control.",
    "explanation": "Basic myoelectric or body-powered prostheses primarily rely on indirect sensory feedback through visual monitoring and physical device interaction, lacking precise, modality-specific sensory information. In contrast, modern robotic prosthetic hands employ advanced feedback strategies that emphasize high precision, coherent timing (synchronicity), accurate spatial mapping (somatotopy), and multiple sensory modalities (touch, vibration, temperature), often using electrical stimulation interfaces to evoke more intuitive and natural sensations, thereby enhancing user control and embodiment.",
    "question_token_count": 42,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 38
  },
  {
    "context": "## 4.1. Decoding Algorithms\nThe clinical standard for RPH control is based on the use of two sEMG channels, with the electrodes placed superficially on antagonist muscles. The envelope of the signal is extracted so that the user can control the closing and opening of the RPH by modulating the amplitude of their muscle contraction. When the amplitude exceeds a certain threshold, the RPH will move depending on which muscle was activated. Companies are offering more DOFs, using cocontraction to\n\ncycle through different types of grasps (e.g., Ottobock's Michelangelo hand). However, this type of control is highly nonintuitive and gives only low dexterity to the user. An alternative to this direct control approach is based on pattern recognition methods, extracting hand-crafted features to characterize the signal in a discriminative way (e.g., the signal root mean square, wavelength, and zero crossing) and classify the type of grasp intended by the user. This solution has become robust enough to reach the market (the Coapt system and Ottobock's Myo Plus). Using 2-12 bipolar sEMG electrodes makes it possible to obtain good classification rates for different kinds of grasps, with 90-95% accuracy for 4-12 classes and up to 75% for 50 classes (68-72).\n\nUsing a similar electrode disposition and classification method, other groups showed the possibility of decoding single-finger movement using the classification of flexion or extension (73, 74). Recently, Bhagwat &amp; Mukherji (75) showed single- and multifinger classification of 15 different movements with 99.79% accuracy. Researchers are also working on proportional control instead of classification, which makes it possible to decode several DOFs (e.g., wrist and finger movements) simultaneously and proportionally (76, 77). This type of control offers continuous position control. Several studies have also shown that single-finger proportional control is feasible, with good results (78, 79).\n\nAs an alternative, nonbiomimetic EMG decoders have been developed that rely on the subject learning inverse maps to relate motor outputs to arbitrary control variables (80). Using an abstract decoding cursor control space, subjects can learn to modulate their EMG activity to reach different targets arranged in a center-out task in order to trigger various grasping movements (81). Dyson et al. (82) recently validated these results on amputee participants; they showed that after training, the difficulty of the tasks could be increased, improving the possibilities for robotic hand control.\n\nWith only a few electrodes placed on muscles of interest, the accurate positioning of the electrodes requires anatomical knowledge; indeed, the type of amputation (congenital or traumatic), the surgical procedure, and the time since amputation (83) could influence the muscle anatomy and make the placement of the electrode tedious and specific to individual subjects. Moreover, a small shift in electrode placement can disrupt the pattern recognition algorithm (84). T o tackle these issues, several authors have proposed HD-sEMG, which consists of a grid of closely spaced electrodes, as an alternative solution. The large number of electrodes allows information to be recorded from a large part of the subject's forearm.\n\nHD-sEMG signals offer high spatial resolution, and recorded signals can be interpreted as spatial images of EMG activity. Using this image representation of EMG data, HD-sEMG is robust to small electrode shifts (85). Boschmann &amp; Platzner (85) used a structural similarity index, borrowed from the computer vision field, on HD-sEMG images combined with a simple one-against-one nearest-neighbor classifier to decode wrist and hand motions. Similarly, Stango et al. (86) used a variogram of images (a measure of the degree of spatial correlation, used mainly in geostatistics) to classify wrist movements. Both groups showed that their methods, which use spatial information from the images, performed better or similarly to the classic feature extraction approach. Moreover, their strategies improved the robustness to electrode shift and electrode number. The use of several spatially close electrodes makes it possible to decompose the EMG signal into its constituent motor unit action potential (50, 87). Kapelner et al. (88) investigated this approach, decomposing EMG signals to extract motor unit activity from forearm muscles during wrist motions. Recently, Dai &amp; Hu (89) showed that an approach consisting of finger joint angle estimation, combining classification for finger selection with EMG decomposition into motor unit activity, outperforms a standard amplitude-based approach.\n\nWe observe a paradigm shift from feature engineering to feature learning using raw data as input for deep neural networks. Studies have shown that combining this deep learning approach with HD-sEMG offers better performance than hand-crafted features in both grasp classification\n\n(90) and simultaneous single-finger and wrist movement classification (91). Deep learning has also shown good results with a smaller number of electrodes for grasp classification (72) and regression of arm or wrist motions (92, 93).\n\nThis approach permits both high dexterity and robustness, with unprecedented performance. However,one of the major difficulties of the deep learning approach is that it requires an extensive data set for training. For example, the deep learning used for the ImageNet challenge in 2012 used 1.2 million images for training on 1,000 categories (94). In the context of hand gesture recognition, generating tens of thousands of examples for a subject is not a viable option.\n\nA possible solution could use domain adaptation [often called transfer learning in the EMG literature (95, 96)], by leveraging data acquired from several subjects to enhance and accelerate training for a new user. Indeed, the aim is to use information from a database of several source domains and adapt it to a target domain (the end user) with a small number of samples. Authors generally apply deep domain adaptation (domain adaptation combined with deep learning) by pretraining a deep neural network and fine-tuning it with a few repetitions of movements by a target subject. The main idea is that gathering the recordings of several participants can meet the necessary conditions to learn a general mapping of all users' sEMG signals.\n\nUsing this idea, C\u00f4t\u00e9-Allard et al. (97) showed that their deep model was able to learn the features and significantly enhance the performance of deep networks on out-of-sample gestures. Using HD-sEMG and deep learning, Du et al. (98) also showed an unsupervised deep domain adaptation method that incrementally learns from data during a new session without explicit calibration of gestures. Consequently, deep learning offers a particularly attractive context from which to develop deep domain adaptation algorithms to leverage interuser data. This approach can increase decoding performance, improve robustness to electrode shift, and reduce the number of repetitions needed during training (99).\n\nAs seen in this section, the search for new EMG decoding algorithms that go beyond thresholdbased detection is an active field of research. Phinyomark &amp; Scheme (100) and Khamparia &amp; Singh (101) have reviewed recent research in EMG pattern recognition methods.\n\nMachine learning in the field of computer vision and object recognition has shown outstanding results using deep learning and is already used commercially by many companies. Some deep learning algorithms based on a pretrained network are now usable without any fine-tuning (e.g., self-driving cars). However, bio-signals are intrinsically different from images and need adaptation. More important, the amount of labeled EMG data available to effectively train deep networks might not be sufficient to capture the evolution of the signal over time (electrode displacement, skin impedance changes, etc.). Therefore, if model architectures and data processing are tailored for bio-signal applications and take into consideration signal evolution with time, deep learning can become a solution for more robust motor intention decoding.\n",
    "topic": "The methodology and benefits of EMG signal decomposition into motor unit action potentials and its role in improving finger joint angle estimation.",
    "response": "<document_analysis>\nThe context provides an in-depth overview of various electromyographic (EMG) decoding algorithms used for controlling robotic prosthetic hands (RPH). It explains the progression from simple threshold-based control to pattern recognition methods, proportional control, and nonbiomimetic decoders. The text highlights the challenges in electrode placement and robustness, motivating the use of high-density surface EMG (HD-sEMG) arrays, which enable recording spatially rich signals interpreted as images. This spatial information helps improve robustness to electrode shifts and allows decomposition of EMG signals into motor unit action potentials (MUAPs).\n\nSpecifically, the text mentions that decomposing EMG signals into MUAPs, made possible by using multiple spatially close electrodes, allows more precise extraction of motor unit activity from forearm muscles during wrist motions. The advanced approach combining classification for finger selection with EMG decomposition into motor unit activity has been shown to outperform standard amplitude-based methods in finger joint angle estimation.\n\nThe passage also discusses the paradigm shift towards deep learning approaches using raw HD-sEMG data, which further improves decoding performance and robustness. However, challenges remain related to data volume requirements and signal variability over time.\n\nFor the question topic focusing on the methodology and benefits of EMG signal decomposition into motor unit action potentials and its role in improving finger joint angle estimation, the text provides sufficient technical detail. It points out that HD-sEMG enables decomposition into constituent MUAPs, which leads to better finger joint angle estimation compared to traditional amplitude-based approaches.\n\nDifficulty rating: 9/10. This question requires understanding of advanced EMG signal processing techniques, the concept of motor units, spatial signal acquisition, and their application in prosthetic control.\n\nThe question should probe the expert's comprehension of how spatially resolved EMG data facilitates decomposition into motor unit activity, why this is beneficial compared to amplitude-based features, and how this translates into improved finger joint angle estimation.\n\nThis encourages reflection on signal processing methodology, neurophysiological interpretation, and practical impact on prosthetic control accuracy.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the decomposition of high-density surface EMG signals into motor unit action potentials enhance the accuracy of finger joint angle estimation compared to standard amplitude-based approaches, and what methodological advantages does this decomposition provide for prosthetic hand control?\n\nExplanation: Decomposition of HD-sEMG into motor unit action potentials allows extraction of individual motor unit firing patterns, providing a more precise and physiologically relevant representation of muscle activation than aggregate amplitude measures. This granular information improves the discrimination of fine finger movements and joint angles, leading to superior estimation accuracy. Methodologically, it leverages the high spatial resolution of HD-sEMG grids to separate overlapping motor unit signals, enhancing robustness to noise and electrode shifts, and enabling more nuanced and continuous control of prosthetic devices.\n\nCorrect Answer: Decomposition extracts individual motor unit firing patterns from HD-sEMG, providing more precise muscle activation data than amplitude alone, which improves finger joint angle estimation accuracy and robustness for prosthetic control.\n</output_format>",
    "question": "How does the decomposition of high-density surface EMG signals into motor unit action potentials enhance the accuracy of finger joint angle estimation compared to standard amplitude-based approaches, and what methodological advantages does this decomposition provide for prosthetic hand control?",
    "answer": "Decomposition extracts individual motor unit firing patterns from HD-sEMG, providing more precise muscle activation data than amplitude alone, which improves finger joint angle estimation accuracy and robustness for prosthetic control.",
    "explanation": "Decomposition of HD-sEMG into motor unit action potentials allows extraction of individual motor unit firing patterns, providing a more precise and physiologically relevant representation of muscle activation than aggregate amplitude measures. This granular information improves the discrimination of fine finger movements and joint angles, leading to superior estimation accuracy. Methodologically, it leverages the high spatial resolution of HD-sEMG grids to separate overlapping motor unit signals, enhancing robustness to noise and electrode shifts, and enabling more nuanced and continuous control of prosthetic devices.",
    "question_token_count": 46,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 39
  },
  {
    "context": "## Transradial amputation:\nThe cosmetic solution is often used for the most distal amputations (e.g., fingers) but is not adapted for patients with a transradial amputation given the dramatic loss of functionality. Bodypowered mechanical hooks, mainly with one-DOF control, are popular solutions thanks to their the partial amputation of the arm below the elbow, at some point along the radial bone\n\nb\n\ne\n\nBattery pack\n\nc\n\nCoil (integrates with prosthetic frame)\n\nCable\n\n(for power and data transmission)\n\nCoil driver module\n\nProsthetic hand\n\nProsthetic control interface\n\nf\n\nBiomimetic: imitating natural processes in order to improve a technical solution\n\nlow price, light weight, and easy maintenance. This type of prosthesis is also well suited for highintensity work due to the control robustness. Also, because the subject must move their shoulder to open and close the hook, these systems have inherent proprioception feedback (9). However, one of the major limitations of the hook solution is the low level of dexterity and nonanthropomorphic appearance. Body-powered hands have solved the anthropomorphic aspect while keeping the robustness of body-powered solutions (10). For example, Baril et al. (11) developed a programmable body-powered hand that can perform different grasp types using a mechanical selector that blocks the closing of one or more fingers. Nevertheless, this solution has its drawback as well: Because of their low mechanical efficiency, body-powered prostheses require large amounts of energy (from 33 N for a hook to 131 N for a hand) to produce a relatively low pinch force (15 N) (12). This could explain their high rejection rate by patients, which ranges between 16% and 66% depending on the survey and time period (13).\n\nHere, we concentrate on RPHs because they potentially offer the most versatile, natural, and power-efficient replacement for amputated hands and could become the default solution for patients. We investigate the challenges in existing RPHs, considering both commercially available solutions ( Supplemental Table 1 ) and those in the research phase ( Supplemental Table 2 ).\n\nMimicking the biomechanics of a hand is not easy. Early prototypes (14) succeeded in designing fingers with skeleton-like structures, but biomimetic actuation was only recently properly implemented using muscle-like actuators (15). The challenge for RPH developers is to embed actuators, sensors, and electronic components into a prosthesis with the same size and weight as the replaced hand (14, 16, 17). Major system integration and miniaturization are necessary before these systems can be used by amputee patients.\n\nInstead, underactuation is a widespread approach to simplify the mechanics while keeping reasonable dexterity. An underactuated system is one where the number of degrees of actuation (DOAs) is smaller than the number of DOFs (see DOA/DOF &lt; 1 in Supplemental Tables 1 and 2 ). The passive (nonactuated) DOFs are exploited to adapt to the surface in contact, as suggested by the concept of morphological computation (18), and to enable a self-adjusting grip without the need to control each articulation. These systems reduce the number of motors needed in the RPH and therefore its complexity, weight, and price.\n",
    "topic": "Evaluate the advantages and limitations of body-powered mechanical hooks and hands in terms of control, proprioceptive feedback, dexterity, anthropomorphism, and energy efficiency.",
    "response": "<document_analysis>\nThe context provides a detailed comparison between body-powered mechanical hooks and body-powered hands in the setting of transradial amputations, emphasizing functional trade-offs. The text highlights that body-powered hooks, despite their one-DOF control, are robust, lightweight, low-cost, and provide inherent proprioceptive feedback through shoulder movements, making them suitable for high-intensity work. However, they suffer from low dexterity and a non-anthropomorphic appearance. Body-powered hands address the anthropomorphic deficit and maintain robustness but have drawbacks including low mechanical efficiency, requiring high input force to generate relatively low pinch force, potentially contributing to high rejection rates among users.\n\nThe passage also contrasts these body-powered solutions with robotic prosthetic hands (RPHs), focusing on challenges like biomimetic actuation, miniaturization, and underactuation for complexity reduction. The key aspects to explore in the question are the nuanced advantages and limitations of body-powered hooks and hands regarding control complexity, proprioception, dexterity, anthropomorphism, and energy efficiency, all critical for prosthetic acceptance and functionality.\n\nDifficulty rating: 8/10. The question demands integration of biomechanical, ergonomic, and user-experience perspectives, addressing both engineering and clinical implications. It requires deep understanding of prosthetic design trade-offs and user interaction.\n\nThe question is designed to provoke expert reflection on the balance between simplicity and functionality in prosthetic design, the role of proprioceptive feedback in user control, and how energy efficiency impacts usability and acceptance. It encourages critical evaluation of how mechanical design choices affect both the physical performance and psychological acceptance of prostheses.\n\nNo irrelevant or bogus content is present. The text is coherent and rich in technical detail relevant to prosthetics engineering and rehabilitation.\n\nTherefore, generating a complex, reflective question-answer pair on the comparative advantages and limitations of body-powered mechanical hooks and hands is fully warranted.\n</document_analysis>\n\n<output_format>\nQuestion: How do body-powered mechanical hooks and body-powered hands differ in terms of control complexity, proprioceptive feedback, dexterity, anthropomorphic appearance, and energy efficiency, and what implications do these differences have on their functional suitability and user acceptance in transradial amputees?\n\nExplanation: Body-powered mechanical hooks typically have simple one-DOF control and leverage shoulder movements to operate, which provides inherent proprioceptive feedback and robustness suitable for high-intensity work; however, they lack dexterity and have a non-anthropomorphic appearance. In contrast, body-powered hands improve anthropomorphism and maintain robustness but require significantly greater input force due to low mechanical efficiency, resulting in limited pinch force and higher rejection rates. These differences imply that while hooks offer ease of control and feedback with less complexity, their limited function and appearance reduce user satisfaction, whereas hands offer better naturalness but at the cost of higher physical effort and potential usability issues.\n\nCorrect Answer: Hooks have simpler control and proprioceptive feedback but low dexterity and poor appearance; hands are more anthropomorphic with better dexterity but less energy efficient, affecting user acceptance accordingly.\n</output_format>",
    "question": "How do body-powered mechanical hooks and body-powered hands differ in terms of control complexity, proprioceptive feedback, dexterity, anthropomorphic appearance, and energy efficiency, and what implications do these differences have on their functional suitability and user acceptance in transradial amputees?",
    "answer": "Hooks have simpler control and proprioceptive feedback but low dexterity and poor appearance; hands are more anthropomorphic with better dexterity but less energy efficient, affecting user acceptance accordingly.",
    "explanation": "Body-powered mechanical hooks typically have simple one-DOF control and leverage shoulder movements to operate, which provides inherent proprioceptive feedback and robustness suitable for high-intensity work; however, they lack dexterity and have a non-anthropomorphic appearance. In contrast, body-powered hands improve anthropomorphism and maintain robustness but require significantly greater input force due to low mechanical efficiency, resulting in limited pinch force and higher rejection rates. These differences imply that while hooks offer ease of control and feedback with less complexity, their limited function and appearance reduce user satisfaction, whereas hands offer better naturalness but at the cost of higher physical effort and potential usability issues.",
    "question_token_count": 54,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 36
  },
  {
    "context": "## 4.4. Perspectives\nMotor decoding for RPHs is progressing in two main directions: Noninvasive approaches have seen advances in decoding algorithms using large data sets and increases in the number of recording points, and implanted electrodes (either muscular or intraneural) have seen improvements that enable better recording stability and more robust decoding. There is currently no consensus on which approach is best for transradial amputee patients, as they each have their own strengths and limitations. The need for daily signal and classification recalibration is a weak point of the classic sEMG approach, which is being addressed by several research groups developing, for example, HD-sEMG.And despite iEMG's promising control performance, which is robust to donning and doffing of the prosthesis, its overall performance gain, when compared with sEMG, may not currently be sufficient to justify an invasive surgery. The same reasoning can be applied to intraneural electrodes.\n\nOne can imagine a future where both invasive and noninvasive approaches will continue to progress and will target either patients who prefer a stable decoding setup or those who do not want to undergo surgery and will accept the need to calibrate their prosthesis on a regular basis (118). Another scenario can be a parallel development of invasive technologies for both sensory and motor functions. Indeed, as shown in Section 5, the approach using intraneural implanted electrodes has permitted unprecedented levels of somatosensory restoration; it might, therefore, be reasonable to perform a single surgery to restore both motor and sensory functions. For this reason, motor decoding using the intraneural interface can become a viable solution if these interfaces one day permit both providing sensory feedback and recording discriminative signals for motor decoding in parallel, but online artifact removal remains an important challenge.\n\nPower consumption is another critical issue: RPHs should embed small electronics because the size of the prosthesis limits the space available for batteries, but doing so usually comes at the cost of limited processing resources. Also, the electronics for the HD-sEMG remain cumbersome due to the large number of input channels and should be miniaturized and portable. Moreover, decoding model complexity is also limited by portable processing resources. In practice, an increased number of electrodes is already available in wearable systems (Sessantaquattro, OT Bioelettronica, Italy) and may become available for prostheses in the future.\n\nFinally, low latency is paramount for seamless prosthesis control [ &lt; 300 ms between user intention and real-time decoding (119)]. Among the studies discussed above, only a few performed analyses to show the feasibility of real-time control (without processing resource limitations), and even fewer included embedded electronics that would translate for home use. One possible solution for real-time decoding with complex models is to bypass embedded electronic limitations; this could be achieved by taking advantage of the computational power of cell phones or by relying on cloud computing and the next generations of wireless cellular networks for low-latency communication.\n",
    "topic": "Challenges and solutions related to daily signal and classification recalibration in noninvasive motor decoding methods and how HD-sEMG addresses these issues.",
    "response": "<document_analysis>\nThe context discusses the state of motor decoding for robotic prosthetic hands (RPHs), focusing on both noninvasive and invasive approaches. A key challenge highlighted for the classic surface electromyography (sEMG) method is the need for daily signal and classification recalibration, which undermines robustness and user convenience. The text mentions that high-density surface electromyography (HD-sEMG) is being developed by research groups to address this specific weakness. HD-sEMG involves increasing the number of recording points, which could improve signal quality and stability, reducing recalibration frequency. However, this comes with challenges such as increased complexity of electronics, power consumption, and the need for miniaturization. The context also contrasts this with invasive methods (intramuscular or intraneural electrodes), which offer more stable signals but at the cost of surgery and other complexities. The question should therefore probe the technical challenges of daily recalibration in sEMG, how HD-sEMG specifically addresses these, and implications for practical prosthetic control. Difficulty is rated at 9 due to requiring expert understanding of signal processing, neuroprosthetics, and biomedical engineering. The question is crafted to stimulate deep reflection on limitations of noninvasive methods and how HD-sEMG advances the field, including trade-offs related to hardware and processing limitations.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the main challenges posed by daily signal and classification recalibration in traditional surface electromyography (sEMG) for noninvasive motor decoding, and how does high-density surface electromyography (HD-sEMG) specifically address these issues to improve prosthetic control robustness?\n\nExplanation: Traditional sEMG suffers from signal variability due to factors like electrode placement, skin conditions, and muscle fatigue, necessitating daily recalibration of decoding algorithms to maintain accuracy. HD-sEMG mitigates these challenges by increasing the number and density of recording electrodes, which enhances spatial resolution and signal redundancy, thereby improving signal stability and reducing the frequency of recalibration. This leads to more robust decoding performance and user convenience despite added complexity in electronics and processing.\n\nCorrect Answer: HD-sEMG increases electrode density to enhance signal stability and reduce the need for daily recalibration caused by variability in traditional sEMG signals.\n</output_format>",
    "question": "What are the main challenges posed by daily signal and classification recalibration in traditional surface electromyography (sEMG) for noninvasive motor decoding, and how does high-density surface electromyography (HD-sEMG) specifically address these issues to improve prosthetic control robustness?",
    "answer": "HD-sEMG increases electrode density to enhance signal stability and reduce the need for daily recalibration caused by variability in traditional sEMG signals.",
    "explanation": "Traditional sEMG suffers from signal variability due to factors like electrode placement, skin conditions, and muscle fatigue, necessitating daily recalibration of decoding algorithms to maintain accuracy. HD-sEMG mitigates these challenges by increasing the number and density of recording electrodes, which enhances spatial resolution and signal redundancy, thereby improving signal stability and reducing the frequency of recalibration. This leads to more robust decoding performance and user convenience despite added complexity in electronics and processing.",
    "question_token_count": 58,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 30
  },
  {
    "context": "## 7. CONCLUSION\nMorethan20years ago,remarkable results by a group of French surgeons for hand transplantation (8) had raised hopes for a future where grafting would be the norm and prosthetics eventually obsolete (176). However, not only has this prediction-unfortunately-not yet come to pass, but also the adoption of new RPH technologies has been slower than expected. As such, RPHs are still a field of active research. Significant efforts have been made to reduce their price and weight, improve their aesthetics and anthropomorphism, increase the robustness and accuracy of their motor intention decoding, and provide natural and accurate somatosensory feedback. We have proposed here an outline of possible iterations of RPHs for the next few years and for 5-10 years in the future.\n\nIn our view, there could soon be a broader integration of simple somatosensory feedback using mature implantable techniques, such as cuff electrodes. Motor decoding using machine learning and shared-control algorithms could permit continuous command of single fingers and broader sets of grasps. Ultimately, the next generation of prosthetics could use more advanced soft implantable electrodes, which could enable more sophisticated sensory encoding (proprioception, temperature perception, touch perception, and nociception) and motor decoding using, for example, deep learning techniques. But to reach this goal, the field must tackle significant challenges related to system integration, electronic miniaturization, computational power, surgical procedure, electrode robustness, the robotic hand itself, and the encoding of somatosensory information.\n",
    "topic": "The potential and requirements for next-generation soft implantable electrodes to enable complex sensory modalities such as proprioception, temperature perception, touch perception, and nociception.",
    "response": "<document_analysis>\nThe provided context outlines the current status and future prospects of robotic prosthetic hands (RPHs), emphasizing the gradual progress from early hopes of hand transplantation to sophisticated prosthetic technologies. It highlights the potential of next-generation soft implantable electrodes to enable complex sensory modalities, including proprioception, temperature perception, touch, and nociception, which represent a significant advancement over current somatosensory feedback methods like cuff electrodes. The text also identifies critical challenges impeding this progress, such as system integration, miniaturization, computational demands, surgical complexity, electrode robustness, and effective sensory encoding.\n\nThe analysis reveals key themes: the evolution of sensory feedback in prosthetics, the integration of advanced motor decoding (machine learning, deep learning), and the multidisciplinary hurdles that must be overcome to realize a fully functional, biologically integrated prosthetic hand. The question should probe a deep understanding of why soft implantable electrodes are pivotal for encoding multiple sensory modalities and what technical and biological challenges must be solved to achieve this.\n\nDifficulty rating: 9/10, given the need to understand cutting-edge bioengineering, neural interfacing, and computational neuroscience aspects.\n\nThe question will encourage reflection on the intersection of materials science, neural engineering, sensory physiology, and computational approaches, and will require a synthesis of knowledge on how these domains converge to enable complex sensory feedback in prosthetics.\n\nThis question will prompt the expert to articulate the multifaceted requirements and implications of employing soft implantable electrodes for advanced sensory encoding, beyond basic tactile feedback, fostering insight into future research directions and technological integration challenges.\n</document_analysis>\n\n<output_format>\nQuestion: What are the primary technical and biological challenges that must be addressed to enable next-generation soft implantable electrodes to accurately encode complex sensory modalities such as proprioception, temperature perception, touch, and nociception in robotic prosthetic hands?\n\nExplanation: Accurately encoding diverse sensory modalities requires overcoming challenges in system integration, ensuring electrode robustness and biocompatibility, achieving electronic miniaturization to implant advanced soft electrodes, developing computational algorithms capable of sophisticated sensory encoding and decoding (e.g., deep learning), and refining surgical procedures to implant these devices safely and effectively, all while maintaining the functional integrity of the robotic hand and naturalistic sensory feedback.\n\nCorrect Answer: Integration complexity, electrode robustness and biocompatibility, miniaturization, advanced computational encoding/decoding, and surgical implantation challenges.\n</output_format>",
    "question": "What are the primary technical and biological challenges that must be addressed to enable next-generation soft implantable electrodes to accurately encode complex sensory modalities such as proprioception, temperature perception, touch, and nociception in robotic prosthetic hands?",
    "answer": "Integration complexity, electrode robustness and biocompatibility, miniaturization, advanced computational encoding/decoding, and surgical implantation challenges.",
    "explanation": "Accurately encoding diverse sensory modalities requires overcoming challenges in system integration, ensuring electrode robustness and biocompatibility, achieving electronic miniaturization to implant advanced soft electrodes, developing computational algorithms capable of sophisticated sensory encoding and decoding (e.g., deep learning), and refining surgical procedures to implant these devices safely and effectively, all while maintaining the functional integrity of the robotic hand and naturalistic sensory feedback.",
    "question_token_count": 47,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 27
  },
  {
    "context": "## 3. INTERFACES WITH THE NEUROMUSCULAR SYSTEM\nDecades of work on robotic prosthetics have led to numerous invasive and noninvasive solutions for interfacing with the body (for a review, see 36) ( Table 1 ). Here, we describe existing technologies and outline the ones we consider the most promising for the future.\n\n\n## 3.1. Taxonomy of Existing Interfaces\nTo classify and evaluate the quality of an interface, selectivity-defined as the ability to record from a specific location within the nerve-is the most straightforward metric. Both spatial and temporal selectivity are important, naturally, as they enable better motor decoding and more localized sensory feedback. Electrode invasiveness, by contrast, is categorized into two large classes, surface electrodes and implanted electrodes, the latter of which includes extraneural (i.e., around the nerve) (37, 38), intraneural (i.e., through the nerve) (6), and regenerative approaches (where the nerve regrows inside the electrode) (39; for reviews, see 36, 40). Invasiveness is often seen as a trade-off to selectivity, with the observation that higher selectivity comes at the cost of greater invasiveness (41). While this relationship continues to be true to a large extent, two amendments are necessary: First, there are a multitude of other dimensions to consider, and second, recent\n\nresults are suggesting that the relationship might not be the same in the motor and the sensory domains. We detail both aspects here.\n\nBeyond the selectivity of an interface, it is crucial to consider its reach and level of discrimination. For example, transverse intrafascicular multichannel electrodes (TIMEs) (42) and longitudinal intrafascicular electrodes (LIFEs) (43) can have a very similar selectivity, but TIMEs reach a more substantial proportion of the nerve and therefore can infer more information about the whole signal. Comparing muscle stimulation with different electrodes, Badia et al. (44) showed that a TIME could target three muscles, whereas they could not activate more than one muscle with a LIFE. Spatial discrimination of neural signals from nontarget signals is influenced not only by the electrode's invasiveness (how close it is to the source) but also by its geometry (e.g., a spherical point source targets a small volume), electrode material, and configuration (e.g., a cylindrical electrode better discriminates the axons perpendicular to the main axis) (45).\n\nSignal quality and stability are also important aspects that have been extensively studied. Work in this area has included interventions to improve the device-tissue interfaces [e.g., electrode coating (46) or a hollow glass cone that permits the ingrowth of cortical neurites in the electrodes (47)], electrode impedance, and filtering processes to increase the signal-to-noise ratio. The recording stability depends on biocompatibility, the electrode's robustness (resistance to physical manipulation), and the stability of the contact between the interface and neural tissue. Significant efforts have been made to develop soft, implantable electrodes (48) in order to reduce insertion trauma and physical mismatches between neural tissues and implantable interfaces. Finally, properly anchoring the electrodes with the neural tissues is also essential to maintain a steady recording or stimulation site over time. This is particularly important in the sensory domain, where the stability of the elicited sensation is paramount for continuous use.\n\nFinally, practicalities such as the cost of the technology and the difficulty of the implant must be considered. As such, an implantation procedure based on a known surgical procedure (49) has a better chance to be accepted and adopted by surgeons. The use of existing devices, materials, and mature technologies is also a way to reduce costs and risks. An example of such a strategy is the use of Utah Arrays, which use well-established electrodes for brain recording, to interface with the peripheral nervous system.\n\nFor motor decoding, surface EMG (sEMG) approaches are by far the most widely used technique to date. Recent implementations using a large number of electrodes [termed high-density sEMG (HD-sEMG) (50)] have shown unprecedented results in terms of accuracy and decoding robustness (for details, see Section 4). Implanted EMG (iEMG) has shown higher performance and stability than sEMG on the continuous control of three DOFs (51). However, studies have found no statistical difference in different electrodes' ability to differentiate among 12 types of grasps (52). Neural interfaces with the peripheral nerves have also shown promising results on grasp classification with TIMEs (53) and proportional control with a Utah Slanted Electrode Array (54). However, the development of real-time control and sensory feedback stimulation is still at an early stage (53, 54) and will need further investigation.\n\nIn the sensory domain, there is no current consensus for noninvasive approaches. T actile feedback using vibrotactile (55, 56), mechanotactile (57), or sensory substitution [e.g., audio (58)] has been proposed. Transcutaneous electrical nerve stimulation (TENS) is a viable noninvasive approach to induce close to natural sensation with amputee patients (59, 60). However, as detailed elsewhere in this review, current solutions using implanted electrodes (particularly intraneural interfaces) have shown levels of sensory recovery far superior to those of noninvasive approaches. This is true from a functional point of view [e.g., the possibility to encode texture (61) or shapes and stiffness (6)], phenomenologically [patients perceive the feedback as close to natural (62)], and in terms of cognitive load (63).\n",
    "topic": "The role of electrode reach and discrimination capacity in enabling multi-muscle activation and richer neural signal inference, exemplified by TIMEs versus LIFEs.",
    "response": "<document_analysis>\nThe provided context offers a detailed overview of neuromuscular interfaces, focusing on their classification by invasiveness, selectivity, spatial and temporal resolution, signal quality, and practical aspects like cost and surgical feasibility. A key nuanced point is the comparison between two types of intrafascicular electrodes: transverse intrafascicular multichannel electrodes (TIMEs) and longitudinal intrafascicular electrodes (LIFEs). Both have similar selectivity, defined as the ability to record from a specific nerve location, yet TIMEs have greater \"reach\"\u2014the capacity to interact with a larger portion of the nerve\u2014and thus can infer a richer, more comprehensive neural signal. This extended reach correlates with the practical ability of TIMEs to activate multiple muscles (three muscles demonstrated) compared to LIFEs (one muscle), emphasizing that selectivity alone does not fully determine interface performance. Instead, reach and spatial discrimination are critical, influenced by electrode geometry, configuration, and placement. This subtle distinction is crucial for understanding how electrode design affects functional outcomes in prosthetics and neuromuscular control.\n\nThe question planned probes a deep understanding of this distinction: why does greater reach and discrimination capacity enable multi-muscle activation and richer signal inference despite similar selectivity? This requires synthesizing knowledge of electrode design, neuroanatomy, and functional implications. The difficulty is high (rated 9/10) because it demands nuanced grasp beyond simple definitions\u2014understanding how electrode geometry and spatial engagement translate into motor control capabilities.\n\nThe question invites experts to reflect critically on the limitations of selectivity as a sole metric, to appreciate multi-dimensional evaluation of interfaces, and to infer practical consequences for prosthetic design. It is highly technical, rooted in the core of neuroengineering interface challenges.\n\nIrrelevant elements such as citations, general historical context, or references to unrelated technologies were excluded from the question focus. The content is meaningful, coherent, and rich in educational value.\n\nHence, the question will focus on comparing TIMEs and LIFEs in terms of reach and discrimination, and their consequences for multi-muscle activation and neural information capture.\n</document_analysis>\n\n<output_format>\nQuestion: How does the greater reach and spatial discrimination capacity of transverse intrafascicular multichannel electrodes (TIMEs) compared to longitudinal intrafascicular electrodes (LIFEs) enable TIMEs to activate multiple muscles and infer richer neural signals, despite similar selectivity levels?\n\nExplanation: Although TIMEs and LIFEs have comparable selectivity (ability to record from specific nerve locations), TIMEs extend their physical engagement to a larger proportion of the nerve due to their transverse geometry, allowing access to more fascicles. This greater reach increases the volume and diversity of neural signals captured, which enables decoding of signals controlling multiple muscles simultaneously. In contrast, LIFEs, with their longitudinal orientation, interact with fewer fascicles, limiting muscle activation and neural information. Thus, reach and spatial discrimination complement selectivity by broadening the interface's effective neural coverage, resulting in richer motor control capabilities.\n\nCorrect Answer: TIMEs\u2019 transverse geometry provides greater nerve reach and spatial discrimination than LIFEs, allowing access to more fascicles and enabling multi-muscle activation and richer neural signal inference despite similar selectivity.\n</output_format>",
    "question": "How does the greater reach and spatial discrimination capacity of transverse intrafascicular multichannel electrodes (TIMEs) compared to longitudinal intrafascicular electrodes (LIFEs) enable TIMEs to activate multiple muscles and infer richer neural signals, despite similar selectivity levels?",
    "answer": "TIMEs\u2019 transverse geometry provides greater nerve reach and spatial discrimination than LIFEs, allowing access to more fascicles and enabling multi-muscle activation and richer neural signal inference despite similar selectivity.",
    "explanation": "Although TIMEs and LIFEs have comparable selectivity (ability to record from specific nerve locations), TIMEs extend their physical engagement to a larger proportion of the nerve due to their transverse geometry, allowing access to more fascicles. This greater reach increases the volume and diversity of neural signals captured, which enables decoding of signals controlling multiple muscles simultaneously. In contrast, LIFEs, with their longitudinal orientation, interact with fewer fascicles, limiting muscle activation and neural information. Thus, reach and spatial discrimination complement selectivity by broadening the interface's effective neural coverage, resulting in richer motor control capabilities.",
    "question_token_count": 55,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 39
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "Exploration of future directions in prosthetic technology including noninvasive intraneural stimulation, soft neurotechnology, and advanced regenerative peripheral nerve interfaces.",
    "response": "<document_analysis>\nThe provided context discusses the evolution and perspectives in prosthetic technologies, emphasizing the transition from rigid to soft robotic prostheses and highlighting the current maturity levels across various prosthetic components such as interfaces, motor decoding, sensory feedback, and sensorization. Central to this excerpt is the examination of innovative actuation systems and the integration of soft robotic designs that improve adaptability, safety, and sensorization in prostheses.\n\nThe table categorizes technologies by their maturity: from widespread use to future directions. Notably, future directions include noninvasive intraneural stimulation and soft neurotechnology for interfaces, and advanced control utilizing regenerative peripheral nerve interfaces combined with deep learning for motor decoding. These future technologies promise improved biocompatibility, finer neural interfacing, enhanced sensory feedback, and more naturalistic control mechanisms.\n\nImplicitly, the text assumes that soft neurotechnologies and regenerative peripheral nerve interfaces will overcome current limitations in invasiveness, signal resolution, and integration complexity. The mention of ultrasound-based noninvasive intraneural stimulation suggests a paradigm shift towards minimally invasive yet precise neural modulation.\n\nThe question should challenge experts to synthesize knowledge about the benefits, challenges, and implications of these emerging technologies for prosthetic function, integration, and user experience. It should also prompt reflection on how these innovations compare to existing approaches and their potential to revolutionize prosthetic control and sensory feedback.\n\nDifficulty is rated at 9/10 due to the requirement for advanced understanding of neuroprosthetics, neural interface technologies, and emerging soft robotics.\n\nThe question aims to provoke a detailed analysis of the interplay between soft neurotechnology, noninvasive neural stimulation, and regenerative interfaces, focusing on their prospective roles and technical hurdles in future prosthetic systems.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do noninvasive intraneural stimulation, soft neurotechnology, and advanced regenerative peripheral nerve interfaces collectively address the current limitations in prosthetic control and sensory feedback, and what are the major technical challenges that must be overcome to integrate these future directions into functional, portable prosthetic devices?\n\nExplanation: These emerging technologies aim to improve neural interfacing by reducing invasiveness (noninvasive stimulation), enhancing biocompatibility and adaptability (soft neurotechnology), and providing high-resolution, stable neural signals (regenerative peripheral nerve interfaces), thereby enabling more precise motor control and richer sensory feedback; however, integration challenges include miniaturization, reliable long-term implantation, complex signal processing, and ensuring safety and robustness in portable systems.\n\nCorrect Answer: They enable less invasive, more biocompatible, and higher-resolution neural interfacing for improved control and feedback, but face challenges in miniaturization, stable long-term integration, complex decoding, and safety for portable use.\n</output_format>",
    "question": "How do noninvasive intraneural stimulation, soft neurotechnology, and advanced regenerative peripheral nerve interfaces collectively address the current limitations in prosthetic control and sensory feedback, and what are the major technical challenges that must be overcome to integrate these future directions into functional, portable prosthetic devices?",
    "answer": "They enable less invasive, more biocompatible, and higher-resolution neural interfacing for improved control and feedback, but face challenges in miniaturization, stable long-term integration, complex decoding, and safety for portable use.",
    "explanation": "These emerging technologies aim to improve neural interfacing by reducing invasiveness (noninvasive stimulation), enhancing biocompatibility and adaptability (soft neurotechnology), and providing high-resolution, stable neural signals (regenerative peripheral nerve interfaces), thereby enabling more precise motor control and richer sensory feedback; however, integration challenges include miniaturization, reliable long-term implantation, complex signal processing, and ensuring safety and robustness in portable systems.",
    "question_token_count": 58,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 46
  },
  {
    "context": "## 7. CONCLUSION\nMorethan20years ago,remarkable results by a group of French surgeons for hand transplantation (8) had raised hopes for a future where grafting would be the norm and prosthetics eventually obsolete (176). However, not only has this prediction-unfortunately-not yet come to pass, but also the adoption of new RPH technologies has been slower than expected. As such, RPHs are still a field of active research. Significant efforts have been made to reduce their price and weight, improve their aesthetics and anthropomorphism, increase the robustness and accuracy of their motor intention decoding, and provide natural and accurate somatosensory feedback. We have proposed here an outline of possible iterations of RPHs for the next few years and for 5-10 years in the future.\n\nIn our view, there could soon be a broader integration of simple somatosensory feedback using mature implantable techniques, such as cuff electrodes. Motor decoding using machine learning and shared-control algorithms could permit continuous command of single fingers and broader sets of grasps. Ultimately, the next generation of prosthetics could use more advanced soft implantable electrodes, which could enable more sophisticated sensory encoding (proprioception, temperature perception, touch perception, and nociception) and motor decoding using, for example, deep learning techniques. But to reach this goal, the field must tackle significant challenges related to system integration, electronic miniaturization, computational power, surgical procedure, electrode robustness, the robotic hand itself, and the encoding of somatosensory information.\n",
    "topic": "The application of machine learning and shared-control algorithms for motor intention decoding and continuous control of individual fingers and grasp patterns in RPHs.",
    "response": "<document_analysis>\nThe provided context discusses the current status and future outlook of robotic prosthetic hands (RPHs), focusing on advancements in motor intention decoding and somatosensory feedback. It highlights the slow adoption of RPHs despite earlier optimism and outlines recent technological improvements, including the integration of machine learning and shared-control algorithms to enable continuous command of single fingers and a variety of grasp patterns. The text also addresses the potential evolution toward advanced implantable electrodes and sophisticated sensory encoding modalities. The central theme in relation to the question topic is the role of machine learning and shared-control in decoding motor intentions for precise and continuous finger and grasp control, emphasizing the complexity of integration, computational demands, and the need for robustness in hardware and software. The difficulty of the question should be high (8-9) to challenge domain experts on the nuanced implications and technical barriers of employing such algorithms in RPHs. The question should encourage reflection on how machine learning and shared control can overcome limitations of traditional control methods and what challenges remain in practical implementation.\n</document_analysis>\n\n<output_format>\nQuestion: How do machine learning and shared-control algorithms enhance the decoding of motor intention for continuous control of individual fingers and grasp patterns in robotic prosthetic hands, and what are the primary technical challenges that must be overcome to implement these approaches effectively?\n\nExplanation: Machine learning algorithms enable the interpretation of complex neural or muscular signals to predict user intent with higher accuracy and adaptability, allowing continuous and independent control of multiple fingers and diverse grasp patterns. Shared-control algorithms further improve usability by combining autonomous system behaviors with user commands to reduce cognitive load and enhance smoothness of control. However, challenges such as system integration complexity, the need for electronic miniaturization to embed computational power, ensuring electrode robustness for reliable signal acquisition, and effective encoding of somatosensory feedback remain critical barriers to practical implementation.\n\nCorrect Answer: They improve motor intention decoding accuracy and adaptability for continuous, fine-grained finger and grasp control but face challenges in system integration, miniaturization, electrode robustness, computational power, and somatosensory encoding.\n</output_format>",
    "question": "How do machine learning and shared-control algorithms enhance the decoding of motor intention for continuous control of individual fingers and grasp patterns in robotic prosthetic hands, and what are the primary technical challenges that must be overcome to implement these approaches effectively?",
    "answer": "They improve motor intention decoding accuracy and adaptability for continuous, fine-grained finger and grasp control but face challenges in system integration, miniaturization, electrode robustness, computational power, and somatosensory encoding.",
    "explanation": "Machine learning algorithms enable the interpretation of complex neural or muscular signals to predict user intent with higher accuracy and adaptability, allowing continuous and independent control of multiple fingers and diverse grasp patterns. Shared-control algorithms further improve usability by combining autonomous system behaviors with user commands to reduce cognitive load and enhance smoothness of control. However, challenges such as system integration complexity, the need for electronic miniaturization to embed computational power, ensuring electrode robustness for reliable signal acquisition, and effective encoding of somatosensory feedback remain critical barriers to practical implementation.",
    "question_token_count": 47,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 41
  },
  {
    "context": "## Figure 1\nExamples of functioning hand replacement. ( a ) A personalized cosmetic hand solution (ITOP , Italy) provides a natural look. Photos adapted with permission from ITOP and Procosil. ( ) A body-powered prosthetic solution (Ottobock, Germany) is a common approach b for people with an upper-limb amputation. Photo reproduced with permission from Ottobock. ( ) An sEMG-based pattern recognition c system (Gen2, Coapt, USA) allows grasp classification. Photo adapted courtesy of Coapt LLC ( http://www.coaptengineering.com ). ( d ) sEMG control and extracellular stimulation via an implanted FINE were used to convey sensory feedback for home-use applications. The implant was stable for more than five years, and home-use electrical stimulation for sensory feedback was investigated for up to 13 days (116). Panel adapted from Reference 116 (CC BY-SA 4.0). ( ) Fully implanted myoelectric sensors provide stronger e and more reliable signals that do not change with arm positioning, socket rotation, or sweating (107). Panel adapted with permission from Reference 107. ( f ) Six-DOF prosthetic hand control (i-Limb Ultra, \u00d6ssur, Iceland) uses threshold-based sEMG control and cocontraction to switch between grasps. ( g ) Sensory feedback conveyed via intraneural TIMEs enables the encoding of objects' shape and stiffness (6). Panel reproduced with permission; copyright 2014 Lifehand 2 / Patrizia T occi. ( h ) Hand transplantation is a promising technique that has not yet become a standard procedure due to several surgical and clinical difficulties. Panel adapted with permission from Reference 177. Abbreviations: DOF, degree of freedom; FINE, flat interface nerve electrode; sEMG, surface electromyography; TIME, transverse intrafascicular multichannel electrode.\n\nsurvey of below-elbow amputees from Sweden, the United Kingdom, and Canada (7), 53% of the respondents wore a cosmetic prosthesis, 13% used a hook, 4% used a cable hand, and 30% used a myoelectric RPH. Despite encouraging results in the late 1990s (8), hand transplantation ( Figure 1 h ) encountered significant surgical and clinical difficulties (rejection and immunosuppression); it has therefore been tested in only a few patients and is not yet considered one of the available options.\n",
    "topic": "The integration of electrical stimulation for sensory feedback in home-use prosthetic applications and its potential benefits and limitations.",
    "response": "<document_analysis>\nThe context describes multiple types of upper-limb prosthetic hands, highlighting a variety of control and feedback technologies. Among these, it specifically mentions the use of surface electromyography (sEMG) and implanted electrodes like the flat interface nerve electrode (FINE) for both control and sensory feedback. The implanted FINE system conveyed sensory feedback via electrical stimulation and was stable for over five years, with home-use electrical stimulation tested for up to 13 days, suggesting a promising but still limited real-world application. The text implies that electrical stimulation for sensory feedback can enhance prosthetic function by providing tactile information, but the relatively short testing period for home use and the complexity of implantation may indicate challenges such as long-term reliability, user adaptation, or clinical practicality. The context also contrasts this with other methods, such as intraneural TIMEs, which encode object properties, and highlights the ongoing surgical challenges in more invasive approaches like hand transplantation. The question should therefore probe the nuanced benefits and limitations of electrical stimulation for sensory feedback in prosthetics, emphasizing understanding of technical implementation, clinical feasibility, and user experience in home settings.\n\nDifficulty rating: 9/10 - The question demands integration of technical, clinical, and practical knowledge regarding advanced prosthetic sensory feedback systems, requiring expertise in biomedical engineering, neuroprosthetics, and clinical rehabilitation.\n\nThe question will invite reflection on the implications of the technology\u2019s stability, duration of use, and potential impact on prosthetic functionality and user quality of life, encouraging critical evaluation rather than simple factual recall.\n\n</document_analysis>\n\n<output_format>\nQuestion: Considering the use of implanted flat interface nerve electrodes (FINE) for sensory feedback in prosthetic hands, what are the primary benefits and significant limitations of integrating electrical stimulation for sensory feedback in home-use applications, particularly in terms of system stability, duration of effective use, and user experience?\n\nExplanation: Implanted FINE electrodes provide stable, long-term interfaces (over five years) enabling sensory feedback through electrical stimulation, which can enhance user perception and control of prosthetic hands. However, home-use electrical stimulation has only been tested for a limited duration (up to 13 days), indicating potential challenges such as adaptation, long-term reliability of stimulation, and practical issues related to implantation and daily use, which limit widespread clinical adoption and sustained user benefit.\n\nCorrect Answer: Long-term implant stability enables reliable sensory feedback, but limited home-use testing duration and challenges in sustained electrical stimulation restrict practical and clinical applicability.\n</output_format>",
    "question": "Considering the use of implanted flat interface nerve electrodes (FINE) for sensory feedback in prosthetic hands, what are the primary benefits and significant limitations of integrating electrical stimulation for sensory feedback in home-use applications, particularly in terms of system stability, duration of effective use, and user experience?",
    "answer": "Long-term implant stability enables reliable sensory feedback, but limited home-use testing duration and challenges in sustained electrical stimulation restrict practical and clinical applicability.",
    "explanation": "Implanted FINE electrodes provide stable, long-term interfaces (over five years) enabling sensory feedback through electrical stimulation, which can enhance user perception and control of prosthetic hands. However, home-use electrical stimulation has only been tested for a limited duration (up to 13 days), indicating potential challenges such as adaptation, long-term reliability of stimulation, and practical issues related to implantation and daily use, which limit widespread clinical adoption and sustained user benefit.",
    "question_token_count": 58,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 28
  },
  {
    "context": "## 4.3. Decoding Motor Intention via Implanted Electrodes\nSurface electrodes cannot precisely record the signal from deep muscles; to overcome this issue, several groups have focused on iEMG electrodes. This technique is more invasive but allows one to record EMG signals (51) uncorrelated from the underlying musculature and avoids the daily placement of electrodes. iEMG is robust against electrode shift (e.g., socket rotation) and change in skin impedance and sweat. Several studies have demonstrated the performance of simultaneous wrist and hand motions (three DOFs) using six to eight iEMG electrodes; Smith &amp; Hargrove (51) showed that iEMG has better decoding performance than sEMG. High decoding performance is reported in real time (106), and in fully implanted setups, the results are stable for several days (107).\n\nOnthe other hand, Farrell &amp; Weir (52) compared the pattern recognition-based grasp classification performance of iEMG and sEMG on 12 movement classes with eight channels and did not find a statistical difference between electrode types. They concluded that the choice of electrode should be based not on classification accuracy but rather on signal consistency over time and robustness to electrode lift-off. Zia ur Rehman et al. (108) compared a standard linear discriminant analysis with a deep network for grasp classification. They performed a multiday analysis comparing six iEMG and six sEMG electrodes, and their results showed that deep learning had better decoding performance and was more stable over time.\n\nKamavuako et al. (109) investigated the effect of combining iEMG to target deep muscles with sEMG on myoelectric control. They showed that the combined solution improved offline and real-time control performance compared with sEMG alone.\n\nWith 32 iEMG electrodes, Dantas et al. (110) compared different decoding methods for the continuous control of five DOFs corresponding to the flexion and extension of each digit. Using a data set aggregation algorithm, they showed a normalized mean squared error as low as 0.033 with a deep convolutional neural network. They also investigated signal stability for 150 days after training, showing a small degradation during the first month (0.003 normalized mean squared error per day with a convolutional neural network), but that degradation stopped in the next four months.\n\nFor transradial amputees, an alternative to using EMG signals to control hand prostheses is decoding from peripheral nerve signals. Different grasp types can be decoded from peripheral nerve signals with high accuracy using different interfaces, both offline and in real time (54, 111113). Implanted peripheral nerve recordings are more invasive than sEMG but are more stable over time. Indeed, donning and doffing the prosthesis does not move these electrodes as much as it does sEMG electrodes. Recently, Cracchiolo et al. (53) decoded up to 11 class states using TIMEs on an amputee subject and showed that the active sites chosen on the first day could also be used in the following sessions, for up to seven days (80% accuracy, compared with 83% by selecting active sites every session). However, this modality is generally used to provide sensory\n\nfeedback (64, 114-116). Therefore the development of new approaches to record neural signals during peripheral stimulation [e.g., artifact removal (117)] is necessary.\n\nVu et al. (39) recently developed a regenerative peripheral nerve interface to increase signal specificity and long-term stability. They implanted transected peripheral nerves into a free muscle graft. After regeneration, revascularization, and reinnervation, the graft becomes a nerve bioamplifier that creates EMG signals. Using chronically implanted iEMG to record from these grafts, they performed five-class decoding in real time with up to 98.2% accuracy with two transradial amputees in a virtual hand environment. They also showed results from a Box and Block T est using an RPH that provided continuous control of two DOFs of thumb motions through their interface combined with a third DOF based on sEMG.\n",
    "topic": "Advances in decoding accuracy and control paradigms demonstrated in recent studies involving fully implanted setups and real-time prosthetic hand control.",
    "response": "<document_analysis>\nThe context discusses advanced techniques for decoding motor intention via implanted electrodes, focusing on intramuscular electromyography (iEMG) and peripheral nerve recordings as alternatives or complements to surface EMG (sEMG). Key points include the improved signal stability and robustness of iEMG and implanted peripheral nerve interfaces compared to sEMG, especially for real-time control of prosthetic hands with multiple degrees of freedom (DOFs). Several studies demonstrate that deep learning methods significantly enhance decoding accuracy and stability over time, including multiday and multi-month analyses. Notably, fully implanted setups achieve stable and high-accuracy decoding for several days to months, enabling continuous control of complex hand motions. The regenerative peripheral nerve interface approach further advances signal specificity and long-term stability by bioamplifying nerve signals through muscle grafts, achieving near 98% accuracy in real-time control tasks. The context also highlights the importance of combining iEMG with sEMG to improve control performance and the ongoing challenges of neural signal recording during sensory feedback stimulation.\n\nThis content is highly technical and relevant, with a strong focus on recent breakthroughs in decoding accuracy and control paradigms for prosthetic hands using implanted electrodes and sophisticated machine learning algorithms. It provides rich material for a complex question probing deep understanding of the technological, methodological, and physiological advances in this domain.\n\nDifficulty rating: 9/10, as the content requires integration of knowledge about neurophysiology, signal processing, machine learning, and prosthetic control systems.\n\nThe question will be designed to challenge experts to synthesize insights about how fully implanted setups and novel interfaces impact decoding accuracy and real-time prosthetic control, including the role of deep learning and interface design.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do fully implanted intramuscular and peripheral nerve electrode systems, combined with advanced decoding algorithms such as deep convolutional neural networks, improve the accuracy, stability, and multi-DOF control of prosthetic hands in real-time applications compared to traditional surface EMG methods, and what are the physiological and technical factors underlying these improvements?\n\nExplanation: Fully implanted intramuscular and peripheral nerve electrodes provide more stable and specific neural signals than surface EMG, as they avoid issues like electrode shift, skin impedance variability, and sweat interference. This stability allows consistent signal acquisition over days to months, supporting continuous multi-DOF control of prosthetic hands. Deep learning algorithms, especially convolutional neural networks, exploit the rich and stable implanted signals to decode complex hand motions with high accuracy and low error rates, outperforming traditional linear methods. Physiologically, implanted electrodes access deep muscle or nerve signals with higher selectivity and less noise. Technically, implant stability and reduced artifact susceptibility enhance long-term decoding reliability. Together, these factors enable real-time prosthetic control with multiple degrees of freedom and improved user experience beyond what is possible with surface EMG.\n\nCorrect Answer: They provide stable, specific neural signals less affected by external factors, enabling deep learning algorithms to decode multi-DOF prosthetic hand motions with higher accuracy and long-term stability in real time.\n</output_format>",
    "question": "How do fully implanted intramuscular and peripheral nerve electrode systems, combined with advanced decoding algorithms such as deep convolutional neural networks, improve the accuracy, stability, and multi-DOF control of prosthetic hands in real-time applications compared to traditional surface EMG methods, and what are the physiological and technical factors underlying these improvements?",
    "answer": "They provide stable, specific neural signals less affected by external factors, enabling deep learning algorithms to decode multi-DOF prosthetic hand motions with higher accuracy and long-term stability in real time.",
    "explanation": "Fully implanted intramuscular and peripheral nerve electrodes provide more stable and specific neural signals than surface EMG, as they avoid issues like electrode shift, skin impedance variability, and sweat interference. This stability allows consistent signal acquisition over days to months, supporting continuous multi-DOF control of prosthetic hands. Deep learning algorithms, especially convolutional neural networks, exploit the rich and stable implanted signals to decode complex hand motions with high accuracy and low error rates, outperforming traditional linear methods. Physiologically, implanted electrodes access deep muscle or nerve signals with higher selectivity and less noise. Technically, implant stability and reduced artifact susceptibility enhance long-term decoding reliability. Together, these factors enable real-time prosthetic control with multiple degrees of freedom and improved user experience beyond what is possible with surface EMG.",
    "question_token_count": 65,
    "answer_correctness_score": 9,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 38
  },
  {
    "context": "## Figure 3\nExamples of available assessment tools. ( a ) The standardized test equipment for the Box and Block T est includes a box with two compartments separated by a barrier and 150 2.5-cm colored blocks. The subject is asked to transfer as many blocks as possible from one compartment to the other in one minute. Panel adapted with permission from Accsim Instrumentos. ( ) The Clothespin Relocation b Test measures hand function (reaching, grasping, and wrist rotation). The measurement consists of the time it takes for the subject to move three clothespins from a horizontal to a vertical bar and then back (see, e.g., 184). Panel adapted with permission from Reference 184. ( ) The Action Research Arm T est standard box is commercially available and contains different objects to assess grasp, grip pinch, c and gross movement functions. Panel reproduced with permission from Rehab Solutions. ( d ) The Virtual Egg T est is a variation of the Box and Block T est where blocks are replaced by breakable objects. In this example, the plastic cubes have a magnetic fuse that breaks if the grasping force exceeds a certain threshold. Panel adapted with permission from Reference 129. ( ) An audio-tactile interaction task e has been used to measure the brain representation of the peripersonal space (the brain's presentation of the space immediately around the body) (175). The test consists of a looming sound (perceived as coming from far away and moving toward the amputated hand) and a vibrator placed on the subject's stump that is triggered when the sound is perceived to be at different distances from the subject (D1 to D5). The position where the presence of the sound facilitates the perception of the vibrator (reaction time) is used as a proxy for the peripersonal space limit ( dashed line ).\n\nThese evaluations are used in rehabilitation and have been clinically validated ( Table 3 ). Most of them were developed for neurological impairments (such as a stroke), multiple sclerosis, or spinal cord injuries and have been adapted for the evaluation of RPHs. While these wellestablished evaluations are essential, detailed investigation of RPHs-mainly when integrating sensory feedback capabilities-implies specific challenges that have been addressed in a series of tests introduced in recent years. These tests, although not yet clinically validated, are, in our opinion, of great interest.\n\nThe Grasping Relative Index of Performance measures the ability to control the desired force during grasping (139) independently from the control and feedback modalities. This measurement is based on the well-known Fitts' law, which states that the difficulty of a reaching task is given by the log of the ratio between the distance to the target and its size; in other words, the farther away and smaller a target is, the harder it is to reach it. Thumser et al. (162) argued that grasping is similar to pointing with the thumb and finger toward selected positions and defined the index of difficulty for grasping as the ratio of the object's weight to its hardness (where grasping a fragile object is analogous to reaching a small target). Other assessments have been proposed to estimate object stiffness (139) and size discrimination (6); Risso et al. (163) investigated the contribution of vision, tactile feedback via intraneural stimulation, and visuo-tactile integration to estimate the size of a handheld object.\n\nThe magnetic table task (164) and the Virtual Egg T est (129) ( Figure 3 d ) are variations of the Box and Block T est in which the blocks are replaced by magnetic cubes and breakable objects, respectively. Both have been used to evaluate the efficacy of different sensory encoding strategies (see 136 for the magnetic table task and 62 for the Virtual Egg T est). Finally, Prosthesis Efficiency and Profitability is an ad hoc measurement for prosthetics with sensory feedback to assess searching, reaching, grasping, manipulating, and decision-making during a foraging task (139).\n\nUse of cognitive load during a sensorimotor task can give an indirect evaluation of the intuitiveness of a task: Do patients need to give their full attention to a particular movement, or are they able to perform it as part of a dual task? Subjects might be asked, for example, to perform a task while counting backward, finding words that start with a given letter, or visually following a moving target on a screen (for an example with a Virtual Egg T est, see 63). More direct measurement of the cognitive burden via electroencephalographic event-related potentials during human-machine interactions has also been proposed (165). Here, the subject must perform a specific task (the primary task) while detecting an auditory stimulus (the secondary task), and the amplitude of the event-related potentials in response to the auditory stimulus then indicates the amount of dedicated attention to the secondary and primary tasks. Simply put, a small response to the auditory cue suggests more extensive attention to the primary task (166) and therefore a greater cognitive load.\n\nThe prolonged use of prosthetic limbs can reverse some of the effects of post-traumatic maladaptive plasticity, one of the most debilitating of which is phantom limb pain, a condition present in the majority of subjects with amputation (167). Phantom limb pain has a complex etiology that can be elicited by a multitude of factors, including nociceptive (neuroma hyperactivity), neuropathic (cortical reorganization), or psychogenic mechanisms. Numerous studies have shown that the use of prosthetics with sensory feedback significantly reduces phantom limb pain for upperlimb (38, 112, 114) and lower-limb (166) amputees. T ypical measurements of pain are the McGill Pain Questionnaire (168), the Neuropathic Pain Symptom Inventory (169), and the Visual Analog Pain intensity scale, but it can also be measured with the DASH assessment (146) and the physical domain of the WHOQOL test.\n\nLongitudinal experiments with amputee patients have demonstrated changes in body schema representation and embodiment of the prosthetic when tactile (62, 170) or proprioceptive (171) feedback is provided to the subject. A questionnaire-based measurement inspired by the rubber hand illusion (172) is often used. T ools for psychometrical measurement of the embodiment include a visuo-tactile integration task (173) and a cross-modal congruency task (174). A similar protocol using audio-tactile stimuli (175) revealed changes of the peripersonal space around the stump following prolonged use of a prosthetic limb ( Figure 3 e ). In the same study, the authors used a tactile distance perception task in subjects' healthy and amputated arms to measure the perceived length of the remaining part of the upper limb and the homologous region of the healthy limb.\n\nEtiology: the cause, set of causes, or manner of causation of a disease or condition\n\nThere is no single measurement that assesses all aspects of the use of an RPH. T o evaluate the validity of novel technology, the experimenter should consider the multifaceted aspects of the impairment and subjects' biopsychosocial welfare, which is possible only via a series of tools, as presented in this section. In the case of prosthetics with sensory feedback, there is a lack of validated and well-established measurements, but several research groups are working to define adapted measurements, which might become the new norm in the future.\n",
    "topic": "The design, purpose, and clinical application of standardized motor function tests such as the Box and Block Test, Clothespin Relocation Test, and Action Research Arm Test in evaluating prosthetic hand function.",
    "response": "<document_analysis>\nThe context provides an in-depth description of various standardized motor function tests used to evaluate hand and arm function, especially in neurological impairments and prosthetic hand (RPH) users. The Box and Block Test, Clothespin Relocation Test, and Action Research Arm Test are described with their design features and specific functional assessments. The Box and Block Test evaluates gross manual dexterity by moving blocks between compartments; the Clothespin Relocation Test measures hand function involving reaching, grasping, and wrist rotation by timing the transfer of clothespins; and the Action Research Arm Test assesses multiple grasp and movement functions with different objects. The tests have been clinically validated and adapted for prosthetic evaluations, though challenges remain for tests integrating sensory feedback. The context also discusses related variations and the multidimensional nature of assessment, emphasizing no single test fully captures all aspects of prosthetic use. Additionally, it touches on the cognitive load aspect and the importance of sensory feedback in embodiment and pain reduction, highlighting the complexity of functional assessment beyond mere motor performance.\n\nThe question should probe the understanding of how these tests are designed to isolate and measure specific motor functions, their clinical validation status, and how their characteristics make them suitable or limited for evaluating prosthetic hand function. It should challenge experts to integrate knowledge of test structure, functional domains assessed, clinical adaptation, and implications for prosthetics evaluation. The question difficulty is high (8/10) given the need for integrating practical test design, clinical application, and prosthetic-specific considerations.\n\nThis question will encourage reflection on how classical motor function tests translate to prosthetic assessment contexts and the nuanced interpretation of their outcomes in a clinical setting.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the design features and functional focus of the Box and Block Test, Clothespin Relocation Test, and Action Research Arm Test respectively enable the standardized assessment of prosthetic hand function, and what are the implications of their clinical validation status for their application in evaluating prosthetic sensory feedback integration?\n\nExplanation: The Box and Block Test, with its simple task of transferring blocks, primarily measures gross manual dexterity and speed, making it suitable for quantifying basic hand function in prosthetic users. The Clothespin Relocation Test focuses on finer motor skills involving reaching, grasping, and wrist rotation, providing timed measures of dexterous hand movements critical for prosthetic control. The Action Research Arm Test assesses a broader range of grasp, grip, pinch, and gross movements using various objects, offering a comprehensive evaluation of arm and hand function. All three tests are clinically validated and widely used, ensuring reliable and standardized assessment outcomes. However, while they effectively measure motor capabilities, their limitations in evaluating sensory feedback integration in prosthetics imply the need for supplementary or adapted tests. The absence of clinical validation for newer sensory feedback-specific assessments means these standardized tests remain foundational but insufficient alone for assessing advanced prosthetic functions involving sensory modalities.\n\nCorrect Answer: Their specific designs isolate gross dexterity (Box and Block), fine motor and wrist rotation (Clothespin Relocation), and comprehensive grasp and movement functions (Action Research Arm), enabling standardized, clinically validated assessment of motor prosthetic function; however, their limited focus on sensory feedback integration necessitates additional or adapted tests for evaluating sensory-enabled prosthetics.\n</output_format>",
    "question": "How do the design features and functional focus of the Box and Block Test, Clothespin Relocation Test, and Action Research Arm Test respectively enable the standardized assessment of prosthetic hand function, and what are the implications of their clinical validation status for their application in evaluating prosthetic sensory feedback integration?",
    "answer": "Their specific designs isolate gross dexterity (Box and Block), fine motor and wrist rotation (Clothespin Relocation), and comprehensive grasp and movement functions (Action Research Arm), enabling standardized, clinically validated assessment of motor prosthetic function; however, their limited focus on sensory feedback integration necessitates additional or adapted tests for evaluating sensory-enabled prosthetics.",
    "explanation": "The Box and Block Test, with its simple task of transferring blocks, primarily measures gross manual dexterity and speed, making it suitable for quantifying basic hand function in prosthetic users. The Clothespin Relocation Test focuses on finer motor skills involving reaching, grasping, and wrist rotation, providing timed measures of dexterous hand movements critical for prosthetic control. The Action Research Arm Test assesses a broader range of grasp, grip, pinch, and gross movements using various objects, offering a comprehensive evaluation of arm and hand function. All three tests are clinically validated and widely used, ensuring reliable and standardized assessment outcomes. However, while they effectively measure motor capabilities, their limitations in evaluating sensory feedback integration in prosthetics imply the need for supplementary or adapted tests. The absence of clinical validation for newer sensory feedback-specific assessments means these standardized tests remain foundational but insufficient alone for assessing advanced prosthetic functions involving sensory modalities.",
    "question_token_count": 61,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 71
  },
  {
    "context": "## 5.1. Sensors for Proprioception\nProprioception is not only fundamental for a dexterous hand prosthesis, enabling vision-free manipulation and multitasking, but is also the key to a properly embodied device (64). Usually, kinematic parameters of the robotic hand and (when available) the force exerted are needed to implement low-level control of the actuators, so they are measured with well-established systems, such as rotary encoders or the motor's current draw.\n\n\n## 5.2. Tactile Sensors\nDespite improvements in sensor miniaturization,computational power,and knowledge of the neurophysiology of somatosensation (tactile sensation and proprioception), the capabilities of sensorized RPHs remain far from those of a natural hand. Overcoming this limitation will require satisfying three conditions: The sensors must match the skin's sensing ability, a sufficient number of sensors must be embedded on the surface of the hand, and it must be possible to reliably read information from them. The first condition can be addressed with current technology, as the resolution of existing force and pressure sensors already matches human skin performance (120). However, fulfilling the second and third conditions is another matter, and we need to push the boundaries of circuit integration in order to create an RPH with many sensors and a way to communicate with them.\n\nThe classical solution of using general-purpose sensors developed separately from the signal conditioning circuit and the subsequent signal processing has shown its limit. Instead, efforts are being made to optimize these devices with prosthetics in mind. For example, borrowing the concept of morphological computation from robotics (121), sensors can be optimized for specific tasks by tuning the features of their mechanical structures accordingly. Indeed, exploiting the low-pass filtering effect of a compliant material or surfaces with specific structures can increase texture discrimination (61, 115). Another example comes from Kim et al. (122), who measured forces using sensors embedded in a soft substrate.\n\n)\n\nContinued\n\n(\n\n| Sensor distribution a                       |            |             |             |             |                  |              |                 |              |\n\n|---------------------------------------------|------------|-------------|-------------|-------------|------------------|--------------|-----------------|--------------|\n\n| Interface                                   | G10 tactor | TIME        | TENS        | TIME        | FINE             | TIME         | Vibrators       | TENS         |\n\n| Electrical stimulation encoding Pulse width | -          | Fixed       | Linear      | Fixed       | Time variant     | Fixed        | -               | Neuromorphic |\n\n| Amplitude                                   | -          | Linear      | Fixed       | Model based | Fixed            | Fixed        | -               | Fixed        |\n\n| Frequency                                   | -          | Fixed       | Fixed       | Model based | Linear           | Neuromorphic | -               | Neuromorphic |\n\n| Mechanical stimulation encoding             | Linear     | -           | -           | -           | -                | -            | Discrete events | -            |\n\n| RPH model                                   | Passive    | IH2 Azzurra | IH2 Azzurra | IH2 Azzurra | SensorHand Speed | IH2 Azzurra  | Various         | bebionic     |\n\n| Reference                                   | 4          | 6           | 60          | 62          | 38               | 61           | 129             | 59           |\n\n| Year                                        | 2011       | 2014        | 2017        | 2018        | 2014             | 2016         | 2016            | 2018         |\n",
    "topic": "The design and functional implications of embedding sensors in soft substrates within prosthetic hands, as exemplified by recent research.",
    "response": "<document_analysis>\nThe context discusses the state of sensors used in robotic prosthetic hands (RPHs) for proprioception and tactile sensing. It highlights the challenges and advancements in replicating the sensory capabilities of a natural human hand. Specifically, it points out that while current sensor resolutions can match human skin, embedding enough sensors and reliably reading their signals remains problematic. The text introduces the concept of morphological computation, where sensors are mechanically optimized for tasks by exploiting material properties, such as compliant surfaces that provide low-pass filtering to enhance texture discrimination. A notable example is the work by Kim et al., who embedded force sensors in a soft substrate, implying advantages in sensor integration and function.\n\nThe detailed table listing various prosthetic hand models and their stimulation encoding methods hints at diverse approaches but does not elaborate on the specific effects of embedding sensors in soft substrates.\n\nThe question should probe deep technical understanding of how embedding sensors in soft materials affects prosthetic hand function and design, including mechanical and signal processing implications. This requires insight into sensor integration challenges, morphological computation benefits, and the impact on tactile feedback fidelity and proprioceptive control.\n\nDifficulty is rated 9/10 due to the need for expert-level knowledge of biomechanics, sensor technology, and neuroprosthetics.\n\nThe question aims to prompt critical thinking about the multi-dimensional implications (mechanical, electrical, computational) of embedding sensors in soft substrates, going beyond superficial understanding.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does embedding tactile sensors within a soft substrate, as in recent prosthetic hand designs, enhance texture discrimination and sensor integration, and what are the key mechanical and signal-processing implications of this approach for replicating natural somatosensory feedback?\n\nExplanation: Embedding sensors in soft substrates allows the mechanical properties of the compliant material to perform morphological computation, such as low-pass filtering, which enhances texture discrimination by smoothing high-frequency noise and emphasizing relevant tactile features. This integration improves sensor distribution density and signal reliability by physically coupling sensors and substrate, facilitating more naturalistic force measurements. However, it also imposes mechanical constraints requiring sensor tuning to substrate deformation and demands advanced signal-processing techniques to decode signals influenced by substrate compliance, which collectively contribute to a more biomimetic somatosensory feedback system in prosthetic hands.\n\nCorrect Answer: It leverages substrate compliance for morphological computation to enhance texture discrimination and sensor integration but requires mechanical tuning and advanced signal processing to replicate natural somatosensory feedback.\n</output_format>",
    "question": "How does embedding tactile sensors within a soft substrate, as in recent prosthetic hand designs, enhance texture discrimination and sensor integration, and what are the key mechanical and signal-processing implications of this approach for replicating natural somatosensory feedback?",
    "answer": "It leverages substrate compliance for morphological computation to enhance texture discrimination and sensor integration but requires mechanical tuning and advanced signal processing to replicate natural somatosensory feedback.",
    "explanation": "Embedding sensors in soft substrates allows the mechanical properties of the compliant material to perform morphological computation, such as low-pass filtering, which enhances texture discrimination by smoothing high-frequency noise and emphasizing relevant tactile features. This integration improves sensor distribution density and signal reliability by physically coupling sensors and substrate, facilitating more naturalistic force measurements. However, it also imposes mechanical constraints requiring sensor tuning to substrate deformation and demands advanced signal-processing techniques to decode signals influenced by substrate compliance, which collectively contribute to a more biomimetic somatosensory feedback system in prosthetic hands.",
    "question_token_count": 48,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 31
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "Functional outcomes and benefits of bilateral hand transplantation and their implications for prosthetic research.",
    "response": "<document_analysis>\nThe context is a list of references from scientific literature primarily focused on prosthetic limb research, sensory feedback integration, pain management in amputees, and related neural engineering topics. Within this list, reference 177 specifically addresses bilateral hand transplantation, reporting on functional benefits in five patients with long-term follow-up. This particular study provides a unique clinical insight into the functional outcomes of bilateral hand transplantation, which is a rare and complex surgical intervention.\n\nThe broader context covers prosthetic control, sensory feedback, embodiment, and neural integration, which are highly relevant to the field of prosthetic research. The bilateral hand transplantation study's functional outcomes can offer critical comparative insights into prosthetic technologies, particularly regarding restoration of function, sensory integration, and patient quality of life.\n\nThe question will focus on the functional benefits reported in bilateral hand transplantation and explore the implications of these outcomes for advancing prosthetic research. This invites a deep reflection on how clinical transplantation outcomes inform the design, goals, and evaluation of advanced prosthetic devices, especially in terms of restoring motor function and sensory feedback. The question is complex, requiring an expert-level understanding of both surgical transplantation and prosthetic technology development.\n\nDifficulty rating: 9/10 \u2013 The question demands synthesis of clinical functional outcomes and translational implications for prosthetic research, engaging high-level expertise.\n\nThe question is designed to provoke critical thinking about how bilateral hand transplantation successes and limitations can guide future prosthetic innovations, including sensory feedback integration and motor control improvements.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the functional benefits observed in patients undergoing bilateral hand transplantation inform and influence the development and evaluation of advanced prosthetic technologies, particularly in terms of restoring motor function and sensory feedback?\n\nExplanation: Bilateral hand transplantation provides a unique clinical model demonstrating the potential for restoring natural motor and sensory function through biological integration, offering benchmarks for prosthetic devices. Understanding the functional benefits and limitations of transplantation helps prosthetic research target improvements in motor control, sensory feedback, and embodiment to better replicate natural limb function.\n\nCorrect Answer: They provide clinical benchmarks of natural motor and sensory restoration that guide prosthetic research toward improving motor control, sensory feedback integration, and embodiment to replicate biological limb function.\n</output_format>",
    "question": "How do the functional benefits observed in patients undergoing bilateral hand transplantation inform and influence the development and evaluation of advanced prosthetic technologies, particularly in terms of restoring motor function and sensory feedback?",
    "answer": "They provide clinical benchmarks of natural motor and sensory restoration that guide prosthetic research toward improving motor control, sensory feedback integration, and embodiment to replicate biological limb function.",
    "explanation": "Bilateral hand transplantation provides a unique clinical model demonstrating the potential for restoring natural motor and sensory function through biological integration, offering benchmarks for prosthetic devices. Understanding the functional benefits and limitations of transplantation helps prosthetic research target improvements in motor control, sensory feedback, and embodiment to better replicate natural limb function.",
    "question_token_count": 37,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 33
  },
  {
    "context": "## Figure 3\nExamples of available assessment tools. ( a ) The standardized test equipment for the Box and Block T est includes a box with two compartments separated by a barrier and 150 2.5-cm colored blocks. The subject is asked to transfer as many blocks as possible from one compartment to the other in one minute. Panel adapted with permission from Accsim Instrumentos. ( ) The Clothespin Relocation b Test measures hand function (reaching, grasping, and wrist rotation). The measurement consists of the time it takes for the subject to move three clothespins from a horizontal to a vertical bar and then back (see, e.g., 184). Panel adapted with permission from Reference 184. ( ) The Action Research Arm T est standard box is commercially available and contains different objects to assess grasp, grip pinch, c and gross movement functions. Panel reproduced with permission from Rehab Solutions. ( d ) The Virtual Egg T est is a variation of the Box and Block T est where blocks are replaced by breakable objects. In this example, the plastic cubes have a magnetic fuse that breaks if the grasping force exceeds a certain threshold. Panel adapted with permission from Reference 129. ( ) An audio-tactile interaction task e has been used to measure the brain representation of the peripersonal space (the brain's presentation of the space immediately around the body) (175). The test consists of a looming sound (perceived as coming from far away and moving toward the amputated hand) and a vibrator placed on the subject's stump that is triggered when the sound is perceived to be at different distances from the subject (D1 to D5). The position where the presence of the sound facilitates the perception of the vibrator (reaction time) is used as a proxy for the peripersonal space limit ( dashed line ).\n\nThese evaluations are used in rehabilitation and have been clinically validated ( Table 3 ). Most of them were developed for neurological impairments (such as a stroke), multiple sclerosis, or spinal cord injuries and have been adapted for the evaluation of RPHs. While these wellestablished evaluations are essential, detailed investigation of RPHs-mainly when integrating sensory feedback capabilities-implies specific challenges that have been addressed in a series of tests introduced in recent years. These tests, although not yet clinically validated, are, in our opinion, of great interest.\n\nThe Grasping Relative Index of Performance measures the ability to control the desired force during grasping (139) independently from the control and feedback modalities. This measurement is based on the well-known Fitts' law, which states that the difficulty of a reaching task is given by the log of the ratio between the distance to the target and its size; in other words, the farther away and smaller a target is, the harder it is to reach it. Thumser et al. (162) argued that grasping is similar to pointing with the thumb and finger toward selected positions and defined the index of difficulty for grasping as the ratio of the object's weight to its hardness (where grasping a fragile object is analogous to reaching a small target). Other assessments have been proposed to estimate object stiffness (139) and size discrimination (6); Risso et al. (163) investigated the contribution of vision, tactile feedback via intraneural stimulation, and visuo-tactile integration to estimate the size of a handheld object.\n\nThe magnetic table task (164) and the Virtual Egg T est (129) ( Figure 3 d ) are variations of the Box and Block T est in which the blocks are replaced by magnetic cubes and breakable objects, respectively. Both have been used to evaluate the efficacy of different sensory encoding strategies (see 136 for the magnetic table task and 62 for the Virtual Egg T est). Finally, Prosthesis Efficiency and Profitability is an ad hoc measurement for prosthetics with sensory feedback to assess searching, reaching, grasping, manipulating, and decision-making during a foraging task (139).\n\nUse of cognitive load during a sensorimotor task can give an indirect evaluation of the intuitiveness of a task: Do patients need to give their full attention to a particular movement, or are they able to perform it as part of a dual task? Subjects might be asked, for example, to perform a task while counting backward, finding words that start with a given letter, or visually following a moving target on a screen (for an example with a Virtual Egg T est, see 63). More direct measurement of the cognitive burden via electroencephalographic event-related potentials during human-machine interactions has also been proposed (165). Here, the subject must perform a specific task (the primary task) while detecting an auditory stimulus (the secondary task), and the amplitude of the event-related potentials in response to the auditory stimulus then indicates the amount of dedicated attention to the secondary and primary tasks. Simply put, a small response to the auditory cue suggests more extensive attention to the primary task (166) and therefore a greater cognitive load.\n\nThe prolonged use of prosthetic limbs can reverse some of the effects of post-traumatic maladaptive plasticity, one of the most debilitating of which is phantom limb pain, a condition present in the majority of subjects with amputation (167). Phantom limb pain has a complex etiology that can be elicited by a multitude of factors, including nociceptive (neuroma hyperactivity), neuropathic (cortical reorganization), or psychogenic mechanisms. Numerous studies have shown that the use of prosthetics with sensory feedback significantly reduces phantom limb pain for upperlimb (38, 112, 114) and lower-limb (166) amputees. T ypical measurements of pain are the McGill Pain Questionnaire (168), the Neuropathic Pain Symptom Inventory (169), and the Visual Analog Pain intensity scale, but it can also be measured with the DASH assessment (146) and the physical domain of the WHOQOL test.\n\nLongitudinal experiments with amputee patients have demonstrated changes in body schema representation and embodiment of the prosthetic when tactile (62, 170) or proprioceptive (171) feedback is provided to the subject. A questionnaire-based measurement inspired by the rubber hand illusion (172) is often used. T ools for psychometrical measurement of the embodiment include a visuo-tactile integration task (173) and a cross-modal congruency task (174). A similar protocol using audio-tactile stimuli (175) revealed changes of the peripersonal space around the stump following prolonged use of a prosthetic limb ( Figure 3 e ). In the same study, the authors used a tactile distance perception task in subjects' healthy and amputated arms to measure the perceived length of the remaining part of the upper limb and the homologous region of the healthy limb.\n\nEtiology: the cause, set of causes, or manner of causation of a disease or condition\n\nThere is no single measurement that assesses all aspects of the use of an RPH. T o evaluate the validity of novel technology, the experimenter should consider the multifaceted aspects of the impairment and subjects' biopsychosocial welfare, which is possible only via a series of tools, as presented in this section. In the case of prosthetics with sensory feedback, there is a lack of validated and well-established measurements, but several research groups are working to define adapted measurements, which might become the new norm in the future.\n",
    "topic": "The role of longitudinal studies in understanding the neuroplastic and psychosocial effects of prolonged prosthesis use with sensory feedback on user adaptation and functional outcomes.",
    "response": "<document_analysis>\nThe context provides a comprehensive overview of various assessment tools used to evaluate prosthetic hand function (RPHs), including standard clinical tests and novel sensory-feedback-specific evaluations. It highlights the complexity of measuring prosthetic use, particularly when sensory feedback is involved, noting that traditional tools are insufficient to capture all aspects of user experience and adaptation. Importantly, the text underscores findings from longitudinal studies with amputee patients showing changes in body schema representation, embodiment of the prosthetic limb, and peripersonal space alterations when tactile or proprioceptive feedback is provided. These studies link neuroplastic changes (e.g., cortical reorganization) and psychosocial effects (e.g., reduction of phantom limb pain) to prolonged prosthesis use with sensory feedback. Additionally, the text discusses how sensory feedback contributes to reducing phantom limb pain, a condition with complex etiology involving maladaptive plasticity. However, it also points out that no single measurement captures all these effects, emphasizing the need for multifaceted and longitudinal evaluations to assess biopsychosocial welfare and functional outcomes comprehensively.\n\nThe implicit assumption is that prolonged use of sensory-feedback-enabled prosthetics induces beneficial neuroplastic and psychosocial adaptations that improve functional integration and user well-being. The longitudinal approach is critical because neuroplastic changes and embodiment evolve over time, and cross-sectional snapshots may fail to capture these dynamics. This also has implications for developing validated, clinically meaningful outcome measures that encompass cognitive, sensory, motor, and psychological domains.\n\nDifficulty rating: 9/10. The question requires integration of neuroplasticity concepts, sensory feedback mechanisms, psychosocial adaptation, and the methodological importance of longitudinal research design, making it highly challenging even for experts.\n\nThe planned question encourages reflection on why longitudinal studies are indispensable for understanding the complex interplay between brain plasticity, embodiment, pain reduction, and functional improvements in prosthetic users with sensory feedback, thus probing deep conceptual and applied knowledge in neurorehabilitation and prosthetics research.\n</document_analysis>\n\n<output_format>\nQuestion: How do longitudinal studies uniquely contribute to elucidating the neuroplastic and psychosocial mechanisms underlying improved embodiment, reduced phantom limb pain, and functional adaptation in users of prosthetic limbs with sensory feedback, compared to cross-sectional assessments?\n\nExplanation: Longitudinal studies track changes over time, capturing the dynamic processes of cortical reorganization, body schema updates, and psychosocial adaptation that occur with prolonged prosthesis use; these processes are critical for understanding how sensory feedback facilitates embodiment and pain reduction, insights that cross-sectional studies cannot provide due to their static nature.\n\nCorrect Answer: By monitoring temporal neuroplastic and psychosocial changes, longitudinal studies reveal how sustained sensory feedback fosters embodiment, reduces phantom limb pain, and improves functional adaptation beyond what cross-sectional snapshots can show.\n</output_format>",
    "question": "How do longitudinal studies uniquely contribute to elucidating the neuroplastic and psychosocial mechanisms underlying improved embodiment, reduced phantom limb pain, and functional adaptation in users of prosthetic limbs with sensory feedback, compared to cross-sectional assessments?",
    "answer": "By monitoring temporal neuroplastic and psychosocial changes, longitudinal studies reveal how sustained sensory feedback fosters embodiment, reduces phantom limb pain, and improves functional adaptation beyond what cross-sectional snapshots can show.",
    "explanation": "Longitudinal studies track changes over time, capturing the dynamic processes of cortical reorganization, body schema updates, and psychosocial adaptation that occur with prolonged prosthesis use; these processes are critical for understanding how sensory feedback facilitates embodiment and pain reduction, insights that cross-sectional studies cannot provide due to their static nature.",
    "question_token_count": 44,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 37
  },
  {
    "context": "## Table 2 ( Continued )\n| Sensor distribution a                       |                |                              |             |                  |\n\n|---------------------------------------------|----------------|------------------------------|-------------|------------------|\n\n| Interface                                   | FINE           | Utah Slanted Electrode Array | TIME        | Cuff electrode   |\n\n| Electrical stimulation encoding Pulse width | Fixed          | Fixed                        | Linear      | Fixed            |\n\n| Amplitude                                   | Fixed          | Fixed                        | Fixed       | Fixed            |\n\n| Frequency                                   | Linear         | Model based                  | Fixed       | Linear           |\n\n| Mechanical stimulation encoding             | -              | -                            | -           | -                |\n\n| RPH model                                   | VariPlus Speed | DEKA Luke                    | IH2 Azzurra | SensorHand Speed |\n\n| Reference                                   | 136            | 139                          | 64          | 138              |\n\n| Year                                        | 2018           | 2019                         | 2019        | 2020             |\n\nAbbreviations: FINE, flat interface nerve electrode; RPH, robotic prosthetic hand; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. a The positions of the pressure sensors are shown in green, the joints where force is measured are shown with solid red lines, and the joints where the position is read are shown with dashed blue lines.\n",
    "topic": "Strategies for encoding electrical stimulation in prosthetic devices, including fixed, linear, and model-based approaches, and their implications for control fidelity and user experience.",
    "response": "<document_analysis>\nThe context provides a comparative overview of different prosthetic hand systems focusing on their sensor distribution, types of electrodes used, and encoding strategies for electrical stimulation. Specifically, it highlights variations in pulse width, amplitude, and frequency modulation approaches\u2014fixed, linear, and model-based\u2014in four different prosthetic interfaces (FINE, Utah Slanted Electrode Array, TIME, and Cuff electrode). The subtle differences in encoding strategies imply varying levels of control fidelity and potential user experience outcomes. For example, fixed encoding may limit adaptability, linear encoding allows modulation in a proportional manner, and model-based encoding suggests the use of computational models to optimize stimulation parameters dynamically. The mention of different years and references indicates the evolution of these strategies. The question should probe the implications of these encoding strategies on prosthetic control fidelity and user experience, requiring deep expertise in neural interface technologies and neuroprosthetic control systems. Difficulty is rated 9/10 due to the need for understanding neuroengineering principles and their practical impact on prosthetic function.\n</document_analysis>\n\n<output_format>\nQuestion: How do fixed, linear, and model-based electrical stimulation encoding strategies differ in their impact on control fidelity and user experience in prosthetic hand interfaces, and what are the potential advantages and limitations of each approach?\n\nExplanation: Fixed encoding uses constant parameters, limiting adaptability but simplifying control; linear encoding modulates parameters proportionally, improving responsiveness; model-based encoding applies computational models for dynamic adjustment, potentially enhancing precision and naturalness but increasing complexity.\n\nCorrect Answer: Fixed encoding offers simplicity but limited adaptability; linear encoding improves proportional control and responsiveness; model-based encoding enables dynamic, precise stimulation tailored to user needs, enhancing control fidelity and user experience but requires complex implementation.\n</output_format>",
    "question": "How do fixed, linear, and model-based electrical stimulation encoding strategies differ in their impact on control fidelity and user experience in prosthetic hand interfaces, and what are the potential advantages and limitations of each approach?",
    "answer": "Fixed encoding offers simplicity but limited adaptability; linear encoding improves proportional control and responsiveness; model-based encoding enables dynamic, precise stimulation tailored to user needs, enhancing control fidelity and user experience but requires complex implementation.",
    "explanation": "Fixed encoding uses constant parameters, limiting adaptability but simplifying control; linear encoding modulates parameters proportionally, improving responsiveness; model-based encoding applies computational models for dynamic adjustment, potentially enhancing precision and naturalness but increasing complexity.",
    "question_token_count": 42,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 2,
    "avg_answer_token_count": 41
  },
  {
    "context": "## 3.2. Perspectives\nThe challenges for future interfaces that can provide the necessary read/write bandwidth to use RPHs in a natural fashion are immense. We argue that the motor and sensory domains raise different problems. Indeed, the stimulation being close to the target is mandatory with current technologies, and therefore the best solutions are the most invasive ones. In the motor domain, it is possible to decompose the signal if we have enough sources (even noninvasive sources, as with sEMG). As shown in Section 4, machine learning techniques can help infer information from noninvasive interfaces.\n\nOn the sensory level, the currently implantable electrodes are the most promising solution. However, the main advancement so far has been for the tactile modality, while the use of other modalities for proprioception has been obtained via a nonhomologous approach based on intraneural stimulation combined with the delivery of homologous tactile feedback via indirectly targeted intraneural electrical stimulation (64).\n\nTemperature sensation is another limit. T emperature is mediated through A \u03b4 fibers (for cold) and C fibers (for warmth). Given the very small size of these fibers (C fibers are 20-100 times smaller than A \u03b2 fibers), it is not possible to target them using existing state-of-the-art electrodes (42). Future electrodes with even higher levels of selectivity might be able to target A \u03b4 and C fibers. Sensory remapping (65) can be another viable solution to simulate temperature feedback on a different part of the body using a temperature display.\n",
    "topic": "Current technological constraints in targeting temperature-sensitive nerve fibers and the implications for restoring thermal sensation in prosthetic users.",
    "response": "<document_analysis>\nThe context discusses the challenges of providing natural sensory feedback in prosthetic devices, emphasizing the differences between motor and sensory domains. It highlights that current implantable electrodes effectively target tactile sensations but face significant limitations in restoring temperature sensation due to the small size of temperature-sensitive nerve fibers (A \u03b4 and C fibers). These fibers are much smaller than those currently targetable (A \u03b2 fibers), making direct stimulation with existing electrode technology unfeasible. The text also mentions the potential future advancement of electrodes with higher selectivity and alternative strategies like sensory remapping to simulate temperature feedback on different body areas. The content is rich in technical detail about nerve fiber types, electrode limitations, and prosthetic sensory restoration strategies, suitable for probing deep expert knowledge.\n\nDifficulty rating: 9/10. The question should require understanding of nerve fiber physiology, electrode technology constraints, and compensatory strategies for sensory feedback in prosthetics.\n\nThe question planned aims to probe the expert\u2019s grasp of the physiological and technical barriers to temperature sensation restoration, as well as the implications for prosthetic design and future research directions. It encourages reflection on the interplay between nerve fiber anatomy and electrode engineering, and the necessity of innovative solutions beyond direct stimulation.\n\nThis will foster deep engagement with the nuanced challenges of sensory neuroprosthetics, focusing on temperature feedback, a less addressed but critical sensory modality.\n\n</document_analysis>\n\n<output_format>\nQuestion: Why do current electrode technologies fail to restore thermal sensation in prosthetic users, and what are the potential strategies to overcome these limitations?\n\nExplanation: Current electrodes cannot target temperature-sensitive A \u03b4 and C fibers because these fibers are significantly smaller than the A \u03b2 fibers that existing electrodes can stimulate; thus, direct stimulation of temperature fibers is unfeasible. To overcome this, future electrodes with higher selectivity might target these small fibers, or alternative approaches such as sensory remapping can simulate temperature feedback on different body parts.\n\nCorrect Answer: Because temperature-sensitive A \u03b4 and C fibers are too small to be targeted by existing electrodes, restoration requires either more selective electrodes or sensory remapping techniques.\n</output_format>",
    "question": "Why do current electrode technologies fail to restore thermal sensation in prosthetic users, and what are the potential strategies to overcome these limitations?",
    "answer": "Because temperature-sensitive A \u03b4 and C fibers are too small to be targeted by existing electrodes, restoration requires either more selective electrodes or sensory remapping techniques.",
    "explanation": "Current electrodes cannot target temperature-sensitive A \u03b4 and C fibers because these fibers are significantly smaller than the A \u03b2 fibers that existing electrodes can stimulate; thus, direct stimulation of temperature fibers is unfeasible. To overcome this, future electrodes with higher selectivity might target these small fibers, or alternative approaches such as sensory remapping can simulate temperature feedback on different body parts.",
    "question_token_count": 27,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 31
  },
  {
    "context": "## Table 2 ( Continued )\n| Sensor distribution a                       |                |                              |             |                  |\n\n|---------------------------------------------|----------------|------------------------------|-------------|------------------|\n\n| Interface                                   | FINE           | Utah Slanted Electrode Array | TIME        | Cuff electrode   |\n\n| Electrical stimulation encoding Pulse width | Fixed          | Fixed                        | Linear      | Fixed            |\n\n| Amplitude                                   | Fixed          | Fixed                        | Fixed       | Fixed            |\n\n| Frequency                                   | Linear         | Model based                  | Fixed       | Linear           |\n\n| Mechanical stimulation encoding             | -              | -                            | -           | -                |\n\n| RPH model                                   | VariPlus Speed | DEKA Luke                    | IH2 Azzurra | SensorHand Speed |\n\n| Reference                                   | 136            | 139                          | 64          | 138              |\n\n| Year                                        | 2018           | 2019                         | 2019        | 2020             |\n\nAbbreviations: FINE, flat interface nerve electrode; RPH, robotic prosthetic hand; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. a The positions of the pressure sensors are shown in green, the joints where force is measured are shown with solid red lines, and the joints where the position is read are shown with dashed blue lines.\n",
    "topic": "Analysis of the relationship between the type of electrode interface and the choice of stimulation encoding strategy in different robotic prosthetic hand models.",
    "response": "<document_analysis>\nThe provided table excerpt compares sensor distribution and electrical stimulation encoding parameters across different electrode interfaces used in robotic prosthetic hands (RPH). The interfaces listed are FINE, Utah Slanted Electrode Array, TIME, and Cuff electrode. For each interface, the table specifies how electrical stimulation parameters\u2014pulse width, amplitude, and frequency\u2014are encoded (e.g., fixed, linear, or model-based). The table also associates each interface with a specific prosthetic hand model and gives reference years. Notably, pulse width and amplitude are mostly fixed across interfaces except for frequency, which varies in encoding method: linear for FINE and Cuff, model-based for Utah Slanted Electrode Array, and fixed for TIME. This reveals a nuanced relationship where the choice of electrode interface influences the stimulation encoding strategy, particularly frequency modulation, possibly reflecting differences in electrode design, selectivity, and control requirements. The information invites deep analysis of how electrode design constraints and capabilities shape encoding methods in neuroprosthetic control systems.\n\nDifficulty is rated 9/10 because the question requires integration of neuroengineering principles, understanding electrode interfaces, stimulation encoding strategies, and their implications for prosthetic function. The question encourages reflection on why certain encoding strategies align with specific electrode types, fostering expert-level insight into interface design and control strategy co-optimization.\n\nThe question is purposeful in encouraging synthesis of knowledge about electrode-neural interaction, signal encoding, and prosthetic control systems, promoting critical engagement with the design trade-offs and functional outcomes in advanced neuroprosthetics.\n\nNo irrelevant or bogus content is present; all data are coherent and meaningful.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the differences in electrode interface design among FINE, Utah Slanted Electrode Array, TIME, and Cuff electrodes influence the choice of electrical stimulation frequency encoding strategies in robotic prosthetic hands, and what might be the underlying neurophysiological rationale for these encoding variations?\n\nExplanation: The frequency encoding strategy varies with electrode type: FINE and Cuff electrodes use linear frequency modulation, Utah Slanted Electrode Array employs model-based frequency encoding, and TIME uses fixed frequency. This reflects the electrode's spatial selectivity and interface complexity; for example, the Utah array\u2019s higher selectivity and channel count allow more sophisticated, model-based modulation to mimic natural neural firing patterns, whereas simpler interfaces favor linear or fixed frequency due to limited selectivity and control channels. These choices optimize neural activation patterns to achieve effective sensory feedback and motor control tailored to each interface\u2019s characteristics.\n\nCorrect Answer: Electrode design complexity and selectivity dictate frequency encoding strategies, with more selective interfaces like Utah Array enabling model-based frequency encoding to better mimic natural neural activity, while simpler interfaces use linear or fixed frequency modulation to suit their limited spatial resolution and control capabilities.\n</output_format>",
    "question": "How do the differences in electrode interface design among FINE, Utah Slanted Electrode Array, TIME, and Cuff electrodes influence the choice of electrical stimulation frequency encoding strategies in robotic prosthetic hands, and what might be the underlying neurophysiological rationale for these encoding variations?",
    "answer": "Electrode design complexity and selectivity dictate frequency encoding strategies, with more selective interfaces like Utah Array enabling model-based frequency encoding to better mimic natural neural activity, while simpler interfaces use linear or fixed frequency modulation to suit their limited spatial resolution and control capabilities.",
    "explanation": "The frequency encoding strategy varies with electrode type: FINE and Cuff electrodes use linear frequency modulation, Utah Slanted Electrode Array employs model-based frequency encoding, and TIME uses fixed frequency. This reflects the electrode's spatial selectivity and interface complexity; for example, the Utah array\u2019s higher selectivity and channel count allow more sophisticated, model-based modulation to mimic natural neural firing patterns, whereas simpler interfaces favor linear or fixed frequency due to limited selectivity and control channels. These choices optimize neural activation patterns to achieve effective sensory feedback and motor control tailored to each interface\u2019s characteristics.",
    "question_token_count": 56,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 50
  },
  {
    "context": "## 4.3. Decoding Motor Intention via Implanted Electrodes\nSurface electrodes cannot precisely record the signal from deep muscles; to overcome this issue, several groups have focused on iEMG electrodes. This technique is more invasive but allows one to record EMG signals (51) uncorrelated from the underlying musculature and avoids the daily placement of electrodes. iEMG is robust against electrode shift (e.g., socket rotation) and change in skin impedance and sweat. Several studies have demonstrated the performance of simultaneous wrist and hand motions (three DOFs) using six to eight iEMG electrodes; Smith &amp; Hargrove (51) showed that iEMG has better decoding performance than sEMG. High decoding performance is reported in real time (106), and in fully implanted setups, the results are stable for several days (107).\n\nOnthe other hand, Farrell &amp; Weir (52) compared the pattern recognition-based grasp classification performance of iEMG and sEMG on 12 movement classes with eight channels and did not find a statistical difference between electrode types. They concluded that the choice of electrode should be based not on classification accuracy but rather on signal consistency over time and robustness to electrode lift-off. Zia ur Rehman et al. (108) compared a standard linear discriminant analysis with a deep network for grasp classification. They performed a multiday analysis comparing six iEMG and six sEMG electrodes, and their results showed that deep learning had better decoding performance and was more stable over time.\n\nKamavuako et al. (109) investigated the effect of combining iEMG to target deep muscles with sEMG on myoelectric control. They showed that the combined solution improved offline and real-time control performance compared with sEMG alone.\n\nWith 32 iEMG electrodes, Dantas et al. (110) compared different decoding methods for the continuous control of five DOFs corresponding to the flexion and extension of each digit. Using a data set aggregation algorithm, they showed a normalized mean squared error as low as 0.033 with a deep convolutional neural network. They also investigated signal stability for 150 days after training, showing a small degradation during the first month (0.003 normalized mean squared error per day with a convolutional neural network), but that degradation stopped in the next four months.\n\nFor transradial amputees, an alternative to using EMG signals to control hand prostheses is decoding from peripheral nerve signals. Different grasp types can be decoded from peripheral nerve signals with high accuracy using different interfaces, both offline and in real time (54, 111113). Implanted peripheral nerve recordings are more invasive than sEMG but are more stable over time. Indeed, donning and doffing the prosthesis does not move these electrodes as much as it does sEMG electrodes. Recently, Cracchiolo et al. (53) decoded up to 11 class states using TIMEs on an amputee subject and showed that the active sites chosen on the first day could also be used in the following sessions, for up to seven days (80% accuracy, compared with 83% by selecting active sites every session). However, this modality is generally used to provide sensory\n\nfeedback (64, 114-116). Therefore the development of new approaches to record neural signals during peripheral stimulation [e.g., artifact removal (117)] is necessary.\n\nVu et al. (39) recently developed a regenerative peripheral nerve interface to increase signal specificity and long-term stability. They implanted transected peripheral nerves into a free muscle graft. After regeneration, revascularization, and reinnervation, the graft becomes a nerve bioamplifier that creates EMG signals. Using chronically implanted iEMG to record from these grafts, they performed five-class decoding in real time with up to 98.2% accuracy with two transradial amputees in a virtual hand environment. They also showed results from a Box and Block T est using an RPH that provided continuous control of two DOFs of thumb motions through their interface combined with a third DOF based on sEMG.\n",
    "topic": "Interpretation of multi-degree-of-freedom control (e.g., wrist, hand, and individual digit movements) using implanted electrodes and the decoding algorithms enabling such fine motor control.",
    "response": "<document_analysis>\nThe context discusses the use of implanted electromyography (iEMG) electrodes for decoding motor intentions with a focus on multi-degree-of-freedom (DOF) control, including wrist, hand, and individual digit movements. It highlights that iEMG electrodes provide more precise and stable signals than surface EMG (sEMG), especially for deep muscles, and are robust against factors like electrode shift and skin impedance changes. The context also examines comparative studies between iEMG and sEMG, noting that while classification accuracy may be similar, iEMG offers greater signal consistency and stability over time. Advances in decoding algorithms, especially deep learning techniques like convolutional neural networks, have significantly improved decoding accuracy and stability over extended periods (e.g., 150 days). Combined use of iEMG and sEMG can further enhance control performance.\n\nFurthermore, the text references peripheral nerve interfaces and regenerative nerve interfaces that allow decoding of multiple grasp types or digit motions with high accuracy. These interfaces, while more invasive, provide stable long-term recordings and can be combined with implanted muscle grafts acting as bioamplifiers to yield highly specific EMG signals for complex control tasks.\n\nThe central ideas involve the technical challenges and solutions in achieving high-fidelity decoding of multiple DOFs for prosthetic control using implanted electrodes, the comparative advantages of iEMG over sEMG, and the role of advanced machine learning algorithms in translating these signals into fine motor commands.\n\nDifficulty rating: 9/10 - The question must probe understanding of both the neurophysiological basis of implanted electrode recordings and the algorithmic approaches enabling multi-DOF control, requiring integration of hardware, signal processing, and machine learning knowledge.\n\nThe question should encourage reflection on the interplay between electrode implantation depth, signal stability, algorithm choice, and practical prosthetic control outcomes, fostering a deep conceptual and applied understanding.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do implanted electromyography (iEMG) electrodes enable more precise multi-degree-of-freedom motor intention decoding compared to surface EMG, and what role do advanced machine learning algorithms play in maintaining high accuracy and signal stability over extended periods for controlling individual digit and wrist movements?\n\nExplanation: Implanted EMG electrodes record signals directly from deep muscles, avoiding issues like electrode shift, skin impedance variability, and crosstalk inherent to surface EMG, thus providing cleaner, more consistent signals essential for decoding multiple degrees of freedom. Advanced machine learning algorithms, particularly deep convolutional neural networks, leverage these high-quality signals to achieve low decoding errors and maintain performance stability over months by effectively modeling complex, nonlinear relationships in the data and compensating for subtle signal degradation, enabling precise real-time control of individual digits and wrist motions.\n\nCorrect Answer: iEMG electrodes record stable, specific deep muscle signals less affected by external factors, and deep learning algorithms decode these signals with high accuracy and temporal stability, enabling precise multi-DOF control.\n</output_format>",
    "question": "How do implanted electromyography (iEMG) electrodes enable more precise multi-degree-of-freedom motor intention decoding compared to surface EMG, and what role do advanced machine learning algorithms play in maintaining high accuracy and signal stability over extended periods for controlling individual digit and wrist movements?",
    "answer": "iEMG electrodes record stable, specific deep muscle signals less affected by external factors, and deep learning algorithms decode these signals with high accuracy and temporal stability, enabling precise multi-DOF control.",
    "explanation": "Implanted EMG electrodes record signals directly from deep muscles, avoiding issues like electrode shift, skin impedance variability, and crosstalk inherent to surface EMG, thus providing cleaner, more consistent signals essential for decoding multiple degrees of freedom. Advanced machine learning algorithms, particularly deep convolutional neural networks, leverage these high-quality signals to achieve low decoding errors and maintain performance stability over months by effectively modeling complex, nonlinear relationships in the data and compensating for subtle signal degradation, enabling precise real-time control of individual digits and wrist motions.",
    "question_token_count": 57,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 39
  },
  {
    "context": "## 2.1. Existing Robotic Prosthetic Hands\nNumerous commercially available RPH solutions use underactuated mechanisms ( Supplemental Table 1 ), including the Michelangelo prosthetic hand (Ottobock, Germany), the i-Limb Ultra (\u00d6ssur, Iceland), the bebionic hand (Ottobock), and the VINCENT evolution 3 (Vincent Systems, Germany). Despite remarkable advances, there is still arguably a trade-off between dexterity and weight in these solutions, with companies usually emphasizing one aspect or the other.\n\nMany research groups are currently working on innovative solutions to tackle the dexterity/ weight dilemma (19), such as the use of a monolithic 3D-printed soft material (20) or mechanical solutions to implement finger synergies via clutches (21). For example, Jing et al. (19) proposed an anthropomorphic RPH using only three motors that could achieve 13 grasp types while weighing only approximately 130 g.\n\nThe price of RPHs is an additional limiting factor for broader adoption by patients. With most advanced solutions costing $10,000-20,000, many researchers advocate for cheaper solutions, particularly for emerging countries (e.g., 22).\n\nOpen source RPHs are an exciting alternative to dramatically reduce the cost of development and distribution. One particularly interesting aspect of such hands is simplified maintenance and repairs (using, e.g., 3D printing) that do not rely on specific suppliers. For example, Open\n\nBionics (United Kingdom) commercializes solutions for transradial amputees (e.g., the medically certified Hero Arm) but also provides the source files for some of their designs, and e-NABLE ( https://enablingthefuture.org ) reports 8,000 recipients of their prosthetics, which were built by volunteers around the world. Open source RPHs also enable users to alter the design to meet their unique needs; for example, the Galileo Hand (23) allows easy customization of the types of movements and number of electromyography (EMG) electrodes.\n\nResearchers are also working on better mechanical solutions to improve RPH dexterity. An underactuated hand prosthesis designed by Abayasiri et al. (24) has finger abduction and adduction to enable it to grasp larger objects, and an adaptive prosthetic hand designed by Yong et al. (25) adds DOFs in the palm with movable metacarpals. The Karlsruhe Institute of T echnology (KIT) prosthetic hand (26) has an embedded camera and real-time object recognition, enabling the hand to be preshaped. Pneumatic artificial muscle (27) permits the development of light, compact solutions. Finally, biomimetic actuation is used for muscle-like actuators (15).\n\nIn addition to the hardware aspect, there are also innovations in RPH control and sensorization. Low-level controllers use information about the state of the device and eventually activate the actuation to meet the desired state imposed by the user's intentions. The choice of the state variable has a strong influence on how the device works. Position or speed can be read through encoders of each joint and controlled; these are straightforward approaches that have been used broadly in robotic applications. When the interaction of the hand with the external environment is of interest, more advanced control systems are implemented, such as torque or impedance control. Both approaches measure the force applied by the actuator, controlling it directly in the first case and simulating compliance in the second. Advanced control strategies enable complex manipulation and smoother gestures at the expense of a bulkier mechanical structure and a more complex control system. Therefore, enabling more sophisticated control requires integrated force and position sensors, which have been previously developed mainly to close the robotic control loop (28).\n\nIn summary, low-cost and light hands have flourished over the last few years. The race to simplify designs and reduce costs through 3D printing should not impact the dexterity of RPHs. For now, underactuated mechanisms are the best solution for RPHs and innovative designs based on synergy mechanisms or friction, the latter of which can help increase the number of DOAs without increasing the number of motors.\n",
    "topic": "Describe the integration of sensor technologies (position, force, impedance sensors) in robotic prosthetic hands and their impact on control strategies and manipulation capabilities.",
    "response": "<document_analysis>\nThe context provides an in-depth overview of current robotic prosthetic hands (RPHs), focusing particularly on mechanical designs, cost factors, and control and sensor technologies. It highlights the use of underactuated mechanisms as a prevailing solution balancing dexterity and weight. Importantly, it discusses sensor integration\u2014position encoders for joint angles or speed, force sensors for torque control, and impedance control to simulate compliance\u2014emphasizing how these sensor inputs influence low-level control strategies. The passage elaborates on how more advanced control strategies that incorporate these sensors enable smoother and more complex manipulation but require more complex hardware and software, increasing mechanical bulk and system complexity. This nuanced relationship between sensor technology and control sophistication, along with the resulting trade-offs, is central to the content. \n\nImplicitly, the integration of sensors is critical for closing the control loop, allowing the prosthetic hand to adapt to environmental interactions rather than simply executing predefined motions. This implies a significant impact on the dexterity and functional capabilities of RPHs. The text also references biomimetic actuation and pneumatic artificial muscles, which may interface with sensor feedback for refined control, though this is less detailed.\n\nDifficulty is rated as 9 because understanding sensor integration\u2019s role in control loops for prosthetic hands requires deep knowledge of robotics, control theory, sensor technologies, and prosthetic design trade-offs.\n\nThe question aims to provoke expert reflection on how different sensor types are employed, their influence on control strategy choices (position, torque, impedance), and how these affect manipulation abilities and mechanical design constraints. It also encourages consideration of the broader implications for dexterity and system complexity.\n\nThis question is highly suitable for domain experts, requiring synthesis of sensor technology and control strategy knowledge contextualized to prosthetic hands.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the integration of position, force, and impedance sensors in robotic prosthetic hands influence the choice of control strategies, and what are the resulting implications for manipulation capabilities and mechanical design complexity?\n\nExplanation: Position sensors provide straightforward joint angle or speed feedback, enabling simple control schemes; force sensors allow torque control for direct force regulation; impedance sensors enable simulation of compliance for adaptive interaction with the environment. Incorporating force and impedance sensing supports advanced control strategies that facilitate complex, smooth manipulation but necessitate bulkier hardware and more complex control systems, representing a trade-off between dexterity and device complexity.\n\nCorrect Answer: Sensor integration enables advanced control strategies (position, torque, impedance control) that enhance manipulation capabilities but increase mechanical and control system complexity.\n</output_format>",
    "question": "How do the integration of position, force, and impedance sensors in robotic prosthetic hands influence the choice of control strategies, and what are the resulting implications for manipulation capabilities and mechanical design complexity?",
    "answer": "Sensor integration enables advanced control strategies (position, torque, impedance control) that enhance manipulation capabilities but increase mechanical and control system complexity.",
    "explanation": "Position sensors provide straightforward joint angle or speed feedback, enabling simple control schemes; force sensors allow torque control for direct force regulation; impedance sensors enable simulation of compliance for adaptive interaction with the environment. Incorporating force and impedance sensing supports advanced control strategies that facilitate complex, smooth manipulation but necessitate bulkier hardware and more complex control systems, representing a trade-off between dexterity and device complexity.",
    "question_token_count": 39,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 27
  },
  {
    "context": "## 2. ROBOTIC HANDS\nFollowing a limb amputation, three solutions are generally considered: passive cosmetic limbs ( Figure 1 a ); mechanical hands, often with hooks ( Figure 1 b ); and RPHs ( Figure 1 c-g ). In a\n\n\n## SKIN MECHANORECEPTORS\nThe skin has four types of mechanoreceptors, which are sensitive to different stimuli and therefore involved in different sensory functions: Merkel disks (which sense skin indentation, fine touch, and texture perception), Ruffini capsules (which sense skin stretch), Pacinian corpuscles (which sense vibration), and Meissner corpuscles (which sense dynamic deformation and slipperiness). Merkel disks and Ruffini capsules are slow-adapting receptors, meaning that they fire continuously during tactile stimuli, with a firing rate related to the pressure applied in their receptive field. Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond mostly to changes in applied pressure or brief stimuli.\n\na\n\nd\n\nPercutaneous leads\n\nFINE\n\nAgonist/antagonist myoelectric control\n\nSingle-DOF\n\nprosthetic hand\n\nAperture sensor\n\nExternal\n\nPressure sensors stimulator\n\nh\n",
    "topic": "Detailed physiological characteristics and functional roles of the four types of skin mechanoreceptors\u2014Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles\u2014in tactile sensory perception.",
    "response": "<document_analysis>\nThe context provides a concise but rich overview of the four types of skin mechanoreceptors: Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles. It details their distinct physiological response properties (slow-adapting vs. fast-adapting) and the specific tactile stimuli they detect (pressure, skin stretch, vibration, dynamic deformation, texture, and slipperiness). The text also links these receptors to different sensory functions such as fine touch, texture perception, and vibration detection, highlighting their complementary roles in tactile sensory perception. \n\nThe information is technical and specialized, targeting knowledge of neurophysiology and somatosensory systems. It requires understanding receptor adaptation rates, stimulus modalities, and how these properties integrate into perception. The context is sufficiently rich for constructing a challenging, domain-expert-level question probing the nuanced distinctions and implications of receptor function for sensory coding.\n\nDifficulty rating: 8/10. The question can deeply probe the expert\u2019s understanding of mechanoreceptor physiology, functional specialization, and implications for tactile perception.\n\nThe question should encourage critical comparison among the receptors, the significance of adaptation rates, and how each contributes uniquely to the tactile sensory experience, beyond mere factual recall.\n\nNo irrelevant or bogus information is present; the content is coherent and educationally valuable.\n\nTherefore, a highly technical and reflective question on the physiological characteristics and roles of these mechanoreceptors in tactile perception is justified and appropriate.\n</document_analysis>\n\n<output_format>\nQuestion: How do the differences in adaptation rates and stimulus sensitivities among Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles collectively enable the skin to encode complex tactile information such as texture, vibration, and dynamic deformation?\n\nExplanation: Merkel disks and Ruffini capsules are slow-adapting receptors that provide continuous information about sustained pressure and skin stretch, essential for perceiving static features like texture and shape; Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond primarily to changes and brief stimuli such as vibration and dynamic skin deformation, enabling detection of transient events like slip or vibration. This complementary division of labor allows the skin to encode both steady-state and dynamic tactile stimuli, providing a rich and nuanced sensory experience.\n\nCorrect Answer: Slow-adapting Merkel disks and Ruffini capsules encode sustained pressure and stretch for texture and shape perception, while fast-adapting Pacinian and Meissner corpuscles detect dynamic changes like vibration and slip, together enabling complex tactile encoding.\n</output_format>",
    "question": "How do the differences in adaptation rates and stimulus sensitivities among Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles collectively enable the skin to encode complex tactile information such as texture, vibration, and dynamic deformation?",
    "answer": "Slow-adapting Merkel disks and Ruffini capsules encode sustained pressure and stretch for texture and shape perception, while fast-adapting Pacinian and Meissner corpuscles detect dynamic changes like vibration and slip, together enabling complex tactile encoding.",
    "explanation": "Merkel disks and Ruffini capsules are slow-adapting receptors that provide continuous information about sustained pressure and skin stretch, essential for perceiving static features like texture and shape; Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond primarily to changes and brief stimuli such as vibration and dynamic skin deformation, enabling detection of transient events like slip or vibration. This complementary division of labor allows the skin to encode both steady-state and dynamic tactile stimuli, providing a rich and nuanced sensory experience.",
    "question_token_count": 49,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 49
  },
  {
    "context": "## 5.5. Perspectives\nWe believe that sensorization will play a significant role in the next generation of RPHs. Here, we discuss three main directions influenced by sensorization: embedded sensorization, improved stimulation strategies, and new computational architectures.\n\n5.5.1. Embedded sensorization. Sensorized hands are not yet prevalent in the literature but are starting to draw interest, especially with the improvement of interfaces for bidirectional prostheses (for a list of RPHs with sensorized fingertips, see Supplemental Tables 1 and 2 ). As a recent example, Controzzi et al. (141) developed the Mia hand (Prensilia, Italy), which is integrated with sensors that can measure normal and tangential forces at the fingertips. Sensorization of RPHs is a design requirement that should be considered as important as other functional requirements for hand prostheses, such as weight or dexterity. T o improve RPH performance and sensor integration, next-generation RPHs should then be designed with their sensorization in mind. Information about hand state (joint position, forces, and touch) can also be beneficial to increase the dexterity of such hands, enabling automatic adjustments such as catching slipping objects (e.g., the bebionic3 hand) and shared-control strategies (see Section 4).\n\n5.5.2. Improved stimulation strategies. Biomimicry is one of the strongest trends in nerve stimulation strategies, as it promises to deliver biologically plausible stimulation patterns to evoke more natural sensations. Biomimetic approaches rely on bio-inspired models to compute the stimulation patterns, so new iterations of these models, based on the current experience in stimulation and neural recording, are needed to improve the quality of elicited sensations.\n\nThese model-based approaches permit simpler modulation strategies that increase the naturalness of sensations. T an et al. (38), for example, proved that a sinusoidal modulation of the pulse width improves the naturalness of the sensation. Formento et al. (142) instead designed a strategy to activate asynchronously stimulated fibers, mimicking healthy neural activity; in their work, they replaced classical biphasic stimulation with a high-frequency burst of pulses that slowly increased in amplitude, and confirmed their hypothesis in ex vivo experiments. Stimulation patterns that try to overcome the physical limits of present neural interfaces (as in 142) while paving the way for more natural evoked sensations also suggest the requirements for the future generation of neural interfaces and stimulators for sensory feedback: increase reaching without losing discrimination.\n\n5.5.3. New computational architectures. Neuromorphic architectures have the potential to represent a paradigm shift in the design of the control systems for bidirectional hand prostheses, going toward distributed systems and edge computing. Both sensor acquisition and stimulation can benefit from these trends because they lead to more reliable systems that scale well with the increase of sensors and stimulation active sites. If the next generation of neuromorphic hardware promotes portability and lower power consumption, it could lead to broader implementation and adoption of neuromorphic systems in bidirectional hand prostheses.\n\nMany RPHs rely on advanced encoding and decoding algorithms implemented with neural networks (62), which are more computationally demanding than traditional approaches. It is interesting that even deep learning networks can be translated into spiking neural networks (143), possibly enabling full neuromorphic hardware encoding and decoding in future prostheses.\n",
    "topic": "The significance of model-based approaches in modulating nerve stimulation to improve sensation naturalness and discrimination in prosthetic sensory feedback.",
    "response": "<document_analysis>\nThe context discusses future perspectives in robotic prosthetic hands (RPHs), focusing on three main directions: embedded sensorization, improved stimulation strategies, and new computational architectures. The section on improved stimulation strategies highlights biomimicry and model-based approaches as key to delivering more natural sensations via nerve stimulation. It gives examples of how model-based modulation (e.g., sinusoidal pulse width modulation, asynchronous activation of fibers) improves the naturalness of evoked sensations. These approaches simplify modulation and help overcome physical limitations of neural interfaces, aiming to enhance sensory feedback by increasing sensation quality without losing discrimination. This reflects a nuanced understanding of how computational and physiological modeling can impact the design of stimulation patterns to evoke biologically plausible and discriminable sensations. The content is highly technical, discussing neural stimulation paradigms, biomimetic modeling, and implications for neural interface design. This supports generating a challenging question about the role, significance, and implications of model-based stimulation approaches for naturalness and discrimination in prosthetic sensory feedback.\n\nDifficulty rating: 9/10 due to the need for deep understanding of neural stimulation, biomimicry, and prosthetic sensory feedback systems.\n\nThe question should invite critical reflection on why model-based approaches are key to improving naturalness and discrimination, how they overcome current interface limitations, and implications for future prosthetic design.\n\nThis topic is meaningful, coherent, and educationally valuable, suitable for domain experts.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do model-based, biomimetic nerve stimulation strategies enhance both the naturalness and discrimination of sensory feedback in prosthetic hands, and what implications do these approaches have for overcoming current limitations of neural interfaces?\n\nExplanation: Model-based biomimetic stimulation strategies use bio-inspired computational models to generate nerve stimulation patterns that mimic natural neural activity, such as asynchronous fiber activation or sinusoidal pulse width modulation. These approaches improve the naturalness of sensations by producing stimulation patterns closer to healthy neural firing, making the feedback feel more biologically plausible. Additionally, by carefully modulating stimulation parameters, they can increase sensory discrimination without losing resolution, addressing a key challenge of current neural interfaces that struggle to balance reaching (stimulating many fibers) with maintaining sensation specificity. Consequently, these strategies suggest requirements for future neural interfaces to support more complex, naturalistic stimulation patterns, ultimately enabling prosthetics with richer, more intuitive sensory feedback.\n\nCorrect Answer: They use bio-inspired models to generate stimulation patterns that mimic natural neural activity, improving sensation naturalness and discrimination, thereby overcoming neural interface limitations by enabling more biologically plausible and discriminable sensory feedback.\n</output_format>",
    "question": "How do model-based, biomimetic nerve stimulation strategies enhance both the naturalness and discrimination of sensory feedback in prosthetic hands, and what implications do these approaches have for overcoming current limitations of neural interfaces?",
    "answer": "They use bio-inspired models to generate stimulation patterns that mimic natural neural activity, improving sensation naturalness and discrimination, thereby overcoming neural interface limitations by enabling more biologically plausible and discriminable sensory feedback.",
    "explanation": "Model-based biomimetic stimulation strategies use bio-inspired computational models to generate nerve stimulation patterns that mimic natural neural activity, such as asynchronous fiber activation or sinusoidal pulse width modulation. These approaches improve the naturalness of sensations by producing stimulation patterns closer to healthy neural firing, making the feedback feel more biologically plausible. Additionally, by carefully modulating stimulation parameters, they can increase sensory discrimination without losing resolution, addressing a key challenge of current neural interfaces that struggle to balance reaching (stimulating many fibers) with maintaining sensation specificity. Consequently, these strategies suggest requirements for future neural interfaces to support more complex, naturalistic stimulation patterns, ultimately enabling prosthetics with richer, more intuitive sensory feedback.",
    "question_token_count": 42,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 39
  },
  {
    "context": "## 4.4. Perspectives\nMotor decoding for RPHs is progressing in two main directions: Noninvasive approaches have seen advances in decoding algorithms using large data sets and increases in the number of recording points, and implanted electrodes (either muscular or intraneural) have seen improvements that enable better recording stability and more robust decoding. There is currently no consensus on which approach is best for transradial amputee patients, as they each have their own strengths and limitations. The need for daily signal and classification recalibration is a weak point of the classic sEMG approach, which is being addressed by several research groups developing, for example, HD-sEMG.And despite iEMG's promising control performance, which is robust to donning and doffing of the prosthesis, its overall performance gain, when compared with sEMG, may not currently be sufficient to justify an invasive surgery. The same reasoning can be applied to intraneural electrodes.\n\nOne can imagine a future where both invasive and noninvasive approaches will continue to progress and will target either patients who prefer a stable decoding setup or those who do not want to undergo surgery and will accept the need to calibrate their prosthesis on a regular basis (118). Another scenario can be a parallel development of invasive technologies for both sensory and motor functions. Indeed, as shown in Section 5, the approach using intraneural implanted electrodes has permitted unprecedented levels of somatosensory restoration; it might, therefore, be reasonable to perform a single surgery to restore both motor and sensory functions. For this reason, motor decoding using the intraneural interface can become a viable solution if these interfaces one day permit both providing sensory feedback and recording discriminative signals for motor decoding in parallel, but online artifact removal remains an important challenge.\n\nPower consumption is another critical issue: RPHs should embed small electronics because the size of the prosthesis limits the space available for batteries, but doing so usually comes at the cost of limited processing resources. Also, the electronics for the HD-sEMG remain cumbersome due to the large number of input channels and should be miniaturized and portable. Moreover, decoding model complexity is also limited by portable processing resources. In practice, an increased number of electrodes is already available in wearable systems (Sessantaquattro, OT Bioelettronica, Italy) and may become available for prostheses in the future.\n\nFinally, low latency is paramount for seamless prosthesis control [ &lt; 300 ms between user intention and real-time decoding (119)]. Among the studies discussed above, only a few performed analyses to show the feasibility of real-time control (without processing resource limitations), and even fewer included embedded electronics that would translate for home use. One possible solution for real-time decoding with complex models is to bypass embedded electronic limitations; this could be achieved by taking advantage of the computational power of cell phones or by relying on cloud computing and the next generations of wireless cellular networks for low-latency communication.\n",
    "topic": "Evaluation of the trade-offs between the invasiveness of implanted electrodes and the performance gains they provide for motor decoding.",
    "response": "<document_analysis>\nThe context discusses two main approaches for motor decoding in robotic prosthetic hands (RPHs): noninvasive methods like sEMG and HD-sEMG, and invasive methods involving implanted electrodes such as muscular or intraneural interfaces. It highlights the ongoing debate regarding which approach is better, as each has distinct advantages and limitations. Noninvasive approaches face challenges like the need for daily recalibration and bulky electronics but avoid surgery, while invasive methods offer potentially more stable decoding and robust control performance but require surgery and still have issues such as artifact removal and limited performance gains that may not justify the invasiveness. The text also mentions potential future scenarios where both approaches coexist, catering to different patient preferences, and the possibility of combining motor and sensory restoration through intraneural electrodes. Additionally, practical concerns such as power consumption, size constraints, processing resources, latency, and real-time feasibility are discussed, emphasizing that invasive solutions currently face challenges that limit widespread adoption despite their theoretical advantages.\n\nImplicit assumptions include the trade-off between invasiveness and performance/stability, patient preference for surgery or convenience, and technological limits on processing and power in embedded systems. The text suggests that while invasive electrodes may offer better performance, the gains are not yet sufficient to outweigh the risks and costs of surgery for many patients, but the potential integration of sensory feedback could shift this balance.\n\nThe difficulty level is rated at 9 because it requires advanced understanding of neuroprosthetics, electrophysiology, signal processing, and clinical decision-making in prosthesis design. The question should prompt critical evaluation of the nuanced trade-offs between invasiveness and performance gains, reflecting on the current technological and clinical landscape and future prospects.\n\nThe question will encourage experts to synthesize knowledge about electrode interfaces, patient-centered care, and technical constraints, fostering deep reflection on why performance improvements do not straightforwardly justify invasive procedures, and how future developments might alter this balance.\n\nThis is meaningful content with rich technical and clinical implications, suitable for generating a challenging, insightful question-answer pair.\n\n</document_analysis>\n\n<output_format>\nQuestion: Considering the current state of motor decoding technologies for robotic prosthetic hands, what are the principal trade-offs between using invasive implanted electrodes versus noninvasive surface EMG methods in terms of performance gains, patient burden, and system practicality, and why do the performance improvements from invasive approaches not yet universally justify the surgical risks involved?\n\nExplanation: Invasive implanted electrodes provide more stable and robust motor signal recordings that are less affected by prosthesis donning and doffing, potentially improving decoding performance; however, these performance gains are modest relative to the risks and burdens of surgery, such as invasiveness, artifact challenges, and long-term implant stability. Noninvasive methods avoid surgery and are improving through high-density arrays and algorithms but require frequent recalibration and face power and latency constraints due to bulky electronics. Thus, the limited performance improvement of invasive methods combined with their surgical risks and technical challenges currently mean they are not universally preferred, although future integration with sensory feedback and technical advances might change this balance.\n\nCorrect Answer: Invasive implanted electrodes offer more stable and robust motor decoding but provide only modest performance gains over noninvasive methods, and these gains do not yet outweigh the surgical risks, patient burden, and technical challenges involved; hence, noninvasive methods remain preferable for many patients despite requiring frequent recalibration and having practical limitations.\n</output_format>",
    "question": "Considering the current state of motor decoding technologies for robotic prosthetic hands, what are the principal trade-offs between using invasive implanted electrodes versus noninvasive surface EMG methods in terms of performance gains, patient burden, and system practicality, and why do the performance improvements from invasive approaches not yet universally justify the surgical risks involved?",
    "answer": "Invasive implanted electrodes offer more stable and robust motor decoding but provide only modest performance gains over noninvasive methods, and these gains do not yet outweigh the surgical risks, patient burden, and technical challenges involved; hence, noninvasive methods remain preferable for many patients despite requiring frequent recalibration and having practical limitations.",
    "explanation": "Invasive implanted electrodes provide more stable and robust motor signal recordings that are less affected by prosthesis donning and doffing, potentially improving decoding performance; however, these performance gains are modest relative to the risks and burdens of surgery, such as invasiveness, artifact challenges, and long-term implant stability. Noninvasive methods avoid surgery and are improving through high-density arrays and algorithms but require frequent recalibration and face power and latency constraints due to bulky electronics. Thus, the limited performance improvement of invasive methods combined with their surgical risks and technical challenges currently mean they are not universally preferred, although future integration with sensory feedback and technical advances might change this balance.",
    "question_token_count": 66,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 64
  },
  {
    "context": "## 4.3. Decoding Motor Intention via Implanted Electrodes\nSurface electrodes cannot precisely record the signal from deep muscles; to overcome this issue, several groups have focused on iEMG electrodes. This technique is more invasive but allows one to record EMG signals (51) uncorrelated from the underlying musculature and avoids the daily placement of electrodes. iEMG is robust against electrode shift (e.g., socket rotation) and change in skin impedance and sweat. Several studies have demonstrated the performance of simultaneous wrist and hand motions (three DOFs) using six to eight iEMG electrodes; Smith &amp; Hargrove (51) showed that iEMG has better decoding performance than sEMG. High decoding performance is reported in real time (106), and in fully implanted setups, the results are stable for several days (107).\n\nOnthe other hand, Farrell &amp; Weir (52) compared the pattern recognition-based grasp classification performance of iEMG and sEMG on 12 movement classes with eight channels and did not find a statistical difference between electrode types. They concluded that the choice of electrode should be based not on classification accuracy but rather on signal consistency over time and robustness to electrode lift-off. Zia ur Rehman et al. (108) compared a standard linear discriminant analysis with a deep network for grasp classification. They performed a multiday analysis comparing six iEMG and six sEMG electrodes, and their results showed that deep learning had better decoding performance and was more stable over time.\n\nKamavuako et al. (109) investigated the effect of combining iEMG to target deep muscles with sEMG on myoelectric control. They showed that the combined solution improved offline and real-time control performance compared with sEMG alone.\n\nWith 32 iEMG electrodes, Dantas et al. (110) compared different decoding methods for the continuous control of five DOFs corresponding to the flexion and extension of each digit. Using a data set aggregation algorithm, they showed a normalized mean squared error as low as 0.033 with a deep convolutional neural network. They also investigated signal stability for 150 days after training, showing a small degradation during the first month (0.003 normalized mean squared error per day with a convolutional neural network), but that degradation stopped in the next four months.\n\nFor transradial amputees, an alternative to using EMG signals to control hand prostheses is decoding from peripheral nerve signals. Different grasp types can be decoded from peripheral nerve signals with high accuracy using different interfaces, both offline and in real time (54, 111113). Implanted peripheral nerve recordings are more invasive than sEMG but are more stable over time. Indeed, donning and doffing the prosthesis does not move these electrodes as much as it does sEMG electrodes. Recently, Cracchiolo et al. (53) decoded up to 11 class states using TIMEs on an amputee subject and showed that the active sites chosen on the first day could also be used in the following sessions, for up to seven days (80% accuracy, compared with 83% by selecting active sites every session). However, this modality is generally used to provide sensory\n\nfeedback (64, 114-116). Therefore the development of new approaches to record neural signals during peripheral stimulation [e.g., artifact removal (117)] is necessary.\n\nVu et al. (39) recently developed a regenerative peripheral nerve interface to increase signal specificity and long-term stability. They implanted transected peripheral nerves into a free muscle graft. After regeneration, revascularization, and reinnervation, the graft becomes a nerve bioamplifier that creates EMG signals. Using chronically implanted iEMG to record from these grafts, they performed five-class decoding in real time with up to 98.2% accuracy with two transradial amputees in a virtual hand environment. They also showed results from a Box and Block T est using an RPH that provided continuous control of two DOFs of thumb motions through their interface combined with a third DOF based on sEMG.\n",
    "topic": "Evaluation of machine learning methods, including linear discriminant analysis and deep neural networks, for decoding grasp classification from iEMG and sEMG signals, with emphasis on multiday stability and performance.",
    "response": "<document_analysis>\nThe context discusses the use of implanted electromyography (iEMG) electrodes versus surface electromyography (sEMG) for decoding motor intention in prosthetic control, focusing on signal quality, stability, and classification accuracy. It highlights comparisons between iEMG and sEMG in various studies, including the use of machine learning methods such as linear discriminant analysis (LDA) and deep neural networks (DNNs) for grasp classification tasks. A key point is the multiday analysis by Zia ur Rehman et al., who compared LDA and deep learning on six iEMG and six sEMG electrodes, finding deep learning to outperform LDA in decoding performance and temporal stability. The context also references the importance of signal consistency and robustness over time, noting that classification accuracy alone is insufficient to determine electrode choice. The text touches upon the use of convolutional neural networks (CNNs) for continuous DOF control with low error and signal stability over months. This implies that deep learning methods provide superior decoding accuracy and maintain performance better over extended periods compared to traditional linear classifiers. The question should probe understanding of how machine learning approaches influence decoding performance and stability when applied to iEMG and sEMG signals over multiple days, requiring insight into the implications of algorithmic choice on prosthetic control reliability and robustness. Difficulty is rated 9/10 because it requires integration of machine learning evaluation, neurophysiological signal properties, and longitudinal performance considerations, which is challenging even for domain experts.\n\nThe question will invite reflection on why deep learning methods might offer advantages over LDA for multiday EMG decoding and the practical consequences for electrode selection and prosthetic control system design.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do deep learning methods compare to linear discriminant analysis in decoding grasp classification from implanted and surface EMG signals over multiple days, and what implications does this have for the stability and robustness of myoelectric prosthetic control?\n\nExplanation: Deep learning methods outperform linear discriminant analysis by providing higher decoding accuracy and greater stability over time when applied to both iEMG and sEMG signals; this suggests that integrating deep neural networks enhances long-term control robustness and reduces performance degradation, influencing electrode choice towards solutions that maintain stable signal quality and decoding consistency for reliable prosthetic function.\n\nCorrect Answer: Deep learning yields higher accuracy and more stable multiday decoding than linear discriminant analysis, improving prosthetic control robustness and supporting electrode choices favoring long-term signal consistency.\n</output_format>",
    "question": "How do deep learning methods compare to linear discriminant analysis in decoding grasp classification from implanted and surface EMG signals over multiple days, and what implications does this have for the stability and robustness of myoelectric prosthetic control?",
    "answer": "Deep learning yields higher accuracy and more stable multiday decoding than linear discriminant analysis, improving prosthetic control robustness and supporting electrode choices favoring long-term signal consistency.",
    "explanation": "Deep learning methods outperform linear discriminant analysis by providing higher decoding accuracy and greater stability over time when applied to both iEMG and sEMG signals; this suggests that integrating deep neural networks enhances long-term control robustness and reduces performance degradation, influencing electrode choice towards solutions that maintain stable signal quality and decoding consistency for reliable prosthetic function.",
    "question_token_count": 44,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 33
  },
  {
    "context": "## DISCLOSURE STATEMENT\nS.M. holds shares in SensArs, which aims to develop bionic limbs for amputees.\n\n\n## ACKNOWLEDGMENTS\nThe authors would like to thank Iason Batzianoulis for his valuable help on robotic hand control. This review was partly funded by the Swiss National Science Foundation through the National Centre of Competence in Research (NCCR) Robotics, the CHRONOS project, the Wyss Center for Bio and Neuroengineering, and the Bertarelli Foundation.\n\n\n## LITERATURE CITED\n- 1. Piazza C, Grioli G, Catalano MG, Bicchi A. 2019. A century of robotic hands. Annu. Rev. Control Robot. Auton. Syst. 2:1-32\n\n- 2. Castiello U. 2005. The neuroscience of grasping. Nat. Rev. Neurosci. 6:726-36\n\n- 3. Bicchi A. 2000. Hands for dexterous manipulation and robust grasping: a difficult road toward simplicity. IEEE Trans. Robot. Autom. 16:652-62\n\n- 4. Marasco PD, Kim K, Colgate JE, Peshkin MA, Kuiken TA. 2011. Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees. Brain 134:747-58\n\n- 5. Ehrsson HH, Rosen B, Stockselius A, Ragno C, Kohler P, Lundborg G. 2008. Upper limb amputees can be induced to experience a rubber hand as their own. Brain 131:3443-52\n\n- 6. Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, et al. 2014. Restoring natural sensory feedback in real-time bidirectional hand prostheses. Sci. Transl. Med. 6:222ra19\n\n- 7. Kyberd PJ, Hill W. 2011. Survey of upper limb prosthesis users in Sweden, the United Kingdom and Canada. Prosthet. Orthot. Int. 35:234-41\n\n- 8. Dubernard JM, Owen E, Herzberg G, Lanzetta M, Martin X, et al. 1999. Human hand allograft: report on first 6 months. Lancet 353:1315-20\n\n- 9. Piazza C, Catalano MG, Godfrey SG, Rossi M, Grioli G, et al. 2017. The SoftHand Pro-H. IEEE Robot. Autom. Mag. 24(4):87-101\n\n- 10. Smit G, Plettenburg DH, Van Der Helm FCT. 2015. The lightweight Delft Cylinder hand: first multiarticulating hand that meets the basic user requirements. IEEE Trans. Neural Syst. Rehabil. Eng. 23:431-40\n\n- 11. Baril M, Lalibert\u00e9 T, Gosselin C, Routhier F. 2013. On the design of a mechanically programmable underactuated anthropomorphic prosthetic gripper. J. Mech. Des. 135:121008\n\n- 12. Smit G, Plettenburg DH. 2010. Efficiency of voluntary closing hand and hook prostheses. Prosthet. Orthot. Int. 34:411-27\n\n- 13. Biddiss E, Chau T. 2007. Upper limb prosthesis use and abandonment: a survey of the last 25 years. Prosthet. Orthot. Int. 31:236-57\n\n- 14. Lotti F, Tiezzi P, Vassura G, Biagiotti L, Palli G, Melchiorri C. 2005. Development of UB Hand 3: early results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 4488-93. Piscataway, NJ: IEEE\n\n- 15. Honda Y, Miyazaki F, Nishikawa A. 2010. Control of pneumatic five-fingered robot hand using antagonistic muscle ratio and antagonistic muscle activity. In 2010 3rd IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics , pp. 337-42. Piscataway, NJ: IEEE\n\n- 16. Cordella F, Ciancio AL, Sacchetti R, Davalli A, Cutti AG, et al. 2016. Literature review on needs of upper limb prosthesis users. Front. Neurosci. 10:209\n\n- 17. Melchiorri C, Palli G, Berselli G, Vassura G. 2013. Development of the UB Hand IV: overview of design solutions and enabling technologies. IEEE Robot. Autom. Mag. 20(3):72-81\n\n- 18. Pfeifer R, Gomez G. 2009. Morphological computation - connecting brain, body, and environment. In Creating Brain-Like Intelligence , ed. B Sendhoff, E K\u00f6rner, O Sporns, H Ritter, K Doya, pp. 66-83. Berlin: Springer\n\n- 19. Jing X, Yong X, Jiang Y, Li G, Yokoi H. 2019. Anthropomorphic prosthetic hand with combination of light weight and diversiform motions. Appl. Sci. 9:4203\n\n- 20. Mohammadi A, Lavranos J, Zhou H, Mutlu R, Alici G, et al. 2020. A practical 3D-printed soft robotic prosthetic hand with multi-articulating capabilities. PLOS ONE 15:e0232766\n\n- 21. Chamara RPDD, Gopura RARC. 2019. An under-actuated mechanism for anthropomorphic robotic prosthetic hand. In 2019 5th International Conference on Control, Automation and Robotics , pp. 162-66. Piscataway, NJ: IEEE\n\n- 22. Pozzobon LA,Da Silva Guerra R, Librelotto GR. 2019. A low-cost, compliant, underactuated prosthetic hand with custom flex sensors for finger bending estimation. In 2019 19th International Conference on Advanced Robotics , pp. 69-74. Piscataway, NJ: IEEE\n\n- 23. Fajardo J, Ferman V, Cardona D, Maldonado G, Lemus A, Rohmer E. 2020. Galileo Hand: an anthropomorphic and affordable upper-limb prosthesis. IEEE Access 8:81365-77\n\n- 24. Abayasiri RAM, Abayasiri RST, Gunawardhana RAGM, Premakumara RMC, Mallikarachchi S, et al. 2020. An under-actuated hand prosthesis with finger abduction and adduction for human like grasps. In 2020 6th International Conference on Control, Automation and Robotics , pp. 574-80. Piscataway, NJ: IEEE\n\n- 25. Yong X, Jing X, Wu X, Jiang J, Yokoi H. 2019. Development of an adaptive prosthetic hand. In 2019 IEEE International Conference on Robotics and Biomimetics , pp. 2800-5. Piscataway, NJ: IEEE\n\n- 26. Weiner P, Starke J, Hundhausen F, Beil J, Asfour T. 2018. The KIT prosthetic hand: design and control. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 3328-34. Piscataway, NJ: IEEE\n\n- 27. Nemoto Y, Ogawa K, Yoshikawa M. 2020. F3Hand II: a flexible five-fingered prosthetic hand using curved pneumatic artificial muscles. In 2020 IEEE/SICE International Symposium on System Integration , pp. 99-104. Piscataway, NJ: IEEE\n\n- 28. Controzzi M, Cipriani C, Carrozza MC. 2008. Mechatronic design of a transradial cybernetic hand. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 576-81. Piscataway, NJ: IEEE\n\n- 29. Trivedi D, Rahn CD, Kier WM, Walker ID. 2008. Soft robotics: biological inspiration, state of the art, and future research. Appl. Bionics Biomech. 5:520417\n\n- 30. Hirose S, Ma S. 1991. Coupled tendon-driven multijoint manipulator. In 1991 IEEE International Conference on Robotics and Automation , pp. 1268-75. Piscataway, NJ: IEEE\n\n- 31. Carrozza MC, Cappiello G, Stellin G, Zaccone F, Vecchi F, et al. 2005. A cosmetic prosthetic hand with tendon driven under-actuated mechanism and compliant joints: ongoing research and preliminary results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 2661-66. Piscataway, NJ: IEEE\n\n- 32. Godfrey SB, Zhao KD, Theuer A, Catalano MG, Bianchi M, et al. 2018. The SoftHand Pro: functional evaluation of a novel, flexible, and robust myoelectric prosthesis. PLOS ONE 13:13e0205653\n\n- 33. Amend J, Lipson H. 2017. The JamHand: dexterous manipulation with minimal actuation. Soft Robot . 4:70-80\n\n- 34. Yamaguchi A, Takemura K, Yokota S, Edamura K. 2011. A robot hand using electro-conjugate fluid. In 2011 IEEE International Conference on Robotics and Automation , pp. 5923-28. Piscataway, NJ: IEEE\n\n- 35. Zhao H, O'Brien K, Li S, Shepherd RF. 2016. Optoelectronically innervated soft prosthetic hand via stretchable optical waveguides. Sci. Robot. 1:eaai7529\n\n- 36. Yoshida K, Bertram MJ, Cox TGH, Riso RR. 2017. Peripheral nerve recording electrodes and techniques. In Neuroprosthetics: Theory and Practice , ed. K Yoshida, MJ Bertram, TG Hunter Cox, RR Riso, pp. 377-466. Singapore: World Sci.\n\n- 37. Navarro X,Valderrama E,Stieglitz T,Sch\u00fcttler M.2001.Selective fascicular stimulation of the rat sciatic nerve with multipolar polyimide cuff electrodes. Restor. Neurol. Neurosci. 18:9-21\n\n- 38. Tan DW, Schiefer MA, Keith MW, Anderson JR, Tyler J, Tyler DJ. 2014. A neural interface provides long-term stable natural touch perception. Sci. Transl. Med. 6:257ra138\n\n- 39. Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, et al. 2020. A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees. Sci. Transl. Med. 12:eaay2857\n\n- 40. Raspopovic S, Cimolato A, Panarese A, Vallone F, del Valle J, et al. 2020. Neural signal recording and processing in somatic neuroprosthetic applications. A review. J. Neurosci. Methods 337:108653\n\n- 41. Navarro X,Krueger TB,Lago N,Micera S,Stieglitz T,Dario P.2005.A critical review of interfaces with the peripheral nervous system for the control of neuroprostheses and hybrid bionic systems. J. Peripher. Nerv. Syst. 258:229-58\n\n- 42. Boretius T, Badia J, Pascual-Font A, Schuettler M, Navarro X, et al. 2010. A transverse intrafascicular multichannel electrode (TIME) to interface with the peripheral nerve. Biosens. Bioelectron. 26:62-69\n\n- 43. Yoshida K, Pellinen D, Pivin D, Rousche P, Kipke D. 2000. Development of the thin-film longitudinal intra-fascicular electrode. In Proceedings of the 5th Annual Conference of the International Functional Electrical Stimulation Society , pp. 279-84. Graz, Austria: Int. Funct. Electr. Stimul. Soc.\n\n- 44. Badia J, Boretius T, Andreu D, Azevedo-Coste C, Stieglitz T, Navarro X. 2011. Comparative analysis of transverse intrafascicular multichannel, longitudinal intrafascicular and multipolar cuff electrodes for the selective stimulation of nerve fascicles. J. Neural Eng. 8:036023\n\n- 45. Howell B, Grill WM. 2015. Design of electrodes for stimulation and recording. In Implantable Neuroprostheses for Restoring Function , ed. K Kilgore, pp. 59-93. Amsterdam: Elsevier\n\n- 46. Cui X, Wiler J, Dzaman M, Altschuler RA, Martin DC. 2003. In vivo studies of polypyrrole/peptide coated neural probes. Biomaterials 24:777-87\n\n- 47. Kennedy PR, Bakay RAE, Sharpe SM. 1992. Behavioral correlates of action potentials recorded chronically inside the cone electrode. Neuroreport 3:605-8\n\n- 48. Lacour SP, Courtine G, Guck J. 2016. Materials and technologies for soft implantable neuroprostheses. Nat. Rev. Mater. 1:16063\n\n- 49. Kipke DR. 2004. Implantable neural probe systems for cortical neuroprostheses. In 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5344-47. Piscataway, NJ: IEEE\n\n- 50. Merletti R, Holobar A, Farina D. 2008. Analysis of motor units with high-density surface electromyography. J. Electromyogr. Kinesiol. 18:879-90\n\n- 51. Smith LH, Hargrove LJ. 2013. Comparison of surface and intramuscular EMG pattern recognition for simultaneous wrist/hand motion classification. In 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4223-6. Piscataway, NJ: IEEE\n\n- 52. Farrell TR, Weir RF. 2008. A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control. IEEE Trans. Biomed. Eng. 55:2198-211\n\n- 53. Cracchiolo M, Valle G, Petrini F, Strauss I, Granata G, et al. 2020. Decoding of grasping tasks from intraneural recordings in trans-radial amputee. J. Neural Eng. 17:026034\n\n- 54. Wendelken S, Page DM, Davis T, Wark HAC, Kluger DT, et al. 2017. Restoration of motor control and proprioceptive and cutaneous sensation in humans with prior upper-limb amputation via multiple Utah Slanted Electrode Arrays (USEAs) implanted in residual peripheral arm nerves. J. Neuroeng. Rehabil. 14:121\n\n- 55. Cipriani C, Dalonzo M, Carrozza MC. 2012. A miniature vibrotactile sensory substitution device for multifingered hand prosthetics. IEEE Trans. Biomed. Eng. 59:400-8\n\n- 56. Chen B, Feng Y, Wang Q. 2016. Combining vibrotactile feedback with volitional myoelectric control for robotic transtibial prostheses. Front. Neurorobot. 10:8\n\n- 57. Antfolk C, D'Alonzo M, Controzzi M, Lundborg G, Rosen B, et al. 2013. Artificial redirection of sensation from prosthetic fingers to the phantom hand map on transradial amputees: vibrotactile versus mechanotactile sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 21:112-20\n\n- 58. Gonzalez J, Soma H, Sekine M, Yu W. 2012. Psycho-physiological assessment of a prosthetic hand sensory feedback system based on an auditory display: a preliminary study. J. Neuroeng. Rehabil. 9:33\n\n- 59. Osborn L, Betthauser J, Kaliki R, Thakor N. 2018. T argeted transcutaneous electrical nerve stimulation for phantom limb sensory feedback. In 2017 IEEE Biomedical Circuits and Systems Conference . Piscataway, NJ: IEEE. https://doi.org/10.1109/BIOCAS.2017.8325200\n\n- 60. D'Anna E, Petrini FM, Artoni F, Popovic I, Simani\u00b4 c I, et al. 2017. A somatotopic bidirectional hand prosthesis with transcutaneous electrical nerve stimulation based sensory feedback. Sci. Rep. 7:10930\n\n- 61. Oddo CM, Raspopovic S, Artoni F, Mazzoni A, Spigler G, et al. 2016. Intraneural stimulation elicits discrimination of textural features by artificial fingertip in intact and amputee humans. eLife 5:e09148\n\n- 62. Valle G, Mazzoni A, Iberite F, D'Anna E, Strauss I, et al. 2018. Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis. Neuron 100:37-45.e7\n\n- 63. Valle G, D'Anna E, Strauss I, Clemente F, Granata G, et al. 2020. Hand control with invasive feedback is not impaired by increased cognitive load. Front. Bioeng. Biotechnol. 8:287\n\n- 64. D'Anna E, Valle G, Mazzoni A, Strauss I, Iberite F, et al. 2019. A closed-loop hand prosthesis with simultaneous intraneural tactile and position feedback. Sci. Robot. 4:eaau8892\n\n- 65. Shokur S, Gallo S, Moioli RC, Donati ARC, Morya E, et al. 2016. Assimilation of virtual legs and perception of floor texture by complete paraplegic patients receiving artificial tactile feedback. Sci. Rep. 6:32293\n\n- 66. Geethanjali P . 2016. Myoelectric control of prosthetic hands: state-of-the-art review. Med. Devices Evid. Res. 9:247-55\n\n- 67. Farina D, Jiang N, Rehbaum H, Holobar A, Graimann B, et al. 2014. The extraction of neural information from the surface EMG for the control of upper-limb prostheses: emerging avenues and challenges. IEEE Trans. Neural Syst. Rehabil. Eng. 22:797-809\n\n- 68. Ferguson S, Dunlop GR. 2002. Grasp recognition from myoelectric signals. In Proceedings of the Australasian Conference on Robotics and Automation , ed. W Friedrich, P Lim, pp. 83-87. Sydney: Aust. Robot. Autom. Assoc.\n\n- 69. Martelloni C, Carpaneto J, Micera S. 2008. Classification of upper arm EMG signals during objectspecific grasp. In 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5061-64. Piscataway, NJ: IEEE\n\n- 70. Kakoty NM, Hazarika SM. 2011. Recognition of grasp types through principal components of DWT based EMG features. In 2011 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/ICORR.2011.5975398\n\n- 71. Castellini C, Van Der Smagt P . 2009. Surface EMG in advanced hand prosthetics. Biol. Cybern. 100:35-47\n\n- 72. Atzori M, Cognolato M, M\u00fcller H. 2016. Deep learning with convolutional neural networks applied to electromyography data: a resource for the classification of movements for prosthetic hands. Front. Neurorobot. 10:9\n\n- 73. Tenore FVG, Ramos A, Fahmy A, Acharya S, Etienne-Cummings R, Thakor NV. 2009. Decoding of individuated finger movements using surface electromyography. IEEE Trans. Biomed. Eng. 56:1427-34\n\n- 74. Bhattachargee CK, Sikder N, Hasan MT, Nahid A. 2019. Finger movement classification based on statistical and frequency features extracted from surface EMG signals. In 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering . Piscataway, NJ: IEEE. https://doi.org/10.1109/IC4ME247184.2019.9036671\n\n- 75. Bhagwat S,Mukherji P.2020.Electromyogram (EMG) based fingers movement recognition using sparse filtering of wavelet packet coefficients. S\u00af adhan\u00af a 45:3\n\n- 76. Muceli S, Farina D. 2012. Simultaneous and proportional estimation of hand kinematics from EMG during mirrored movements at multiple degrees-of-freedom. IEEE Trans. Neural Syst. Rehabil. Eng. 20:37178\n\n- 77. Jiang N, Vest-Nielsen JL, Muceli S, Farina D. 2012. EMG-based simultaneous and proportional estimation of wrist/hand kinematics in uni-lateral trans-radial amputees. J. Neuroeng. Rehabil. 9:42\n\n- 78. Hioki M, Kawasaki H. 2012. Estimation of finger joint angles from sEMG using a neural network including time delay factor and recurrent structure. ISRN Rehabil . 2012:604314\n\n- 79. Zhuang KZ,Sommer N,Mendez V,Aryan S,Formento E,et al.2019.Shared human-robot proportional control of a dexterous myoelectric prosthesis. Nat. Mach. Intell. 1:400-11\n\n- 80. Mussa-Ivaldi FA, Casadio M, Danziger ZC, Mosier KM, Scheidt RA. 2011. Sensory motor remapping of space in human-machine interfaces. Prog. Brain Res. 191:45-64\n\n- 81. Dyson M, Barnes J, Nazarpour K. 2018. Myoelectric control with abstract decoders. J. Neural Eng. 15:056003\n\n- 82. Dyson M, Dupan S, Jones H, Nazarpour K. 2020. Learning, generalization, and scalability of abstract myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:1539-47\n\n- 83. Daley H,Englehart K,Hargrove L,Kuruganti U.2012.High density electromyography data of normally limbed and transradial amputee subjects for multifunction prosthetic control. J. Electromyogr. Kinesiol. 22:478-84\n\n- 84. Hargrove L,Englehart K,Hudgins B.2006.The effect of electrode displacements on pattern recognition based myoelectric control. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 2203-6. Piscataway, NJ: IEEE\n\n- 85. Boschmann A, Platzner M. 2014. T owards robust HD EMG pattern recognition: reducing electrode displacement effect using structural similarity. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4547-50. Piscataway, NJ: IEEE\n\n- 86. Stango A, Negro F, Farina D. 2015. Spatial correlation of high density EMG signals provides features robust to electrode number and shift in pattern recognition for myocontrol. IEEE Trans. Neural Syst. Rehabil. Eng. 23:189-98\n\n- 87. Farina D, Holobar A, Merletti R, Enoka RM. 2010. Decoding the neural drive to muscles from the surface electromyogram. Clin. Neurophysiol. 121:1616-23\n\n- 88. Kapelner T, Negro F, Aszmann OC, Farina D. 2018. Decoding motor unit activity from forearm muscles: perspectives for myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 26:244-51\n\n- 89. Dai C, Hu X. 2020. Finger joint angle estimation based on motoneuron discharge activities. IEEE J. Biomed. Heal. Inform. 24:760-67\n\n- 90. Hu Y, Wong Y, Wei W, Du Y, Kankanhalli M, Geng W. 2018. A novel attention-based hybrid CNNRNNarchitecture for sEMG-based gesture recognition. PLOS ONE 13:e0206049\n\n- 91. Olsson AE, Sager P, Andersson E, Bj\u00f6rkman A, Male\u0161evi\u00b4 c N, Antfolk C. 2019. Extraction of multilabelled movement information from the raw HD-sEMG image with time-domain depth. Sci. Rep. 9:7244\n\n- 92. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. Regression convolutional neural network for improved simultaneous EMG control. J. Neural Eng. 16:036015\n\n- 93. Xia P, Hu J, Peng Y. 2018. EMG-based estimation of limb movement using deep learning with recurrent convolutional neural networks. Artif. Organs 42:E67-77\n\n- 94. Alom MZ, Taha TM, Yakopcic C, Westberg S, Sidike P, et al. 2018. The history began from AlexNet: a comprehensive survey on deep learning approaches. arXiv:1803.01164 [cs.CV]\n\n- 95. Patricia N, Caputo B. 2014. Learning to learn, from transfer learning to domain adaptation: a unifying perspective. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , pp. 1442-49. Piscataway, NJ: IEEE\n\n- 96. Tommasi T, Orabona F, Castellini C, Caputo B. 2013. Improving control of dexterous hand prostheses using adaptive learning. IEEE Trans. Robot. 29:207-19\n\n- 97. C\u00f4t\u00e9-Allard U, Fall CL, Drouin A, Campeau-Lecours A, Gosselin C, et al. 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans. Neural Syst. Rehabil. Eng. 27:760-71\n\n- 98. Du Y, Jin W, Wei W, Hu Y, Geng W. 2017. Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation. Sensors 17:6-9\n\n- 99. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:370-79\n\n- 100. Phinyomark A, Scheme E. 2018. EMG pattern recognition in the era of big data and deep learning. Big Data Cogn. Comput. 2:21\n\n- 101. Khamparia A, Singh KM. 2019. A systematic review on deep learning architectures and applications. Expert Syst . 36:e12400\n\n- 102. Biddiss E, Chau T. 2007. Upper-limb prosthetics: critical factors in device abandonment. Am. J. Phys. Med. Rehabil. 86:977-87\n\n- 103. Do\u0161en S, Cipriani C, Kosti\u00b4 c M, Controzzi M, Carrozza MC, Popovi\u02c7 c DB. 2010. Cognitive vision system for control of dexterous prosthetic hands: experimental evaluation. J. Neuroeng. Rehabil. 7:42\n\n- 104. Light CM, Chappell PH, Hudgins B, Engelhart K. 2002. Intelligent multifunction myoelectric control of hand prostheses. J. Med. Eng. Technol. 26:139-46\n\n- 105. Fani S, Bianchi M, Jain S, Neto JSP, Boege S, et al. 2016. Assessment of myoelectric controller performance and kinematic behavior of a novel soft synergy-inspired robotic hand for prosthetic applications. Front. Neurorobot. 10:11\n\n- 106. Smith LH, Kuiken TA, Hargrove LJ. 2014. Real-time simultaneous and proportional myoelectric control using intramuscular EMG. J. Neural Eng. 11:066013\n\n- 107. Pasquina PF, Evangelista M, Carvalho AJ, Lockhart J, Griffin S, et al. 2015. First-in-man demonstration of a fully implanted myoelectric sensors system to control an advanced electromechanical prosthetic hand. J. Neurosci. Methods 244:85-93\n\n- 108. Zia ur Rehman M, Gilani S, Waris A, Niazi I, Slabaugh G, et al. 2018. Stacked sparse autoencoders for EMG-based classification of hand motions: a comparative multi day analyses between surface and intramuscular EMG. Appl. Sci. 8:1126\n\n- 109. Kamavuako EN, Scheme EJ, Englehart KB. 2014. Combined surface and intramuscular EMG for improved real-time myoelectric control performance. Biomed. Signal. Process. Control 10:102-7\n\n- 110. Dantas H, Warren DJ, Wendelken SM, Davis TS, Clark GA, Mathews VJ. 2019. Deep learning movement intent decoders trained with dataset aggregation for prosthetic limb control. IEEE Trans. Biomed. Eng. 66:3192-203\n\n- 111. Petrini FM, Mazzoni A, Rigosa J, Giambattistelli F, Granata G, et al. 2019. Microneurography as a tool to develop decoding algorithms for peripheral neuro-controlled hand prostheses. BioMed. Eng. OnLine 18:44\n\n- 112. Rossini PM, Micera S, Benvenuto A, Carpaneto J, Cavallo G, et al. 2010. Double nerve intraneural interface implant on a human amputee for robotic hand control. Clin. Neurophysiol. 121:777-83\n\n- 113. Davis TS, Wark HAC, Hutchinson DT, Warren DJ, O'Neill K, et al. 2016. Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves. J. Neural Eng. 13:036001\n\n- 114. Petrini FM, Valle G, Strauss I, Granata G, Di Iorio R, et al. 2019. Six-month assessment of a hand prosthesis with intraneural tactile feedback. Ann. Neurol. 85:137-54\n\n- 115. Mazzoni A, Oddo CM, Valle G, Camboni D, Strauss I, et al. 2020. Morphological neural computation restores discrimination of naturalistic textures in trans-radial amputees. Sci. Rep. 10:527\n\n- 116. Graczyk EL, Schiefer MA, Saal HP, Delhaye BP, Bensmaia SJ, Tyler DJ. 2016. The neural basis of perceived intensity in natural and artificial touch. Sci. Transl. Med. 8:362ra142\n\n- 117. Kogler V, Nguyen TAK, Digiovanna J, Micera S. 2011. Recording vestibular evoked potentials induced by electrical stimulation of the horizontal semicircular canal in guinea pig. In 2011 5th International IEEE/EMBS Conference on Neural Engineering , pp. 261-64. Piscataway, NJ: IEEE\n\n- 118. Micera S, Carpaneto J, Raspopovic S. 2010. Control of hand prostheses using peripheral information. IEEE Rev. Biomed. Eng. 3:48-68\n\n- 119. Englehart K,Hudgins B.2003.A robust,real-time control scheme for multifunction myoelectric control. IEEE Trans. Biomed. Eng. 50:848-54\n\n- 120. Park M, Bok BG, Ahn JH, Kim MS. 2018. Recent advances in tactile sensing technology. Micromachines 9:321\n\n- 121. Pfeifer R, Iida F, G\u00f3mez G. 2006. Morphological computation for adaptive behavior and cognition. Int. Congr. Ser. 1291:22-9\n\n- 122. Kim Y, Chortos A, Xu W, Liu Y, Oh JY, et al. 2018. A bioinspired flexible organic artificial afferent nerve. Science 360:998-1003\n\n- 123. WuJ, Jia QS, Johansson KH, Shi L. 2013. Event-based sensor data scheduling: trade-off between communication rate and estimation quality. IEEE Trans. Autom. Control 58:1041-6\n\n- 124. Bartolozzi C, Ros PM, Diotalevi F, Jamali N, Natale L, et al. 2017. Event-driven encoding of off-theshelf tactile sensors for compression and latency optimisation for robotic skin. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 166-73. Piscataway, NJ: IEEE\n\n- 125. Lee WW,Tan YJ,Yao H,Li S,See HH,et al. 2019. A neuro-inspired artificial peripheral nervous system for scalable electronic skins. Sci. Robot. 4:eaax2198\n\n- 126. Antfolk C, D'Alonzo M, Ros\u00e9n B, Lundborg G, Sebelius F, Cipriani C. 2013. Sensory feedback in upper limb prosthetics. Expert Rev. Med. Devices 10:45-54\n\n- 127. Mann RW, Reimers SD. 1970. Kinesthetic sensing for the EMG controlled 'Boston Arm.' IEEE Trans. Man-Mach. Syst. 11:110-15\n\n- 128. Patterson PE, Katz JA. 1992. Design and evaluation of a sensory feedback system that provides grasping pressure in a myoelectric hand. J. Rehabil. Res. Dev. 29:1-8\n\n- 129. Clemente F, D'Alonzo M, Controzzi M, Edin BB, Cipriani C. 2016. Non-invasive, temporally discrete feedback of object contact and release improves grasp control of closed-loop myoelectric transradial prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 24:1314-22\n\n- 130. D'Alonzo M, Clemente F, Cipriani C. 2015. Vibrotactile stimulation promotes embodiment of an alien hand in amputees with phantom sensations. IEEE Trans. Neural Syst. Rehabil. Eng. 23:450-57\n\n- 131. Stephens-Fripp B, Alici G, Mutlu R. 2018. A review of non-invasive sensory feedback methods for transradial prosthetic hands. IEEE Access 6:6878-99\n\n- 132. Dosen S, Markovic M, Strbac M, Belic M, Kojic V, et al. 2017. Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 25:183-95\n\n- 133. Geng B,Dong J,Jensen W,Dosen S,Farina D,Kamavuako EN.2018.Psychophysical evaluation of subdermal electrical stimulation in relation to prosthesis sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 26:709-15\n\n- 134. Dong J, Geng B, Niazi IK, Amjad I, Dosen S, et al. 2020. The variability of psychophysical parameters following surface and subdermal stimulation: a multiday study in amputees. IEEE Trans. Neural Syst. Rehabil. Eng. 28:174-80\n\n- 135. Flesher SN, Downey JE, Weiss JM, Hughes CL, Herrera AJ, et al. 2019. Restored tactile sensation improves neuroprosthetic arm control. bioRxiv 653428. https://doi.org/10.1101/653428\n\n- 136. Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ. 2018. Home use of a neural-connected sensory prosthesis provides the functional and psychosocial experience of having a hand again. Sci. Rep. 8:9866\n\n|   137. | George JA, Page DM, Davis TS, Duncan CC, Hutchinson T, et al. 2020. Long-term performance of Utah Slanted Electrode Arrays and intramuscular electromyographic leads implanted chronically in human arm nerves and muscles. bioRxiv 2020.03.30.016683. https://doi.org/10.1101/2020.03.30. 016683                                                      |\n\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n|    138 | Ortiz-Catalan M, Mastinu E, Sassu P, Aszmann O, Br\u00e5nemark R. 2020. Self-contained neuromuscu- loskeletal arm prostheses. N. Engl. J. Med. 382:1732-38                                                                                                                                                                                                  |\n\n|    139 | George JA, Kluger DT,Davis TS,Wendelken SM,Okorokova EV,et al.2019.Biomimetic sensory feed- back through peripheral nerve stimulation improves dexterous use of a bionic hand. Sci. Robot. 4:eaax2352                                                                                                                                                  |\n\n|    140 | Chandrasekaran S,Nanivadekar AC,McKernan G,Helm ER,Boninger ML,et al.2020.Sensory restora- tion by epidural stimulation of the lateral spinal cord in upper-limb amputees. eLife 9:e54349                                                                                                                                                              |\n\n|    141 | Controzzi M, Clemente F, Barone D, Luciani LB, Pierotti N, et al. 2019. Progress towards the devel- opment of the DeTOP hand prosthesis: a sensorized transradial prosthesis for clinical use. In Converg- ing Clinical and Engineering Research on Neurorehabilitation III , ed. L Masia, S Micera, M Akay, J Pons, pp. 103-6. Cham, Switz.: Springer |\n\n|    142 | Formento E,D'Anna E,Gribi S,Lacour SP,Micera S.2019.A biomimetic electrical stimulation strategy to induce asynchronous stochastic neural activity. J. Neural Eng. 17:046019                                                                                                                                                                           |\n\n|    143 | Sengupta A, Ye Y, Wang R, Liu C, Roy K. 2019. Going deeper in spiking neural networks: VGG and residual architectures. Front Neurosci . 13:95                                                                                                                                                                                                          |\n\n|    144 | Lindner HYN, N\u00e4tterlund BS, Hermansson LMN. 2010. Upper limb prosthetic outcome measures: review and content comparison based on International Classification of Functioning, Disability and Health. Prosthet. Orthot. Int. 34:109-28                                                                                                                  |\n\n|    145 | Hill W, Stavdahl \u00d8, Hermansson LN, Kyberd P, Swanson S, Hubbard S. 2009. Functional outcomes in the WHO-ICF model: establishment of the upper limb prosthetic outcome measures group. J. Prosthet. Orthot. 21:115-19                                                                                                                                   |\n\n|    146 | Hudak PL, Amadio PC, Bombardier C. 1996. Development of an upper extremity outcome measure: the DASH (Disabilities of the Arm, Shoulder, and Head). Am. J. Ind. Med. 29:602-8                                                                                                                                                                          |\n\n|    147 | Beaton DE, Wright JG, Katz JN, Amadio P, Bombardier C, et al. 2005. Development of the Quick- DASH: comparison of three item-reduction approaches. J. Bone Jt. Surg. A 87:1038-46                                                                                                                                                                      |\n\n|    148 | Harper A, Power M, Orley J, Herrman H, Schofield H, et al. 1998. Development of the World Health Organization WHOQOL-BREF quality of life assessment. Psychol. Med. 28:551-58                                                                                                                                                                          |\n\n|    149 | Burckhardt CS, Anderson KL. 2003. The Quality of Life Scale (QOLS): reliability, validity, and utiliza- tion. Health Qual. Life Outcomes 1:60                                                                                                                                                                                                          |\n\n|    150 | Heinemann AW, Bode RK, O'Reilly C. 2003. Development and measurement properties of the Or- thotics and Prosthetics User's Survey (OPUS): a comprehensive set of clinical outcome instruments. Prosthet. Orthot. Int. 27:191-206                                                                                                                        |\n\n|    151 | Lendaro E,Middleton A,Brown S,Ortiz-Catalan M.2020.Out of the clinic, into the home: the in-home use of phantom motor execution aided by machine learning and augmented reality for the treatment of phantom limb pain. J. Pain Res. 13:195-209                                                                                                        |\n\n|    152 | Johansson RS, Flanagan JR. 2009. Coding and use of tactile signals from the fingertips in object manip- ulation tasks. Nat. Rev. Neurosci. 10:345-59                                                                                                                                                                                                   |\n\n|    153 | Taub E, Uswatte G, Pidikiti R. 1999. Constraint-induced movement therapy: a new family of techniques with broad application to physical rehabilitation-a clinical review. J. Rehabil. Res. Dev. 36:237-51                                                                                                                                              |\n\n|    154 | Mathiowetz V, Volland G, Kashman N, Weber K. 1985. Adult norms for the Box and Block T est of manual dexterity. Am. J. Occup. Ther. 39:386-91                                                                                                                                                                                                          |\n\n|    155 | Hebert JS, Lewicke J. 2012. Case report of modified box and blocks test with motion capture to measure prosthetic function. J. Rehabil. Res. Dev. 49:1163-74                                                                                                                                                                                           |\n\n|    156 | Hebert JS, Lewicke J, Williams TR, Vette AH. 2014. Normative data for modified box and blocks test measuring upper-limb function via motion capture. J. Rehabil. Res. Dev. 51:919-31                                                                                                                                                                   |\n\n|    157 | Mathiowetz V, Weber K, Kashman N, Volland G. 1985. Adult norms for the Nine Hole Peg T est of finger dexterity. Occup. Ther. J. Res. 5:24-38                                                                                                                                                                                                           |\n\n- 158. Lambercy O,Fluet MC,Lamers I,Kerkhofs L,Feys P, Gassert R. 2013. Assessment of upper limb motor function in patients with multiple sclerosis using the Virtual Peg Insertion T est: a pilot study. In 2013 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/\n",
    "topic": "Methods for restoring naturalistic sensory feedback in upper limb prostheses and their effects on embodiment and manual dexterity in amputees.",
    "response": "<document_analysis>\nThe provided context is a comprehensive bibliography and acknowledgments section from a scholarly review related to robotic hands and upper limb prostheses, with an extensive list of cited literature addressing various aspects of prosthetic design, control, sensory feedback, neural interfaces, and rehabilitation outcomes.\n\nCentral themes identifiable from the references and the few contextual statements include:\n- Development and control of robotic and prosthetic hands, including myoelectric and neural control methods.\n- Techniques for restoring sensory feedback in prostheses, such as intraneural stimulation, vibrotactile feedback, and electrotactile feedback.\n- The impact of sensory feedback restoration on embodiment\u2014the sense of ownership of the prosthetic limb\u2014and manual dexterity.\n- Neurophysiological and engineering approaches for bidirectional prosthetic control.\n- Clinical and functional outcome assessments related to prosthesis use and acceptance.\n\nImplicit in this content is the understanding that restoring naturalistic sensory feedback is crucial for improving the functional integration of prostheses, reducing device abandonment, and enhancing user experience through embodiment and improved dexterity.\n\nGiven the complexity and breadth of the references, a challenging question can be formulated that probes the nuanced understanding of how different sensory feedback methods influence embodiment and manual dexterity, referencing the underlying mechanisms and comparative outcomes.\n\nDifficulty rating: 9/10 due to the necessity for expert knowledge in neuroprosthetics, sensory feedback technologies, and clinical rehabilitation effects.\n\nThe question should encourage critical reflection on the mechanisms by which sensory feedback modalities affect user perception and function, and the implications for prosthetic design.\n\nNo irrelevant or bogus information detected; content is highly meaningful and suitable for question generation.\n</document_analysis>\n\n<output_format>\nQuestion: How do biomimetic intraneural sensory feedback approaches compare to non-invasive vibrotactile methods in enhancing embodiment and manual dexterity in upper limb amputees using prosthetic hands, and what neural mechanisms underlie these differences?\n\nExplanation: Biomimetic intraneural sensory feedback directly stimulates peripheral nerves in a manner that closely mimics natural sensory input, leading to enhanced sensation naturalness, improved tactile sensitivity, and superior manual dexterity compared to non-invasive vibrotactile feedback, which provides indirect and less natural sensory cues; the intraneural approach facilitates more precise somatotopic and modality-specific activation of afferent fibers, promoting stronger embodiment through more authentic sensory integration in the central nervous system.\n\nCorrect Answer: Biomimetic intraneural sensory feedback provides more natural, modality-specific sensations that improve embodiment and manual dexterity better than non-invasive vibrotactile methods by directly stimulating peripheral nerves to mimic natural afferent input.\n</output_format>",
    "question": "How do biomimetic intraneural sensory feedback approaches compare to non-invasive vibrotactile methods in enhancing embodiment and manual dexterity in upper limb amputees using prosthetic hands, and what neural mechanisms underlie these differences?",
    "answer": "Biomimetic intraneural sensory feedback provides more natural, modality-specific sensations that improve embodiment and manual dexterity better than non-invasive vibrotactile methods by directly stimulating peripheral nerves to mimic natural afferent input.",
    "explanation": "Biomimetic intraneural sensory feedback directly stimulates peripheral nerves in a manner that closely mimics natural sensory input, leading to enhanced sensation naturalness, improved tactile sensitivity, and superior manual dexterity compared to non-invasive vibrotactile feedback, which provides indirect and less natural sensory cues; the intraneural approach facilitates more precise somatotopic and modality-specific activation of afferent fibers, promoting stronger embodiment through more authentic sensory integration in the central nervous system.",
    "question_token_count": 47,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 46
  },
  {
    "context": "## 5.5. Perspectives\nWe believe that sensorization will play a significant role in the next generation of RPHs. Here, we discuss three main directions influenced by sensorization: embedded sensorization, improved stimulation strategies, and new computational architectures.\n\n5.5.1. Embedded sensorization. Sensorized hands are not yet prevalent in the literature but are starting to draw interest, especially with the improvement of interfaces for bidirectional prostheses (for a list of RPHs with sensorized fingertips, see Supplemental Tables 1 and 2 ). As a recent example, Controzzi et al. (141) developed the Mia hand (Prensilia, Italy), which is integrated with sensors that can measure normal and tangential forces at the fingertips. Sensorization of RPHs is a design requirement that should be considered as important as other functional requirements for hand prostheses, such as weight or dexterity. T o improve RPH performance and sensor integration, next-generation RPHs should then be designed with their sensorization in mind. Information about hand state (joint position, forces, and touch) can also be beneficial to increase the dexterity of such hands, enabling automatic adjustments such as catching slipping objects (e.g., the bebionic3 hand) and shared-control strategies (see Section 4).\n\n5.5.2. Improved stimulation strategies. Biomimicry is one of the strongest trends in nerve stimulation strategies, as it promises to deliver biologically plausible stimulation patterns to evoke more natural sensations. Biomimetic approaches rely on bio-inspired models to compute the stimulation patterns, so new iterations of these models, based on the current experience in stimulation and neural recording, are needed to improve the quality of elicited sensations.\n\nThese model-based approaches permit simpler modulation strategies that increase the naturalness of sensations. T an et al. (38), for example, proved that a sinusoidal modulation of the pulse width improves the naturalness of the sensation. Formento et al. (142) instead designed a strategy to activate asynchronously stimulated fibers, mimicking healthy neural activity; in their work, they replaced classical biphasic stimulation with a high-frequency burst of pulses that slowly increased in amplitude, and confirmed their hypothesis in ex vivo experiments. Stimulation patterns that try to overcome the physical limits of present neural interfaces (as in 142) while paving the way for more natural evoked sensations also suggest the requirements for the future generation of neural interfaces and stimulators for sensory feedback: increase reaching without losing discrimination.\n\n5.5.3. New computational architectures. Neuromorphic architectures have the potential to represent a paradigm shift in the design of the control systems for bidirectional hand prostheses, going toward distributed systems and edge computing. Both sensor acquisition and stimulation can benefit from these trends because they lead to more reliable systems that scale well with the increase of sensors and stimulation active sites. If the next generation of neuromorphic hardware promotes portability and lower power consumption, it could lead to broader implementation and adoption of neuromorphic systems in bidirectional hand prostheses.\n\nMany RPHs rely on advanced encoding and decoding algorithms implemented with neural networks (62), which are more computationally demanding than traditional approaches. It is interesting that even deep learning networks can be translated into spiking neural networks (143), possibly enabling full neuromorphic hardware encoding and decoding in future prostheses.\n",
    "topic": "The implications of neuromorphic hardware portability and low power consumption on the adoption and scalability of advanced prosthetic control systems.",
    "response": "<document_analysis>\nThe context discusses future perspectives in the development of robotic prosthetic hands (RPHs), focusing on three directions influenced by sensorization: embedded sensorization, improved stimulation strategies, and new computational architectures. The segment on new computational architectures highlights neuromorphic architectures as a potential paradigm shift for bidirectional prostheses control systems. These architectures support distributed systems and edge computing, which enhance reliability and scalability with increasing sensors and stimulation sites. Crucially, the text notes that if neuromorphic hardware achieves portability and low power consumption, it could lead to broader implementation and adoption in RPHs. This is significant because current advanced encoding and decoding algorithms, often implemented with neural networks, are computationally demanding. The possibility of translating deep learning networks into spiking neural networks suggests full neuromorphic hardware implementations could become feasible.\n\nThis implies that overcoming current hardware limitations in power and portability is pivotal for scalability and widespread adoption of advanced prosthetic control systems. The question can challenge experts to analyze how these hardware characteristics affect system reliability, scalability, and practical deployment, linking computational theory to real-world prosthetic applications.\n\nDifficulty rating: 9/10, since it requires understanding neuromorphic computing, prosthetic control systems, neural network translation, and practical engineering constraints.\n\nThe question will encourage critical reflection on how hardware improvements influence prosthetic technology adoption and scalability, requiring synthesis of technical hardware constraints with prosthetic system design and clinical applicability.\n\nThis is meaningful and educationally valuable content with sufficient technical depth.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do improvements in neuromorphic hardware portability and low power consumption fundamentally influence the scalability and broader adoption of advanced bidirectional prosthetic hand control systems, particularly in relation to the integration of distributed sensor acquisition and neural stimulation sites?\n\nExplanation: Portability and low power consumption enable neuromorphic architectures to be implemented as compact, energy-efficient edge devices, making it feasible to embed them directly within prosthetic hands. This supports distributed processing of sensor data and stimulation commands close to the source, improving system reliability and responsiveness. Consequently, systems can scale to incorporate more sensors and stimulation sites without prohibitive power or size constraints, fostering broader adoption of advanced prostheses that rely on computationally demanding neural network algorithms.\n\nCorrect Answer: They enable compact, energy-efficient edge computing that supports scalable, reliable distributed processing of sensors and stimulation, facilitating wider adoption of advanced prosthetic control systems.\n</output_format>",
    "question": "How do improvements in neuromorphic hardware portability and low power consumption fundamentally influence the scalability and broader adoption of advanced bidirectional prosthetic hand control systems, particularly in relation to the integration of distributed sensor acquisition and neural stimulation sites?",
    "answer": "They enable compact, energy-efficient edge computing that supports scalable, reliable distributed processing of sensors and stimulation, facilitating wider adoption of advanced prosthetic control systems.",
    "explanation": "Portability and low power consumption enable neuromorphic architectures to be implemented as compact, energy-efficient edge devices, making it feasible to embed them directly within prosthetic hands. This supports distributed processing of sensor data and stimulation commands close to the source, improving system reliability and responsiveness. Consequently, systems can scale to incorporate more sensors and stimulation sites without prohibitive power or size constraints, fostering broader adoption of advanced prostheses that rely on computationally demanding neural network algorithms.",
    "question_token_count": 45,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 31
  },
  {
    "context": "## 5.4. Sensory Feedback\nIn basic myoelectric or body-powered prostheses, feedback is delivered mainly by visually inspecting the movements of the prosthesis and by the physical interaction between the device and the user (126), as with hook prostheses. Clearly, the goal of a modern RPH is to deliver richer information more intuitively.\n\nSensory feedback strategies are characterized by their precision and the coherence between the evoked sensation and the desired one in terms of timing (synchronicity), position (somatotopy), and modality (i.e., touch, vibration, and temperature). Feedback techniques encode sensor values to stimulation parameters, which in turn are strongly tied to the chosen stimulation interface ( Table 2 ). Here, we focus mainly on electrical interfaces for feedback, but we also briefly discuss the mechanical interfaces.\n\nNoninvasive feedback strategies are attractive approaches since they do not necessitate surgical interventions ( Figure 2 a ). Starting with the Boston Arm, which Mann &amp; Reimers (127) used to demonstrate that position feedback was needed for precise reaching movements, these techniques have improved in both mechanical and electrical interfaces with the user. Indeed, the intact mechanoreceptors in the skin of the arm can be stimulated with small linear (128) or vibrating (129) motors that vary in their driving amplitude and frequency. On the other hand, mechanical stimulation brings an unavoidable delay of approximately 400 ms in the delivery of the sensation (130), and the integration and miniaturization of mechanoreceptors are challenging. The miniaturization of noninvasive feedback approaches is also challenging.\n",
    "topic": "The technical considerations involved in encoding sensor data into stimulation parameters for feedback systems in prosthetics.",
    "response": "<document_analysis>\nThe context discusses sensory feedback in prosthetic hands, emphasizing the importance of encoding sensor data into stimulation parameters for effective feedback. Central ideas include the need for precision and coherence in timing (synchronicity), spatial location (somatotopy), and modality matching between the evoked and desired sensations. The relationship between sensor values and stimulation parameters is critical and is strongly influenced by the choice of stimulation interface, particularly electrical interfaces, while mechanical interfaces have limitations such as latency and miniaturization challenges. The subtle complexities of achieving synchronous, somatotopically relevant, and modality-appropriate feedback highlight the technical challenges in designing feedback systems. There is an implicit assumption that encoding sensor data into stimulation parameters requires careful consideration of the physiological and perceptual aspects of sensory feedback, as well as the engineering constraints of the stimulation devices.\n\nDifficulty rating: 9/10 due to the integration of neurophysiological, technical, and engineering considerations required to design effective feedback systems.\n\nThe question should probe the candidate\u2019s understanding of how sensor data is translated into meaningful and coherent sensory feedback, particularly how timing, spatial mapping, and modality constraints influence the encoding process and system design. It should encourage reflection on the interplay between sensor technology, stimulation interfaces, and user perception, as well as the technical trade-offs involved.\n\nThe question will invite critical engagement by asking about the key technical considerations in the encoding process, requiring synthesis of physiological and engineering knowledge and implications for prosthetic feedback design.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the key technical considerations in encoding sensor data into stimulation parameters for sensory feedback systems in prosthetics, and how do timing, spatial mapping, and modality coherence influence the design of these encoding strategies?\n\nExplanation: Effective encoding of sensor data into stimulation parameters must ensure that the evoked sensations are precise and coherent with the desired feedback in terms of timing (synchronicity), spatial location (somatotopy), and sensory modality (e.g., touch, vibration). Timing ensures the feedback is delivered synchronously with the prosthetic interaction to avoid perceptual delays; spatial mapping aligns the stimulation location with the natural sensory map on the user\u2019s body to provide intuitive feedback; and modality coherence guarantees that the type of sensation evoked matches the physical property being sensed, enhancing naturalness and usability. These considerations are tightly linked to the chosen stimulation interface and affect the parameters such as amplitude, frequency, and spatial distribution of the stimulus, making the encoding process a complex integration of physiological and technical constraints.\n\nCorrect Answer: Ensuring precise timing (synchronicity), correct spatial mapping (somatotopy), and modality coherence in stimulation parameters to produce intuitive, naturalistic feedback aligned with the sensed data. \n</output_format>",
    "question": "What are the key technical considerations in encoding sensor data into stimulation parameters for sensory feedback systems in prosthetics, and how do timing, spatial mapping, and modality coherence influence the design of these encoding strategies?",
    "answer": "Ensuring precise timing (synchronicity), correct spatial mapping (somatotopy), and modality coherence in stimulation parameters to produce intuitive, naturalistic feedback aligned with the sensed data.",
    "explanation": "Effective encoding of sensor data into stimulation parameters must ensure that the evoked sensations are precise and coherent with the desired feedback in terms of timing (synchronicity), spatial location (somatotopy), and sensory modality (e.g., touch, vibration). Timing ensures the feedback is delivered synchronously with the prosthetic interaction to avoid perceptual delays; spatial mapping aligns the stimulation location with the natural sensory map on the user\u2019s body to provide intuitive feedback; and modality coherence guarantees that the type of sensation evoked matches the physical property being sensed, enhancing naturalness and usability. These considerations are tightly linked to the chosen stimulation interface and affect the parameters such as amplitude, frequency, and spatial distribution of the stimulus, making the encoding process a complex integration of physiological and technical constraints.",
    "question_token_count": 41,
    "answer_correctness_score": 9,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 36
  },
  {
    "context": "## 4.1. Decoding Algorithms\nThe clinical standard for RPH control is based on the use of two sEMG channels, with the electrodes placed superficially on antagonist muscles. The envelope of the signal is extracted so that the user can control the closing and opening of the RPH by modulating the amplitude of their muscle contraction. When the amplitude exceeds a certain threshold, the RPH will move depending on which muscle was activated. Companies are offering more DOFs, using cocontraction to\n\ncycle through different types of grasps (e.g., Ottobock's Michelangelo hand). However, this type of control is highly nonintuitive and gives only low dexterity to the user. An alternative to this direct control approach is based on pattern recognition methods, extracting hand-crafted features to characterize the signal in a discriminative way (e.g., the signal root mean square, wavelength, and zero crossing) and classify the type of grasp intended by the user. This solution has become robust enough to reach the market (the Coapt system and Ottobock's Myo Plus). Using 2-12 bipolar sEMG electrodes makes it possible to obtain good classification rates for different kinds of grasps, with 90-95% accuracy for 4-12 classes and up to 75% for 50 classes (68-72).\n\nUsing a similar electrode disposition and classification method, other groups showed the possibility of decoding single-finger movement using the classification of flexion or extension (73, 74). Recently, Bhagwat &amp; Mukherji (75) showed single- and multifinger classification of 15 different movements with 99.79% accuracy. Researchers are also working on proportional control instead of classification, which makes it possible to decode several DOFs (e.g., wrist and finger movements) simultaneously and proportionally (76, 77). This type of control offers continuous position control. Several studies have also shown that single-finger proportional control is feasible, with good results (78, 79).\n\nAs an alternative, nonbiomimetic EMG decoders have been developed that rely on the subject learning inverse maps to relate motor outputs to arbitrary control variables (80). Using an abstract decoding cursor control space, subjects can learn to modulate their EMG activity to reach different targets arranged in a center-out task in order to trigger various grasping movements (81). Dyson et al. (82) recently validated these results on amputee participants; they showed that after training, the difficulty of the tasks could be increased, improving the possibilities for robotic hand control.\n\nWith only a few electrodes placed on muscles of interest, the accurate positioning of the electrodes requires anatomical knowledge; indeed, the type of amputation (congenital or traumatic), the surgical procedure, and the time since amputation (83) could influence the muscle anatomy and make the placement of the electrode tedious and specific to individual subjects. Moreover, a small shift in electrode placement can disrupt the pattern recognition algorithm (84). T o tackle these issues, several authors have proposed HD-sEMG, which consists of a grid of closely spaced electrodes, as an alternative solution. The large number of electrodes allows information to be recorded from a large part of the subject's forearm.\n\nHD-sEMG signals offer high spatial resolution, and recorded signals can be interpreted as spatial images of EMG activity. Using this image representation of EMG data, HD-sEMG is robust to small electrode shifts (85). Boschmann &amp; Platzner (85) used a structural similarity index, borrowed from the computer vision field, on HD-sEMG images combined with a simple one-against-one nearest-neighbor classifier to decode wrist and hand motions. Similarly, Stango et al. (86) used a variogram of images (a measure of the degree of spatial correlation, used mainly in geostatistics) to classify wrist movements. Both groups showed that their methods, which use spatial information from the images, performed better or similarly to the classic feature extraction approach. Moreover, their strategies improved the robustness to electrode shift and electrode number. The use of several spatially close electrodes makes it possible to decompose the EMG signal into its constituent motor unit action potential (50, 87). Kapelner et al. (88) investigated this approach, decomposing EMG signals to extract motor unit activity from forearm muscles during wrist motions. Recently, Dai &amp; Hu (89) showed that an approach consisting of finger joint angle estimation, combining classification for finger selection with EMG decomposition into motor unit activity, outperforms a standard amplitude-based approach.\n\nWe observe a paradigm shift from feature engineering to feature learning using raw data as input for deep neural networks. Studies have shown that combining this deep learning approach with HD-sEMG offers better performance than hand-crafted features in both grasp classification\n\n(90) and simultaneous single-finger and wrist movement classification (91). Deep learning has also shown good results with a smaller number of electrodes for grasp classification (72) and regression of arm or wrist motions (92, 93).\n\nThis approach permits both high dexterity and robustness, with unprecedented performance. However,one of the major difficulties of the deep learning approach is that it requires an extensive data set for training. For example, the deep learning used for the ImageNet challenge in 2012 used 1.2 million images for training on 1,000 categories (94). In the context of hand gesture recognition, generating tens of thousands of examples for a subject is not a viable option.\n\nA possible solution could use domain adaptation [often called transfer learning in the EMG literature (95, 96)], by leveraging data acquired from several subjects to enhance and accelerate training for a new user. Indeed, the aim is to use information from a database of several source domains and adapt it to a target domain (the end user) with a small number of samples. Authors generally apply deep domain adaptation (domain adaptation combined with deep learning) by pretraining a deep neural network and fine-tuning it with a few repetitions of movements by a target subject. The main idea is that gathering the recordings of several participants can meet the necessary conditions to learn a general mapping of all users' sEMG signals.\n\nUsing this idea, C\u00f4t\u00e9-Allard et al. (97) showed that their deep model was able to learn the features and significantly enhance the performance of deep networks on out-of-sample gestures. Using HD-sEMG and deep learning, Du et al. (98) also showed an unsupervised deep domain adaptation method that incrementally learns from data during a new session without explicit calibration of gestures. Consequently, deep learning offers a particularly attractive context from which to develop deep domain adaptation algorithms to leverage interuser data. This approach can increase decoding performance, improve robustness to electrode shift, and reduce the number of repetitions needed during training (99).\n\nAs seen in this section, the search for new EMG decoding algorithms that go beyond thresholdbased detection is an active field of research. Phinyomark &amp; Scheme (100) and Khamparia &amp; Singh (101) have reviewed recent research in EMG pattern recognition methods.\n\nMachine learning in the field of computer vision and object recognition has shown outstanding results using deep learning and is already used commercially by many companies. Some deep learning algorithms based on a pretrained network are now usable without any fine-tuning (e.g., self-driving cars). However, bio-signals are intrinsically different from images and need adaptation. More important, the amount of labeled EMG data available to effectively train deep networks might not be sufficient to capture the evolution of the signal over time (electrode displacement, skin impedance changes, etc.). Therefore, if model architectures and data processing are tailored for bio-signal applications and take into consideration signal evolution with time, deep learning can become a solution for more robust motor intention decoding.\n",
    "topic": "The concept of domain adaptation (transfer learning) in EMG decoding to leverage inter-subject data for improved training efficiency and robustness.",
    "response": "<document_analysis>\nThe context discusses various EMG decoding algorithms for robotic prosthetic hand (RPH) control, highlighting the transition from simple threshold-based control to sophisticated pattern recognition and deep learning methods. A key challenge identified is the requirement of large datasets for training deep neural networks, which is impractical for individual subjects due to the time and effort needed to collect extensive labeled EMG data. Domain adaptation, or transfer learning, emerges as a pivotal strategy to address this issue by leveraging data from multiple subjects (source domains) to improve training efficiency and robustness for a new user (target domain) with limited data. This approach involves pretraining on a large dataset and fine-tuning with minimal data from the new user, allowing models to generalize better across subjects, adapt to electrode shifts, and reduce calibration time. The context also mentions unsupervised deep domain adaptation methods that can incrementally learn without explicit calibration, further enhancing applicability. The nuanced discussion includes the challenges posed by bio-signals' variability over time and the necessity to tailor architectures to handle such dynamics.\n\nDifficulty rating: 9/10 due to the complex interplay of machine learning concepts, bio-signal variability, and practical implications for prosthetic control.\n\nThe planned question is designed to probe an expert\u2019s deep understanding of how domain adaptation mechanisms specifically address the limitations of deep learning in EMG decoding, including their impact on training efficiency, robustness to electrode shifts, and inter-subject variability. It also invites reflection on the unique challenges posed by bio-signals versus other data types and the practical significance of these methods in clinical and commercial prosthetic applications.\n\nThis question requires synthesis of advanced machine learning concepts applied in a biomedical context, making it highly challenging even for domain experts.\n</document_analysis>\n\n<output_format>\nQuestion: How does domain adaptation (transfer learning) enhance the training efficiency and robustness of deep learning models for EMG decoding across different subjects, and what unique challenges do bio-signals pose that this approach helps to mitigate?\n\nExplanation: Domain adaptation improves training efficiency by leveraging large datasets from multiple source subjects to pretrain deep learning models, which are then fine-tuned with minimal data from a new target user, reducing the need for extensive individual data collection. This approach increases robustness by enabling models to generalize across inter-subject variability and adapt to electrode shifts and changes in signal characteristics over time. Bio-signals, unlike images, exhibit high variability due to factors like electrode displacement and skin impedance changes, making consistent data collection difficult; domain adaptation helps overcome these challenges by learning a generalizable feature mapping that can be adapted to individual users with fewer samples.\n\nCorrect Answer: By pretraining on multi-subject data and fine-tuning on limited target data, domain adaptation enables deep models to generalize across subjects, improving robustness to electrode shifts and bio-signal variability, thus reducing required training data and enhancing decoder reliability.\n</output_format>",
    "question": "How does domain adaptation (transfer learning) enhance the training efficiency and robustness of deep learning models for EMG decoding across different subjects, and what unique challenges do bio-signals pose that this approach helps to mitigate?",
    "answer": "By pretraining on multi-subject data and fine-tuning on limited target data, domain adaptation enables deep models to generalize across subjects, improving robustness to electrode shifts and bio-signal variability, thus reducing required training data and enhancing decoder reliability.",
    "explanation": "Domain adaptation improves training efficiency by leveraging large datasets from multiple source subjects to pretrain deep learning models, which are then fine-tuned with minimal data from a new target user, reducing the need for extensive individual data collection. This approach increases robustness by enabling models to generalize across inter-subject variability and adapt to electrode shifts and changes in signal characteristics over time. Bio-signals, unlike images, exhibit high variability due to factors like electrode displacement and skin impedance changes, making consistent data collection difficult; domain adaptation helps overcome these challenges by learning a generalizable feature mapping that can be adapted to individual users with fewer samples.",
    "question_token_count": 43,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 47
  },
  {
    "context": "## 5.1. Sensors for Proprioception\nProprioception is not only fundamental for a dexterous hand prosthesis, enabling vision-free manipulation and multitasking, but is also the key to a properly embodied device (64). Usually, kinematic parameters of the robotic hand and (when available) the force exerted are needed to implement low-level control of the actuators, so they are measured with well-established systems, such as rotary encoders or the motor's current draw.\n\n\n## 5.2. Tactile Sensors\nDespite improvements in sensor miniaturization,computational power,and knowledge of the neurophysiology of somatosensation (tactile sensation and proprioception), the capabilities of sensorized RPHs remain far from those of a natural hand. Overcoming this limitation will require satisfying three conditions: The sensors must match the skin's sensing ability, a sufficient number of sensors must be embedded on the surface of the hand, and it must be possible to reliably read information from them. The first condition can be addressed with current technology, as the resolution of existing force and pressure sensors already matches human skin performance (120). However, fulfilling the second and third conditions is another matter, and we need to push the boundaries of circuit integration in order to create an RPH with many sensors and a way to communicate with them.\n\nThe classical solution of using general-purpose sensors developed separately from the signal conditioning circuit and the subsequent signal processing has shown its limit. Instead, efforts are being made to optimize these devices with prosthetics in mind. For example, borrowing the concept of morphological computation from robotics (121), sensors can be optimized for specific tasks by tuning the features of their mechanical structures accordingly. Indeed, exploiting the low-pass filtering effect of a compliant material or surfaces with specific structures can increase texture discrimination (61, 115). Another example comes from Kim et al. (122), who measured forces using sensors embedded in a soft substrate.\n\n)\n\nContinued\n\n(\n\n| Sensor distribution a                       |            |             |             |             |                  |              |                 |              |\n\n|---------------------------------------------|------------|-------------|-------------|-------------|------------------|--------------|-----------------|--------------|\n\n| Interface                                   | G10 tactor | TIME        | TENS        | TIME        | FINE             | TIME         | Vibrators       | TENS         |\n\n| Electrical stimulation encoding Pulse width | -          | Fixed       | Linear      | Fixed       | Time variant     | Fixed        | -               | Neuromorphic |\n\n| Amplitude                                   | -          | Linear      | Fixed       | Model based | Fixed            | Fixed        | -               | Fixed        |\n\n| Frequency                                   | -          | Fixed       | Fixed       | Model based | Linear           | Neuromorphic | -               | Neuromorphic |\n\n| Mechanical stimulation encoding             | Linear     | -           | -           | -           | -                | -            | Discrete events | -            |\n\n| RPH model                                   | Passive    | IH2 Azzurra | IH2 Azzurra | IH2 Azzurra | SensorHand Speed | IH2 Azzurra  | Various         | bebionic     |\n\n| Reference                                   | 4          | 6           | 60          | 62          | 38               | 61           | 129             | 59           |\n\n| Year                                        | 2011       | 2014        | 2017        | 2018        | 2014             | 2016         | 2016            | 2018         |\n",
    "topic": "The three critical conditions required for tactile sensors in robotic prosthetic hands to match the sensing capabilities of natural human skin.",
    "response": "<document_analysis>\nThe context discusses the challenges and requirements for tactile sensors in robotic prosthetic hands (RPHs) to approach the sensory capabilities of the natural human hand. It identifies three critical conditions for sensors to match human skin sensing: (1) sensor resolution matching skin ability, (2) sufficient sensor density on the prosthetic surface, and (3) reliable communication and reading of sensor data. The text highlights that current sensor technology can meet the first condition, but the second and third conditions remain significant hurdles, involving circuit integration and data communication challenges. The passage also touches on advances such as morphological computation and embedding sensors in compliant substrates to improve tactile sensing. The provided table, although partially visible, seems to relate to different RPHs and stimulation encoding modalities but does not directly expand on the three conditions. The question aims to probe deep understanding of these critical conditions and their implications, requiring synthesis beyond superficial recall. Difficulty is rated at 8/10 due to the need for integration of sensor technology, neurophysiological matching, and engineering constraints. The question encourages reflection on why each condition is essential and how they interplay to approach natural skin sensing capabilities.\n</document_analysis>\n\n<output_format>\nQuestion: What are the three essential conditions that tactile sensors in robotic prosthetic hands must fulfill to match the sensing capabilities of natural human skin, and why is each condition critical in overcoming current limitations?\n\nExplanation: The three conditions are: (1) sensors must have resolution comparable to human skin to accurately detect fine tactile details; (2) a sufficient number of sensors must be embedded on the prosthetic surface to provide comprehensive spatial coverage and detailed input akin to natural skin; (3) reliable reading and communication of sensor data are necessary to process and utilize the tactile information effectively. The first ensures sensory fidelity, the second guarantees the spatial density needed for detailed perception, and the third addresses the technical challenge of integrating and transmitting vast sensor data, which current systems struggle with.\n\nCorrect Answer: Matching skin-level sensor resolution, embedding sufficient sensor density on the prosthetic surface, and ensuring reliable communication and reading of sensor data.\n</output_format>",
    "question": "What are the three essential conditions that tactile sensors in robotic prosthetic hands must fulfill to match the sensing capabilities of natural human skin, and why is each condition critical in overcoming current limitations?",
    "answer": "Matching skin-level sensor resolution, embedding sufficient sensor density on the prosthetic surface, and ensuring reliable communication and reading of sensor data.",
    "explanation": "The three conditions are: (1) sensors must have resolution comparable to human skin to accurately detect fine tactile details; (2) a sufficient number of sensors must be embedded on the prosthetic surface to provide comprehensive spatial coverage and detailed input akin to natural skin; (3) reliable reading and communication of sensor data are necessary to process and utilize the tactile information effectively. The first ensures sensory fidelity, the second guarantees the spatial density needed for detailed perception, and the third addresses the technical challenge of integrating and transmitting vast sensor data, which current systems struggle with.",
    "question_token_count": 38,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 7,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 27
  },
  {
    "context": "## 7. CONCLUSION\nMorethan20years ago,remarkable results by a group of French surgeons for hand transplantation (8) had raised hopes for a future where grafting would be the norm and prosthetics eventually obsolete (176). However, not only has this prediction-unfortunately-not yet come to pass, but also the adoption of new RPH technologies has been slower than expected. As such, RPHs are still a field of active research. Significant efforts have been made to reduce their price and weight, improve their aesthetics and anthropomorphism, increase the robustness and accuracy of their motor intention decoding, and provide natural and accurate somatosensory feedback. We have proposed here an outline of possible iterations of RPHs for the next few years and for 5-10 years in the future.\n\nIn our view, there could soon be a broader integration of simple somatosensory feedback using mature implantable techniques, such as cuff electrodes. Motor decoding using machine learning and shared-control algorithms could permit continuous command of single fingers and broader sets of grasps. Ultimately, the next generation of prosthetics could use more advanced soft implantable electrodes, which could enable more sophisticated sensory encoding (proprioception, temperature perception, touch perception, and nociception) and motor decoding using, for example, deep learning techniques. But to reach this goal, the field must tackle significant challenges related to system integration, electronic miniaturization, computational power, surgical procedure, electrode robustness, the robotic hand itself, and the encoding of somatosensory information.\n",
    "topic": "The key technological challenges currently limiting the widespread adoption of robotic prosthetic hands (RPHs), including cost, weight, aesthetics, and anthropomorphism.",
    "response": "<document_analysis>\nThe conclusion section provides a reflective summary of the state of robotic prosthetic hands (RPHs) after more than two decades of development since the pioneering hand transplantation surgeries. It highlights that despite early optimism, RPH adoption remains limited and the field is still actively evolving. The text emphasizes several intertwined technological challenges impeding widespread use: high cost and weight, suboptimal aesthetics and anthropomorphism, limited robustness and accuracy in motor intention decoding, and inadequate somatosensory feedback. It also outlines promising future directions involving implantable electrodes for sensory feedback and advanced machine learning for motor decoding, but notes these are contingent upon overcoming significant barriers in system integration, miniaturization, computational power, surgical techniques, electrode durability, and sensory encoding strategies.\n\nThe implicit assumptions are that improving these technical aspects will drive broader adoption of RPHs and that current limitations are primarily technological rather than socio-economic. The document calls for multidisciplinary advances to harmonize the mechanical, electronic, computational, and surgical domains. The complexity level is high (rated 9/10) given the interdisciplinary expertise required to address these multifaceted problems.\n\nThe planned question will probe the candidate\u2019s ability to synthesize the multiple, complex technological challenges that currently restrict RPH adoption, requiring not only recall but critical integration of how these factors interrelate and impact practical deployment.\n\nThis question is highly relevant, sufficiently complex, and encourages deep reflection on the state-of-the-art and future needs of RPH technology.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the primary interconnected technological challenges currently limiting the widespread adoption of robotic prosthetic hands, and how do these challenges collectively impact the functional and practical deployment of these devices?\n\nExplanation: The main challenges include reducing cost and weight, improving aesthetics and anthropomorphism, enhancing the robustness and accuracy of motor intention decoding, and providing natural somatosensory feedback. These factors are interdependent; for example, achieving advanced sensory feedback requires sophisticated implantable electrodes and computational power, which influence device weight, complexity, and cost. Additionally, system integration, electronic miniaturization, surgical procedures, electrode durability, and the robotic hand design itself are critical barriers. Together, these challenges hinder the development of prosthetics that are functionally effective, comfortable, and acceptable to users, thus limiting widespread adoption.\n\nCorrect Answer: Cost, weight, aesthetics, anthropomorphism, motor decoding accuracy, somatosensory feedback, system integration, miniaturization, computational power, surgical challenges, and electrode robustness collectively limit widespread RPH adoption.\n</output_format>",
    "question": "What are the primary interconnected technological challenges currently limiting the widespread adoption of robotic prosthetic hands, and how do these challenges collectively impact the functional and practical deployment of these devices?",
    "answer": "Cost, weight, aesthetics, anthropomorphism, motor decoding accuracy, somatosensory feedback, system integration, miniaturization, computational power, surgical challenges, and electrode robustness collectively limit widespread RPH adoption.",
    "explanation": "The main challenges include reducing cost and weight, improving aesthetics and anthropomorphism, enhancing the robustness and accuracy of motor intention decoding, and providing natural somatosensory feedback. These factors are interdependent; for example, achieving advanced sensory feedback requires sophisticated implantable electrodes and computational power, which influence device weight, complexity, and cost. Additionally, system integration, electronic miniaturization, surgical procedures, electrode durability, and the robotic hand design itself are critical barriers. Together, these challenges hinder the development of prosthetics that are functionally effective, comfortable, and acceptable to users, thus limiting widespread adoption.",
    "question_token_count": 35,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 42
  },
  {
    "context": "## Table 2 ( Continued )\n| Sensor distribution a                       |                |                              |             |                  |\n\n|---------------------------------------------|----------------|------------------------------|-------------|------------------|\n\n| Interface                                   | FINE           | Utah Slanted Electrode Array | TIME        | Cuff electrode   |\n\n| Electrical stimulation encoding Pulse width | Fixed          | Fixed                        | Linear      | Fixed            |\n\n| Amplitude                                   | Fixed          | Fixed                        | Fixed       | Fixed            |\n\n| Frequency                                   | Linear         | Model based                  | Fixed       | Linear           |\n\n| Mechanical stimulation encoding             | -              | -                            | -           | -                |\n\n| RPH model                                   | VariPlus Speed | DEKA Luke                    | IH2 Azzurra | SensorHand Speed |\n\n| Reference                                   | 136            | 139                          | 64          | 138              |\n\n| Year                                        | 2018           | 2019                         | 2019        | 2020             |\n\nAbbreviations: FINE, flat interface nerve electrode; RPH, robotic prosthetic hand; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. a The positions of the pressure sensors are shown in green, the joints where force is measured are shown with solid red lines, and the joints where the position is read are shown with dashed blue lines.\n",
    "topic": "Assessment of referenced studies (by year and identifier) to understand research trends and technological progress in nerve electrode and prosthetic hand sensor design.",
    "response": "<document_analysis>\nThe provided context is a continuation of a table summarizing key technical characteristics of various nerve electrode interfaces and robotic prosthetic hands (RPH) from studies referenced by year and identifier. It lists four different interface types (FINE, Utah Slanted Electrode Array, TIME, and Cuff electrode) alongside their stimulation encoding parameters (pulse width, amplitude, frequency), the associated robotic prosthetic hand model, and the year of publication. The table notes the encoding strategy variations (fixed, linear, model-based) and the sensor distribution aspects related to pressure sensors, force-measuring joints, and position-reading joints. This data enables an analysis of the evolution in nerve electrode technology and prosthetic hand sensor design over time (2018-2020).\n\nKey themes include:\n- Variability in electrical stimulation encoding methods across interfaces and years.\n- The relationship between electrode type and prosthetic hand model.\n- Temporal trends in design complexity, such as model-based frequency encoding introduced in 2019.\n- The consistency of fixed amplitude encoding across all interfaces.\n- The absence of mechanical stimulation encoding in these models.\n\nThe implicit assumption is that changes in encoding methods and interface designs reflect technological progress aiming for improved prosthetic control and sensory feedback. The variations in stimulation frequency encoding strategies suggest a research trend toward more biologically inspired or adaptive control methods.\n\nDifficulty is rated at 8/10 due to the need to integrate technical knowledge of neural interfaces, prosthetic design, and interpret subtle trends in research progression from sparse tabular data.\n\nA highly challenging question could ask for critical reflection on how the evolution of electrical stimulation encoding strategies from 2018 to 2020, as represented by these studies, reflects broader trends in prosthetic hand sensory integration and control sophistication.\n\nThe question must push a domain expert to synthesize the implications of fixed versus model-based encoding approaches and relate them to technological advancements in prosthetic interfaces across the referenced years.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the progression from fixed to model-based electrical stimulation frequency encoding in nerve electrode interfaces between 2018 and 2019 reflect broader advancements in prosthetic hand sensorimotor integration, and what implications does this have for the design of more adaptive and biomimetic prosthetic control systems?\n\nExplanation: The shift from fixed or linear frequency encoding (2018) to model-based encoding (2019) indicates a move towards more sophisticated, biologically inspired stimulation strategies that can better replicate natural neural signaling patterns, enhancing sensory feedback and motor control in prosthetic hands. This evolution reflects an increased focus on adaptive, context-sensitive control systems capable of more nuanced interactions with the user's nervous system, thereby advancing the biomimicry and functional integration of prosthetic devices.\n\nCorrect Answer: It signifies a transition towards adaptive, biologically inspired stimulation methods enhancing sensory feedback and control, enabling more biomimetic and sophisticated prosthetic sensorimotor integration.\n</output_format>",
    "question": "How does the progression from fixed to model-based electrical stimulation frequency encoding in nerve electrode interfaces between 2018 and 2019 reflect broader advancements in prosthetic hand sensorimotor integration, and what implications does this have for the design of more adaptive and biomimetic prosthetic control systems?",
    "answer": "It signifies a transition towards adaptive, biologically inspired stimulation methods enhancing sensory feedback and control, enabling more biomimetic and sophisticated prosthetic sensorimotor integration.",
    "explanation": "The shift from fixed or linear frequency encoding (2018) to model-based encoding (2019) indicates a move towards more sophisticated, biologically inspired stimulation strategies that can better replicate natural neural signaling patterns, enhancing sensory feedback and motor control in prosthetic hands. This evolution reflects an increased focus on adaptive, context-sensitive control systems capable of more nuanced interactions with the user's nervous system, thereby advancing the biomimicry and functional integration of prosthetic devices.",
    "question_token_count": 59,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 32
  },
  {
    "context": "## Neuroprosthesis:\na device that connects to the nervous system and either replaces missing parts of it or improves it\n\n\n## 1. INTRODUCTION\nDecades of research on robotic prosthetic hands (RPHs) have led to a paradoxical situation: On the one hand, the development of novel RPHs is among the most exciting fields of robotics (1), but on the other hand, the vast majority of amputee patients still use technologies that have changed little in almost half a century. However, this apparent discrepancy might seem less surprising when considering the immense challenge of developing a prosthetic that can mimic the functions of a hand. Indeed, the hand has one of the largest sensory representations in the brain, and grasping is among the most complex coordination tasks (2); the hand has both the highest density of mechanoreceptors in the human body (see the sidebar titled Skin Mechanoreceptors) and the largest number of degrees of freedom (DOFs); and the hand permits people to both experience the surrounding world and shape it.\n\nThe challenges are multiple and intricate, and they can be overcome only by combining advanced mechatronic solutions for dexterous and highly sensorized robotic hands with new approaches for robust and effective interfaces with users' nervous systems to allow seamless naturalartificial integration. As such, several viable solutions can emerge from this multidimensional optimization problem.\n\nTremendous efforts have been made in the past 20 years on the quest for an RPH that is easy to wear, comfortable, and intuitive to control. The design of such a device can be considered a compromise among dexterity, robustness, and usability (3). In the past 5 years, another aspect has been proposed by researchers as an essential milestone: sensorization. Indeed, feedback systems can increase both the acceptability and the performance of the new generation of RPHs (4-6).\n\nThis review summarizes the main achievements in this field. In particular, after providing an overview of the existing neuroprostheses and their characteristics, we focus on four central aspects: ( a ) stable interfaces that enable a new connection with the nervous system to record neural signals and stimulate neural structures, ( b ) algorithmic strategies for decoding motor intentions, ( c ) RPH sensorization plus encoding strategies to convey somatosensory feedback, and ( d ) assessment methods to measure the efficacy of a given strategy or technology. Throughout the review, we keep a patient-centered perspective and ask ourselves, Does a novel approach significantly improve the subjects' quality of life? Is it easy to learn and natural to use? And does it improve their independence? On a technical aspect, our goal is to provide a critical view of the most advanced technologies and a perspective on future implementations of RPHs.\n",
    "topic": "Explain the emerging importance of sensorization and somatosensory feedback in enhancing the acceptability and performance of modern robotic prosthetic hands.",
    "response": "<document_analysis>\nThe context discusses the development of robotic prosthetic hands (RPHs) and highlights the complexity of replicating the human hand's functionality due to its high sensory representation in the brain, dense mechanoreceptor distribution, and many degrees of freedom. It notes the historical stagnation of prosthetic technology despite advances and explains that recent efforts focus on achieving a balance among dexterity, robustness, and usability. Crucially, the text identifies sensorization\u2014integrating sensory feedback systems\u2014as a newly emphasized milestone within the last five years. This sensorization aims to provide somatosensory feedback, improving both performance and user acceptability by enabling more natural and intuitive control of prosthetics. The text also stresses the importance of interfaces with the nervous system and encoding strategies for conveying feedback, which suggests that feedback systems are central to bridging the gap between artificial and natural hand functionality. The challenge is multidisciplinary, involving hardware, neural interfaces, and algorithmic decoding. The question is highly technical and probes understanding of why sensorization and somatosensory feedback are transformative in prosthetic development, demanding synthesis of neurophysiology, robotics, and user-centered design. Difficulty rating: 9/10 due to the need for deep understanding of neuroprosthetics and sensory feedback integration. The question invites reflection on the impact of sensory feedback in enhancing prosthetic performance and user quality of life, linking technological advances to clinical and user outcomes.\n</document_analysis>\n\n<output_format>\nQuestion: How does the integration of sensorization and somatosensory feedback in robotic prosthetic hands fundamentally enhance both the functional performance and user acceptability compared to traditional prosthetics, and what are the underlying neurophysiological principles that justify this emerging emphasis?\n\nExplanation: Sensorization provides robotic prosthetics with the ability to convey sensory information back to the user, enabling more natural, intuitive control and improved motor coordination by mimicking the hand\u2019s rich sensory input. This feedback loop increases the prosthetic\u2019s usability and acceptance by allowing users to perceive touch and proprioception, which are critical for complex grasping and manipulation tasks due to the hand\u2019s high density of mechanoreceptors and extensive brain sensory representation.\n\nCorrect Answer: By enabling bidirectional sensory feedback that replicates natural touch and proprioception, sensorization improves motor control precision and intuitiveness, thereby enhancing performance and user acceptance, grounded in the hand\u2019s dense mechanoreceptor network and large cortical sensory representation.\n</output_format>",
    "question": "How does the integration of sensorization and somatosensory feedback in robotic prosthetic hands fundamentally enhance both the functional performance and user acceptability compared to traditional prosthetics, and what are the underlying neurophysiological principles that justify this emerging emphasis?",
    "answer": "By enabling bidirectional sensory feedback that replicates natural touch and proprioception, sensorization improves motor control precision and intuitiveness, thereby enhancing performance and user acceptance, grounded in the hand\u2019s dense mechanoreceptor network and large cortical sensory representation.",
    "explanation": "Sensorization provides robotic prosthetics with the ability to convey sensory information back to the user, enabling more natural, intuitive control and improved motor coordination by mimicking the hand\u2019s rich sensory input. This feedback loop increases the prosthetic\u2019s usability and acceptance by allowing users to perceive touch and proprioception, which are critical for complex grasping and manipulation tasks due to the hand\u2019s high density of mechanoreceptors and extensive brain sensory representation.",
    "question_token_count": 49,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 47
  },
  {
    "context": "## 2. ROBOTIC HANDS\nFollowing a limb amputation, three solutions are generally considered: passive cosmetic limbs ( Figure 1 a ); mechanical hands, often with hooks ( Figure 1 b ); and RPHs ( Figure 1 c-g ). In a\n\n\n## SKIN MECHANORECEPTORS\nThe skin has four types of mechanoreceptors, which are sensitive to different stimuli and therefore involved in different sensory functions: Merkel disks (which sense skin indentation, fine touch, and texture perception), Ruffini capsules (which sense skin stretch), Pacinian corpuscles (which sense vibration), and Meissner corpuscles (which sense dynamic deformation and slipperiness). Merkel disks and Ruffini capsules are slow-adapting receptors, meaning that they fire continuously during tactile stimuli, with a firing rate related to the pressure applied in their receptive field. Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond mostly to changes in applied pressure or brief stimuli.\n\na\n\nd\n\nPercutaneous leads\n\nFINE\n\nAgonist/antagonist myoelectric control\n\nSingle-DOF\n\nprosthetic hand\n\nAperture sensor\n\nExternal\n\nPressure sensors stimulator\n\nh\n",
    "topic": "Potential applications of mechanoreceptor adaptation properties in the design of tactile sensors for prosthetic devices aimed at replicating human touch sensations.",
    "response": "<document_analysis>\nThe context discusses types of mechanoreceptors in the skin, detailing their sensory modalities and adaptation properties: Merkel disks and Ruffini capsules are slow-adapting, providing continuous feedback proportional to pressure; Pacinian and Meissner corpuscles are fast-adapting, responding primarily to dynamic changes in stimuli. This classification is crucial for replicating human tactile sensation in prosthetic devices. The implicit understanding is that designing tactile sensors for prosthetics could leverage these distinct adaptation characteristics to mimic natural touch more accurately. The context also briefly references prosthetic hand types and control schemes, indicating potential integration of sensory feedback. The complexity arises in applying neurophysiological principles of mechanoreceptor function to engineering tactile sensors in prosthetic hands to achieve nuanced touch perception. This demands deep knowledge of sensory physiology, sensor design, and prosthetic control integration.\n\nDifficulty rating: 9/10 due to interdisciplinary synthesis and application of sensory adaptation properties in advanced prosthetic design.\n\nThe question will probe how the slow- and fast-adapting mechanoreceptor properties can be strategically utilized in tactile sensor arrays to reproduce continuous pressure sensation and transient dynamic touch cues, encouraging reflection on sensor types, signal processing, and feedback mechanisms relevant to prosthetics.\n\nThis invites experts to integrate physiological knowledge with engineering and prosthetic application, highlighting the importance of adaptation rates in replicating natural tactile feedback.\n\n</document_analysis>\n\n<output_format>\nQuestion: How can the distinct slow-adapting and fast-adapting properties of Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles be strategically applied in the design of tactile sensors for prosthetic hands to effectively replicate the continuous pressure and dynamic touch sensations of human skin?\n\nExplanation: Slow-adapting receptors like Merkel disks and Ruffini capsules provide continuous feedback proportional to sustained pressure, so sensors mimicking them should maintain steady output during static contact; fast-adapting receptors like Pacinian and Meissner corpuscles respond to transient changes, so sensors replicating them must detect rapid variations such as vibrations or slip, enabling prosthetic hands to convey both steady and dynamic tactile information essential for nuanced touch.\n\nCorrect Answer: By designing tactile sensors that replicate slow-adapting receptors for continuous pressure sensing and fast-adapting receptors for dynamic stimulus detection, prosthetics can deliver both sustained touch and transient tactile cues mirroring human skin sensation.\n</output_format>",
    "question": "How can the distinct slow-adapting and fast-adapting properties of Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles be strategically applied in the design of tactile sensors for prosthetic hands to effectively replicate the continuous pressure and dynamic touch sensations of human skin?",
    "answer": "By designing tactile sensors that replicate slow-adapting receptors for continuous pressure sensing and fast-adapting receptors for dynamic stimulus detection, prosthetics can deliver both sustained touch and transient tactile cues mirroring human skin sensation.",
    "explanation": "Slow-adapting receptors like Merkel disks and Ruffini capsules provide continuous feedback proportional to sustained pressure, so sensors mimicking them should maintain steady output during static contact; fast-adapting receptors like Pacinian and Meissner corpuscles respond to transient changes, so sensors replicating them must detect rapid variations such as vibrations or slip, enabling prosthetic hands to convey both steady and dynamic tactile information essential for nuanced touch.",
    "question_token_count": 61,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 6,
    "avg_answer_token_count": 44
  },
  {
    "context": "## 2.1. Existing Robotic Prosthetic Hands\nNumerous commercially available RPH solutions use underactuated mechanisms ( Supplemental Table 1 ), including the Michelangelo prosthetic hand (Ottobock, Germany), the i-Limb Ultra (\u00d6ssur, Iceland), the bebionic hand (Ottobock), and the VINCENT evolution 3 (Vincent Systems, Germany). Despite remarkable advances, there is still arguably a trade-off between dexterity and weight in these solutions, with companies usually emphasizing one aspect or the other.\n\nMany research groups are currently working on innovative solutions to tackle the dexterity/ weight dilemma (19), such as the use of a monolithic 3D-printed soft material (20) or mechanical solutions to implement finger synergies via clutches (21). For example, Jing et al. (19) proposed an anthropomorphic RPH using only three motors that could achieve 13 grasp types while weighing only approximately 130 g.\n\nThe price of RPHs is an additional limiting factor for broader adoption by patients. With most advanced solutions costing $10,000-20,000, many researchers advocate for cheaper solutions, particularly for emerging countries (e.g., 22).\n\nOpen source RPHs are an exciting alternative to dramatically reduce the cost of development and distribution. One particularly interesting aspect of such hands is simplified maintenance and repairs (using, e.g., 3D printing) that do not rely on specific suppliers. For example, Open\n\nBionics (United Kingdom) commercializes solutions for transradial amputees (e.g., the medically certified Hero Arm) but also provides the source files for some of their designs, and e-NABLE ( https://enablingthefuture.org ) reports 8,000 recipients of their prosthetics, which were built by volunteers around the world. Open source RPHs also enable users to alter the design to meet their unique needs; for example, the Galileo Hand (23) allows easy customization of the types of movements and number of electromyography (EMG) electrodes.\n\nResearchers are also working on better mechanical solutions to improve RPH dexterity. An underactuated hand prosthesis designed by Abayasiri et al. (24) has finger abduction and adduction to enable it to grasp larger objects, and an adaptive prosthetic hand designed by Yong et al. (25) adds DOFs in the palm with movable metacarpals. The Karlsruhe Institute of T echnology (KIT) prosthetic hand (26) has an embedded camera and real-time object recognition, enabling the hand to be preshaped. Pneumatic artificial muscle (27) permits the development of light, compact solutions. Finally, biomimetic actuation is used for muscle-like actuators (15).\n\nIn addition to the hardware aspect, there are also innovations in RPH control and sensorization. Low-level controllers use information about the state of the device and eventually activate the actuation to meet the desired state imposed by the user's intentions. The choice of the state variable has a strong influence on how the device works. Position or speed can be read through encoders of each joint and controlled; these are straightforward approaches that have been used broadly in robotic applications. When the interaction of the hand with the external environment is of interest, more advanced control systems are implemented, such as torque or impedance control. Both approaches measure the force applied by the actuator, controlling it directly in the first case and simulating compliance in the second. Advanced control strategies enable complex manipulation and smoother gestures at the expense of a bulkier mechanical structure and a more complex control system. Therefore, enabling more sophisticated control requires integrated force and position sensors, which have been previously developed mainly to close the robotic control loop (28).\n\nIn summary, low-cost and light hands have flourished over the last few years. The race to simplify designs and reduce costs through 3D printing should not impact the dexterity of RPHs. For now, underactuated mechanisms are the best solution for RPHs and innovative designs based on synergy mechanisms or friction, the latter of which can help increase the number of DOAs without increasing the number of motors.\n",
    "topic": "Discuss the significance of open-source robotic prosthetic hands, including how 3D printing and community involvement contribute to customization, maintenance, and cost reduction.",
    "response": "<document_analysis>\nThe provided context offers an in-depth discussion about the state of robotic prosthetic hands (RPHs), focusing on their mechanical design, control systems, and cost factors. A significant portion of the text centers on open-source RPHs as an alternative to expensive commercial products, highlighting their potential for cost reduction, customization, and maintenance advantages. The mention of 3D printing and community-driven initiatives such as e-NABLE illustrates how open-source models enable easier repairs and personalized adaptations without dependence on proprietary supply chains. This fosters accessibility, especially in emerging countries, and empowers users to tailor prosthetics to their unique needs. The text also notes how open-source hands simplify maintenance by allowing users or local technicians to print replacement parts and modify designs, which is critical for broader adoption. The analysis reveals a complex interplay between technological innovation (like synergy mechanisms), economic barriers, and social/community factors. The question should probe not just the factual benefits but also the underlying mechanisms\u2014how 3D printing and community involvement uniquely contribute to these outcomes, and why this matters in the broader context of prosthetic development and accessibility.\n\nDifficulty: 9/10 \u2014 The question requires synthesis of mechanical, economic, and social insights, demanding a nuanced understanding of prosthetic technology, manufacturing, and healthcare accessibility challenges.\n\nThe question invites deep reflection on the transformative potential of open-source models combined with additive manufacturing and community participation, pushing experts to consider both technical and societal implications.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do open-source robotic prosthetic hands leverage 3D printing and community involvement to enhance customization, simplify maintenance, and reduce costs, and why are these factors critical for expanding prosthetic accessibility?\n\nExplanation: Open-source RPHs provide source files that enable users and volunteers worldwide to print and modify prosthetic components using 3D printing, which drastically lowers production costs and reliance on specialized suppliers. Community involvement, exemplified by global volunteer networks, facilitates widespread distribution and individualized customization to meet unique user needs. Simplified maintenance arises from the ability to locally produce replacement parts and adapt designs, reducing downtime and expenses. These factors are crucial because commercial RPHs are often prohibitively expensive and less adaptable, limiting access especially in emerging countries; thus, open-source models democratize prosthetic availability by combining affordable manufacturing with user-driven design flexibility.\n\nCorrect Answer: They use 3D printing and global community networks to enable low-cost production, easy local repairs, and personalized design modifications, making prosthetics more affordable and accessible worldwide.\n</output_format>",
    "question": "How do open-source robotic prosthetic hands leverage 3D printing and community involvement to enhance customization, simplify maintenance, and reduce costs, and why are these factors critical for expanding prosthetic accessibility?",
    "answer": "They use 3D printing and global community networks to enable low-cost production, easy local repairs, and personalized design modifications, making prosthetics more affordable and accessible worldwide.",
    "explanation": "Open-source RPHs provide source files that enable users and volunteers worldwide to print and modify prosthetic components using 3D printing, which drastically lowers production costs and reliance on specialized suppliers. Community involvement, exemplified by global volunteer networks, facilitates widespread distribution and individualized customization to meet unique user needs. Simplified maintenance arises from the ability to locally produce replacement parts and adapt designs, reducing downtime and expenses. These factors are crucial because commercial RPHs are often prohibitively expensive and less adaptable, limiting access especially in emerging countries; thus, open-source models democratize prosthetic availability by combining affordable manufacturing with user-driven design flexibility.",
    "question_token_count": 40,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 9,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 35
  },
  {
    "context": "## 7. CONCLUSION\nMorethan20years ago,remarkable results by a group of French surgeons for hand transplantation (8) had raised hopes for a future where grafting would be the norm and prosthetics eventually obsolete (176). However, not only has this prediction-unfortunately-not yet come to pass, but also the adoption of new RPH technologies has been slower than expected. As such, RPHs are still a field of active research. Significant efforts have been made to reduce their price and weight, improve their aesthetics and anthropomorphism, increase the robustness and accuracy of their motor intention decoding, and provide natural and accurate somatosensory feedback. We have proposed here an outline of possible iterations of RPHs for the next few years and for 5-10 years in the future.\n\nIn our view, there could soon be a broader integration of simple somatosensory feedback using mature implantable techniques, such as cuff electrodes. Motor decoding using machine learning and shared-control algorithms could permit continuous command of single fingers and broader sets of grasps. Ultimately, the next generation of prosthetics could use more advanced soft implantable electrodes, which could enable more sophisticated sensory encoding (proprioception, temperature perception, touch perception, and nociception) and motor decoding using, for example, deep learning techniques. But to reach this goal, the field must tackle significant challenges related to system integration, electronic miniaturization, computational power, surgical procedure, electrode robustness, the robotic hand itself, and the encoding of somatosensory information.\n",
    "topic": "The robustness and longevity issues of implantable electrodes and their impact on the reliability of sensory feedback and motor control in prosthetic hands.",
    "response": "<document_analysis>\nThe conclusion highlights the slow progress and ongoing challenges in the field of robotic prosthetic hands (RPHs), particularly emphasizing the integration of somatosensory feedback and motor decoding capabilities via implantable electrodes. It mentions that while mature implantable techniques like cuff electrodes enable simple somatosensory feedback, the future aims to use advanced soft implantable electrodes for more sophisticated sensory modalities and motor control using deep learning. A critical challenge identified is electrode robustness, which directly impacts system integration, reliability, and longevity of sensory feedback and motor control. The complexity involves balancing miniaturization, surgical feasibility, and maintaining stable, accurate encoding of sensory signals and motor intentions over time. This issue is central to advancing prosthetics from experimental to routine clinical use, affecting both user experience and device performance. The question can probe understanding of how electrode robustness influences these factors and the broader implications for prosthetic reliability and acceptance.\n\nDifficulty rating: 9/10 - The question demands deep knowledge of neuroprosthetics, bioelectronics, sensory encoding, and their interplay in clinical and technical contexts.\n\nThe question should invite reflection on the critical role of electrode durability, how its failure modes degrade prosthetic function, and the technological and biological challenges involved in ensuring consistent sensory-motor integration over long periods.\n\nThis approach ensures a highly challenging, insightful question that tests expertise on the nuanced technical and clinical consequences of implantable electrode robustness in advanced prosthetic hands.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the robustness and longevity of implantable electrodes critically influence the reliability of sensory feedback and motor control in advanced prosthetic hands, and what are the primary challenges in maintaining this reliability over time?\n\nExplanation: Implantable electrodes serve as the interface for both decoding motor intentions and delivering somatosensory feedback; their robustness directly affects signal fidelity and stability. Degradation or failure of these electrodes can cause signal loss or noise, leading to inaccurate motor commands and unreliable sensory feedback, which diminishes prosthetic functionality and user trust. Maintaining reliability is challenged by biological responses (e.g., tissue encapsulation), mechanical wear, miniaturization limits, surgical implantation constraints, and the need for stable long-term electrical properties in a dynamic physiological environment.\n\nCorrect Answer: Electrode robustness determines stable, high-fidelity neural interfacing essential for consistent sensory-motor function, but is challenged by biological tissue reactions, mechanical degradation, and technological limits impacting long-term prosthetic reliability.\n</output_format>",
    "question": "How do the robustness and longevity of implantable electrodes critically influence the reliability of sensory feedback and motor control in advanced prosthetic hands, and what are the primary challenges in maintaining this reliability over time?",
    "answer": "Electrode robustness determines stable, high-fidelity neural interfacing essential for consistent sensory-motor function, but is challenged by biological tissue reactions, mechanical degradation, and technological limits impacting long-term prosthetic reliability.",
    "explanation": "Implantable electrodes serve as the interface for both decoding motor intentions and delivering somatosensory feedback; their robustness directly affects signal fidelity and stability. Degradation or failure of these electrodes can cause signal loss or noise, leading to inaccurate motor commands and unreliable sensory feedback, which diminishes prosthetic functionality and user trust. Maintaining reliability is challenged by biological responses (e.g., tissue encapsulation), mechanical wear, miniaturization limits, surgical implantation constraints, and the need for stable long-term electrical properties in a dynamic physiological environment.",
    "question_token_count": 40,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 41
  },
  {
    "context": "## Figure 2\nA neural interface and the target area for somatosensory feedback. ( a ) Noninvasive strategies include tactors targeting Meissner corpuscles and encoding pressure (4), vibrators that activate Pacinian corpuscle mechanoreceptors (129), and TENS (59), which targets the nerve noninvasively. ( ) Invasive peripheral b nervous system stimulation can be done with cuff electrodes (138) or FINEs (38, 136) that stimulate the nerve from outside the fiber. TIMEs (6, 60, 61, 64, 181) and Utah Slanted Electrode Arrays (182) are more invasive and are inserted through the nerve but stimulate directly from inside the fiber. ( ) Epidural c stimulation of the lateral spinal cord at the cervical level was able to induce tactile sensation in three upperarm amputees (140). Abbreviations: FINE, flat interface nerve electrode; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. Nerve designs in panels a and b adapted with permission from Reference 42; images created with BioRender.com.\n\nElectrical stimulation is usually delivered as train pulses, of which width, amplitude, and frequency can be independently modulated and can be conveyed noninvasively through the skin; this technique is generally known as electrotactile feedback (131). Single electrotactile electrodes can be assembled in bands and arrays (132) for targeting multiple sites at the same time, encoding information in both the position and amplitude of the stimulation. The main drawbacks of electrotactile stimulation are the dependence of sensory thresholds on the stimulation position (131), which forces a calibration after each mounting, and the artifacts induced in EMG readings, which strongly impair its application in closed-loop RPHs.\n\nElectrocutaneous stimulation tries to overcome electrotactile limitations by implanting subdermally thin electrodes. Geng et al. (133) characterized the sensations evoked and highlighted improvements in the detection threshold, the threshold of noticeable differences, and the general pleasantness compared with traditional electrotactile feedback. Electrocutaneous stimulation still has technical issues in real-world implementations, such as interference with EMG readings and variability in stimulation parameters over time (134), which impair long-term applications.\n\nFeedback through neural electrodes is a promising modality that matches how sensory information is transmitted in the nervous system ( Figure 2 b ). These electrodes are implemented at both the cortical (135) and peripheral levels. Here, we focus on techniques targeting the peripheral nervous system.\n\nThe three controlled parameters are the frequency, amplitude, and pulse width; the most straightforward approach is proportional modulation according to sensor readings. Studies have shown that this method can be successful even in long-term implants (114, 136-138) and confirmed the improvements brought by sensory feedback through peripheral nervous system interfaces in both performance and embodiment.\n\nCompared with noninvasive approaches, invasive neural stimulation has the advantage of being able to elicit sensations intuitive for the user, as they are delivered through the expected biological route (the peripheral nervous system) for sensory feedback. The focus in this field is currently shifting from basic feedback to evoking complex and natural sensations, feeding high-level features such as texture (61), and in general exploiting the potential of stimulating the nerves directly. Noninvasive feedback strategies are limited in the spatial precision of the evoked sensation in both mechanical and electrical stimulation (60).\n\nThe naturalness and information content of the stimulation can be improved by modulating with patterns that go beyond a simple relation with the sensor value. George et al. (139) devised two biomimetic stimulation patterns: one that is proportional to the first derivative of the force and another that is proportional to the aggregated tactile nerve response. Both approaches outperformed standard modulation techniques and were felt to be more informative by the user. Valle et al. (62) started from a model of the response to the touch of human afferent fibers and modulated frequency and amplitude according to a simulated fire rate and fiber recruitment; at the cost of a small reduction in sensitivity, the user reported a consistent increase in the naturalness of the sensation together with an increase in dexterity during functional evaluations. Both of these studies highlighted that the goal is not only to elicit precise sensations but also to focus on naturalness and intuitiveness. Neuromorphic stimulation patterns have also proven to be rich in information not only about tactile contact but also about the sliding speed and texture of an object (115).\n\nConsidering the complex surgical procedure and the effort needed to develop a peripheral nervous system interface, techniques based on spinal cord stimulation are promising, as they rely on devices that have already been tested and approved by the US Food and Drug Administration. Chandrasekaran et al. (140) recently demonstrated a sensory neuroprosthesis for amputee subjects with spinal cord stimulation ( Figure 2 c ). The main issue with this approach is the difficulty of eliciting natural sensations; biomimetic stimulation approaches could help address this limitation in the future.\n",
    "topic": "Challenges and strategies to overcome variability and long-term stability issues in electrical stimulation-based sensory feedback systems.",
    "response": "<document_analysis>\nThe context describes various modalities of sensory feedback for neuroprosthetics, focusing on electrical stimulation techniques: noninvasive electrotactile and electrocutaneous stimulation, invasive peripheral nerve interfaces, and spinal cord stimulation. It highlights the parameters modulated in stimulation (frequency, amplitude, pulse width), the challenges such as sensory threshold variability depending on stimulation site, interference with EMG signals, and variability over time affecting long-term stability and usability. Electrocutaneous stimulation, while improving detection thresholds and user comfort compared to electrotactile, still suffers from variability and interference issues in practical applications. Invasive peripheral nerve stimulation offers more natural, intuitive sensations and higher spatial precision, and recent biomimetic and neuromorphic stimulation patterns aim to improve naturalness and information content. Spinal cord stimulation presents a promising alternative due to existing FDA-approved devices but faces challenges in eliciting natural sensations.\n\nImplicit in the text are challenges related to stability and variability in sensory thresholds that necessitate recalibration in noninvasive methods and technical difficulties in maintaining consistent stimulation parameters over time in electrocutaneous devices. The invasive approaches, while more natural, require complex surgeries and sophisticated biomimetic modulation to enhance naturalness and stability. The mention of biomimetic and neuromorphic stimulation patterns implies a strategic approach to overcome limitations of simple proportional modulation, thus potentially improving long-term stability and user experience.\n\nDifficulty rating: 9/10 due to the technical complexity of understanding neurostimulation parameters, biological implications, and advanced modulation strategies.\n\nThe question should provoke reflection on the reasons behind variability and instability in these systems and the state-of-the-art strategies to mitigate these challenges, emphasizing both technical and biological considerations, as well as the trade-offs between invasiveness and feedback quality.\n\nThe question will encourage experts to synthesize information about the sources of variability (e.g., stimulation position, electrode-tissue interface changes), challenges in long-term use (e.g., EMG interference, parameter drift), and the advanced biomimetic modulation strategies designed to improve naturalness, intuitiveness, and stability of sensory feedback.\n\nThis will deepen understanding of the interplay between engineering design, neurophysiology, and clinical application constraints in the development of sensory neuroprosthetics.\n</document_analysis>\n\n<output_format>\nQuestion: What are the primary factors contributing to variability and long-term stability challenges in electrical stimulation-based sensory feedback systems, and how do biomimetic and neuromorphic modulation strategies address these issues to improve naturalness and user experience?\n\nExplanation: Variability and stability challenges arise mainly from changes in stimulation position affecting sensory thresholds, interference with EMG signals, and temporal variability in stimulation parameters that complicate calibration and long-term use. Biomimetic and neuromorphic modulation strategies transcend simple proportional stimulation by mimicking natural tactile nerve responses and firing patterns, which enhances the naturalness, intuitiveness, and information richness of the evoked sensations, thereby improving user embodiment and functional performance despite underlying variability.\n\nCorrect Answer: Variability stems from stimulation position dependence, EMG interference, and parameter drift over time; biomimetic and neuromorphic patterns improve naturalness and stability by replicating physiological nerve firing patterns and encoding complex tactile information.\n</output_format>",
    "question": "What are the primary factors contributing to variability and long-term stability challenges in electrical stimulation-based sensory feedback systems, and how do biomimetic and neuromorphic modulation strategies address these issues to improve naturalness and user experience?",
    "answer": "Variability stems from stimulation position dependence, EMG interference, and parameter drift over time; biomimetic and neuromorphic patterns improve naturalness and stability by replicating physiological nerve firing patterns and encoding complex tactile information.",
    "explanation": "Variability and stability challenges arise mainly from changes in stimulation position affecting sensory thresholds, interference with EMG signals, and temporal variability in stimulation parameters that complicate calibration and long-term use. Biomimetic and neuromorphic modulation strategies transcend simple proportional stimulation by mimicking natural tactile nerve responses and firing patterns, which enhances the naturalness, intuitiveness, and information richness of the evoked sensations, thereby improving user embodiment and functional performance despite underlying variability.",
    "question_token_count": 44,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 44
  },
  {
    "context": "## Figure 1\nExamples of functioning hand replacement. ( a ) A personalized cosmetic hand solution (ITOP , Italy) provides a natural look. Photos adapted with permission from ITOP and Procosil. ( ) A body-powered prosthetic solution (Ottobock, Germany) is a common approach b for people with an upper-limb amputation. Photo reproduced with permission from Ottobock. ( ) An sEMG-based pattern recognition c system (Gen2, Coapt, USA) allows grasp classification. Photo adapted courtesy of Coapt LLC ( http://www.coaptengineering.com ). ( d ) sEMG control and extracellular stimulation via an implanted FINE were used to convey sensory feedback for home-use applications. The implant was stable for more than five years, and home-use electrical stimulation for sensory feedback was investigated for up to 13 days (116). Panel adapted from Reference 116 (CC BY-SA 4.0). ( ) Fully implanted myoelectric sensors provide stronger e and more reliable signals that do not change with arm positioning, socket rotation, or sweating (107). Panel adapted with permission from Reference 107. ( f ) Six-DOF prosthetic hand control (i-Limb Ultra, \u00d6ssur, Iceland) uses threshold-based sEMG control and cocontraction to switch between grasps. ( g ) Sensory feedback conveyed via intraneural TIMEs enables the encoding of objects' shape and stiffness (6). Panel reproduced with permission; copyright 2014 Lifehand 2 / Patrizia T occi. ( h ) Hand transplantation is a promising technique that has not yet become a standard procedure due to several surgical and clinical difficulties. Panel adapted with permission from Reference 177. Abbreviations: DOF, degree of freedom; FINE, flat interface nerve electrode; sEMG, surface electromyography; TIME, transverse intrafascicular multichannel electrode.\n\nsurvey of below-elbow amputees from Sweden, the United Kingdom, and Canada (7), 53% of the respondents wore a cosmetic prosthesis, 13% used a hook, 4% used a cable hand, and 30% used a myoelectric RPH. Despite encouraging results in the late 1990s (8), hand transplantation ( Figure 1 h ) encountered significant surgical and clinical difficulties (rejection and immunosuppression); it has therefore been tested in only a few patients and is not yet considered one of the available options.\n",
    "topic": "The methods and significance of conveying sensory information such as object shape and stiffness through neural interfaces in prosthetic hands.",
    "response": "<document_analysis>\nThe context discusses various types of prosthetic hand solutions and control methods, highlighting particularly advanced approaches for sensory feedback in prosthetic hands. Specifically, it mentions sensory feedback conveyed via intraneural TIMEs (transverse intrafascicular multichannel electrodes), which enable encoding of object shape and stiffness. This is a highly technical and complex area involving interfacing directly with peripheral nerves to restore sensory modalities. Such neural interfaces can provide more natural and intuitive feedback for the user, improving prosthesis functionality and embodiment.\n\nThe key points are the use of intraneural electrodes for sensory feedback, the encoding of tactile properties like shape and stiffness, and the implication that this feedback can enhance prosthetic control and user experience. This involves understanding the challenges of stable, selective nerve interfacing and the significance of sensory restoration beyond motor control.\n\nThis topic is highly specialized, requiring knowledge of neuroprosthetics, peripheral nerve interfaces, sensory encoding, and prosthetic design. The question should probe deep understanding of how neural interfaces translate physical object properties into sensory signals and why this is significant for prosthetic users.\n\nDifficulty is rated 9/10 due to the technical depth and interdisciplinary knowledge required.\n\nThe question will invite reflection on the mechanism and impact of sensory feedback through neural interfaces, requiring synthesis of neuroengineering and clinical prosthetics concepts.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do intraneural transverse intrafascicular multichannel electrodes (TIMEs) enable the encoding of object shape and stiffness for sensory feedback in prosthetic hands, and why is this capability significant for improving the functional integration of prosthetic devices?\n\nExplanation: TIMEs interface directly with peripheral nerve fibers, allowing selective stimulation of sensory neurons to mimic natural tactile sensations corresponding to object shape and stiffness; this restores intuitive sensory feedback, enhancing the user's ability to perceive and manipulate objects more naturally, thereby improving prosthetic embodiment and control.\n\nCorrect Answer: TIMEs selectively stimulate sensory nerve fibers to replicate tactile cues of shape and stiffness, providing naturalistic sensory feedback that improves prosthesis functionality and user embodiment.\n</output_format>",
    "question": "How do intraneural transverse intrafascicular multichannel electrodes (TIMEs) enable the encoding of object shape and stiffness for sensory feedback in prosthetic hands, and why is this capability significant for improving the functional integration of prosthetic devices?",
    "answer": "TIMEs selectively stimulate sensory nerve fibers to replicate tactile cues of shape and stiffness, providing naturalistic sensory feedback that improves prosthesis functionality and user embodiment.",
    "explanation": "TIMEs interface directly with peripheral nerve fibers, allowing selective stimulation of sensory neurons to mimic natural tactile sensations corresponding to object shape and stiffness; this restores intuitive sensory feedback, enhancing the user's ability to perceive and manipulate objects more naturally, thereby improving prosthetic embodiment and control.",
    "question_token_count": 51,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 31
  },
  {
    "context": "## Neuroprosthesis:\na device that connects to the nervous system and either replaces missing parts of it or improves it\n\n\n## 1. INTRODUCTION\nDecades of research on robotic prosthetic hands (RPHs) have led to a paradoxical situation: On the one hand, the development of novel RPHs is among the most exciting fields of robotics (1), but on the other hand, the vast majority of amputee patients still use technologies that have changed little in almost half a century. However, this apparent discrepancy might seem less surprising when considering the immense challenge of developing a prosthetic that can mimic the functions of a hand. Indeed, the hand has one of the largest sensory representations in the brain, and grasping is among the most complex coordination tasks (2); the hand has both the highest density of mechanoreceptors in the human body (see the sidebar titled Skin Mechanoreceptors) and the largest number of degrees of freedom (DOFs); and the hand permits people to both experience the surrounding world and shape it.\n\nThe challenges are multiple and intricate, and they can be overcome only by combining advanced mechatronic solutions for dexterous and highly sensorized robotic hands with new approaches for robust and effective interfaces with users' nervous systems to allow seamless naturalartificial integration. As such, several viable solutions can emerge from this multidimensional optimization problem.\n\nTremendous efforts have been made in the past 20 years on the quest for an RPH that is easy to wear, comfortable, and intuitive to control. The design of such a device can be considered a compromise among dexterity, robustness, and usability (3). In the past 5 years, another aspect has been proposed by researchers as an essential milestone: sensorization. Indeed, feedback systems can increase both the acceptability and the performance of the new generation of RPHs (4-6).\n\nThis review summarizes the main achievements in this field. In particular, after providing an overview of the existing neuroprostheses and their characteristics, we focus on four central aspects: ( a ) stable interfaces that enable a new connection with the nervous system to record neural signals and stimulate neural structures, ( b ) algorithmic strategies for decoding motor intentions, ( c ) RPH sensorization plus encoding strategies to convey somatosensory feedback, and ( d ) assessment methods to measure the efficacy of a given strategy or technology. Throughout the review, we keep a patient-centered perspective and ask ourselves, Does a novel approach significantly improve the subjects' quality of life? Is it easy to learn and natural to use? And does it improve their independence? On a technical aspect, our goal is to provide a critical view of the most advanced technologies and a perspective on future implementations of RPHs.\n",
    "topic": "Discuss the neurophysiological complexity of the human hand, including its sensory representation, mechanoreceptor density, and degrees of freedom, and explain why these factors complicate the design of robotic prosthetic hands.",
    "response": "<document_analysis>\nThe context provides a comprehensive overview of the challenges involved in designing robotic prosthetic hands (RPHs), emphasizing the neurophysiological complexity of the human hand. Central ideas include the hand's extensive sensory representation in the brain, the highest density of mechanoreceptors in the body, and the largest number of degrees of freedom (DOFs), all of which contribute to the difficulty of replicating its function in prosthetics. The text highlights how these factors lead to intricate coordination tasks such as grasping and the dual role of the hand in both sensing and manipulating the environment. These complexities require advanced mechatronics combined with sophisticated neural interfaces to achieve natural control and sensory feedback, underscoring why current prosthetic technologies lag despite decades of research.\n\nImplicit assumptions involve the necessity for seamless integration between artificial devices and the nervous system to mimic natural hand function. The mention of sensorization and feedback systems as recent milestones further points to the importance of conveying somatosensory information for usability and acceptance. The difficulty rating for a question probing this topic is high (9/10) because it demands understanding of neuroanatomy, sensorimotor integration, biomechanics, and prosthetic technology challenges. A well-crafted question can invite experts to analyze how each neurophysiological factor translates into design constraints and why current solutions struggle to overcome them, fostering deep reflection on interdisciplinary requirements.\n\nThis question encourages synthesis of neurophysiological knowledge with engineering and clinical implications, suitable for domain experts in neuroprosthetics, neuroscience, and biomedical engineering. It avoids simple recall by demanding explanation of the causal relationship between biological complexity and technological challenges, aligning with the goal of producing a highly challenging, insightful question-answer pair.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the human hand's extensive sensory representation in the brain, its exceptionally high density of mechanoreceptors, and its large number of degrees of freedom collectively contribute to the complexity in designing robotic prosthetic hands that can replicate natural hand function?\n\nExplanation: The human hand\u2019s large sensory representation corresponds to a highly detailed neural map required for precise sensory processing; the high density of mechanoreceptors provides rich tactile feedback essential for nuanced perception; and the numerous degrees of freedom enable complex, coordinated movements. Together, these neurophysiological features demand prosthetic designs that can interface seamlessly with the nervous system to decode intricate motor commands and deliver sophisticated sensory feedback, making it exceptionally difficult to create prosthetics that are both dexterous and intuitive.\n\nCorrect Answer: Because the hand's detailed brain representation, dense tactile receptors, and many degrees of freedom require prosthetics to replicate complex sensorimotor integration and rich sensory feedback, significantly complicating design and control.\n</output_format>",
    "question": "How do the human hand's extensive sensory representation in the brain, its exceptionally high density of mechanoreceptors, and its large number of degrees of freedom collectively contribute to the complexity in designing robotic prosthetic hands that can replicate natural hand function?",
    "answer": "Because the hand's detailed brain representation, dense tactile receptors, and many degrees of freedom require prosthetics to replicate complex sensorimotor integration and rich sensory feedback, significantly complicating design and control.",
    "explanation": "The human hand\u2019s large sensory representation corresponds to a highly detailed neural map required for precise sensory processing; the high density of mechanoreceptors provides rich tactile feedback essential for nuanced perception; and the numerous degrees of freedom enable complex, coordinated movements. Together, these neurophysiological features demand prosthetic designs that can interface seamlessly with the nervous system to decode intricate motor commands and deliver sophisticated sensory feedback, making it exceptionally difficult to create prosthetics that are both dexterous and intuitive.",
    "question_token_count": 49,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 9,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 40
  },
  {
    "context": "## 4.4. Perspectives\nMotor decoding for RPHs is progressing in two main directions: Noninvasive approaches have seen advances in decoding algorithms using large data sets and increases in the number of recording points, and implanted electrodes (either muscular or intraneural) have seen improvements that enable better recording stability and more robust decoding. There is currently no consensus on which approach is best for transradial amputee patients, as they each have their own strengths and limitations. The need for daily signal and classification recalibration is a weak point of the classic sEMG approach, which is being addressed by several research groups developing, for example, HD-sEMG.And despite iEMG's promising control performance, which is robust to donning and doffing of the prosthesis, its overall performance gain, when compared with sEMG, may not currently be sufficient to justify an invasive surgery. The same reasoning can be applied to intraneural electrodes.\n\nOne can imagine a future where both invasive and noninvasive approaches will continue to progress and will target either patients who prefer a stable decoding setup or those who do not want to undergo surgery and will accept the need to calibrate their prosthesis on a regular basis (118). Another scenario can be a parallel development of invasive technologies for both sensory and motor functions. Indeed, as shown in Section 5, the approach using intraneural implanted electrodes has permitted unprecedented levels of somatosensory restoration; it might, therefore, be reasonable to perform a single surgery to restore both motor and sensory functions. For this reason, motor decoding using the intraneural interface can become a viable solution if these interfaces one day permit both providing sensory feedback and recording discriminative signals for motor decoding in parallel, but online artifact removal remains an important challenge.\n\nPower consumption is another critical issue: RPHs should embed small electronics because the size of the prosthesis limits the space available for batteries, but doing so usually comes at the cost of limited processing resources. Also, the electronics for the HD-sEMG remain cumbersome due to the large number of input channels and should be miniaturized and portable. Moreover, decoding model complexity is also limited by portable processing resources. In practice, an increased number of electrodes is already available in wearable systems (Sessantaquattro, OT Bioelettronica, Italy) and may become available for prostheses in the future.\n\nFinally, low latency is paramount for seamless prosthesis control [ &lt; 300 ms between user intention and real-time decoding (119)]. Among the studies discussed above, only a few performed analyses to show the feasibility of real-time control (without processing resource limitations), and even fewer included embedded electronics that would translate for home use. One possible solution for real-time decoding with complex models is to bypass embedded electronic limitations; this could be achieved by taking advantage of the computational power of cell phones or by relying on cloud computing and the next generations of wireless cellular networks for low-latency communication.\n",
    "topic": "Comparative analysis of noninvasive (sEMG, HD-sEMG) and invasive (implanted muscular and intraneural electrodes) motor decoding approaches for transradial amputee prosthesis control, including their strengths, limitations, and patient suitability.",
    "response": "<document_analysis>\nThe context discusses the current state and future perspectives of motor decoding techniques for robotic prosthetic hands (RPHs) in transradial amputees, focusing on two main approaches: noninvasive (such as classic sEMG and HD-sEMG) and invasive (implanted muscular electrodes and intraneural electrodes). It highlights the trade-offs between these approaches, including signal stability, need for recalibration, surgical invasiveness, robustness to prosthesis donning and doffing, and sensory feedback potential. Noninvasive methods suffer from daily recalibration needs but avoid surgery, while invasive methods offer improved stability and potential combined motor-sensory restoration but involve surgical risks and challenges such as artifact removal. The text also touches on technical constraints like power consumption, processing resources, and latency requirements for real-time control, emphasizing that both approaches have strengths and limitations without a clear consensus on superiority. Patient preference and clinical goals appear to be critical factors in approach selection.\n\nImplicit in the analysis is the assumption that future progress will likely see coexistence of both approaches tailored to patient needs. The possibility of combining sensory feedback with motor decoding in intraneural interfaces presents a unique advantage of invasive methods. Challenges include miniaturization of electronics for noninvasive high-density setups and overcoming artifact removal in invasive setups.\n\nDifficulty rating: 9/10 due to the requirement for deep knowledge of neurophysiology, prosthetics engineering, signal processing, and clinical implications.\n\nThe question should probe an expert\u2019s ability to critically compare the two approaches, synthesize their technical and clinical trade-offs, and predict patient suitability scenarios, encouraging reflection on nuanced complexities rather than superficial comparison.\n\nHence, the question will ask for a detailed comparative analysis considering technical performance, patient experience, and future clinical applicability, pushing for expert-level insight.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the technical strengths and limitations of noninvasive (sEMG, HD-sEMG) versus invasive (implanted muscular and intraneural electrodes) motor decoding approaches influence their suitability for transradial amputee prosthesis control, and in what clinical or patient preference scenarios might one approach be favored over the other despite these trade-offs?\n\nExplanation: Noninvasive approaches like sEMG and HD-sEMG avoid surgery and are thus preferable for patients unwilling to undergo invasive procedures, but they require frequent recalibration due to signal instability and face challenges in miniaturizing electronics for real-time control. Invasive methods, including implanted muscular and intraneural electrodes, offer more stable recordings and the unique potential for combined motor control and sensory feedback, making them favorable for patients prioritizing stable and robust prosthesis control, despite surgical risks and challenges like artifact removal. Therefore, patient suitability depends on balancing preferences for surgical intervention, desire for stable long-term control, acceptance of recalibration needs, and clinical goals such as sensory restoration.\n\nCorrect Answer: Noninvasive methods favor patients avoiding surgery but require regular recalibration and face hardware miniaturization challenges, while invasive methods offer stable decoding and sensory feedback potential suited for patients prioritizing robustness and combined functions despite surgical risks.\n</output_format>",
    "question": "How do the technical strengths and limitations of noninvasive (sEMG, HD-sEMG) versus invasive (implanted muscular and intraneural electrodes) motor decoding approaches influence their suitability for transradial amputee prosthesis control, and in what clinical or patient preference scenarios might one approach be favored over the other despite these trade-offs?",
    "answer": "Noninvasive methods favor patients avoiding surgery but require regular recalibration and face hardware miniaturization challenges, while invasive methods offer stable decoding and sensory feedback potential suited for patients prioritizing robustness and combined functions despite surgical risks.",
    "explanation": "Noninvasive approaches like sEMG and HD-sEMG avoid surgery and are thus preferable for patients unwilling to undergo invasive procedures, but they require frequent recalibration due to signal instability and face challenges in miniaturizing electronics for real-time control. Invasive methods, including implanted muscular and intraneural electrodes, offer more stable recordings and the unique potential for combined motor control and sensory feedback, making them favorable for patients prioritizing stable and robust prosthesis control, despite surgical risks and challenges like artifact removal. Therefore, patient suitability depends on balancing preferences for surgical intervention, desire for stable long-term control, acceptance of recalibration needs, and clinical goals such as sensory restoration.",
    "question_token_count": 71,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 44
  },
  {
    "context": "## 5.4. Sensory Feedback\nIn basic myoelectric or body-powered prostheses, feedback is delivered mainly by visually inspecting the movements of the prosthesis and by the physical interaction between the device and the user (126), as with hook prostheses. Clearly, the goal of a modern RPH is to deliver richer information more intuitively.\n\nSensory feedback strategies are characterized by their precision and the coherence between the evoked sensation and the desired one in terms of timing (synchronicity), position (somatotopy), and modality (i.e., touch, vibration, and temperature). Feedback techniques encode sensor values to stimulation parameters, which in turn are strongly tied to the chosen stimulation interface ( Table 2 ). Here, we focus mainly on electrical interfaces for feedback, but we also briefly discuss the mechanical interfaces.\n\nNoninvasive feedback strategies are attractive approaches since they do not necessitate surgical interventions ( Figure 2 a ). Starting with the Boston Arm, which Mann &amp; Reimers (127) used to demonstrate that position feedback was needed for precise reaching movements, these techniques have improved in both mechanical and electrical interfaces with the user. Indeed, the intact mechanoreceptors in the skin of the arm can be stimulated with small linear (128) or vibrating (129) motors that vary in their driving amplitude and frequency. On the other hand, mechanical stimulation brings an unavoidable delay of approximately 400 ms in the delivery of the sensation (130), and the integration and miniaturization of mechanoreceptors are challenging. The miniaturization of noninvasive feedback approaches is also challenging.\n",
    "topic": "The physiological basis and technological methods for stimulating intact mechanoreceptors in the skin to deliver sensory feedback noninvasively.",
    "response": "<document_analysis>\nThe provided context discusses sensory feedback methods for prosthetic hands (RPH), focusing on the physiological and technological aspects of noninvasive stimulation of intact skin mechanoreceptors. It highlights the importance of feedback coherence in timing (synchronicity), location (somatotopy), and modality (touch, vibration, temperature). It explains that noninvasive approaches avoid surgery by stimulating intact mechanoreceptors on the user's skin, typically using mechanical actuators like linear or vibrating motors with modulated amplitude and frequency. It also notes inherent challenges, such as a sensory delay (~400 ms) caused by mechanical stimulation and difficulties in miniaturization and integration of these devices. The discussion integrates physiological principles (mechanoreceptor activation) with technological constraints (actuator types, latency, miniaturization), which is crucial for advancing intuitive and precise prosthetic feedback systems.\n\nThis information is coherent, educationally valuable, and suitable for generating a challenging question that probes understanding of both the physiological basis of mechanoreceptor stimulation and the technological methods for achieving noninvasive sensory feedback, including limitations.\n\nDifficulty rating: 8/10 due to requiring interdisciplinary knowledge of sensory physiology and engineering constraints.\n\nThe question should prompt reflection on how intact mechanoreceptors can be stimulated noninvasively, what technological means are used, and what physiological and technical limitations affect the feedback quality (e.g., delay, miniaturization). This will assess deep understanding of sensory feedback system design in prosthetics.\n\nNo irrelevant or bogus content detected.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do noninvasive sensory feedback systems stimulate intact mechanoreceptors in the skin to convey information in prosthetic devices, and what are the primary physiological and technological challenges associated with these methods?\n\nExplanation: Noninvasive systems stimulate intact skin mechanoreceptors using mechanical actuators such as small linear or vibrating motors that modulate amplitude and frequency to encode sensor information. Physiologically, these actuators target the skin\u2019s mechanoreceptors to evoke sensations corresponding to touch or vibration. Technologically, these methods face challenges including an inherent delay of about 400 milliseconds in sensation delivery due to mechanical transduction, and difficulties in integrating and miniaturizing the actuators for practical use, which impact the feedback\u2019s synchronicity and intuitiveness.\n\nCorrect Answer: By mechanically stimulating intact skin mechanoreceptors with small linear or vibrating motors modulating amplitude and frequency; main challenges are the ~400 ms delay in sensation delivery and difficulties in actuator integration and miniaturization.\n</output_format>",
    "question": "How do noninvasive sensory feedback systems stimulate intact mechanoreceptors in the skin to convey information in prosthetic devices, and what are the primary physiological and technological challenges associated with these methods?",
    "answer": "By mechanically stimulating intact skin mechanoreceptors with small linear or vibrating motors modulating amplitude and frequency; main challenges are the ~400 ms delay in sensation delivery and difficulties in actuator integration and miniaturization.",
    "explanation": "Noninvasive systems stimulate intact skin mechanoreceptors using mechanical actuators such as small linear or vibrating motors that modulate amplitude and frequency to encode sensor information. Physiologically, these actuators target the skin\u2019s mechanoreceptors to evoke sensations corresponding to touch or vibration. Technologically, these methods face challenges including an inherent delay of about 400 milliseconds in sensation delivery due to mechanical transduction, and difficulties in integrating and miniaturizing the actuators for practical use, which impact the feedback\u2019s synchronicity and intuitiveness.",
    "question_token_count": 39,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 7,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 42
  },
  {
    "context": "## 5.1. Sensors for Proprioception\nProprioception is not only fundamental for a dexterous hand prosthesis, enabling vision-free manipulation and multitasking, but is also the key to a properly embodied device (64). Usually, kinematic parameters of the robotic hand and (when available) the force exerted are needed to implement low-level control of the actuators, so they are measured with well-established systems, such as rotary encoders or the motor's current draw.\n\n\n## 5.2. Tactile Sensors\nDespite improvements in sensor miniaturization,computational power,and knowledge of the neurophysiology of somatosensation (tactile sensation and proprioception), the capabilities of sensorized RPHs remain far from those of a natural hand. Overcoming this limitation will require satisfying three conditions: The sensors must match the skin's sensing ability, a sufficient number of sensors must be embedded on the surface of the hand, and it must be possible to reliably read information from them. The first condition can be addressed with current technology, as the resolution of existing force and pressure sensors already matches human skin performance (120). However, fulfilling the second and third conditions is another matter, and we need to push the boundaries of circuit integration in order to create an RPH with many sensors and a way to communicate with them.\n\nThe classical solution of using general-purpose sensors developed separately from the signal conditioning circuit and the subsequent signal processing has shown its limit. Instead, efforts are being made to optimize these devices with prosthetics in mind. For example, borrowing the concept of morphological computation from robotics (121), sensors can be optimized for specific tasks by tuning the features of their mechanical structures accordingly. Indeed, exploiting the low-pass filtering effect of a compliant material or surfaces with specific structures can increase texture discrimination (61, 115). Another example comes from Kim et al. (122), who measured forces using sensors embedded in a soft substrate.\n\n)\n\nContinued\n\n(\n\n| Sensor distribution a                       |            |             |             |             |                  |              |                 |              |\n\n|---------------------------------------------|------------|-------------|-------------|-------------|------------------|--------------|-----------------|--------------|\n\n| Interface                                   | G10 tactor | TIME        | TENS        | TIME        | FINE             | TIME         | Vibrators       | TENS         |\n\n| Electrical stimulation encoding Pulse width | -          | Fixed       | Linear      | Fixed       | Time variant     | Fixed        | -               | Neuromorphic |\n\n| Amplitude                                   | -          | Linear      | Fixed       | Model based | Fixed            | Fixed        | -               | Fixed        |\n\n| Frequency                                   | -          | Fixed       | Fixed       | Model based | Linear           | Neuromorphic | -               | Neuromorphic |\n\n| Mechanical stimulation encoding             | Linear     | -           | -           | -           | -                | -            | Discrete events | -            |\n\n| RPH model                                   | Passive    | IH2 Azzurra | IH2 Azzurra | IH2 Azzurra | SensorHand Speed | IH2 Azzurra  | Various         | bebionic     |\n\n| Reference                                   | 4          | 6           | 60          | 62          | 38               | 61           | 129             | 59           |\n\n| Year                                        | 2011       | 2014        | 2017        | 2018        | 2014             | 2016         | 2016            | 2018         |\n",
    "topic": "The importance of sensor miniaturization and computational power advancements in approaching human-like tactile sensing in prosthetic hands.",
    "response": "<document_analysis>\nThe provided context discusses proprioception and tactile sensing in robotic prosthetic hands (RPHs), emphasizing the challenges in replicating the natural hand's sensory capabilities. It highlights three critical conditions for tactile sensors to match human skin: sensor resolution, sensor density, and reliable communication. While sensor miniaturization and computational power have improved to the extent that sensor resolution can match human skin, the main challenges remain embedding sufficient sensors and effectively communicating their data. The text also references the limitations of classical sensor approaches and mentions advanced strategies such as morphological computation and embedding sensors in soft substrates to enhance tactile feedback. The tabular data suggests various encoding methods and different prosthetic models employing diverse tactile sensing strategies.\n\nThe implicit assumption is that advances in sensor miniaturization and computational power alone are insufficient to fully replicate human tactile sensing; integration strategies and communication protocols are equally critical. The detailed discussion points toward a multidisciplinary challenge involving materials science, electronics, neurophysiology, and robotics.\n\nDifficulty rating is 9/10, as the question must probe not only the importance of miniaturization and computation but also their limitations and the broader system-level integration challenges to approach human-like tactile sensing.\n\nA well-crafted question would invite critical reflection on how these technological advancements contribute to tactile sensing, what limitations persist despite them, and what systemic innovations are necessary beyond miniaturization and computational power.\n\nThis approach will challenge domain experts to synthesize knowledge of sensor technology, system design, and neurophysiological requirements, ensuring deep engagement with the topic.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do advancements in sensor miniaturization and computational power contribute to replicating human-like tactile sensing in prosthetic hands, and why are these advancements alone insufficient without innovations in sensor distribution and communication?\n\nExplanation: While sensor miniaturization and computational power enable sensors to match the resolution of human skin, these alone do not solve the challenges of embedding a sufficient number of sensors on the prosthetic surface and reliably reading their data; overcoming these requires innovations in sensor distribution, integration, and communication strategies to fully replicate natural tactile capabilities.\n\nCorrect Answer: Because although miniaturization and computational power achieve human-like sensor resolution, replicating natural tactile sensing demands dense sensor integration and reliable communication systems beyond just these advancements.\n</output_format>",
    "question": "How do advancements in sensor miniaturization and computational power contribute to replicating human-like tactile sensing in prosthetic hands, and why are these advancements alone insufficient without innovations in sensor distribution and communication?",
    "answer": "Because although miniaturization and computational power achieve human-like sensor resolution, replicating natural tactile sensing demands dense sensor integration and reliable communication systems beyond just these advancements.",
    "explanation": "While sensor miniaturization and computational power enable sensors to match the resolution of human skin, these alone do not solve the challenges of embedding a sufficient number of sensors on the prosthetic surface and reliably reading their data; overcoming these requires innovations in sensor distribution, integration, and communication strategies to fully replicate natural tactile capabilities.",
    "question_token_count": 40,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 33
  },
  {
    "context": "## Table 2 ( Continued )\n| Sensor distribution a                       |                |                              |             |                  |\n\n|---------------------------------------------|----------------|------------------------------|-------------|------------------|\n\n| Interface                                   | FINE           | Utah Slanted Electrode Array | TIME        | Cuff electrode   |\n\n| Electrical stimulation encoding Pulse width | Fixed          | Fixed                        | Linear      | Fixed            |\n\n| Amplitude                                   | Fixed          | Fixed                        | Fixed       | Fixed            |\n\n| Frequency                                   | Linear         | Model based                  | Fixed       | Linear           |\n\n| Mechanical stimulation encoding             | -              | -                            | -           | -                |\n\n| RPH model                                   | VariPlus Speed | DEKA Luke                    | IH2 Azzurra | SensorHand Speed |\n\n| Reference                                   | 136            | 139                          | 64          | 138              |\n\n| Year                                        | 2018           | 2019                         | 2019        | 2020             |\n\nAbbreviations: FINE, flat interface nerve electrode; RPH, robotic prosthetic hand; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. a The positions of the pressure sensors are shown in green, the joints where force is measured are shown with solid red lines, and the joints where the position is read are shown with dashed blue lines.\n",
    "topic": "Integration and placement of pressure sensors, force measurement joints, and position reading joints in prosthetic hands and how these sensor distributions influence prosthetic control.",
    "response": "<document_analysis>\nThe context provides a detailed table segment describing various prosthetic hand models and their sensor distributions, focusing on electrical stimulation parameters and sensor placements. It includes different electrode interfaces (FINE, Utah Slanted Electrode Array, TIME, Cuff electrode), stimulation encoding methods (pulse width, amplitude, frequency), and their configurations (fixed, linear, model-based). The sensor distribution is specified in terms of pressure sensor locations (green), force measurement joints (solid red lines), and position reading joints (dashed blue lines). These sensor placements are critical for feedback and control in robotic prosthetic hands (RPH models like VariPlus Speed, DEKA Luke, IH2 Azzurra, SensorHand Speed).\n\nThe nuanced theme lies in how the distribution and types of sensors, combined with electrical stimulation encoding strategies, impact the control fidelity and sensory feedback of prosthetic hands. The relationship between sensor placement and the type of nerve interface can influence the precision and responsiveness of prosthetic control.\n\nImplicit in this context is the assumption that sensor placement and encoding strategies must be optimized together to achieve effective prosthetic control. The impact of sensor distribution on the interpretation of force and position data for feedback loops in prosthetic control systems is a subtle but critical point.\n\nThe difficulty rating for a question engaging these concepts is high (9/10), as it requires an expert-level understanding of neuroprosthetics, sensor integration, and control system design.\n\nThe question should prompt reflection on how sensor placement and interface choice influence prosthetic hand control, encouraging synthesis of knowledge on sensor modalities, encoding strategies, and their integration in multi-sensor prosthetics.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the specific distribution of pressure sensors, force measurement joints, and position reading joints in prosthetic hands interact with the choice of nerve interface and electrical stimulation encoding to influence the precision and responsiveness of prosthetic hand control?\n\nExplanation: The distribution of sensors determines the quality and type of sensory feedback available, while the nerve interface and stimulation encoding methods dictate how this feedback is transduced into neural signals; their interplay directly affects how accurately and responsively the prosthetic hand can be controlled.\n\nCorrect Answer: Sensor distribution provides critical spatial and force data that, combined with the nerve interface\u2019s encoding strategy (pulse width, amplitude, frequency modulation), shapes the fidelity of sensory feedback and motor control, thus influencing prosthetic precision and responsiveness.\n</output_format>",
    "question": "How does the specific distribution of pressure sensors, force measurement joints, and position reading joints in prosthetic hands interact with the choice of nerve interface and electrical stimulation encoding to influence the precision and responsiveness of prosthetic hand control?",
    "answer": "Sensor distribution provides critical spatial and force data that, combined with the nerve interface\u2019s encoding strategy (pulse width, amplitude, frequency modulation), shapes the fidelity of sensory feedback and motor control, thus influencing prosthetic precision and responsiveness.",
    "explanation": "The distribution of sensors determines the quality and type of sensory feedback available, while the nerve interface and stimulation encoding methods dictate how this feedback is transduced into neural signals; their interplay directly affects how accurately and responsively the prosthetic hand can be controlled.",
    "question_token_count": 45,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 6,
    "avg_answer_token_count": 46
  },
  {
    "context": "## Current Solutions and Future Trends for Robotic Prosthetic Hands\nVincent Mendez, 1, \u2217 Francesco Iberite, 2, \u2217 Solaiman Shokur, 1,\u2020 and Silvestro Micera 1,2,\u2020\n\n1 Center for Neuroprosthetics and Institute of Bioengineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1202 Gen\u00e8ve, Switzerland; email: silvestro.micera@epfl.ch\n\n2 BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, 56127 Pisa, Italy\n\n\n## Keywords\nhand, prosthesis, neuroprostheses, sensory feedback, electromyography, EMG\n\n\n## Abstract\nThe desire for functional replacement of a missing hand is an ancient one. Historically, humans have replaced a missing limb with a prosthesis for cosmetic, vocational, or personal autonomy reasons. The hand is a powerful tool, and its loss causes severe physical and often mental debilitation. Technological advancements have allowed the development of increasingly effective artificial hands, which can improve the quality of life of people who suffered a hand amputation. Here, we review the state of the art of robotic prosthetic hands (RPHs), with particular attention to the potential and current limits of their main building blocks: the hand itself, approaches to decoding voluntary commands and controlling the hand, and systems and methods for providing sensory feedback to the user. We also briefly describe existing approaches to characterizing the performance of subjects using RPHs for grasping tasks and provide perspectives on the future of different components and the overall field of RPH development.\n",
    "topic": "Future perspectives and emerging trends in the development of robotic prosthetic hands, including innovations in control, sensory feedback, and mechanical design.",
    "response": "<document_analysis>\nThe provided text is an abstract from a scholarly article discussing the current state and future prospects of robotic prosthetic hands (RPHs). The central themes include the historical and contemporary significance of prosthetic hands, the technological components that constitute RPHs (mechanical design, voluntary control decoding, sensory feedback systems), and the evaluation methods for performance in grasping tasks. The abstract highlights the importance of integrating advanced control and sensory feedback to improve user autonomy and quality of life. It also points to ongoing challenges and future directions in the field, suggesting evolving innovations in mechanical design, control strategies (likely involving electromyography and neuroprosthetic techniques), and sensory feedback mechanisms that could significantly enhance prosthesis functionality. The text is concise but dense, implying complex interdisciplinary knowledge in neuroprosthetics, robotics, bioengineering, and human-machine interfaces.\n\nImplicit assumptions include the need for closed-loop systems combining motor control and sensory feedback for effective prosthesis operation and the importance of user-centered performance assessment. The future trends likely involve more naturalistic, intuitive control schemes and improved sensory feedback to restore a sense of touch or proprioception, which are critical for dexterous manipulation.\n\nDifficulty rating: 9/10 \u2014 The question should address advanced concepts such as the integration of neurophysiological signals for control, the challenges in sensory feedback implementation, and how mechanical innovations can synergize with these to enhance functionality.\n\nThe question should encourage reflection on how emerging technologies and interdisciplinary approaches might overcome current limitations, requiring an expert to synthesize knowledge of robotics, neuroscience, and prosthetic design.\n\nSince the abstract is highly relevant, coherent, and educationally valuable, generating a question-answer pair is appropriate.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do emerging innovations in control strategies, sensory feedback systems, and mechanical design collectively address the current limitations of robotic prosthetic hands to enhance their functional integration and user experience?\n\nExplanation: Emerging innovations in control strategies aim to decode voluntary commands more accurately and intuitively, often through advanced electromyography and neuroprosthetic interfaces, allowing users to command prosthetic hands with greater dexterity. Sensory feedback systems are being developed to restore tactile and proprioceptive sensations, closing the sensorimotor loop and improving the user's ability to perform complex grasping tasks. Mechanical design improvements focus on replicating the biomechanical complexity and dexterity of natural hands, enhancing durability, and enabling more natural movements. Together, these innovations synergize to overcome limitations such as unnatural control, lack of feedback, and mechanical constraints, leading to prostheses that integrate more seamlessly with the user's nervous system and daily activities.\n\nCorrect Answer: By integrating advanced voluntary command decoding, restoring sensory feedback to close the sensorimotor loop, and improving biomechanically inspired mechanical designs, robotic prosthetic hands overcome current functional and experiential limitations to achieve more natural, intuitive, and effective use.\n</output_format>",
    "question": "How do emerging innovations in control strategies, sensory feedback systems, and mechanical design collectively address the current limitations of robotic prosthetic hands to enhance their functional integration and user experience?",
    "answer": "By integrating advanced voluntary command decoding, restoring sensory feedback to close the sensorimotor loop, and improving biomechanically inspired mechanical designs, robotic prosthetic hands overcome current functional and experiential limitations to achieve more natural, intuitive, and effective use.",
    "explanation": "Emerging innovations in control strategies aim to decode voluntary commands more accurately and intuitively, often through advanced electromyography and neuroprosthetic interfaces, allowing users to command prosthetic hands with greater dexterity. Sensory feedback systems are being developed to restore tactile and proprioceptive sensations, closing the sensorimotor loop and improving the user's ability to perform complex grasping tasks. Mechanical design improvements focus on replicating the biomechanical complexity and dexterity of natural hands, enhancing durability, and enabling more natural movements. Together, these innovations synergize to overcome limitations such as unnatural control, lack of feedback, and mechanical constraints, leading to prostheses that integrate more seamlessly with the user's nervous system and daily activities.",
    "question_token_count": 35,
    "answer_correctness_score": 9,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 50
  },
  {
    "context": "## 5.1. Sensors for Proprioception\nProprioception is not only fundamental for a dexterous hand prosthesis, enabling vision-free manipulation and multitasking, but is also the key to a properly embodied device (64). Usually, kinematic parameters of the robotic hand and (when available) the force exerted are needed to implement low-level control of the actuators, so they are measured with well-established systems, such as rotary encoders or the motor's current draw.\n\n\n## 5.2. Tactile Sensors\nDespite improvements in sensor miniaturization,computational power,and knowledge of the neurophysiology of somatosensation (tactile sensation and proprioception), the capabilities of sensorized RPHs remain far from those of a natural hand. Overcoming this limitation will require satisfying three conditions: The sensors must match the skin's sensing ability, a sufficient number of sensors must be embedded on the surface of the hand, and it must be possible to reliably read information from them. The first condition can be addressed with current technology, as the resolution of existing force and pressure sensors already matches human skin performance (120). However, fulfilling the second and third conditions is another matter, and we need to push the boundaries of circuit integration in order to create an RPH with many sensors and a way to communicate with them.\n\nThe classical solution of using general-purpose sensors developed separately from the signal conditioning circuit and the subsequent signal processing has shown its limit. Instead, efforts are being made to optimize these devices with prosthetics in mind. For example, borrowing the concept of morphological computation from robotics (121), sensors can be optimized for specific tasks by tuning the features of their mechanical structures accordingly. Indeed, exploiting the low-pass filtering effect of a compliant material or surfaces with specific structures can increase texture discrimination (61, 115). Another example comes from Kim et al. (122), who measured forces using sensors embedded in a soft substrate.\n\n)\n\nContinued\n\n(\n\n| Sensor distribution a                       |            |             |             |             |                  |              |                 |              |\n\n|---------------------------------------------|------------|-------------|-------------|-------------|------------------|--------------|-----------------|--------------|\n\n| Interface                                   | G10 tactor | TIME        | TENS        | TIME        | FINE             | TIME         | Vibrators       | TENS         |\n\n| Electrical stimulation encoding Pulse width | -          | Fixed       | Linear      | Fixed       | Time variant     | Fixed        | -               | Neuromorphic |\n\n| Amplitude                                   | -          | Linear      | Fixed       | Model based | Fixed            | Fixed        | -               | Fixed        |\n\n| Frequency                                   | -          | Fixed       | Fixed       | Model based | Linear           | Neuromorphic | -               | Neuromorphic |\n\n| Mechanical stimulation encoding             | Linear     | -           | -           | -           | -                | -            | Discrete events | -            |\n\n| RPH model                                   | Passive    | IH2 Azzurra | IH2 Azzurra | IH2 Azzurra | SensorHand Speed | IH2 Azzurra  | Various         | bebionic     |\n\n| Reference                                   | 4          | 6           | 60          | 62          | 38               | 61           | 129             | 59           |\n\n| Year                                        | 2011       | 2014        | 2017        | 2018        | 2014             | 2016         | 2016            | 2018         |\n",
    "topic": "The limitations of classical general-purpose sensors and signal processing approaches in prosthetic tactile sensing and the need for optimization specific to prosthetic applications.",
    "response": "<document_analysis>\nThe provided context discusses the challenges in tactile sensing for robotic prosthetic hands (RPHs). Although sensor miniaturization and computational advances have been made, current prosthetic tactile sensing remains significantly inferior to natural human touch. The text identifies three key conditions for improving tactile sensing: matching skin sensing ability, embedding enough sensors on the hand surface, and reliably reading sensor data. It notes that while sensor resolution is sufficient, the main challenges lie in sensor integration density and data communication.\n\nThe classical approach\u2014using general-purpose sensors developed independently of the signal conditioning and processing circuitry\u2014has reached its limits. This implies that simply combining off-the-shelf sensors with separate electronics is insufficient for achieving the required sensor density and communication reliability in prosthetic hands. The text highlights the need to optimize sensors specifically for prosthetic use, for example by applying concepts like morphological computation to tune sensor mechanical properties for task-specific sensing improvements.\n\nThus, the key theme is the inadequacy of classical sensor+processing modular approaches for high-density tactile sensing in prosthetics and the consequent necessity to rethink sensor design and integration holistically, tailored for prosthetic requirements. This involves mechanical, electronic, and computational co-design to overcome limitations in scalability, signal fidelity, and communication.\n\nDifficulty rating: 9/10. The question should probe expert understanding of why classical general-purpose sensor approaches fail in prosthetic tactile sensing and how specialized optimization addresses these challenges, requiring knowledge of sensor design, integration, and neuroprosthetics.\n\nThe question will focus on analyzing the limitations of classical sensor and signal processing paradigms in the context of prosthetic tactile sensing and the rationale and principles behind optimization strategies tailored to prosthetic applications.\n\nThe question will invite reflection on the implications of sensor integration challenges and the role of morphological computation and mechanical tuning in enhancing sensor performance, encouraging deep engagement with the interplay of hardware and signal processing in advanced prosthetic tactile sensing.\n\n</document_analysis>\n\n<output_format>\nQuestion: Why do classical general-purpose sensors and separate signal processing circuits reach their limits in prosthetic tactile sensing, and how does optimizing sensor design specifically for prosthetic applications, such as through morphological computation, address these limitations?\n\nExplanation: Classical sensors and separate signal conditioning lack the integration and scalability needed for high-density tactile sensing on prosthetic hands, leading to communication and reliability challenges. Optimizing sensors specifically for prosthetics, including tuning mechanical structures via morphological computation, enables task-specific filtering and improved texture discrimination while facilitating dense sensor embedding and reliable data readout.\n\nCorrect Answer: Because classical sensors and separate processing lack integration and scalability for dense, reliable sensing, prosthetic-specific optimization\u2014including morphological computation\u2014enables mechanically tuned sensors that improve performance and communication in high-density arrays.\n</output_format>",
    "question": "Why do classical general-purpose sensors and separate signal processing circuits reach their limits in prosthetic tactile sensing, and how does optimizing sensor design specifically for prosthetic applications, such as through morphological computation, address these limitations?",
    "answer": "Because classical sensors and separate processing lack integration and scalability for dense, reliable sensing, prosthetic-specific optimization\u2014including morphological computation\u2014enables mechanically tuned sensors that improve performance and communication in high-density arrays.",
    "explanation": "Classical sensors and separate signal conditioning lack the integration and scalability needed for high-density tactile sensing on prosthetic hands, leading to communication and reliability challenges. Optimizing sensors specifically for prosthetics, including tuning mechanical structures via morphological computation, enables task-specific filtering and improved texture discrimination while facilitating dense sensor embedding and reliable data readout.",
    "question_token_count": 43,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 41
  },
  {
    "context": "## Table 2 ( Continued )\n| Sensor distribution a                       |                |                              |             |                  |\n\n|---------------------------------------------|----------------|------------------------------|-------------|------------------|\n\n| Interface                                   | FINE           | Utah Slanted Electrode Array | TIME        | Cuff electrode   |\n\n| Electrical stimulation encoding Pulse width | Fixed          | Fixed                        | Linear      | Fixed            |\n\n| Amplitude                                   | Fixed          | Fixed                        | Fixed       | Fixed            |\n\n| Frequency                                   | Linear         | Model based                  | Fixed       | Linear           |\n\n| Mechanical stimulation encoding             | -              | -                            | -           | -                |\n\n| RPH model                                   | VariPlus Speed | DEKA Luke                    | IH2 Azzurra | SensorHand Speed |\n\n| Reference                                   | 136            | 139                          | 64          | 138              |\n\n| Year                                        | 2018           | 2019                         | 2019        | 2020             |\n\nAbbreviations: FINE, flat interface nerve electrode; RPH, robotic prosthetic hand; TENS, transcutaneous electrical nerve stimulation; TIME, transverse intrafascicular multichannel electrode. a The positions of the pressure sensors are shown in green, the joints where force is measured are shown with solid red lines, and the joints where the position is read are shown with dashed blue lines.\n",
    "topic": "The influence of electrode interface and stimulation encoding methods on the integration of sensory feedback and motor control in advanced prosthetic hands.",
    "response": "<document_analysis>\nThe context presents a comparative table of sensor distributions and stimulation encoding methods across different advanced prosthetic hand models, focusing on electrode interfaces (FINE, Utah Slanted Electrode Array, TIME, and Cuff electrode), and the parameters used for electrical stimulation encoding, such as pulse width, amplitude, and frequency. It also notes the presence or absence of mechanical stimulation encoding and references specific robotic prosthetic hand models with associated years.\n\nKey themes include how different electrode interfaces employ varied encoding strategies\u2014fixed versus linear or model-based modulation of pulse width and frequency\u2014to convey sensory feedback. This variation likely impacts how sensory information is integrated with motor control in prosthetics, influencing the naturalness and functionality of the prosthetic hand.\n\nImplicit in the data is the complexity of interfacing neural signals with prosthetic devices, where choices in electrode design and stimulation encoding critically determine the efficacy of sensory feedback integration. The use of fixed versus adaptive (linear or model-based) stimulation parameters suggests differing approaches to mimic natural neural signaling.\n\nDifficulty is rated at 9/10 due to the technical specificity and the necessity to understand neural interfaces, electrical stimulation paradigms, and sensorimotor integration in prosthetics.\n\nThe question should probe how electrode interface types and encoding methods affect the quality and integration of sensory feedback with motor control, encouraging synthesis of knowledge about neuroprosthetics, stimulation strategies, and sensorimotor integration.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do variations in electrode interface types and electrical stimulation encoding methods influence the effectiveness of sensory feedback integration with motor control in advanced prosthetic hands?\n\nExplanation: Different electrode interfaces (such as FINE, Utah Slanted Electrode Array, TIME, and cuff electrodes) utilize distinct stimulation encoding strategies (fixed, linear, or model-based modulation of pulse width and frequency) that affect the fidelity and adaptability of sensory signals delivered to the nervous system, thereby impacting how naturally and effectively sensory feedback is integrated with motor commands for prosthetic control.\n\nCorrect Answer: Electrode interface types and encoding methods determine the precision and adaptability of sensory signals, with interfaces using linear or model-based stimulation encoding enabling more natural and effective integration of sensory feedback with motor control than fixed-parameter approaches.\n</output_format>",
    "question": "How do variations in electrode interface types and electrical stimulation encoding methods influence the effectiveness of sensory feedback integration with motor control in advanced prosthetic hands?",
    "answer": "Electrode interface types and encoding methods determine the precision and adaptability of sensory signals, with interfaces using linear or model-based stimulation encoding enabling more natural and effective integration of sensory feedback with motor control than fixed-parameter approaches.",
    "explanation": "Different electrode interfaces (such as FINE, Utah Slanted Electrode Array, TIME, and cuff electrodes) utilize distinct stimulation encoding strategies (fixed, linear, or model-based modulation of pulse width and frequency) that affect the fidelity and adaptability of sensory signals delivered to the nervous system, thereby impacting how naturally and effectively sensory feedback is integrated with motor commands for prosthetic control.",
    "question_token_count": 29,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 43
  },
  {
    "context": "## Table 3 Clinical assessments for transradial amputees using robotic prosthetic hands\n| Somatosensory feedback   | Implicit                                            | Implicit Implicit           |                      | Explicit                   | Explicit                        | Implicit            | Implicit                         |                          | Explicit                                | Implicit      |                              | Implicit             | Explicit          |               |\n\n|--------------------------|-----------------------------------------------------|-----------------------------|----------------------|----------------------------|---------------------------------|---------------------|----------------------------------|--------------------------|-----------------------------------------|---------------|------------------------------|----------------------|-------------------|---------------|\n\n| Fine movement            |                                                     |                             |                      |                            |                                 | X                   |                                  |                          |                                         |               |                              |                      |                   |               |\n\n| Measurement Reach        |                                                     | X                           |                      |                            | X                               | X                   |                                  |                          | X                                       |               |                              |                      | X                 |               |\n\n| Grasp                    |                                                     | X                           |                      | X                          | X                               |                     |                                  |                          | X                                       |               |                              | X                    |                   |               |\n\n| Embodiment               |                                                     |                             | X                    |                            |                                 |                     |                                  | X                        |                                         |               |                              |                      |                   |               |\n\n| Quality of life          |                                                     |                             |                      |                            |                                 |                     | X                                |                          |                                         | X             |                              |                      |                   | X             |\n\n| Clinically validated     | X X                                                 |                             |                      |                            |                                 | X                   | X                                |                          |                                         | X             | X                            |                      |                   | X             |\n\n| Measurement type         | Handling and manipulation of objects Pick and place | Pick and place              | Psychometric         | Grasping                   | Pick and place                  | Pick and place      | Questionnaire                    | Psychometric             | Pick and place, manipulation            | Questionnaire | Handling and manipulation of | objects              | Pick and place    | Questionnaire |\n\n| Reference(s)             | 160 154, 155                                        | 159                         | 183                  | 139                        | 164                             | 157, 158            | 144, 150                         | 175                      | 139                                     | 147           | 161                          |                      | 129               | 148           |\n\n| Name                     | Action Research Arm Test Box and Block T est        | Clothespin Relocation T est | Cross Congruent Task | Grasping Relative Index of | Performance Magnetic table task | Nine Hole Peg T est | Orthotics and Prosthetics User's | Survey Peripersonal test | Prosthesis Efficiency and Profitability | QuickDASH     | Southampton Hand             | Assessment Procedure | Virtual Egg T est | WHOQOL-BREF   |\n\nAbbreviations: QuickDASH, short version of the Disabilities of the Arm, Shoulder, and Head questionnaire; WHOQOL-BREF, short version of the World Health Organization Quality of Life scale.\n",
    "topic": "The distinction between implicit and explicit somatosensory feedback modalities and their roles in clinical assessments of robotic prosthetic hands for transradial amputees.",
    "response": "<document_analysis>\nThe table presents a detailed overview of clinical assessments used for evaluating robotic prosthetic hands in transradial amputees, with a specific focus on the somatosensory feedback modalities classified as implicit and explicit. It categorizes various assessments based on whether they engage implicit or explicit somatosensory feedback and links these modalities to different functional domains such as fine movement, reach measurement, grasp, embodiment, quality of life, and clinical validation. The assessments include psychometric tests, questionnaires, and physical manipulation tasks (e.g., pick and place, grasping). The implicit feedback appears associated with automatic, unconscious sensory integration during tasks like object handling and manipulation, while explicit feedback relates to conscious sensory perception and awareness, as inferred from psychometric and embodiment measures. The table also highlights which tests incorporate these feedback types and their clinical validation status, illustrating how implicit and explicit feedback modalities contribute differently to evaluating prosthetic function, user experience, and quality of life.\n\nThis content is highly relevant and informative for understanding how implicit and explicit somatosensory feedback are operationalized in clinical assessments, making it suitable for generating a complex, expert-level question. The complexity is high (rated 9/10) because it involves nuanced distinctions between sensory feedback types, their functional implications, and their integration into clinical evaluation frameworks. The question should challenge experts to differentiate these modalities conceptually and practically within the clinical context, promoting deep reflection on their roles in prosthetic performance assessment.\n\nThe question should encourage synthesis of how implicit versus explicit feedback modalities influence different clinical outcomes and why certain tests are designed to target one or the other, probing an expert\u2019s understanding of sensory-motor integration in prosthetic use and assessment design.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do implicit and explicit somatosensory feedback modalities differentially influence the design and interpretation of clinical assessments for robotic prosthetic hands in transradial amputees, particularly regarding measures of grasp, embodiment, and quality of life?\n\nExplanation: Implicit feedback involves unconscious sensory integration during tasks like handling and manipulation, reflected in performance-based assessments such as grasp and reach tests, while explicit feedback relates to conscious sensory awareness and embodiment, often evaluated through psychometric and questionnaire-based measures; understanding their differential influence is crucial because it informs why certain clinical tests emphasize functional performance versus subjective experience, affecting interpretation of prosthetic efficacy and user adaptation.\n\nCorrect Answer: Implicit feedback underpins performance-based functional tests like grasp and reach by enabling unconscious sensorimotor integration, whereas explicit feedback underlies psychometric and embodiment assessments by capturing conscious sensory perception and user experience, guiding distinct evaluation approaches in clinical assessments.\n</output_format>",
    "question": "How do implicit and explicit somatosensory feedback modalities differentially influence the design and interpretation of clinical assessments for robotic prosthetic hands in transradial amputees, particularly regarding measures of grasp, embodiment, and quality of life?",
    "answer": "Implicit feedback underpins performance-based functional tests like grasp and reach by enabling unconscious sensorimotor integration, whereas explicit feedback underlies psychometric and embodiment assessments by capturing conscious sensory perception and user experience, guiding distinct evaluation approaches in clinical assessments.",
    "explanation": "Implicit feedback involves unconscious sensory integration during tasks like handling and manipulation, reflected in performance-based assessments such as grasp and reach tests, while explicit feedback relates to conscious sensory awareness and embodiment, often evaluated through psychometric and questionnaire-based measures; understanding their differential influence is crucial because it informs why certain clinical tests emphasize functional performance versus subjective experience, affecting interpretation of prosthetic efficacy and user adaptation.",
    "question_token_count": 45,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 48
  },
  {
    "context": "## 4.2. Shared Control to Help Motor Decoding\nThe ultimate goal of RPH control is to be as close as possible to controlling a natural hand. Therefore, an ideal control needs to be intuitive and continuous over individual fingers and wrist movements. Increasing the number of DOFs and developing proportional control will increase dexterity for prosthesis users but will inevitably reduce the overall robustness of the decoder. Since reliability is one of the main factors for upper-limb prosthesis users (102), this is a significant issue for the commercialization of more dexterous control schemes.\n\nOne possible solution to improve decoding robustness is to add robotic automation of some portion of the motor command. Shared-control strategies between a subject and a smart robotic hand have been reported for automated preshaping and grasping (103), grip force adjustment\n\n(104), slip detection, and hand closing (105). In the context of single-finger proportional control, Zhuang et al. (79) proposed a shared-control strategy to increase grasp robustness (avoiding accidental drops), by maximizing the number of contacts between the RPH and an object while allowing the user to maintain full autonomy over decisions about grasping and releasing, grasp preshaping, and non-grasp-related motions. These strategies allow both freedom during singlefinger control and robustness during a grasp event (79) and can perform more dexterous movements that cannot be decoded based on EMG alone. However, they necessitate many DOAs (e.g., active control of each phalanx to reposition the fingers around an object), which is still a significant challenge in terms of motor miniaturization, power consumption, and cost.\n",
    "topic": "Examine the challenges and engineering considerations related to implementing many degrees of actuation (DOAs) in prosthetic hands, including motor miniaturization, power consumption, and cost.",
    "response": "<document_analysis>\nThe passage discusses the complexity of achieving naturalistic control in robotic prosthetic hands (RPH) with multiple degrees of freedom (DOFs) and proportional control to enhance dexterity. It highlights the trade-off between increasing dexterity through more DOFs and maintaining decoder robustness, which is critical for user reliability and commercial viability. Shared control strategies are introduced as a solution to improve robustness by combining user input and robotic automation, especially for grasping tasks. However, implementing these shared control strategies often requires many degrees of actuation (DOAs), such as active control of each finger phalanx, which raises significant engineering challenges. These challenges include motor miniaturization to fit small spaces, managing power consumption to ensure practical battery life, and controlling costs to keep the prosthesis affordable. The passage implicitly assumes that these engineering constraints limit the scalability and feasibility of highly dexterous prosthetic hands. The difficulty of the question is rated 9 because it requires integrating knowledge of robotics, prosthetic design, control theory, and engineering trade-offs. The question encourages reflection on how these mechanical and electrical design constraints influence the development and commercialization of advanced prosthetic devices.\n</document_analysis>\n\n<output_format>\nQuestion: How do the engineering challenges of motor miniaturization, power consumption, and cost specifically constrain the implementation of many degrees of actuation (DOAs) in prosthetic hands, and why are these constraints significant for advancing prosthesis dexterity and commercialization?\n\nExplanation: Implementing many DOAs requires fitting numerous small, precise motors into limited space (miniaturization), which is difficult and costly; increased actuators consume more power, reducing battery life and usability; and the complexity and quantity of components drive up manufacturing costs. These constraints limit the practical realization of highly dexterous prosthetic hands despite their potential for improved functionality, thus impacting robustness, user reliability, and commercial viability.\n\nCorrect Answer: Because fitting many small motors is challenging and expensive, increases power demands, and raises production costs, these engineering constraints limit the practicality and commercialization of highly dexterous prosthetic hands with many DOAs.\n</output_format>",
    "question": "How do the engineering challenges of motor miniaturization, power consumption, and cost specifically constrain the implementation of many degrees of actuation (DOAs) in prosthetic hands, and why are these constraints significant for advancing prosthesis dexterity and commercialization?",
    "answer": "Because fitting many small motors is challenging and expensive, increases power demands, and raises production costs, these engineering constraints limit the practicality and commercialization of highly dexterous prosthetic hands with many DOAs.",
    "explanation": "Implementing many DOAs requires fitting numerous small, precise motors into limited space (miniaturization), which is difficult and costly; increased actuators consume more power, reducing battery life and usability; and the complexity and quantity of components drive up manufacturing costs. These constraints limit the practical realization of highly dexterous prosthetic hands despite their potential for improved functionality, thus impacting robustness, user reliability, and commercial viability.",
    "question_token_count": 52,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 6,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 43
  },
  {
    "context": "## Figure 1\nExamples of functioning hand replacement. ( a ) A personalized cosmetic hand solution (ITOP , Italy) provides a natural look. Photos adapted with permission from ITOP and Procosil. ( ) A body-powered prosthetic solution (Ottobock, Germany) is a common approach b for people with an upper-limb amputation. Photo reproduced with permission from Ottobock. ( ) An sEMG-based pattern recognition c system (Gen2, Coapt, USA) allows grasp classification. Photo adapted courtesy of Coapt LLC ( http://www.coaptengineering.com ). ( d ) sEMG control and extracellular stimulation via an implanted FINE were used to convey sensory feedback for home-use applications. The implant was stable for more than five years, and home-use electrical stimulation for sensory feedback was investigated for up to 13 days (116). Panel adapted from Reference 116 (CC BY-SA 4.0). ( ) Fully implanted myoelectric sensors provide stronger e and more reliable signals that do not change with arm positioning, socket rotation, or sweating (107). Panel adapted with permission from Reference 107. ( f ) Six-DOF prosthetic hand control (i-Limb Ultra, \u00d6ssur, Iceland) uses threshold-based sEMG control and cocontraction to switch between grasps. ( g ) Sensory feedback conveyed via intraneural TIMEs enables the encoding of objects' shape and stiffness (6). Panel reproduced with permission; copyright 2014 Lifehand 2 / Patrizia T occi. ( h ) Hand transplantation is a promising technique that has not yet become a standard procedure due to several surgical and clinical difficulties. Panel adapted with permission from Reference 177. Abbreviations: DOF, degree of freedom; FINE, flat interface nerve electrode; sEMG, surface electromyography; TIME, transverse intrafascicular multichannel electrode.\n\nsurvey of below-elbow amputees from Sweden, the United Kingdom, and Canada (7), 53% of the respondents wore a cosmetic prosthesis, 13% used a hook, 4% used a cable hand, and 30% used a myoelectric RPH. Despite encouraging results in the late 1990s (8), hand transplantation ( Figure 1 h ) encountered significant surgical and clinical difficulties (rejection and immunosuppression); it has therefore been tested in only a few patients and is not yet considered one of the available options.\n",
    "topic": "The importance and impact of degrees of freedom (DOF) in prosthetic hand design and control strategies, including multi-DOF prosthetic devices like the i-Limb Ultra.",
    "response": "<document_analysis>\nThe provided context offers a detailed overview of various prosthetic hand solutions, highlighting different control strategies and technologies, including cosmetic hands, body-powered prostheses, surface electromyography (sEMG) systems, implanted sensors, and sensory feedback methods. Among these, the mention of the i-Limb Ultra (\u00d6ssur, Iceland) stands out as a six-degree-of-freedom (DOF) prosthetic hand that utilizes threshold-based sEMG control and cocontraction for switching between grasps. This detail is crucial for understanding how increased DOF enhances functionality and control complexity in prosthetics.\n\nCentral ideas include the diversity of prosthetic technologies, the challenge of achieving natural and reliable control signals, and the trade-offs between different control modalities. The notion of DOF is implicitly linked to the complexity and dexterity of prosthetic hands, with multi-DOF devices like the i-Limb Ultra enabling more nuanced hand movements and grip patterns.\n\nSubtle details such as the use of cocontraction to switch grasp modes in a multi-DOF system suggest the importance of intuitive and efficient control strategies when managing increased mechanical complexity. The presence of sensory feedback technologies (e.g., intraneural TIMEs) also indicates a trend toward integrating both motor control and sensory information, which may further leverage the advantages of multiple DOFs.\n\nDifficulty rating: 9/10. The question should probe understanding of how degrees of freedom influence prosthetic design and control, the implications for user control complexity, and the trade-offs in implementing multi-DOF systems, demanding a deep grasp of neuroprosthetics and human-machine interfaces.\n\nThe question will invite reflection on the interplay between mechanical DOFs and control strategies, encouraging a critical evaluation of the advantages and challenges associated with multi-DOF prosthetic hands, such as the i-Limb Ultra.\n\nThe context is meaningful, technical, and highly relevant to advanced prosthetic design and control, suitable for generating a challenging question-answer pair.\n</document_analysis>\n\n<output_format>\nQuestion: How do increased degrees of freedom (DOF) in prosthetic hands, exemplified by devices like the six-DOF i-Limb Ultra, influence the complexity and effectiveness of control strategies such as threshold-based sEMG and cocontraction switching, and what are the key challenges this poses for user operation and intuitive control?\n\nExplanation: Increased DOFs in prosthetic hands enable more natural and versatile movements but also introduce greater control complexity. Devices like the i-Limb Ultra use threshold-based sEMG signals combined with cocontraction to switch between multiple grasp patterns, which requires the user to generate distinct muscle activation patterns reliably. This elevates the cognitive and physical demand on users, making intuitive control more challenging. Key challenges include ensuring reliable signal detection despite factors like arm positioning and sweating, managing the switching between multiple DOFs without confusion or fatigue, and designing control algorithms that balance functionality with usability.\n\nCorrect Answer: Increased DOFs enhance dexterity but require complex control strategies like threshold-based sEMG combined with cocontraction, posing challenges in reliable signal detection, cognitive load, and intuitive user operation.\n</output_format>",
    "question": "How do increased degrees of freedom (DOF) in prosthetic hands, exemplified by devices like the six-DOF i-Limb Ultra, influence the complexity and effectiveness of control strategies such as threshold-based sEMG and cocontraction switching, and what are the key challenges this poses for user operation and intuitive control?",
    "answer": "Increased DOFs enhance dexterity but require complex control strategies like threshold-based sEMG combined with cocontraction, posing challenges in reliable signal detection, cognitive load, and intuitive user operation.",
    "explanation": "Increased DOFs in prosthetic hands enable more natural and versatile movements but also introduce greater control complexity. Devices like the i-Limb Ultra use threshold-based sEMG signals combined with cocontraction to switch between multiple grasp patterns, which requires the user to generate distinct muscle activation patterns reliably. This elevates the cognitive and physical demand on users, making intuitive control more challenging. Key challenges include ensuring reliable signal detection despite factors like arm positioning and sweating, managing the switching between multiple DOFs without confusion or fatigue, and designing control algorithms that balance functionality with usability.",
    "question_token_count": 65,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 39
  },
  {
    "context": "## 4.1. Decoding Algorithms\nThe clinical standard for RPH control is based on the use of two sEMG channels, with the electrodes placed superficially on antagonist muscles. The envelope of the signal is extracted so that the user can control the closing and opening of the RPH by modulating the amplitude of their muscle contraction. When the amplitude exceeds a certain threshold, the RPH will move depending on which muscle was activated. Companies are offering more DOFs, using cocontraction to\n\ncycle through different types of grasps (e.g., Ottobock's Michelangelo hand). However, this type of control is highly nonintuitive and gives only low dexterity to the user. An alternative to this direct control approach is based on pattern recognition methods, extracting hand-crafted features to characterize the signal in a discriminative way (e.g., the signal root mean square, wavelength, and zero crossing) and classify the type of grasp intended by the user. This solution has become robust enough to reach the market (the Coapt system and Ottobock's Myo Plus). Using 2-12 bipolar sEMG electrodes makes it possible to obtain good classification rates for different kinds of grasps, with 90-95% accuracy for 4-12 classes and up to 75% for 50 classes (68-72).\n\nUsing a similar electrode disposition and classification method, other groups showed the possibility of decoding single-finger movement using the classification of flexion or extension (73, 74). Recently, Bhagwat &amp; Mukherji (75) showed single- and multifinger classification of 15 different movements with 99.79% accuracy. Researchers are also working on proportional control instead of classification, which makes it possible to decode several DOFs (e.g., wrist and finger movements) simultaneously and proportionally (76, 77). This type of control offers continuous position control. Several studies have also shown that single-finger proportional control is feasible, with good results (78, 79).\n\nAs an alternative, nonbiomimetic EMG decoders have been developed that rely on the subject learning inverse maps to relate motor outputs to arbitrary control variables (80). Using an abstract decoding cursor control space, subjects can learn to modulate their EMG activity to reach different targets arranged in a center-out task in order to trigger various grasping movements (81). Dyson et al. (82) recently validated these results on amputee participants; they showed that after training, the difficulty of the tasks could be increased, improving the possibilities for robotic hand control.\n\nWith only a few electrodes placed on muscles of interest, the accurate positioning of the electrodes requires anatomical knowledge; indeed, the type of amputation (congenital or traumatic), the surgical procedure, and the time since amputation (83) could influence the muscle anatomy and make the placement of the electrode tedious and specific to individual subjects. Moreover, a small shift in electrode placement can disrupt the pattern recognition algorithm (84). T o tackle these issues, several authors have proposed HD-sEMG, which consists of a grid of closely spaced electrodes, as an alternative solution. The large number of electrodes allows information to be recorded from a large part of the subject's forearm.\n\nHD-sEMG signals offer high spatial resolution, and recorded signals can be interpreted as spatial images of EMG activity. Using this image representation of EMG data, HD-sEMG is robust to small electrode shifts (85). Boschmann &amp; Platzner (85) used a structural similarity index, borrowed from the computer vision field, on HD-sEMG images combined with a simple one-against-one nearest-neighbor classifier to decode wrist and hand motions. Similarly, Stango et al. (86) used a variogram of images (a measure of the degree of spatial correlation, used mainly in geostatistics) to classify wrist movements. Both groups showed that their methods, which use spatial information from the images, performed better or similarly to the classic feature extraction approach. Moreover, their strategies improved the robustness to electrode shift and electrode number. The use of several spatially close electrodes makes it possible to decompose the EMG signal into its constituent motor unit action potential (50, 87). Kapelner et al. (88) investigated this approach, decomposing EMG signals to extract motor unit activity from forearm muscles during wrist motions. Recently, Dai &amp; Hu (89) showed that an approach consisting of finger joint angle estimation, combining classification for finger selection with EMG decomposition into motor unit activity, outperforms a standard amplitude-based approach.\n\nWe observe a paradigm shift from feature engineering to feature learning using raw data as input for deep neural networks. Studies have shown that combining this deep learning approach with HD-sEMG offers better performance than hand-crafted features in both grasp classification\n\n(90) and simultaneous single-finger and wrist movement classification (91). Deep learning has also shown good results with a smaller number of electrodes for grasp classification (72) and regression of arm or wrist motions (92, 93).\n\nThis approach permits both high dexterity and robustness, with unprecedented performance. However,one of the major difficulties of the deep learning approach is that it requires an extensive data set for training. For example, the deep learning used for the ImageNet challenge in 2012 used 1.2 million images for training on 1,000 categories (94). In the context of hand gesture recognition, generating tens of thousands of examples for a subject is not a viable option.\n\nA possible solution could use domain adaptation [often called transfer learning in the EMG literature (95, 96)], by leveraging data acquired from several subjects to enhance and accelerate training for a new user. Indeed, the aim is to use information from a database of several source domains and adapt it to a target domain (the end user) with a small number of samples. Authors generally apply deep domain adaptation (domain adaptation combined with deep learning) by pretraining a deep neural network and fine-tuning it with a few repetitions of movements by a target subject. The main idea is that gathering the recordings of several participants can meet the necessary conditions to learn a general mapping of all users' sEMG signals.\n\nUsing this idea, C\u00f4t\u00e9-Allard et al. (97) showed that their deep model was able to learn the features and significantly enhance the performance of deep networks on out-of-sample gestures. Using HD-sEMG and deep learning, Du et al. (98) also showed an unsupervised deep domain adaptation method that incrementally learns from data during a new session without explicit calibration of gestures. Consequently, deep learning offers a particularly attractive context from which to develop deep domain adaptation algorithms to leverage interuser data. This approach can increase decoding performance, improve robustness to electrode shift, and reduce the number of repetitions needed during training (99).\n\nAs seen in this section, the search for new EMG decoding algorithms that go beyond thresholdbased detection is an active field of research. Phinyomark &amp; Scheme (100) and Khamparia &amp; Singh (101) have reviewed recent research in EMG pattern recognition methods.\n\nMachine learning in the field of computer vision and object recognition has shown outstanding results using deep learning and is already used commercially by many companies. Some deep learning algorithms based on a pretrained network are now usable without any fine-tuning (e.g., self-driving cars). However, bio-signals are intrinsically different from images and need adaptation. More important, the amount of labeled EMG data available to effectively train deep networks might not be sufficient to capture the evolution of the signal over time (electrode displacement, skin impedance changes, etc.). Therefore, if model architectures and data processing are tailored for bio-signal applications and take into consideration signal evolution with time, deep learning can become a solution for more robust motor intention decoding.\n",
    "topic": "The development and advantages of proportional control methods enabling simultaneous, continuous multi-DOF control of wrist and finger movements.",
    "response": "<document_analysis>\nThe context details advanced decoding algorithms for robotic prosthetic hand (RPH) control, emphasizing evolution from threshold-based methods to pattern recognition and deep learning approaches. It highlights the limitations of classical two-channel sEMG control and the benefits of multi-electrode setups with pattern recognition to classify discrete grasps. The discussion then advances to proportional control methods enabling simultaneous, continuous control of multiple degrees of freedom (DOFs) such as wrist and finger movements. This proportional approach allows decoding of motion intensity and direction continuously, rather than discrete classification, thus providing more natural and dexterous control. The text also addresses the technical challenges in electrode placement and signal variability, proposing HD-sEMG and deep learning as robust solutions. It touches on the potential of deep domain adaptation to reduce training burden and improve inter-subject generalization.\n\nThe question topic focuses on the development and advantages of proportional control methods for simultaneous multi-DOF wrist and finger movement decoding. These methods contrast with classification-based control by enabling continuous and simultaneous control signals for multiple joints, improving naturalness and dexterity of prosthetic control. This requires understanding how proportional control differs from classification, the technical mechanisms enabling it (e.g., signal processing, feature extraction, regression), and the practical implications in RPH functionality.\n\nDifficulty: 9/10. The question requires integration of multiple complex concepts: EMG signal decoding, classification vs. regression control paradigms, multi-DOF simultaneous decoding, and practical prosthetic control implications. It demands deep understanding of neural engineering, signal processing, and machine learning applications in prosthetics.\n\nThe question will invite critical reflection on the technical and functional significance of proportional control methods, encouraging nuanced understanding of how continuous control enables enhanced dexterity and the challenges it entails.\n\nThe context is rich, coherent, and highly suitable for generating a challenging expert-level question.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do proportional control methods for EMG decoding enable simultaneous and continuous multi-degree-of-freedom control of wrist and finger movements, and what are the key advantages of these methods compared to traditional classification-based control in robotic prosthetic hands?\n\nExplanation: Proportional control methods decode EMG signals to produce continuous output signals reflecting the intensity and direction of muscle activation, allowing multiple DOFs (such as wrist and finger joints) to be controlled simultaneously and smoothly. Unlike classification-based control, which discretely categorizes intended movements, proportional control offers continuous position control, improving the naturalness and dexterity of prosthetic hand operation. This approach enables simultaneous modulation of multiple muscle signals, facilitating more intuitive and precise multi-joint movements, essential for complex hand functions. Additionally, proportional control supports single-finger control and regression-based decoding, enhancing functional outcomes beyond the limited low-dexterity grasps achievable with classification alone.\n\nCorrect Answer: By decoding EMG signals into continuous control signals proportional to muscle activation, proportional control methods enable simultaneous, continuous multi-DOF control of wrist and finger movements, offering more natural, dexterous, and intuitive prosthetic control compared to discrete classification-based methods. \n</output_format>",
    "question": "How do proportional control methods for EMG decoding enable simultaneous and continuous multi-degree-of-freedom control of wrist and finger movements, and what are the key advantages of these methods compared to traditional classification-based control in robotic prosthetic hands?",
    "answer": "By decoding EMG signals into continuous control signals proportional to muscle activation, proportional control methods enable simultaneous, continuous multi-DOF control of wrist and finger movements, offering more natural, dexterous, and intuitive prosthetic control compared to discrete classification-based methods.",
    "explanation": "Proportional control methods decode EMG signals to produce continuous output signals reflecting the intensity and direction of muscle activation, allowing multiple DOFs (such as wrist and finger joints) to be controlled simultaneously and smoothly. Unlike classification-based control, which discretely categorizes intended movements, proportional control offers continuous position control, improving the naturalness and dexterity of prosthetic hand operation. This approach enables simultaneous modulation of multiple muscle signals, facilitating more intuitive and precise multi-joint movements, essential for complex hand functions. Additionally, proportional control supports single-finger control and regression-based decoding, enhancing functional outcomes beyond the limited low-dexterity grasps achievable with classification alone.",
    "question_token_count": 47,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 52
  },
  {
    "context": "## 5.5. Perspectives\nWe believe that sensorization will play a significant role in the next generation of RPHs. Here, we discuss three main directions influenced by sensorization: embedded sensorization, improved stimulation strategies, and new computational architectures.\n\n5.5.1. Embedded sensorization. Sensorized hands are not yet prevalent in the literature but are starting to draw interest, especially with the improvement of interfaces for bidirectional prostheses (for a list of RPHs with sensorized fingertips, see Supplemental Tables 1 and 2 ). As a recent example, Controzzi et al. (141) developed the Mia hand (Prensilia, Italy), which is integrated with sensors that can measure normal and tangential forces at the fingertips. Sensorization of RPHs is a design requirement that should be considered as important as other functional requirements for hand prostheses, such as weight or dexterity. T o improve RPH performance and sensor integration, next-generation RPHs should then be designed with their sensorization in mind. Information about hand state (joint position, forces, and touch) can also be beneficial to increase the dexterity of such hands, enabling automatic adjustments such as catching slipping objects (e.g., the bebionic3 hand) and shared-control strategies (see Section 4).\n\n5.5.2. Improved stimulation strategies. Biomimicry is one of the strongest trends in nerve stimulation strategies, as it promises to deliver biologically plausible stimulation patterns to evoke more natural sensations. Biomimetic approaches rely on bio-inspired models to compute the stimulation patterns, so new iterations of these models, based on the current experience in stimulation and neural recording, are needed to improve the quality of elicited sensations.\n\nThese model-based approaches permit simpler modulation strategies that increase the naturalness of sensations. T an et al. (38), for example, proved that a sinusoidal modulation of the pulse width improves the naturalness of the sensation. Formento et al. (142) instead designed a strategy to activate asynchronously stimulated fibers, mimicking healthy neural activity; in their work, they replaced classical biphasic stimulation with a high-frequency burst of pulses that slowly increased in amplitude, and confirmed their hypothesis in ex vivo experiments. Stimulation patterns that try to overcome the physical limits of present neural interfaces (as in 142) while paving the way for more natural evoked sensations also suggest the requirements for the future generation of neural interfaces and stimulators for sensory feedback: increase reaching without losing discrimination.\n\n5.5.3. New computational architectures. Neuromorphic architectures have the potential to represent a paradigm shift in the design of the control systems for bidirectional hand prostheses, going toward distributed systems and edge computing. Both sensor acquisition and stimulation can benefit from these trends because they lead to more reliable systems that scale well with the increase of sensors and stimulation active sites. If the next generation of neuromorphic hardware promotes portability and lower power consumption, it could lead to broader implementation and adoption of neuromorphic systems in bidirectional hand prostheses.\n\nMany RPHs rely on advanced encoding and decoding algorithms implemented with neural networks (62), which are more computationally demanding than traditional approaches. It is interesting that even deep learning networks can be translated into spiking neural networks (143), possibly enabling full neuromorphic hardware encoding and decoding in future prostheses.\n",
    "topic": "Design considerations for integrating sensorization as a fundamental requirement alongside weight and dexterity in next-generation robotic prosthetic hands.",
    "response": "<document_analysis>\nThe provided text emphasizes the emerging importance of sensorization in robotic prosthetic hands (RPHs), highlighting it as a critical design consideration on par with traditional factors such as weight and dexterity. Embedded sensorization is portrayed as a foundational element that can significantly enhance prosthetic functionality through improved feedback and automatic adjustments. The text also discusses the integration challenges and opportunities for sensorization, such as the need to embed sensors that measure forces and joint positions, which are essential for advanced control strategies like shared control and slip detection. This implies a shift in prosthetic design philosophy where sensorization is not an add-on but a core aspect influencing mechanical design, control algorithms, and user experience. \n\nThe passage suggests that future RPHs must be intentionally designed with sensorization from the outset to maximize performance, implying that retrofitting sensor systems might limit functionality or integration quality. This raises complex design challenges, including sensor placement, durability, power consumption, and data processing capabilities, especially given the trend toward neuromorphic architectures. The question can probe understanding of how sensorization fundamentally changes design priorities and trade-offs in RPHs.\n\nDifficulty rating: 9/10 due to the need for an expert-level understanding of prosthetic design, sensor integration challenges, and implications for control systems.\n\nThe question should encourage the expert to reflect on the multidimensional impact of treating sensorization as a core design requirement alongside weight and dexterity, including mechanical, electronic, and computational considerations.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does prioritizing embedded sensorization as a fundamental design requirement alongside weight and dexterity fundamentally alter the design considerations and trade-offs in next-generation robotic prosthetic hands?\n\nExplanation: Prioritizing embedded sensorization necessitates redesigning prosthetic hands to accommodate sensors that provide continuous feedback on joint position, forces, and touch, which influences mechanical structure, power management, and control strategies. This integration requires balancing sensor placement and robustness without compromising weight or dexterity, incorporating advanced data processing architectures (such as neuromorphic systems) to handle increased sensor data, and enabling adaptive behaviors like slip detection and shared control, fundamentally shifting prosthetic design from purely mechanical to tightly integrated mechatronic systems.\n\nCorrect Answer: It requires redesigning the prosthesis to integrate sensors for continuous feedback, balancing sensor placement and robustness with weight and dexterity constraints, adopting advanced computational architectures for data processing, and enabling adaptive control strategies, thus transforming the prosthetic hand into a tightly integrated mechatronic system rather than a purely mechanical device.\n</output_format>",
    "question": "How does prioritizing embedded sensorization as a fundamental design requirement alongside weight and dexterity fundamentally alter the design considerations and trade-offs in next-generation robotic prosthetic hands?",
    "answer": "It requires redesigning the prosthesis to integrate sensors for continuous feedback, balancing sensor placement and robustness with weight and dexterity constraints, adopting advanced computational architectures for data processing, and enabling adaptive control strategies, thus transforming the prosthetic hand into a tightly integrated mechatronic system rather than a purely mechanical device.",
    "explanation": "Prioritizing embedded sensorization necessitates redesigning prosthetic hands to accommodate sensors that provide continuous feedback on joint position, forces, and touch, which influences mechanical structure, power management, and control strategies. This integration requires balancing sensor placement and robustness without compromising weight or dexterity, incorporating advanced data processing architectures (such as neuromorphic systems) to handle increased sensor data, and enabling adaptive behaviors like slip detection and shared control, fundamentally shifting prosthetic design from purely mechanical to tightly integrated mechatronic systems.",
    "question_token_count": 33,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 62
  },
  {
    "context": "## Current Solutions and Future Trends for Robotic Prosthetic Hands\nVincent Mendez, 1, \u2217 Francesco Iberite, 2, \u2217 Solaiman Shokur, 1,\u2020 and Silvestro Micera 1,2,\u2020\n\n1 Center for Neuroprosthetics and Institute of Bioengineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1202 Gen\u00e8ve, Switzerland; email: silvestro.micera@epfl.ch\n\n2 BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, 56127 Pisa, Italy\n\n\n## Keywords\nhand, prosthesis, neuroprostheses, sensory feedback, electromyography, EMG\n\n\n## Abstract\nThe desire for functional replacement of a missing hand is an ancient one. Historically, humans have replaced a missing limb with a prosthesis for cosmetic, vocational, or personal autonomy reasons. The hand is a powerful tool, and its loss causes severe physical and often mental debilitation. Technological advancements have allowed the development of increasingly effective artificial hands, which can improve the quality of life of people who suffered a hand amputation. Here, we review the state of the art of robotic prosthetic hands (RPHs), with particular attention to the potential and current limits of their main building blocks: the hand itself, approaches to decoding voluntary commands and controlling the hand, and systems and methods for providing sensory feedback to the user. We also briefly describe existing approaches to characterizing the performance of subjects using RPHs for grasping tasks and provide perspectives on the future of different components and the overall field of RPH development.\n",
    "topic": "The main mechanical and functional challenges in designing robotic prosthetic hands that replicate natural hand movements and dexterity.",
    "response": "<document_analysis>\nThe context provides a high-level overview of the state of robotic prosthetic hands (RPHs), focusing on their building blocks: the prosthetic hand mechanics, command decoding and control, and sensory feedback systems. It emphasizes the complexity of replicating natural hand function, highlighting that the hand is a powerful tool whose loss causes significant physical and psychological impact. The text alludes to both current capabilities and limitations in the design and control of RPHs, as well as the importance of sensory feedback to enhance user experience and performance. The abstract indicates that the review also covers performance characterization and future perspectives, implying a nuanced understanding of the technological and functional challenges in RPH development.\n\nThe question topic requests a highly challenging, technical question about the main mechanical and functional challenges in designing robotic prosthetic hands that replicate natural hand movements and dexterity. This requires synthesizing knowledge of biomechanics, neuroprosthetics, control systems, and sensory integration. The challenge lies in articulating the complexities and interplay of mechanical design constraints, control decoding limitations (e.g., EMG signal interpretation), and sensory feedback deficits that hinder naturalistic dexterity replication.\n\nDifficulty is rated 9/10 because the question demands a comprehensive and deep understanding of multidisciplinary aspects of RPH design, touching on both mechanical engineering and neuroprosthetic control theory, and requires insight into current technological limits and future needs.\n\nThe question should encourage reflection on the inherent difficulties in mimicking the natural hand\u2019s dexterity, including the trade-offs between mechanical complexity, intuitive control, and sensory feedback integration. It invites consideration of the interplay between hardware and neuro-control systems, which is crucial for advancing prosthetic hand performance.\n\nSince the context is a summary abstract, the question and answer must be constructed to reflect general expert-level understanding rather than specific experimental details.\n\nNo irrelevant or bogus content detected.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the principal mechanical and functional challenges in designing robotic prosthetic hands that can replicate the complex movements and dexterity of a natural human hand, and how do these challenges impact the integration of voluntary control and sensory feedback systems?\n\nExplanation: The key challenges include replicating the biomechanical complexity of the natural hand with multiple degrees of freedom and finely coordinated movements, designing actuators and mechanisms that are compact, lightweight, and capable of nuanced force control, and developing control systems that can accurately decode voluntary motor commands from limited and noisy signals such as electromyography. Additionally, integrating sensory feedback that restores tactile and proprioceptive information is difficult but essential to achieving naturalistic dexterity. These challenges affect the prosthesis's responsiveness, intuitiveness, and functional performance, making seamless integration of mechanical design, control decoding, and sensory feedback systems critical yet highly complex.\n\nCorrect Answer: Replicating the natural hand\u2019s biomechanical complexity with compact, precise actuators; accurately decoding voluntary motor commands from limited signals; and integrating effective sensory feedback to restore tactile and proprioceptive information are the principal challenges impacting control and functionality.\n</output_format>",
    "question": "What are the principal mechanical and functional challenges in designing robotic prosthetic hands that can replicate the complex movements and dexterity of a natural human hand, and how do these challenges impact the integration of voluntary control and sensory feedback systems?",
    "answer": "Replicating the natural hand\u2019s biomechanical complexity with compact, precise actuators; accurately decoding voluntary motor commands from limited signals; and integrating effective sensory feedback to restore tactile and proprioceptive information are the principal challenges impacting control and functionality.",
    "explanation": "The key challenges include replicating the biomechanical complexity of the natural hand with multiple degrees of freedom and finely coordinated movements, designing actuators and mechanisms that are compact, lightweight, and capable of nuanced force control, and developing control systems that can accurately decode voluntary motor commands from limited and noisy signals such as electromyography. Additionally, integrating sensory feedback that restores tactile and proprioceptive information is difficult but essential to achieving naturalistic dexterity. These challenges affect the prosthesis's responsiveness, intuitiveness, and functional performance, making seamless integration of mechanical design, control decoding, and sensory feedback systems critical yet highly complex.",
    "question_token_count": 46,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 47
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "Detailed evaluation of the technological maturity levels of motor and sensory interfaces, including body harnesses, sEMG, implanted electrodes, and osseointegration.",
    "response": "<document_analysis>\nThe context provides a detailed overview of the current state and future directions of prosthetic hand technologies, with a particular focus on the maturity levels of various interfaces (motor and sensory) and actuation systems. The central themes include the evolution from rigid to soft robotic architectures, the emergence of innovative actuation and sensing technologies, and a comprehensive maturity table categorizing technologies into widespread, mature, cutting-edge, and future directions. The table distinguishes motor interfaces (e.g., body harness, sEMG, iEMG), sensory interfaces (vibrotactile, TENS, osseointegration), and combined motor-sensory interfaces (osseointegration, FINEs).\n\nKey nuanced details include:\n- The progression of motor interfaces from body harnesses (most widespread) to advanced regenerative peripheral nerve interfaces and deep learning-based control (future directions).\n- Sensory feedback evolving from no feedback to complex biomimetic stimulation and proprioception.\n- Sensory interfaces like vibrotactile and TENS are mature, whereas neuromorphic and multimodal sensory feedback are cutting-edge.\n- The role of implanted electrodes such as FINEs, TIMEs, LIFEs, and their relative maturity status.\n- Osseointegration as both a motor and sensory interface at mature home-use levels.\n- The early stage but promising integration of soft neurotechnology and noninvasive intraneural stimulation.\n\nImplicit assumptions: \n- The maturity levels reflect both technological readiness and practical deployment feasibility.\n- Integration of motor and sensory interfaces is critical for advancing prosthetic utility.\n- Soft robotics and embedded sensing will significantly impact future prosthetic designs.\n\nDifficulty rating: 9/10. The question requires synthesis of complex, categorized data about multiple interface technologies, their maturity stages, and the implications for prosthetic development.\n\nThe question invites critical understanding of how these interfaces relate in terms of development, deployment, and future research, encouraging domain experts to articulate the nuanced technological landscape and the interplay between motor and sensory solutions.\n\nThis question is purposeful as it probes expert knowledge on the comparative technological readiness and integration challenges of multiple interfaces, a key concern in advanced prosthetic design.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the maturity levels of motor and sensory interfaces for prosthetic hands compare, particularly regarding the use of body harnesses, surface and implanted electromyography (sEMG and iEMG), osseointegration, and flat interface nerve electrodes (FINEs), and what implications do these differences have for the future integration of motor and sensory functions in prosthetic devices?\n\nExplanation: The maturity levels indicate that body harnesses and threshold-based sEMG represent the most widespread motor interfaces, while more advanced motor decoding interfaces like implanted EMG and pattern recognition are mature or cutting-edge. Sensory interfaces such as vibrotactile feedback and TENS have reached mature home use, whereas neuromorphic and biomimetic stimulations remain cutting-edge. Osseointegration uniquely appears as both a mature motor and sensory interface, while FINEs are mature sensory interfaces. These disparities suggest that while traditional motor control methods are well established, integrating sophisticated sensory feedback and combining motor-sensory functions through implanted electrodes like FINEs and osseointegration remains a critical frontier for future prosthetic development.\n\nCorrect Answer: Body harnesses and threshold-based sEMG are the most widespread motor interfaces; implanted EMG and FINEs are mature or cutting-edge; osseointegration serves as a mature combined motor-sensory interface; this indicates that future prosthetics will focus on integrating advanced motor decoding with sophisticated sensory feedback via implanted technologies.\n</output_format>",
    "question": "How do the maturity levels of motor and sensory interfaces for prosthetic hands compare, particularly regarding the use of body harnesses, surface and implanted electromyography (sEMG and iEMG), osseointegration, and flat interface nerve electrodes (FINEs), and what implications do these differences have for the future integration of motor and sensory functions in prosthetic devices?",
    "answer": "Body harnesses and threshold-based sEMG are the most widespread motor interfaces; implanted EMG and FINEs are mature or cutting-edge; osseointegration serves as a mature combined motor-sensory interface; this indicates that future prosthetics will focus on integrating advanced motor decoding with sophisticated sensory feedback via implanted technologies.",
    "explanation": "The maturity levels indicate that body harnesses and threshold-based sEMG represent the most widespread motor interfaces, while more advanced motor decoding interfaces like implanted EMG and pattern recognition are mature or cutting-edge. Sensory interfaces such as vibrotactile feedback and TENS have reached mature home use, whereas neuromorphic and biomimetic stimulations remain cutting-edge. Osseointegration uniquely appears as both a mature motor and sensory interface, while FINEs are mature sensory interfaces. These disparities suggest that while traditional motor control methods are well established, integrating sophisticated sensory feedback and combining motor-sensory functions through implanted electrodes like FINEs and osseointegration remains a critical frontier for future prosthetic development.",
    "question_token_count": 78,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 66
  },
  {
    "context": "## 2. ROBOTIC HANDS\nFollowing a limb amputation, three solutions are generally considered: passive cosmetic limbs ( Figure 1 a ); mechanical hands, often with hooks ( Figure 1 b ); and RPHs ( Figure 1 c-g ). In a\n\n\n## SKIN MECHANORECEPTORS\nThe skin has four types of mechanoreceptors, which are sensitive to different stimuli and therefore involved in different sensory functions: Merkel disks (which sense skin indentation, fine touch, and texture perception), Ruffini capsules (which sense skin stretch), Pacinian corpuscles (which sense vibration), and Meissner corpuscles (which sense dynamic deformation and slipperiness). Merkel disks and Ruffini capsules are slow-adapting receptors, meaning that they fire continuously during tactile stimuli, with a firing rate related to the pressure applied in their receptive field. Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond mostly to changes in applied pressure or brief stimuli.\n\na\n\nd\n\nPercutaneous leads\n\nFINE\n\nAgonist/antagonist myoelectric control\n\nSingle-DOF\n\nprosthetic hand\n\nAperture sensor\n\nExternal\n\nPressure sensors stimulator\n\nh\n",
    "topic": "The principles and challenges of agonist/antagonist myoelectric control strategies for single-degree-of-freedom prosthetic hands.",
    "response": "<document_analysis>\nThe context discusses various types of prosthetic hands following limb amputation, including robotic prosthetic hands (RPHs). It specifically references agonist/antagonist myoelectric control for single-degree-of-freedom (DOF) prosthetic hands. Though the text is fragmented, it mentions mechanoreceptors in the skin and their sensory functions, which are relevant for sensory feedback in prosthetics. The key focus relevant to the question topic is the agonist/antagonist myoelectric control strategy for a single-DOF prosthetic hand.\n\nThis control strategy typically involves recording electrical signals from muscle pairs that act in opposition (agonist and antagonist muscles) to generate intuitive and proportional control of the prosthetic joint. The challenge lies in decoding these signals accurately to translate user intent into smooth, precise prosthetic movements, especially with limited degrees of freedom. Implicit challenges include signal cross-talk, muscle fatigue, and the absence of natural proprioceptive feedback, which may be partially addressed by integrating sensors and stimulators.\n\nThe difficulty level is high (8-9) because understanding and implementing agonist/antagonist myoelectric control requires deep knowledge of muscle physiology, signal processing, neural control, and prosthetic hardware integration. The question should provoke reflection on the control principles, their implications for prosthetic function, and the inherent challenges in replicating natural hand movements with single-DOF systems.\n\nThe question will encourage the responder to synthesize knowledge about muscle control, sensorimotor integration, and prosthetic design limitations, suitable for domain experts in biomedical engineering, neuroprosthetics, or rehabilitation robotics.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the fundamental principles behind agonist/antagonist myoelectric control in single-degree-of-freedom prosthetic hands, and what key challenges limit the naturalness and precision of movement achievable with this control strategy?\n\nExplanation: Agonist/antagonist myoelectric control leverages the electrical activity of opposing muscle pairs to generate proportional and intuitive control signals for a prosthetic joint, mimicking natural muscle coordination. The key challenges include accurately decoding these signals amidst muscle cross-talk and fatigue, limited degrees of freedom restricting movement complexity, and the lack of intrinsic sensory feedback, which together reduce the naturalness and precision of prosthetic hand movements.\n\nCorrect Answer: Using opposing muscle signals to proportionally control joint movement; challenges include signal decoding accuracy, muscle fatigue, limited movement complexity, and absence of natural sensory feedback.\n</output_format>",
    "question": "What are the fundamental principles behind agonist/antagonist myoelectric control in single-degree-of-freedom prosthetic hands, and what key challenges limit the naturalness and precision of movement achievable with this control strategy?",
    "answer": "Using opposing muscle signals to proportionally control joint movement; challenges include signal decoding accuracy, muscle fatigue, limited movement complexity, and absence of natural sensory feedback.",
    "explanation": "Agonist/antagonist myoelectric control leverages the electrical activity of opposing muscle pairs to generate proportional and intuitive control signals for a prosthetic joint, mimicking natural muscle coordination. The key challenges include accurately decoding these signals amidst muscle cross-talk and fatigue, limited degrees of freedom restricting movement complexity, and the lack of intrinsic sensory feedback, which together reduce the naturalness and precision of prosthetic hand movements.",
    "question_token_count": 43,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 4,
    "avg_answer_token_count": 32
  },
  {
    "context": "## 3.2. Perspectives\nThe challenges for future interfaces that can provide the necessary read/write bandwidth to use RPHs in a natural fashion are immense. We argue that the motor and sensory domains raise different problems. Indeed, the stimulation being close to the target is mandatory with current technologies, and therefore the best solutions are the most invasive ones. In the motor domain, it is possible to decompose the signal if we have enough sources (even noninvasive sources, as with sEMG). As shown in Section 4, machine learning techniques can help infer information from noninvasive interfaces.\n\nOn the sensory level, the currently implantable electrodes are the most promising solution. However, the main advancement so far has been for the tactile modality, while the use of other modalities for proprioception has been obtained via a nonhomologous approach based on intraneural stimulation combined with the delivery of homologous tactile feedback via indirectly targeted intraneural electrical stimulation (64).\n\nTemperature sensation is another limit. T emperature is mediated through A \u03b4 fibers (for cold) and C fibers (for warmth). Given the very small size of these fibers (C fibers are 20-100 times smaller than A \u03b2 fibers), it is not possible to target them using existing state-of-the-art electrodes (42). Future electrodes with even higher levels of selectivity might be able to target A \u03b4 and C fibers. Sensory remapping (65) can be another viable solution to simulate temperature feedback on a different part of the body using a temperature display.\n",
    "topic": "The application and potential of noninvasive signal acquisition methods such as surface electromyography (sEMG) combined with machine learning for motor control in prosthetics.",
    "response": "<document_analysis>\nThe provided text discusses the challenges and current technologies related to interfaces for prosthetic hand control, focusing on motor and sensory domains. It highlights that invasive methods are currently the most effective for sensory feedback due to proximity requirements, while motor control can utilize noninvasive sources like sEMG if enough signal sources are available. Machine learning is emphasized as a key enabler to infer meaningful motor control signals from these noninvasive sources. The context also contrasts motor and sensory challenges, noting that sensory feedback involves complex fiber types that are difficult to target noninvasively. The text mentions the potential for future electrodes and sensory remapping but centers the motor domain solution on decomposing signals from sEMG aided by machine learning.\n\nThe question should probe the nuanced understanding of how noninvasive sEMG combined with machine learning can overcome limitations of signal acquisition for motor control, the implications of signal decomposition, and the contrast with sensory domain challenges. The difficulty is rated at 8/10 because the question requires synthesis of signal processing, neurophysiology, and prosthetic control interface knowledge.\n\nThe question must encourage reflection on why noninvasive methods are viable for motor but not sensory control currently, the role machine learning plays in enhancing these signals, and the challenges involved in signal source acquisition and decomposition.\n\nThe text is meaningful, coherent, and educationally valuable, hence suitable for generating a high-level expert question.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the combination of noninvasive surface electromyography (sEMG) and machine learning techniques enable effective motor control in prosthetic devices despite the challenges of signal decomposition, and why is this approach currently more feasible for motor domains compared to sensory feedback modalities?\n\nExplanation: Noninvasive sEMG captures muscle electrical activity from multiple sources, and machine learning algorithms can decompose and interpret these complex signals to infer intended motor commands accurately. This approach is more feasible for motor control because muscle signals are accessible and decomposable even noninvasively, whereas sensory feedback requires direct stimulation near specific small nerve fibers that current technology cannot effectively target noninvasively.\n\nCorrect Answer: Machine learning interprets decomposed sEMG signals from multiple muscles noninvasively, enabling motor control, which is more feasible than sensory feedback due to the accessibility of muscle signals versus the invasive targeting required for sensory nerve fibers.\n</output_format>",
    "question": "How does the combination of noninvasive surface electromyography (sEMG) and machine learning techniques enable effective motor control in prosthetic devices despite the challenges of signal decomposition, and why is this approach currently more feasible for motor domains compared to sensory feedback modalities?",
    "answer": "Machine learning interprets decomposed sEMG signals from multiple muscles noninvasively, enabling motor control, which is more feasible than sensory feedback due to the accessibility of muscle signals versus the invasive targeting required for sensory nerve fibers.",
    "explanation": "Noninvasive sEMG captures muscle electrical activity from multiple sources, and machine learning algorithms can decompose and interpret these complex signals to infer intended motor commands accurately. This approach is more feasible for motor control because muscle signals are accessible and decomposable even noninvasively, whereas sensory feedback requires direct stimulation near specific small nerve fibers that current technology cannot effectively target noninvasively.",
    "question_token_count": 54,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 46
  },
  {
    "context": "## Neuroprosthesis:\na device that connects to the nervous system and either replaces missing parts of it or improves it\n\n\n## 1. INTRODUCTION\nDecades of research on robotic prosthetic hands (RPHs) have led to a paradoxical situation: On the one hand, the development of novel RPHs is among the most exciting fields of robotics (1), but on the other hand, the vast majority of amputee patients still use technologies that have changed little in almost half a century. However, this apparent discrepancy might seem less surprising when considering the immense challenge of developing a prosthetic that can mimic the functions of a hand. Indeed, the hand has one of the largest sensory representations in the brain, and grasping is among the most complex coordination tasks (2); the hand has both the highest density of mechanoreceptors in the human body (see the sidebar titled Skin Mechanoreceptors) and the largest number of degrees of freedom (DOFs); and the hand permits people to both experience the surrounding world and shape it.\n\nThe challenges are multiple and intricate, and they can be overcome only by combining advanced mechatronic solutions for dexterous and highly sensorized robotic hands with new approaches for robust and effective interfaces with users' nervous systems to allow seamless naturalartificial integration. As such, several viable solutions can emerge from this multidimensional optimization problem.\n\nTremendous efforts have been made in the past 20 years on the quest for an RPH that is easy to wear, comfortable, and intuitive to control. The design of such a device can be considered a compromise among dexterity, robustness, and usability (3). In the past 5 years, another aspect has been proposed by researchers as an essential milestone: sensorization. Indeed, feedback systems can increase both the acceptability and the performance of the new generation of RPHs (4-6).\n\nThis review summarizes the main achievements in this field. In particular, after providing an overview of the existing neuroprostheses and their characteristics, we focus on four central aspects: ( a ) stable interfaces that enable a new connection with the nervous system to record neural signals and stimulate neural structures, ( b ) algorithmic strategies for decoding motor intentions, ( c ) RPH sensorization plus encoding strategies to convey somatosensory feedback, and ( d ) assessment methods to measure the efficacy of a given strategy or technology. Throughout the review, we keep a patient-centered perspective and ask ourselves, Does a novel approach significantly improve the subjects' quality of life? Is it easy to learn and natural to use? And does it improve their independence? On a technical aspect, our goal is to provide a critical view of the most advanced technologies and a perspective on future implementations of RPHs.\n",
    "topic": "Analyze encoding strategies for conveying somatosensory feedback through robotic prosthetic hand sensorization and their impact on user experience.",
    "response": "<document_analysis>\nThe context provides a comprehensive overview of the state and challenges of robotic prosthetic hands (RPHs), emphasizing the complexity of replicating human hand function due to its dense sensory representation and high degrees of freedom. It highlights the multidimensional challenge requiring advanced mechatronics and nervous system interfacing. Notably, it identifies sensorization and somatosensory feedback encoding as a recent critical milestone in prosthetic development, directly linked to improving both performance and user acceptability. The text outlines four central aspects of RPH research, including sensorization plus encoding strategies to convey somatosensory feedback, which implies the importance of how sensory information from the prosthesis is translated and presented to the user\u2019s nervous system to create natural, intuitive experiences. This is fundamental for enabling users to perceive touch or movement through the prosthesis, which is a key factor in usability and quality of life improvements. The context also stresses the patient-centered approach, focusing on natural use, learning ease, and independence. However, the text does not provide detailed technical descriptions of specific encoding strategies but establishes their significance in the overall system and their impact on user experience.\n\nDifficulty rating: 8/10 \u2013 The question requires understanding of advanced neuroprosthetics concepts, including sensorization, neural interfaces, encoding of sensory signals, and their effects on human perception and functional outcomes, demanding integration of interdisciplinary knowledge in neuroscience, robotics, and human-machine interaction.\n\nThe question is designed to probe a domain expert\u2019s understanding of the critical role of encoding strategies in transforming raw sensory data from robotic prostheses into meaningful somatosensory feedback, how these strategies influence the user\u2019s perception and control, and the implications for improving prosthesis functionality and quality of life. It encourages reflection on the technical and experiential challenges of designing encoding schemes that can be effectively interpreted by the nervous system, thereby bridging artificial and biological sensory domains.\n\nGiven the content\u2019s focus and the question topic, this is a meaningful and challenging question that requires deep insight into neuroprosthetic sensorization and feedback mechanisms.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do encoding strategies for somatosensory feedback in robotic prosthetic hands transform raw sensor data into meaningful neural signals, and what implications do these strategies have on the naturalness of user experience and functional independence?\n\nExplanation: Encoding strategies convert mechanical or electrical signals from prosthetic sensors into neural stimulation patterns interpretable by the user\u2019s nervous system, thereby enabling tactile and proprioceptive sensations; the effectiveness of these strategies directly affects how naturally users perceive and control the prosthesis, influencing ease of learning, intuitiveness, and ultimately their independence and quality of life.\n\nCorrect Answer: Encoding strategies map prosthetic sensor outputs into neural stimulation patterns that replicate natural somatosensory signals, enhancing the intuitiveness and functionality of prosthesis use and improving user experience and independence.\n</output_format>",
    "question": "How do encoding strategies for somatosensory feedback in robotic prosthetic hands transform raw sensor data into meaningful neural signals, and what implications do these strategies have on the naturalness of user experience and functional independence?",
    "answer": "Encoding strategies map prosthetic sensor outputs into neural stimulation patterns that replicate natural somatosensory signals, enhancing the intuitiveness and functionality of prosthesis use and improving user experience and independence.",
    "explanation": "Encoding strategies convert mechanical or electrical signals from prosthetic sensors into neural stimulation patterns interpretable by the user\u2019s nervous system, thereby enabling tactile and proprioceptive sensations; the effectiveness of these strategies directly affects how naturally users perceive and control the prosthesis, influencing ease of learning, intuitiveness, and ultimately their independence and quality of life.",
    "question_token_count": 42,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 37
  },
  {
    "context": "## 3.2. Perspectives\nThe challenges for future interfaces that can provide the necessary read/write bandwidth to use RPHs in a natural fashion are immense. We argue that the motor and sensory domains raise different problems. Indeed, the stimulation being close to the target is mandatory with current technologies, and therefore the best solutions are the most invasive ones. In the motor domain, it is possible to decompose the signal if we have enough sources (even noninvasive sources, as with sEMG). As shown in Section 4, machine learning techniques can help infer information from noninvasive interfaces.\n\nOn the sensory level, the currently implantable electrodes are the most promising solution. However, the main advancement so far has been for the tactile modality, while the use of other modalities for proprioception has been obtained via a nonhomologous approach based on intraneural stimulation combined with the delivery of homologous tactile feedback via indirectly targeted intraneural electrical stimulation (64).\n\nTemperature sensation is another limit. T emperature is mediated through A \u03b4 fibers (for cold) and C fibers (for warmth). Given the very small size of these fibers (C fibers are 20-100 times smaller than A \u03b2 fibers), it is not possible to target them using existing state-of-the-art electrodes (42). Future electrodes with even higher levels of selectivity might be able to target A \u03b4 and C fibers. Sensory remapping (65) can be another viable solution to simulate temperature feedback on a different part of the body using a temperature display.\n",
    "topic": "The role and limitations of invasive implantable electrodes in providing tactile and proprioceptive feedback in sensory prosthetics.",
    "response": "<document_analysis>\nThe context addresses the critical challenges and technological considerations for developing interfaces capable of providing naturalistic read/write bandwidth for sensory prosthetic systems, specifically focusing on the sensory domain. It highlights the current reliance on invasive implantable electrodes as the most promising approach for delivering tactile feedback, while noting that proprioceptive feedback has been approached through nonhomologous intraneural stimulation methods combined with tactile feedback. A key limitation is the inability of current electrodes to selectively stimulate very small sensory fibers responsible for temperature sensation (A \u03b4 and C fibers) due to their minute size relative to other fibers. The text also suggests future directions involving electrodes with higher selectivity and sensory remapping techniques to simulate temperature feedback. The discussion implicitly contrasts the motor and sensory challenges, emphasizing that while motor signals can sometimes be decoded noninvasively, sensory feedback currently demands invasive solutions, with nuanced limitations depending on the sensory modality.\n\nThe implicit assumptions include the necessity of spatial proximity in stimulation for effective sensory feedback, the technical constraints of electrode selectivity based on fiber size, and the potential for alternative solutions like sensory remapping when direct stimulation is not feasible.\n\nThe question difficulty is rated 9/10 due to the need for deep understanding of neurophysiology, prosthetic interface technologies, and the specific challenges of different sensory modalities.\n\nThe question should prompt synthesis of knowledge on the technological constraints of implantable electrodes, their current achievements (tactile feedback), partial solutions for proprioception, and the nuanced limitations for temperature sensation, encouraging reflection on both the biological and engineering dimensions of sensory prosthetics.\n\nThis analysis confirms the context is rich, coherent, and suitable for generating a highly challenging expert-level question.\n\n</document_analysis>\n\n<output_format>\nQuestion: Considering current implantable electrode technologies, what are the fundamental limitations that restrict their ability to provide comprehensive sensory feedback in prosthetics, particularly regarding proprioception and temperature sensation, and how do these limitations influence the strategies used to restore these modalities?\n\nExplanation: Current implantable electrodes can effectively provide tactile feedback due to their ability to stimulate larger sensory fibers (A \u03b2 fibers) but struggle with proprioception, which has been addressed through nonhomologous intraneural stimulation combined with tactile feedback rather than direct homologous stimulation. Temperature sensation is limited by the extremely small size of A \u03b4 and C fibers responsible for cold and warmth, respectively, which current electrodes cannot selectively target. These biological and technological constraints have led to strategies like indirect stimulation and sensory remapping to simulate these feedback modalities.\n\nCorrect Answer: The small size and selective targeting limitations of implantable electrodes prevent direct stimulation of proprioceptive and temperature fibers, requiring indirect approaches such as nonhomologous intraneural stimulation for proprioception and sensory remapping for temperature feedback.\n</output_format>",
    "question": "Considering current implantable electrode technologies, what are the fundamental limitations that restrict their ability to provide comprehensive sensory feedback in prosthetics, particularly regarding proprioception and temperature sensation, and how do these limitations influence the strategies used to restore these modalities?",
    "answer": "The small size and selective targeting limitations of implantable electrodes prevent direct stimulation of proprioceptive and temperature fibers, requiring indirect approaches such as nonhomologous intraneural stimulation for proprioception and sensory remapping for temperature feedback.",
    "explanation": "Current implantable electrodes can effectively provide tactile feedback due to their ability to stimulate larger sensory fibers (A \u03b2 fibers) but struggle with proprioception, which has been addressed through nonhomologous intraneural stimulation combined with tactile feedback rather than direct homologous stimulation. Temperature sensation is limited by the extremely small size of A \u03b4 and C fibers responsible for cold and warmth, respectively, which current electrodes cannot selectively target. These biological and technological constraints have led to strategies like indirect stimulation and sensory remapping to simulate these feedback modalities.",
    "question_token_count": 48,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 45
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "Assessment techniques for evaluating the quality and effectiveness of supplementary sensory feedback using the crossmodal congruency task.",
    "response": "<document_analysis>\nThe provided context is primarily a bibliographic list referencing a wide variety of research articles related to prosthetics, sensory feedback, neural interfacing, and functional assessment tools. Among these, reference 174 specifically addresses the \"crossmodal congruency task\" as a method for assessing the quality of supplementary sensory feedback. This task is linked to evaluating how well sensory feedback integrates with other sensory modalities, such as vision and touch, in the context of prosthesis use.\n\nThe other references mention related concepts such as embodiment of prostheses, sensory feedback restoration, and multisensory integration, which provide background and complementary perspectives on the importance of sensory feedback in prosthetic control and perception. However, the explicit mention and focus on assessment techniques using the crossmodal congruency task is narrowly found in reference 174.\n\nGiven this, the question should focus on the methodological and conceptual basis of the crossmodal congruency task as an assessment tool for supplementary sensory feedback quality. The question should challenge experts to critically engage with how this task measures multisensory integration, its implications for prosthesis embodiment, and the interpretation of its results in evaluating feedback systems.\n\nDifficulty is rated at 9/10 because understanding and explaining the crossmodal congruency task requires advanced knowledge of multisensory integration, psychophysical assessment methods, and their application in prosthetics research.\n\nThe question will invite experts to reflect on the theoretical underpinnings of the task, how it operationalizes sensory feedback quality, and its relevance in improving prosthetic function and user experience.\n\nNo irrelevant or bogus information detected; all references are relevant to the field of prosthetic sensory feedback and assessment.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the crossmodal congruency task function as an assessment technique to evaluate the quality and effectiveness of supplementary sensory feedback in prosthetic users, and what are its implications for understanding multisensory integration in prosthesis embodiment?\n\nExplanation: The crossmodal congruency task evaluates how well supplementary sensory feedback aligns with natural sensory modalities by measuring reaction times and error rates when conflicting or congruent sensory stimuli are presented simultaneously across modalities, such as visual and tactile inputs. High congruency effects indicate effective integration of artificial sensory feedback with natural perception, which is critical for prosthesis embodiment and intuitive control. This task reveals the extent to which supplementary feedback is perceived as coherent and integrated, thus providing a quantitative measure of feedback quality and its impact on multisensory body representation.\n\nCorrect Answer: It measures multisensory integration by comparing reaction times and errors to congruent versus incongruent crossmodal stimuli, indicating how well supplementary sensory feedback aligns with natural senses to support prosthesis embodiment.\n</output_format>",
    "question": "How does the crossmodal congruency task function as an assessment technique to evaluate the quality and effectiveness of supplementary sensory feedback in prosthetic users, and what are its implications for understanding multisensory integration in prosthesis embodiment?",
    "answer": "It measures multisensory integration by comparing reaction times and errors to congruent versus incongruent crossmodal stimuli, indicating how well supplementary sensory feedback aligns with natural senses to support prosthesis embodiment.",
    "explanation": "The crossmodal congruency task evaluates how well supplementary sensory feedback aligns with natural sensory modalities by measuring reaction times and error rates when conflicting or congruent sensory stimuli are presented simultaneously across modalities, such as visual and tactile inputs. High congruency effects indicate effective integration of artificial sensory feedback with natural perception, which is critical for prosthesis embodiment and intuitive control. This task reveals the extent to which supplementary feedback is perceived as coherent and integrated, thus providing a quantitative measure of feedback quality and its impact on multisensory body representation.",
    "question_token_count": 44,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 38
  },
  {
    "context": "## Current Solutions and Future Trends for Robotic Prosthetic Hands\nVincent Mendez, 1, \u2217 Francesco Iberite, 2, \u2217 Solaiman Shokur, 1,\u2020 and Silvestro Micera 1,2,\u2020\n\n1 Center for Neuroprosthetics and Institute of Bioengineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1202 Gen\u00e8ve, Switzerland; email: silvestro.micera@epfl.ch\n\n2 BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, 56127 Pisa, Italy\n\n\n## Keywords\nhand, prosthesis, neuroprostheses, sensory feedback, electromyography, EMG\n\n\n## Abstract\nThe desire for functional replacement of a missing hand is an ancient one. Historically, humans have replaced a missing limb with a prosthesis for cosmetic, vocational, or personal autonomy reasons. The hand is a powerful tool, and its loss causes severe physical and often mental debilitation. Technological advancements have allowed the development of increasingly effective artificial hands, which can improve the quality of life of people who suffered a hand amputation. Here, we review the state of the art of robotic prosthetic hands (RPHs), with particular attention to the potential and current limits of their main building blocks: the hand itself, approaches to decoding voluntary commands and controlling the hand, and systems and methods for providing sensory feedback to the user. We also briefly describe existing approaches to characterizing the performance of subjects using RPHs for grasping tasks and provide perspectives on the future of different components and the overall field of RPH development.\n",
    "topic": "The current limitations of robotic prosthetic hands in achieving naturalistic function and the technological barriers to overcome.",
    "response": "<document_analysis>\nThe provided context is an abstract overview of the state of robotic prosthetic hands (RPHs), emphasizing their historical significance, functional importance, and recent technological advances. The text highlights three main components critical to RPH performance: the mechanical hand design, voluntary command decoding and control, and sensory feedback systems. It also alludes to current limitations and challenges in these areas, as well as the evaluation of prosthesis performance. The abstract suggests that despite progress, there remain significant barriers to achieving naturalistic hand function, involving both hardware and neural interfacing complexities.\n\nImplicit assumptions include the necessity of integrating sensory feedback for naturalistic function, the difficulty of accurately decoding voluntary motor commands, and the challenge of replicating the complex biomechanics and dexterity of a natural hand. The abstract points to ongoing research and future trends aiming to overcome these barriers, implying multidisciplinary challenges spanning engineering, neuroscience, and clinical application.\n\nThe difficulty level is rated at 9/10 due to the advanced interdisciplinary knowledge required to understand and critically analyze current limitations and barriers in RPH technology. The question should encourage reflection on the nuanced interplay between mechanical design, neural control, and sensory feedback, and why each remains an obstacle to fully naturalistic prostheses.\n\nThe question will probe understanding of the core technological limitations preventing robotic prosthetic hands from achieving naturalistic function and the specific technological challenges that must be overcome to advance the field. This will require synthesis of knowledge about biomechanics, neural decoding, sensory integration, and control systems, inviting deep critical engagement.\n\nThe content is meaningful, coherent, and educationally valuable, suitable for generating a challenging question-answer pair for experts in neuroprosthetics and bioengineering.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the principal technological limitations in robotic prosthetic hands that prevent them from achieving naturalistic hand function, and how do these limitations relate to the challenges in voluntary command decoding, mechanical design, and sensory feedback integration?\n\nExplanation: The naturalistic function of robotic prosthetic hands is limited primarily by three interconnected technological challenges: accurately decoding voluntary motor commands from the user, replicating the complex biomechanical capabilities of the human hand in the mechanical design, and providing effective sensory feedback that enables the user to perceive and modulate grasping actions naturally. Voluntary command decoding is constrained by current signal acquisition and interpretation methods (e.g., electromyography), which do not yet allow seamless, intuitive control. Mechanical designs struggle to emulate the dexterity, degrees of freedom, and robustness of a biological hand. Sensory feedback systems remain rudimentary, limiting the user's ability to perceive touch, force, and proprioception, which are essential for natural manipulation. These limitations collectively hinder the full restoration of hand functionality and intuitive control, requiring advances in neuroengineering, materials science, and sensor technologies.\n\nCorrect Answer: Limitations in voluntary command decoding accuracy, mechanical dexterity replication, and effective sensory feedback integration prevent naturalistic robotic prosthetic hand function.\n</output_format>",
    "question": "What are the principal technological limitations in robotic prosthetic hands that prevent them from achieving naturalistic hand function, and how do these limitations relate to the challenges in voluntary command decoding, mechanical design, and sensory feedback integration?",
    "answer": "Limitations in voluntary command decoding accuracy, mechanical dexterity replication, and effective sensory feedback integration prevent naturalistic robotic prosthetic hand function.",
    "explanation": "The naturalistic function of robotic prosthetic hands is limited primarily by three interconnected technological challenges: accurately decoding voluntary motor commands from the user, replicating the complex biomechanical capabilities of the human hand in the mechanical design, and providing effective sensory feedback that enables the user to perceive and modulate grasping actions naturally. Voluntary command decoding is constrained by current signal acquisition and interpretation methods (e.g., electromyography), which do not yet allow seamless, intuitive control. Mechanical designs struggle to emulate the dexterity, degrees of freedom, and robustness of a biological hand. Sensory feedback systems remain rudimentary, limiting the user's ability to perceive touch, force, and proprioception, which are essential for natural manipulation. These limitations collectively hinder the full restoration of hand functionality and intuitive control, requiring advances in neuroengineering, materials science, and sensor technologies.",
    "question_token_count": 44,
    "answer_correctness_score": 9,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 28
  },
  {
    "context": "## 5. RESTORING SENSORY FEEDBACK\nSensory information plays a critical role in both the exploration of the external environment and in any manipulation task. When an individual interacts with surrounding objects, tactile sensations are used to infer features such as size, compliance, temperature, and texture, while the same sensations are exploited to handle them properly or use them as tools. From this perspective, aiming to restore afferent sensory channels from a hand prosthesis is a critical step in designing a device that ensures two key aspects: dexterous manipulation and embodiment of the prosthetic device.\n\nThe design of a sensory feedback system that can successfully deliver information relies on three fundamental blocks working together: ( a ) sensor readings, processed by ( ) an encoding b strategy capable of translating meaningful information to the user, through ( ) an interface. Prec vious sections have described the different available interfaces; here, we present the encoding techniques and sensors relevant to the design of modern hand prostheses ( Table 1 ).\n\nSensors mounted on a robotic hand should ideally record the whole spectrum of available human sensations, from both external and internal sources. Indeed, sensory information from the human hand covers both interactions with the external world (tactile perception, thermal perception, and nociception, i.e., perception of pain) and internal perception of the positions of the joints and the length and forces exerted by the muscles, together known as proprioception. Table 2 shows examples of sensor placements on RPHs from recent studies.\n",
    "topic": "The current state and examples of sensor placements on robotic prosthetic hands as demonstrated in recent research studies.",
    "response": "<document_analysis>\nThe context discusses the critical importance of sensory feedback in prosthetic hand design, emphasizing the need for restoring afferent sensory channels to achieve dexterous manipulation and embodiment. It outlines the three key components of a sensory feedback system: sensors, encoding strategies, and interfaces. It highlights that sensors on robotic hands should ideally capture a full range of human sensations, including tactile, thermal, nociceptive (pain), and proprioceptive inputs (joint position, muscle length, and force). The text references recent studies that demonstrate examples of sensor placements on robotic prosthetic hands, indicating a current research trend toward integrating multisensory inputs for improved prosthesis function. This content is meaningful and technical, suitable for generating a challenging question about how sensor placement strategies in robotic prosthetic hands reflect the complexity of human sensory modalities and their integration for functional restoration.\n\nThe implicit assumption is that restoring comprehensive sensory feedback, including both external and internal sensations, is vital for prosthetic hand success. The question can probe understanding of how sensor placements correspond to human sensory functions and the implications for prosthesis control and embodiment.\n\nDifficulty is rated 8/10 due to the need for deep understanding of sensory modalities, sensor technology, prosthetic design challenges, and interpretation of recent research trends.\n\nThe question will invite reflection on the complexity of sensor integration in robotic prosthetics, encouraging synthesis of knowledge about human sensory systems and engineering solutions.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do recent research studies on robotic prosthetic hands strategically place sensors to replicate the full spectrum of human sensory modalities, and what are the implications of these placements for restoring both tactile perception and proprioception in prosthesis users?\n\nExplanation: Recent studies place sensors on robotic prosthetic hands to capture external sensations such as touch, temperature, and pain, as well as internal proprioceptive signals like joint position and muscle force; this comprehensive sensor placement enables the prosthesis to deliver rich sensory feedback crucial for dexterous manipulation and embodiment, bridging the gap between artificial and natural hand function.\n\nCorrect Answer: By positioning sensors to detect both external (tactile, thermal, nociceptive) and internal (proprioceptive) stimuli, robotic prostheses restore comprehensive sensory feedback that supports dexterous control and embodiment.\n</output_format>",
    "question": "How do recent research studies on robotic prosthetic hands strategically place sensors to replicate the full spectrum of human sensory modalities, and what are the implications of these placements for restoring both tactile perception and proprioception in prosthesis users?",
    "answer": "By positioning sensors to detect both external (tactile, thermal, nociceptive) and internal (proprioceptive) stimuli, robotic prostheses restore comprehensive sensory feedback that supports dexterous control and embodiment.",
    "explanation": "Recent studies place sensors on robotic prosthetic hands to capture external sensations such as touch, temperature, and pain, as well as internal proprioceptive signals like joint position and muscle force; this comprehensive sensor placement enables the prosthesis to deliver rich sensory feedback crucial for dexterous manipulation and embodiment, bridging the gap between artificial and natural hand function.",
    "question_token_count": 45,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 7,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 44
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "The implications of combining sensory and motor interfaces for improved bidirectional communication between the prosthetic device and the user\u2019s nervous system.",
    "response": "<document_analysis>\nThe context discusses the evolving landscape of prosthetic hand technologies, particularly emphasizing the transition from rigid to soft robotic designs and the integration of innovative actuation and sensory systems. A detailed table outlines the maturity levels of various interface technologies, motor decoding methods, sensory feedback mechanisms, and sensorization advancements. Importantly, it highlights the convergence of motor and sensory interfaces that enable bidirectional communication with the user's nervous system, such as osseointegration and advanced electrode arrays (e.g., FINEs, regenerative electrodes). The text suggests that combining sensory and motor interfaces enhances prosthetic functionality by enabling both control signals to be decoded from the user and sensory feedback to be delivered back, improving intuitiveness, safety, and efficiency. The question should probe the nuanced implications of this integration\u2014how it affects prosthetic performance, user embodiment, and potential challenges\u2014requiring deep domain expertise in neuroprosthetics, interface technologies, and human-machine interaction.\n\nDifficulty rating: 9/10 given the advanced integration of neurotechnology, biomechanics, and control theory involved.\n\nThe question should invite reflection on the bidirectional interface paradigm's impact on prosthetic technology evolution, user experience, and clinical applicability.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the integration of combined sensory and motor interfaces in prosthetic devices enhance bidirectional communication with the user\u2019s nervous system, and what are the primary implications of this integration for improving prosthetic control, user embodiment, and safety?\n\nExplanation: The integration of sensory and motor interfaces enables simultaneous decoding of motor intent and delivery of sensory feedback, facilitating closed-loop communication between the prosthetic and the nervous system; this enhances intuitive control, increases embodiment by providing naturalistic sensations, and improves safety through real-time feedback, ultimately advancing prosthetic functionality beyond unidirectional control systems.\n\nCorrect Answer: It enables closed-loop communication by decoding motor commands and delivering sensory feedback, thereby improving intuitive control, embodiment, and safety of the prosthetic device.\n</output_format>",
    "question": "How does the integration of combined sensory and motor interfaces in prosthetic devices enhance bidirectional communication with the user\u2019s nervous system, and what are the primary implications of this integration for improving prosthetic control, user embodiment, and safety?",
    "answer": "It enables closed-loop communication by decoding motor commands and delivering sensory feedback, thereby improving intuitive control, embodiment, and safety of the prosthetic device.",
    "explanation": "The integration of sensory and motor interfaces enables simultaneous decoding of motor intent and delivery of sensory feedback, facilitating closed-loop communication between the prosthetic and the nervous system; this enhances intuitive control, increases embodiment by providing naturalistic sensations, and improves safety through real-time feedback, ultimately advancing prosthetic functionality beyond unidirectional control systems.",
    "question_token_count": 46,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 6,
    "avg_answer_token_count": 30
  },
  {
    "context": "## Current Solutions and Future Trends for Robotic Prosthetic Hands\nVincent Mendez, 1, \u2217 Francesco Iberite, 2, \u2217 Solaiman Shokur, 1,\u2020 and Silvestro Micera 1,2,\u2020\n\n1 Center for Neuroprosthetics and Institute of Bioengineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1202 Gen\u00e8ve, Switzerland; email: silvestro.micera@epfl.ch\n\n2 BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, 56127 Pisa, Italy\n\n\n## Keywords\nhand, prosthesis, neuroprostheses, sensory feedback, electromyography, EMG\n\n\n## Abstract\nThe desire for functional replacement of a missing hand is an ancient one. Historically, humans have replaced a missing limb with a prosthesis for cosmetic, vocational, or personal autonomy reasons. The hand is a powerful tool, and its loss causes severe physical and often mental debilitation. Technological advancements have allowed the development of increasingly effective artificial hands, which can improve the quality of life of people who suffered a hand amputation. Here, we review the state of the art of robotic prosthetic hands (RPHs), with particular attention to the potential and current limits of their main building blocks: the hand itself, approaches to decoding voluntary commands and controlling the hand, and systems and methods for providing sensory feedback to the user. We also briefly describe existing approaches to characterizing the performance of subjects using RPHs for grasping tasks and provide perspectives on the future of different components and the overall field of RPH development.\n",
    "topic": "Techniques and criteria for evaluating the performance of users operating robotic prosthetic hands, especially in grasping tasks.",
    "response": "<document_analysis>\nThe context is an abstract summarizing a review on robotic prosthetic hands (RPHs), focusing on the hand device, command decoding and control strategies, sensory feedback provision, and evaluation of user performance in grasping tasks. The content is coherent and rich with technical themes: prosthetic hand design, neuroprosthetic control via electromyography (EMG), sensory feedback systems, and performance characterization methods. While the abstract does not provide exhaustive detail on evaluation techniques, it explicitly mentions that it \"briefly describe[s] existing approaches to characterizing the performance of subjects using RPHs for grasping tasks.\"\n\nImplicitly, the evaluation of user performance is critical because grasping functionality is a complex, sensorimotor task requiring integration of voluntary control, mechanical design, and sensory feedback. Understanding these evaluation approaches is key to advancing RPH utility and user satisfaction. The question can probe a deep understanding of the multifaceted criteria and methodologies used to assess effectiveness and dexterity of prosthetic hand users.\n\nDifficulty is rated 9/10 because it requires expertise in neuroprosthetics, biomechanics, control systems, and sensory feedback integration, with a critical understanding of how performance is quantified in real functional tasks.\n\nThe question should invite reflection on what performance metrics are most meaningful, how sensory feedback and control strategies influence these metrics, and the implications for future RPH development.\n\nThe abstract contains meaningful and technical content appropriate for generating a highly challenging question-answer pair.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the key criteria and methods used to evaluate user performance in grasping tasks with robotic prosthetic hands, and how do these evaluation approaches reflect the integration of voluntary command decoding and sensory feedback systems?\n\nExplanation: Evaluating user performance in RPH grasping tasks involves measuring functional outcomes like grasp success, dexterity, speed, and precision. Methods often include standardized tests simulating real-world object manipulation, force modulation assessments, and user-reported outcomes. These evaluations reflect how well voluntary command decoding (e.g., EMG signals) translates into intended movements and how sensory feedback enhances control accuracy and object interaction, thereby directly linking control strategies and feedback integration to practical prosthesis functionality.\n\nCorrect Answer: Performance is evaluated by standardized grasping tests measuring success rate, dexterity, speed, and precision, which assess how effectively voluntary command decoding and sensory feedback enable accurate and functional hand control.\n</output_format>",
    "question": "What are the key criteria and methods used to evaluate user performance in grasping tasks with robotic prosthetic hands, and how do these evaluation approaches reflect the integration of voluntary command decoding and sensory feedback systems?",
    "answer": "Performance is evaluated by standardized grasping tests measuring success rate, dexterity, speed, and precision, which assess how effectively voluntary command decoding and sensory feedback enable accurate and functional hand control.",
    "explanation": "Evaluating user performance in RPH grasping tasks involves measuring functional outcomes like grasp success, dexterity, speed, and precision. Methods often include standardized tests simulating real-world object manipulation, force modulation assessments, and user-reported outcomes. These evaluations reflect how well voluntary command decoding (e.g., EMG signals) translates into intended movements and how sensory feedback enhances control accuracy and object interaction, thereby directly linking control strategies and feedback integration to practical prosthesis functionality.",
    "question_token_count": 41,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 6,
    "avg_answer_token_count": 38
  },
  {
    "context": "## 4.3. Decoding Motor Intention via Implanted Electrodes\nSurface electrodes cannot precisely record the signal from deep muscles; to overcome this issue, several groups have focused on iEMG electrodes. This technique is more invasive but allows one to record EMG signals (51) uncorrelated from the underlying musculature and avoids the daily placement of electrodes. iEMG is robust against electrode shift (e.g., socket rotation) and change in skin impedance and sweat. Several studies have demonstrated the performance of simultaneous wrist and hand motions (three DOFs) using six to eight iEMG electrodes; Smith &amp; Hargrove (51) showed that iEMG has better decoding performance than sEMG. High decoding performance is reported in real time (106), and in fully implanted setups, the results are stable for several days (107).\n\nOnthe other hand, Farrell &amp; Weir (52) compared the pattern recognition-based grasp classification performance of iEMG and sEMG on 12 movement classes with eight channels and did not find a statistical difference between electrode types. They concluded that the choice of electrode should be based not on classification accuracy but rather on signal consistency over time and robustness to electrode lift-off. Zia ur Rehman et al. (108) compared a standard linear discriminant analysis with a deep network for grasp classification. They performed a multiday analysis comparing six iEMG and six sEMG electrodes, and their results showed that deep learning had better decoding performance and was more stable over time.\n\nKamavuako et al. (109) investigated the effect of combining iEMG to target deep muscles with sEMG on myoelectric control. They showed that the combined solution improved offline and real-time control performance compared with sEMG alone.\n\nWith 32 iEMG electrodes, Dantas et al. (110) compared different decoding methods for the continuous control of five DOFs corresponding to the flexion and extension of each digit. Using a data set aggregation algorithm, they showed a normalized mean squared error as low as 0.033 with a deep convolutional neural network. They also investigated signal stability for 150 days after training, showing a small degradation during the first month (0.003 normalized mean squared error per day with a convolutional neural network), but that degradation stopped in the next four months.\n\nFor transradial amputees, an alternative to using EMG signals to control hand prostheses is decoding from peripheral nerve signals. Different grasp types can be decoded from peripheral nerve signals with high accuracy using different interfaces, both offline and in real time (54, 111113). Implanted peripheral nerve recordings are more invasive than sEMG but are more stable over time. Indeed, donning and doffing the prosthesis does not move these electrodes as much as it does sEMG electrodes. Recently, Cracchiolo et al. (53) decoded up to 11 class states using TIMEs on an amputee subject and showed that the active sites chosen on the first day could also be used in the following sessions, for up to seven days (80% accuracy, compared with 83% by selecting active sites every session). However, this modality is generally used to provide sensory\n\nfeedback (64, 114-116). Therefore the development of new approaches to record neural signals during peripheral stimulation [e.g., artifact removal (117)] is necessary.\n\nVu et al. (39) recently developed a regenerative peripheral nerve interface to increase signal specificity and long-term stability. They implanted transected peripheral nerves into a free muscle graft. After regeneration, revascularization, and reinnervation, the graft becomes a nerve bioamplifier that creates EMG signals. Using chronically implanted iEMG to record from these grafts, they performed five-class decoding in real time with up to 98.2% accuracy with two transradial amputees in a virtual hand environment. They also showed results from a Box and Block T est using an RPH that provided continuous control of two DOFs of thumb motions through their interface combined with a third DOF based on sEMG.\n",
    "topic": "Design, function, and clinical implications of regenerative peripheral nerve interfaces using free muscle grafts as bioamplifiers for chronic iEMG signal recording.",
    "response": "<document_analysis>\nThe provided context elaborates on the use of implanted electromyography (iEMG) electrodes for decoding motor intentions, specifically highlighting the advantages of iEMG over surface EMG (sEMG) in terms of signal specificity, robustness, and stability over time. It also contrasts different electrode modalities, including peripheral nerve interfaces. The last part of the text focuses on a recently developed regenerative peripheral nerve interface (RPNI) that uses free muscle grafts implanted with transected peripheral nerves to act as bioamplifiers for chronic iEMG signal recording. This approach leverages muscle regeneration, revascularization, and reinnervation to create stable, specific EMG signals, demonstrated with high decoding accuracy in transradial amputees.\n\nKey themes include the design principle of using free muscle grafts as bioamplifiers, the functional mechanism of nerve regeneration into the graft to produce amplified EMG signals, and the clinical implications evidenced by real-time, high-accuracy decoding and continuous control of multiple degrees of freedom (DOFs). The regenerative interface addresses challenges such as long-term signal stability and specificity in chronic implanted iEMG systems, which are critical for prosthetic control. The context also contrasts this approach with direct peripheral nerve recordings and sEMG, emphasizing its potential advantages in signal quality and stability.\n\nThe topic invites probing questions on the bioengineering design rationale, physiological mechanisms underlying the interface\u2019s function, and its clinical relevance in improving motor intention decoding and prosthetic control. A challenging question would require integrating knowledge of peripheral nerve physiology, muscle regeneration biology, signal acquisition principles, and prosthetic control technology.\n\nDifficulty is rated 9/10 due to the technical complexity and interdisciplinary understanding required.\n\nThe question should stimulate reflection on how the regenerative peripheral nerve interface design overcomes limitations of other methods and the implications for long-term clinical prosthetic applications.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the design of regenerative peripheral nerve interfaces using free muscle grafts as bioamplifiers enhance chronic implanted EMG signal specificity and stability, and what are the key physiological mechanisms that enable this approach to achieve high-accuracy multi-degree-of-freedom motor intention decoding in transradial amputees?\n\nExplanation: The regenerative peripheral nerve interface design involves implanting transected peripheral nerves into free muscle grafts that regenerate, revascularize, and reinnervate, transforming the graft into a bioamplifier of neural signals. This biological amplification enhances EMG signal specificity by providing a well-vascularized, innervated muscle tissue that produces robust, localized electrical activity directly related to the nerve\u2019s motor intent. The physiological mechanisms of nerve regeneration and muscle reinnervation establish stable neuromuscular junctions, ensuring long-term signal stability and reducing variability seen in surface electrodes. This stable, high-fidelity signal allows for precise decoding of multiple degrees of freedom in real time, demonstrated by up to 98.2% accuracy in transradial amputees controlling virtual and physical prosthetic hands.\n\nCorrect Answer: By implanting transected nerves into free muscle grafts that regenerate and reinnervate, the interface creates a biologically amplified, stable EMG signal from the graft muscle, leveraging nerve regeneration and muscle reinnervation to enhance signal specificity and stability, enabling accurate multi-DOF motor decoding.\n</output_format>",
    "question": "How does the design of regenerative peripheral nerve interfaces using free muscle grafts as bioamplifiers enhance chronic implanted EMG signal specificity and stability, and what are the key physiological mechanisms that enable this approach to achieve high-accuracy multi-degree-of-freedom motor intention decoding in transradial amputees?",
    "answer": "By implanting transected nerves into free muscle grafts that regenerate and reinnervate, the interface creates a biologically amplified, stable EMG signal from the graft muscle, leveraging nerve regeneration and muscle reinnervation to enhance signal specificity and stability, enabling accurate multi-DOF motor decoding.",
    "explanation": "The regenerative peripheral nerve interface design involves implanting transected peripheral nerves into free muscle grafts that regenerate, revascularize, and reinnervate, transforming the graft into a bioamplifier of neural signals. This biological amplification enhances EMG signal specificity by providing a well-vascularized, innervated muscle tissue that produces robust, localized electrical activity directly related to the nerve\u2019s motor intent. The physiological mechanisms of nerve regeneration and muscle reinnervation establish stable neuromuscular junctions, ensuring long-term signal stability and reducing variability seen in surface electrodes. This stable, high-fidelity signal allows for precise decoding of multiple degrees of freedom in real time, demonstrated by up to 98.2% accuracy in transradial amputees controlling virtual and physical prosthetic hands.",
    "question_token_count": 60,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 10,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 60
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "The evolution of sensory feedback mechanisms in prosthetics from no feedback to biomimetic and multimodal stimulation, including neuromorphic and texture feedback.",
    "response": "<document_analysis>\nThe provided context outlines the progression of sensory feedback technologies in prosthetics, moving from no feedback to increasingly sophisticated systems such as vibrotactile feedback, touch contact, position sensing, neuromorphic feedback, texture sensing, object stiffness detection, multimodal feedback, and biomimetic stimulation. The context also situates these developments within a maturity framework: from widespread and mature technologies to cutting-edge laboratory research and future directions. It highlights the integration of sensory feedback with motor interfaces and sensorization in prosthetic hands, emphasizing how advancements aim to mimic natural sensory experiences to improve prosthetic function and user embodiment. This evolution reflects a trend toward more nuanced, multimodal, and biomimetic feedback systems that enable more intuitive and effective prosthetic control.\n\nImplicit in this progression is the challenge of replicating complex human sensory modalities to enhance proprioception and fine motor control. The mention of neuromorphic feedback suggests the application of bioinspired computational models that mimic neural processing, indicating a deeper integration of neuroscience and engineering. Texture and object stiffness feedback point to tactile discrimination capabilities beyond simple contact detection. The inclusion of temperature feedback and proprioception in future directions further underscores the ambition to achieve comprehensive sensory restoration.\n\nThe difficulty level is high (around 8) because understanding this evolution requires knowledge of neuroengineering, sensor technology, prosthetic design, and the interface between biological and artificial systems.\n\nThe question should probe understanding of how these feedback mechanisms have evolved technically and conceptually, their significance in prosthetic function, and the implications of integrating advanced biomimetic and neuromorphic systems.\n\nThe question will encourage reflection on the challenges and innovations in sensory feedback, connecting sensory modalities to prosthetic utility and user experience.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the progression from no sensory feedback to advanced biomimetic and multimodal stimulation\u2014including neuromorphic and texture feedback\u2014enhance the functional integration and user embodiment of prosthetic limbs, and what are the primary technical challenges that must be addressed to achieve naturalistic sensory restoration?\n\nExplanation: Advanced sensory feedback systems move beyond simple contact detection to replicate complex tactile and proprioceptive signals, enabling users to perceive texture, stiffness, and position, which are critical for fine motor control and embodiment. Neuromorphic feedback mimics neural processing, allowing more natural and efficient encoding of sensory information. This progression enhances the intuitive use of prosthetics and improves safety and efficiency. The main challenges include developing reliable interfaces that can deliver rich, multimodal feedback without invasive procedures, integrating sensors that replicate biological mechanoreceptors, and ensuring the real-time processing of sensory data to match natural neural timing and patterns.\n\nCorrect Answer: By progressively replicating complex tactile and proprioceptive signals through biomimetic and neuromorphic systems, advanced sensory feedback improves prosthetic control and embodiment, with key challenges including sensor integration, naturalistic encoding, and noninvasive, real-time neural interfacing.\n</output_format>",
    "question": "How does the progression from no sensory feedback to advanced biomimetic and multimodal stimulation\u2014including neuromorphic and texture feedback\u2014enhance the functional integration and user embodiment of prosthetic limbs, and what are the primary technical challenges that must be addressed to achieve naturalistic sensory restoration?",
    "answer": "By progressively replicating complex tactile and proprioceptive signals through biomimetic and neuromorphic systems, advanced sensory feedback improves prosthetic control and embodiment, with key challenges including sensor integration, naturalistic encoding, and noninvasive, real-time neural interfacing.",
    "explanation": "Advanced sensory feedback systems move beyond simple contact detection to replicate complex tactile and proprioceptive signals, enabling users to perceive texture, stiffness, and position, which are critical for fine motor control and embodiment. Neuromorphic feedback mimics neural processing, allowing more natural and efficient encoding of sensory information. This progression enhances the intuitive use of prosthetics and improves safety and efficiency. The main challenges include developing reliable interfaces that can deliver rich, multimodal feedback without invasive procedures, integrating sensors that replicate biological mechanoreceptors, and ensuring the real-time processing of sensory data to match natural neural timing and patterns.",
    "question_token_count": 56,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 52
  },
  {
    "context": "## DISCLOSURE STATEMENT\nS.M. holds shares in SensArs, which aims to develop bionic limbs for amputees.\n\n\n## ACKNOWLEDGMENTS\nThe authors would like to thank Iason Batzianoulis for his valuable help on robotic hand control. This review was partly funded by the Swiss National Science Foundation through the National Centre of Competence in Research (NCCR) Robotics, the CHRONOS project, the Wyss Center for Bio and Neuroengineering, and the Bertarelli Foundation.\n\n\n## LITERATURE CITED\n- 1. Piazza C, Grioli G, Catalano MG, Bicchi A. 2019. A century of robotic hands. Annu. Rev. Control Robot. Auton. Syst. 2:1-32\n\n- 2. Castiello U. 2005. The neuroscience of grasping. Nat. Rev. Neurosci. 6:726-36\n\n- 3. Bicchi A. 2000. Hands for dexterous manipulation and robust grasping: a difficult road toward simplicity. IEEE Trans. Robot. Autom. 16:652-62\n\n- 4. Marasco PD, Kim K, Colgate JE, Peshkin MA, Kuiken TA. 2011. Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees. Brain 134:747-58\n\n- 5. Ehrsson HH, Rosen B, Stockselius A, Ragno C, Kohler P, Lundborg G. 2008. Upper limb amputees can be induced to experience a rubber hand as their own. Brain 131:3443-52\n\n- 6. Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, et al. 2014. Restoring natural sensory feedback in real-time bidirectional hand prostheses. Sci. Transl. Med. 6:222ra19\n\n- 7. Kyberd PJ, Hill W. 2011. Survey of upper limb prosthesis users in Sweden, the United Kingdom and Canada. Prosthet. Orthot. Int. 35:234-41\n\n- 8. Dubernard JM, Owen E, Herzberg G, Lanzetta M, Martin X, et al. 1999. Human hand allograft: report on first 6 months. Lancet 353:1315-20\n\n- 9. Piazza C, Catalano MG, Godfrey SG, Rossi M, Grioli G, et al. 2017. The SoftHand Pro-H. IEEE Robot. Autom. Mag. 24(4):87-101\n\n- 10. Smit G, Plettenburg DH, Van Der Helm FCT. 2015. The lightweight Delft Cylinder hand: first multiarticulating hand that meets the basic user requirements. IEEE Trans. Neural Syst. Rehabil. Eng. 23:431-40\n\n- 11. Baril M, Lalibert\u00e9 T, Gosselin C, Routhier F. 2013. On the design of a mechanically programmable underactuated anthropomorphic prosthetic gripper. J. Mech. Des. 135:121008\n\n- 12. Smit G, Plettenburg DH. 2010. Efficiency of voluntary closing hand and hook prostheses. Prosthet. Orthot. Int. 34:411-27\n\n- 13. Biddiss E, Chau T. 2007. Upper limb prosthesis use and abandonment: a survey of the last 25 years. Prosthet. Orthot. Int. 31:236-57\n\n- 14. Lotti F, Tiezzi P, Vassura G, Biagiotti L, Palli G, Melchiorri C. 2005. Development of UB Hand 3: early results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 4488-93. Piscataway, NJ: IEEE\n\n- 15. Honda Y, Miyazaki F, Nishikawa A. 2010. Control of pneumatic five-fingered robot hand using antagonistic muscle ratio and antagonistic muscle activity. In 2010 3rd IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics , pp. 337-42. Piscataway, NJ: IEEE\n\n- 16. Cordella F, Ciancio AL, Sacchetti R, Davalli A, Cutti AG, et al. 2016. Literature review on needs of upper limb prosthesis users. Front. Neurosci. 10:209\n\n- 17. Melchiorri C, Palli G, Berselli G, Vassura G. 2013. Development of the UB Hand IV: overview of design solutions and enabling technologies. IEEE Robot. Autom. Mag. 20(3):72-81\n\n- 18. Pfeifer R, Gomez G. 2009. Morphological computation - connecting brain, body, and environment. In Creating Brain-Like Intelligence , ed. B Sendhoff, E K\u00f6rner, O Sporns, H Ritter, K Doya, pp. 66-83. Berlin: Springer\n\n- 19. Jing X, Yong X, Jiang Y, Li G, Yokoi H. 2019. Anthropomorphic prosthetic hand with combination of light weight and diversiform motions. Appl. Sci. 9:4203\n\n- 20. Mohammadi A, Lavranos J, Zhou H, Mutlu R, Alici G, et al. 2020. A practical 3D-printed soft robotic prosthetic hand with multi-articulating capabilities. PLOS ONE 15:e0232766\n\n- 21. Chamara RPDD, Gopura RARC. 2019. An under-actuated mechanism for anthropomorphic robotic prosthetic hand. In 2019 5th International Conference on Control, Automation and Robotics , pp. 162-66. Piscataway, NJ: IEEE\n\n- 22. Pozzobon LA,Da Silva Guerra R, Librelotto GR. 2019. A low-cost, compliant, underactuated prosthetic hand with custom flex sensors for finger bending estimation. In 2019 19th International Conference on Advanced Robotics , pp. 69-74. Piscataway, NJ: IEEE\n\n- 23. Fajardo J, Ferman V, Cardona D, Maldonado G, Lemus A, Rohmer E. 2020. Galileo Hand: an anthropomorphic and affordable upper-limb prosthesis. IEEE Access 8:81365-77\n\n- 24. Abayasiri RAM, Abayasiri RST, Gunawardhana RAGM, Premakumara RMC, Mallikarachchi S, et al. 2020. An under-actuated hand prosthesis with finger abduction and adduction for human like grasps. In 2020 6th International Conference on Control, Automation and Robotics , pp. 574-80. Piscataway, NJ: IEEE\n\n- 25. Yong X, Jing X, Wu X, Jiang J, Yokoi H. 2019. Development of an adaptive prosthetic hand. In 2019 IEEE International Conference on Robotics and Biomimetics , pp. 2800-5. Piscataway, NJ: IEEE\n\n- 26. Weiner P, Starke J, Hundhausen F, Beil J, Asfour T. 2018. The KIT prosthetic hand: design and control. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 3328-34. Piscataway, NJ: IEEE\n\n- 27. Nemoto Y, Ogawa K, Yoshikawa M. 2020. F3Hand II: a flexible five-fingered prosthetic hand using curved pneumatic artificial muscles. In 2020 IEEE/SICE International Symposium on System Integration , pp. 99-104. Piscataway, NJ: IEEE\n\n- 28. Controzzi M, Cipriani C, Carrozza MC. 2008. Mechatronic design of a transradial cybernetic hand. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 576-81. Piscataway, NJ: IEEE\n\n- 29. Trivedi D, Rahn CD, Kier WM, Walker ID. 2008. Soft robotics: biological inspiration, state of the art, and future research. Appl. Bionics Biomech. 5:520417\n\n- 30. Hirose S, Ma S. 1991. Coupled tendon-driven multijoint manipulator. In 1991 IEEE International Conference on Robotics and Automation , pp. 1268-75. Piscataway, NJ: IEEE\n\n- 31. Carrozza MC, Cappiello G, Stellin G, Zaccone F, Vecchi F, et al. 2005. A cosmetic prosthetic hand with tendon driven under-actuated mechanism and compliant joints: ongoing research and preliminary results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 2661-66. Piscataway, NJ: IEEE\n\n- 32. Godfrey SB, Zhao KD, Theuer A, Catalano MG, Bianchi M, et al. 2018. The SoftHand Pro: functional evaluation of a novel, flexible, and robust myoelectric prosthesis. PLOS ONE 13:13e0205653\n\n- 33. Amend J, Lipson H. 2017. The JamHand: dexterous manipulation with minimal actuation. Soft Robot . 4:70-80\n\n- 34. Yamaguchi A, Takemura K, Yokota S, Edamura K. 2011. A robot hand using electro-conjugate fluid. In 2011 IEEE International Conference on Robotics and Automation , pp. 5923-28. Piscataway, NJ: IEEE\n\n- 35. Zhao H, O'Brien K, Li S, Shepherd RF. 2016. Optoelectronically innervated soft prosthetic hand via stretchable optical waveguides. Sci. Robot. 1:eaai7529\n\n- 36. Yoshida K, Bertram MJ, Cox TGH, Riso RR. 2017. Peripheral nerve recording electrodes and techniques. In Neuroprosthetics: Theory and Practice , ed. K Yoshida, MJ Bertram, TG Hunter Cox, RR Riso, pp. 377-466. Singapore: World Sci.\n\n- 37. Navarro X,Valderrama E,Stieglitz T,Sch\u00fcttler M.2001.Selective fascicular stimulation of the rat sciatic nerve with multipolar polyimide cuff electrodes. Restor. Neurol. Neurosci. 18:9-21\n\n- 38. Tan DW, Schiefer MA, Keith MW, Anderson JR, Tyler J, Tyler DJ. 2014. A neural interface provides long-term stable natural touch perception. Sci. Transl. Med. 6:257ra138\n\n- 39. Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, et al. 2020. A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees. Sci. Transl. Med. 12:eaay2857\n\n- 40. Raspopovic S, Cimolato A, Panarese A, Vallone F, del Valle J, et al. 2020. Neural signal recording and processing in somatic neuroprosthetic applications. A review. J. Neurosci. Methods 337:108653\n\n- 41. Navarro X,Krueger TB,Lago N,Micera S,Stieglitz T,Dario P.2005.A critical review of interfaces with the peripheral nervous system for the control of neuroprostheses and hybrid bionic systems. J. Peripher. Nerv. Syst. 258:229-58\n\n- 42. Boretius T, Badia J, Pascual-Font A, Schuettler M, Navarro X, et al. 2010. A transverse intrafascicular multichannel electrode (TIME) to interface with the peripheral nerve. Biosens. Bioelectron. 26:62-69\n\n- 43. Yoshida K, Pellinen D, Pivin D, Rousche P, Kipke D. 2000. Development of the thin-film longitudinal intra-fascicular electrode. In Proceedings of the 5th Annual Conference of the International Functional Electrical Stimulation Society , pp. 279-84. Graz, Austria: Int. Funct. Electr. Stimul. Soc.\n\n- 44. Badia J, Boretius T, Andreu D, Azevedo-Coste C, Stieglitz T, Navarro X. 2011. Comparative analysis of transverse intrafascicular multichannel, longitudinal intrafascicular and multipolar cuff electrodes for the selective stimulation of nerve fascicles. J. Neural Eng. 8:036023\n\n- 45. Howell B, Grill WM. 2015. Design of electrodes for stimulation and recording. In Implantable Neuroprostheses for Restoring Function , ed. K Kilgore, pp. 59-93. Amsterdam: Elsevier\n\n- 46. Cui X, Wiler J, Dzaman M, Altschuler RA, Martin DC. 2003. In vivo studies of polypyrrole/peptide coated neural probes. Biomaterials 24:777-87\n\n- 47. Kennedy PR, Bakay RAE, Sharpe SM. 1992. Behavioral correlates of action potentials recorded chronically inside the cone electrode. Neuroreport 3:605-8\n\n- 48. Lacour SP, Courtine G, Guck J. 2016. Materials and technologies for soft implantable neuroprostheses. Nat. Rev. Mater. 1:16063\n\n- 49. Kipke DR. 2004. Implantable neural probe systems for cortical neuroprostheses. In 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5344-47. Piscataway, NJ: IEEE\n\n- 50. Merletti R, Holobar A, Farina D. 2008. Analysis of motor units with high-density surface electromyography. J. Electromyogr. Kinesiol. 18:879-90\n\n- 51. Smith LH, Hargrove LJ. 2013. Comparison of surface and intramuscular EMG pattern recognition for simultaneous wrist/hand motion classification. In 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4223-6. Piscataway, NJ: IEEE\n\n- 52. Farrell TR, Weir RF. 2008. A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control. IEEE Trans. Biomed. Eng. 55:2198-211\n\n- 53. Cracchiolo M, Valle G, Petrini F, Strauss I, Granata G, et al. 2020. Decoding of grasping tasks from intraneural recordings in trans-radial amputee. J. Neural Eng. 17:026034\n\n- 54. Wendelken S, Page DM, Davis T, Wark HAC, Kluger DT, et al. 2017. Restoration of motor control and proprioceptive and cutaneous sensation in humans with prior upper-limb amputation via multiple Utah Slanted Electrode Arrays (USEAs) implanted in residual peripheral arm nerves. J. Neuroeng. Rehabil. 14:121\n\n- 55. Cipriani C, Dalonzo M, Carrozza MC. 2012. A miniature vibrotactile sensory substitution device for multifingered hand prosthetics. IEEE Trans. Biomed. Eng. 59:400-8\n\n- 56. Chen B, Feng Y, Wang Q. 2016. Combining vibrotactile feedback with volitional myoelectric control for robotic transtibial prostheses. Front. Neurorobot. 10:8\n\n- 57. Antfolk C, D'Alonzo M, Controzzi M, Lundborg G, Rosen B, et al. 2013. Artificial redirection of sensation from prosthetic fingers to the phantom hand map on transradial amputees: vibrotactile versus mechanotactile sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 21:112-20\n\n- 58. Gonzalez J, Soma H, Sekine M, Yu W. 2012. Psycho-physiological assessment of a prosthetic hand sensory feedback system based on an auditory display: a preliminary study. J. Neuroeng. Rehabil. 9:33\n\n- 59. Osborn L, Betthauser J, Kaliki R, Thakor N. 2018. T argeted transcutaneous electrical nerve stimulation for phantom limb sensory feedback. In 2017 IEEE Biomedical Circuits and Systems Conference . Piscataway, NJ: IEEE. https://doi.org/10.1109/BIOCAS.2017.8325200\n\n- 60. D'Anna E, Petrini FM, Artoni F, Popovic I, Simani\u00b4 c I, et al. 2017. A somatotopic bidirectional hand prosthesis with transcutaneous electrical nerve stimulation based sensory feedback. Sci. Rep. 7:10930\n\n- 61. Oddo CM, Raspopovic S, Artoni F, Mazzoni A, Spigler G, et al. 2016. Intraneural stimulation elicits discrimination of textural features by artificial fingertip in intact and amputee humans. eLife 5:e09148\n\n- 62. Valle G, Mazzoni A, Iberite F, D'Anna E, Strauss I, et al. 2018. Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis. Neuron 100:37-45.e7\n\n- 63. Valle G, D'Anna E, Strauss I, Clemente F, Granata G, et al. 2020. Hand control with invasive feedback is not impaired by increased cognitive load. Front. Bioeng. Biotechnol. 8:287\n\n- 64. D'Anna E, Valle G, Mazzoni A, Strauss I, Iberite F, et al. 2019. A closed-loop hand prosthesis with simultaneous intraneural tactile and position feedback. Sci. Robot. 4:eaau8892\n\n- 65. Shokur S, Gallo S, Moioli RC, Donati ARC, Morya E, et al. 2016. Assimilation of virtual legs and perception of floor texture by complete paraplegic patients receiving artificial tactile feedback. Sci. Rep. 6:32293\n\n- 66. Geethanjali P . 2016. Myoelectric control of prosthetic hands: state-of-the-art review. Med. Devices Evid. Res. 9:247-55\n\n- 67. Farina D, Jiang N, Rehbaum H, Holobar A, Graimann B, et al. 2014. The extraction of neural information from the surface EMG for the control of upper-limb prostheses: emerging avenues and challenges. IEEE Trans. Neural Syst. Rehabil. Eng. 22:797-809\n\n- 68. Ferguson S, Dunlop GR. 2002. Grasp recognition from myoelectric signals. In Proceedings of the Australasian Conference on Robotics and Automation , ed. W Friedrich, P Lim, pp. 83-87. Sydney: Aust. Robot. Autom. Assoc.\n\n- 69. Martelloni C, Carpaneto J, Micera S. 2008. Classification of upper arm EMG signals during objectspecific grasp. In 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5061-64. Piscataway, NJ: IEEE\n\n- 70. Kakoty NM, Hazarika SM. 2011. Recognition of grasp types through principal components of DWT based EMG features. In 2011 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/ICORR.2011.5975398\n\n- 71. Castellini C, Van Der Smagt P . 2009. Surface EMG in advanced hand prosthetics. Biol. Cybern. 100:35-47\n\n- 72. Atzori M, Cognolato M, M\u00fcller H. 2016. Deep learning with convolutional neural networks applied to electromyography data: a resource for the classification of movements for prosthetic hands. Front. Neurorobot. 10:9\n\n- 73. Tenore FVG, Ramos A, Fahmy A, Acharya S, Etienne-Cummings R, Thakor NV. 2009. Decoding of individuated finger movements using surface electromyography. IEEE Trans. Biomed. Eng. 56:1427-34\n\n- 74. Bhattachargee CK, Sikder N, Hasan MT, Nahid A. 2019. Finger movement classification based on statistical and frequency features extracted from surface EMG signals. In 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering . Piscataway, NJ: IEEE. https://doi.org/10.1109/IC4ME247184.2019.9036671\n\n- 75. Bhagwat S,Mukherji P.2020.Electromyogram (EMG) based fingers movement recognition using sparse filtering of wavelet packet coefficients. S\u00af adhan\u00af a 45:3\n\n- 76. Muceli S, Farina D. 2012. Simultaneous and proportional estimation of hand kinematics from EMG during mirrored movements at multiple degrees-of-freedom. IEEE Trans. Neural Syst. Rehabil. Eng. 20:37178\n\n- 77. Jiang N, Vest-Nielsen JL, Muceli S, Farina D. 2012. EMG-based simultaneous and proportional estimation of wrist/hand kinematics in uni-lateral trans-radial amputees. J. Neuroeng. Rehabil. 9:42\n\n- 78. Hioki M, Kawasaki H. 2012. Estimation of finger joint angles from sEMG using a neural network including time delay factor and recurrent structure. ISRN Rehabil . 2012:604314\n\n- 79. Zhuang KZ,Sommer N,Mendez V,Aryan S,Formento E,et al.2019.Shared human-robot proportional control of a dexterous myoelectric prosthesis. Nat. Mach. Intell. 1:400-11\n\n- 80. Mussa-Ivaldi FA, Casadio M, Danziger ZC, Mosier KM, Scheidt RA. 2011. Sensory motor remapping of space in human-machine interfaces. Prog. Brain Res. 191:45-64\n\n- 81. Dyson M, Barnes J, Nazarpour K. 2018. Myoelectric control with abstract decoders. J. Neural Eng. 15:056003\n\n- 82. Dyson M, Dupan S, Jones H, Nazarpour K. 2020. Learning, generalization, and scalability of abstract myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:1539-47\n\n- 83. Daley H,Englehart K,Hargrove L,Kuruganti U.2012.High density electromyography data of normally limbed and transradial amputee subjects for multifunction prosthetic control. J. Electromyogr. Kinesiol. 22:478-84\n\n- 84. Hargrove L,Englehart K,Hudgins B.2006.The effect of electrode displacements on pattern recognition based myoelectric control. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 2203-6. Piscataway, NJ: IEEE\n\n- 85. Boschmann A, Platzner M. 2014. T owards robust HD EMG pattern recognition: reducing electrode displacement effect using structural similarity. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4547-50. Piscataway, NJ: IEEE\n\n- 86. Stango A, Negro F, Farina D. 2015. Spatial correlation of high density EMG signals provides features robust to electrode number and shift in pattern recognition for myocontrol. IEEE Trans. Neural Syst. Rehabil. Eng. 23:189-98\n\n- 87. Farina D, Holobar A, Merletti R, Enoka RM. 2010. Decoding the neural drive to muscles from the surface electromyogram. Clin. Neurophysiol. 121:1616-23\n\n- 88. Kapelner T, Negro F, Aszmann OC, Farina D. 2018. Decoding motor unit activity from forearm muscles: perspectives for myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 26:244-51\n\n- 89. Dai C, Hu X. 2020. Finger joint angle estimation based on motoneuron discharge activities. IEEE J. Biomed. Heal. Inform. 24:760-67\n\n- 90. Hu Y, Wong Y, Wei W, Du Y, Kankanhalli M, Geng W. 2018. A novel attention-based hybrid CNNRNNarchitecture for sEMG-based gesture recognition. PLOS ONE 13:e0206049\n\n- 91. Olsson AE, Sager P, Andersson E, Bj\u00f6rkman A, Male\u0161evi\u00b4 c N, Antfolk C. 2019. Extraction of multilabelled movement information from the raw HD-sEMG image with time-domain depth. Sci. Rep. 9:7244\n\n- 92. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. Regression convolutional neural network for improved simultaneous EMG control. J. Neural Eng. 16:036015\n\n- 93. Xia P, Hu J, Peng Y. 2018. EMG-based estimation of limb movement using deep learning with recurrent convolutional neural networks. Artif. Organs 42:E67-77\n\n- 94. Alom MZ, Taha TM, Yakopcic C, Westberg S, Sidike P, et al. 2018. The history began from AlexNet: a comprehensive survey on deep learning approaches. arXiv:1803.01164 [cs.CV]\n\n- 95. Patricia N, Caputo B. 2014. Learning to learn, from transfer learning to domain adaptation: a unifying perspective. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , pp. 1442-49. Piscataway, NJ: IEEE\n\n- 96. Tommasi T, Orabona F, Castellini C, Caputo B. 2013. Improving control of dexterous hand prostheses using adaptive learning. IEEE Trans. Robot. 29:207-19\n\n- 97. C\u00f4t\u00e9-Allard U, Fall CL, Drouin A, Campeau-Lecours A, Gosselin C, et al. 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans. Neural Syst. Rehabil. Eng. 27:760-71\n\n- 98. Du Y, Jin W, Wei W, Hu Y, Geng W. 2017. Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation. Sensors 17:6-9\n\n- 99. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:370-79\n\n- 100. Phinyomark A, Scheme E. 2018. EMG pattern recognition in the era of big data and deep learning. Big Data Cogn. Comput. 2:21\n\n- 101. Khamparia A, Singh KM. 2019. A systematic review on deep learning architectures and applications. Expert Syst . 36:e12400\n\n- 102. Biddiss E, Chau T. 2007. Upper-limb prosthetics: critical factors in device abandonment. Am. J. Phys. Med. Rehabil. 86:977-87\n\n- 103. Do\u0161en S, Cipriani C, Kosti\u00b4 c M, Controzzi M, Carrozza MC, Popovi\u02c7 c DB. 2010. Cognitive vision system for control of dexterous prosthetic hands: experimental evaluation. J. Neuroeng. Rehabil. 7:42\n\n- 104. Light CM, Chappell PH, Hudgins B, Engelhart K. 2002. Intelligent multifunction myoelectric control of hand prostheses. J. Med. Eng. Technol. 26:139-46\n\n- 105. Fani S, Bianchi M, Jain S, Neto JSP, Boege S, et al. 2016. Assessment of myoelectric controller performance and kinematic behavior of a novel soft synergy-inspired robotic hand for prosthetic applications. Front. Neurorobot. 10:11\n\n- 106. Smith LH, Kuiken TA, Hargrove LJ. 2014. Real-time simultaneous and proportional myoelectric control using intramuscular EMG. J. Neural Eng. 11:066013\n\n- 107. Pasquina PF, Evangelista M, Carvalho AJ, Lockhart J, Griffin S, et al. 2015. First-in-man demonstration of a fully implanted myoelectric sensors system to control an advanced electromechanical prosthetic hand. J. Neurosci. Methods 244:85-93\n\n- 108. Zia ur Rehman M, Gilani S, Waris A, Niazi I, Slabaugh G, et al. 2018. Stacked sparse autoencoders for EMG-based classification of hand motions: a comparative multi day analyses between surface and intramuscular EMG. Appl. Sci. 8:1126\n\n- 109. Kamavuako EN, Scheme EJ, Englehart KB. 2014. Combined surface and intramuscular EMG for improved real-time myoelectric control performance. Biomed. Signal. Process. Control 10:102-7\n\n- 110. Dantas H, Warren DJ, Wendelken SM, Davis TS, Clark GA, Mathews VJ. 2019. Deep learning movement intent decoders trained with dataset aggregation for prosthetic limb control. IEEE Trans. Biomed. Eng. 66:3192-203\n\n- 111. Petrini FM, Mazzoni A, Rigosa J, Giambattistelli F, Granata G, et al. 2019. Microneurography as a tool to develop decoding algorithms for peripheral neuro-controlled hand prostheses. BioMed. Eng. OnLine 18:44\n\n- 112. Rossini PM, Micera S, Benvenuto A, Carpaneto J, Cavallo G, et al. 2010. Double nerve intraneural interface implant on a human amputee for robotic hand control. Clin. Neurophysiol. 121:777-83\n\n- 113. Davis TS, Wark HAC, Hutchinson DT, Warren DJ, O'Neill K, et al. 2016. Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves. J. Neural Eng. 13:036001\n\n- 114. Petrini FM, Valle G, Strauss I, Granata G, Di Iorio R, et al. 2019. Six-month assessment of a hand prosthesis with intraneural tactile feedback. Ann. Neurol. 85:137-54\n\n- 115. Mazzoni A, Oddo CM, Valle G, Camboni D, Strauss I, et al. 2020. Morphological neural computation restores discrimination of naturalistic textures in trans-radial amputees. Sci. Rep. 10:527\n\n- 116. Graczyk EL, Schiefer MA, Saal HP, Delhaye BP, Bensmaia SJ, Tyler DJ. 2016. The neural basis of perceived intensity in natural and artificial touch. Sci. Transl. Med. 8:362ra142\n\n- 117. Kogler V, Nguyen TAK, Digiovanna J, Micera S. 2011. Recording vestibular evoked potentials induced by electrical stimulation of the horizontal semicircular canal in guinea pig. In 2011 5th International IEEE/EMBS Conference on Neural Engineering , pp. 261-64. Piscataway, NJ: IEEE\n\n- 118. Micera S, Carpaneto J, Raspopovic S. 2010. Control of hand prostheses using peripheral information. IEEE Rev. Biomed. Eng. 3:48-68\n\n- 119. Englehart K,Hudgins B.2003.A robust,real-time control scheme for multifunction myoelectric control. IEEE Trans. Biomed. Eng. 50:848-54\n\n- 120. Park M, Bok BG, Ahn JH, Kim MS. 2018. Recent advances in tactile sensing technology. Micromachines 9:321\n\n- 121. Pfeifer R, Iida F, G\u00f3mez G. 2006. Morphological computation for adaptive behavior and cognition. Int. Congr. Ser. 1291:22-9\n\n- 122. Kim Y, Chortos A, Xu W, Liu Y, Oh JY, et al. 2018. A bioinspired flexible organic artificial afferent nerve. Science 360:998-1003\n\n- 123. WuJ, Jia QS, Johansson KH, Shi L. 2013. Event-based sensor data scheduling: trade-off between communication rate and estimation quality. IEEE Trans. Autom. Control 58:1041-6\n\n- 124. Bartolozzi C, Ros PM, Diotalevi F, Jamali N, Natale L, et al. 2017. Event-driven encoding of off-theshelf tactile sensors for compression and latency optimisation for robotic skin. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 166-73. Piscataway, NJ: IEEE\n\n- 125. Lee WW,Tan YJ,Yao H,Li S,See HH,et al. 2019. A neuro-inspired artificial peripheral nervous system for scalable electronic skins. Sci. Robot. 4:eaax2198\n\n- 126. Antfolk C, D'Alonzo M, Ros\u00e9n B, Lundborg G, Sebelius F, Cipriani C. 2013. Sensory feedback in upper limb prosthetics. Expert Rev. Med. Devices 10:45-54\n\n- 127. Mann RW, Reimers SD. 1970. Kinesthetic sensing for the EMG controlled 'Boston Arm.' IEEE Trans. Man-Mach. Syst. 11:110-15\n\n- 128. Patterson PE, Katz JA. 1992. Design and evaluation of a sensory feedback system that provides grasping pressure in a myoelectric hand. J. Rehabil. Res. Dev. 29:1-8\n\n- 129. Clemente F, D'Alonzo M, Controzzi M, Edin BB, Cipriani C. 2016. Non-invasive, temporally discrete feedback of object contact and release improves grasp control of closed-loop myoelectric transradial prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 24:1314-22\n\n- 130. D'Alonzo M, Clemente F, Cipriani C. 2015. Vibrotactile stimulation promotes embodiment of an alien hand in amputees with phantom sensations. IEEE Trans. Neural Syst. Rehabil. Eng. 23:450-57\n\n- 131. Stephens-Fripp B, Alici G, Mutlu R. 2018. A review of non-invasive sensory feedback methods for transradial prosthetic hands. IEEE Access 6:6878-99\n\n- 132. Dosen S, Markovic M, Strbac M, Belic M, Kojic V, et al. 2017. Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 25:183-95\n\n- 133. Geng B,Dong J,Jensen W,Dosen S,Farina D,Kamavuako EN.2018.Psychophysical evaluation of subdermal electrical stimulation in relation to prosthesis sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 26:709-15\n\n- 134. Dong J, Geng B, Niazi IK, Amjad I, Dosen S, et al. 2020. The variability of psychophysical parameters following surface and subdermal stimulation: a multiday study in amputees. IEEE Trans. Neural Syst. Rehabil. Eng. 28:174-80\n\n- 135. Flesher SN, Downey JE, Weiss JM, Hughes CL, Herrera AJ, et al. 2019. Restored tactile sensation improves neuroprosthetic arm control. bioRxiv 653428. https://doi.org/10.1101/653428\n\n- 136. Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ. 2018. Home use of a neural-connected sensory prosthesis provides the functional and psychosocial experience of having a hand again. Sci. Rep. 8:9866\n\n|   137. | George JA, Page DM, Davis TS, Duncan CC, Hutchinson T, et al. 2020. Long-term performance of Utah Slanted Electrode Arrays and intramuscular electromyographic leads implanted chronically in human arm nerves and muscles. bioRxiv 2020.03.30.016683. https://doi.org/10.1101/2020.03.30. 016683                                                      |\n\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n|    138 | Ortiz-Catalan M, Mastinu E, Sassu P, Aszmann O, Br\u00e5nemark R. 2020. Self-contained neuromuscu- loskeletal arm prostheses. N. Engl. J. Med. 382:1732-38                                                                                                                                                                                                  |\n\n|    139 | George JA, Kluger DT,Davis TS,Wendelken SM,Okorokova EV,et al.2019.Biomimetic sensory feed- back through peripheral nerve stimulation improves dexterous use of a bionic hand. Sci. Robot. 4:eaax2352                                                                                                                                                  |\n\n|    140 | Chandrasekaran S,Nanivadekar AC,McKernan G,Helm ER,Boninger ML,et al.2020.Sensory restora- tion by epidural stimulation of the lateral spinal cord in upper-limb amputees. eLife 9:e54349                                                                                                                                                              |\n\n|    141 | Controzzi M, Clemente F, Barone D, Luciani LB, Pierotti N, et al. 2019. Progress towards the devel- opment of the DeTOP hand prosthesis: a sensorized transradial prosthesis for clinical use. In Converg- ing Clinical and Engineering Research on Neurorehabilitation III , ed. L Masia, S Micera, M Akay, J Pons, pp. 103-6. Cham, Switz.: Springer |\n\n|    142 | Formento E,D'Anna E,Gribi S,Lacour SP,Micera S.2019.A biomimetic electrical stimulation strategy to induce asynchronous stochastic neural activity. J. Neural Eng. 17:046019                                                                                                                                                                           |\n\n|    143 | Sengupta A, Ye Y, Wang R, Liu C, Roy K. 2019. Going deeper in spiking neural networks: VGG and residual architectures. Front Neurosci . 13:95                                                                                                                                                                                                          |\n\n|    144 | Lindner HYN, N\u00e4tterlund BS, Hermansson LMN. 2010. Upper limb prosthetic outcome measures: review and content comparison based on International Classification of Functioning, Disability and Health. Prosthet. Orthot. Int. 34:109-28                                                                                                                  |\n\n|    145 | Hill W, Stavdahl \u00d8, Hermansson LN, Kyberd P, Swanson S, Hubbard S. 2009. Functional outcomes in the WHO-ICF model: establishment of the upper limb prosthetic outcome measures group. J. Prosthet. Orthot. 21:115-19                                                                                                                                   |\n\n|    146 | Hudak PL, Amadio PC, Bombardier C. 1996. Development of an upper extremity outcome measure: the DASH (Disabilities of the Arm, Shoulder, and Head). Am. J. Ind. Med. 29:602-8                                                                                                                                                                          |\n\n|    147 | Beaton DE, Wright JG, Katz JN, Amadio P, Bombardier C, et al. 2005. Development of the Quick- DASH: comparison of three item-reduction approaches. J. Bone Jt. Surg. A 87:1038-46                                                                                                                                                                      |\n\n|    148 | Harper A, Power M, Orley J, Herrman H, Schofield H, et al. 1998. Development of the World Health Organization WHOQOL-BREF quality of life assessment. Psychol. Med. 28:551-58                                                                                                                                                                          |\n\n|    149 | Burckhardt CS, Anderson KL. 2003. The Quality of Life Scale (QOLS): reliability, validity, and utiliza- tion. Health Qual. Life Outcomes 1:60                                                                                                                                                                                                          |\n\n|    150 | Heinemann AW, Bode RK, O'Reilly C. 2003. Development and measurement properties of the Or- thotics and Prosthetics User's Survey (OPUS): a comprehensive set of clinical outcome instruments. Prosthet. Orthot. Int. 27:191-206                                                                                                                        |\n\n|    151 | Lendaro E,Middleton A,Brown S,Ortiz-Catalan M.2020.Out of the clinic, into the home: the in-home use of phantom motor execution aided by machine learning and augmented reality for the treatment of phantom limb pain. J. Pain Res. 13:195-209                                                                                                        |\n\n|    152 | Johansson RS, Flanagan JR. 2009. Coding and use of tactile signals from the fingertips in object manip- ulation tasks. Nat. Rev. Neurosci. 10:345-59                                                                                                                                                                                                   |\n\n|    153 | Taub E, Uswatte G, Pidikiti R. 1999. Constraint-induced movement therapy: a new family of techniques with broad application to physical rehabilitation-a clinical review. J. Rehabil. Res. Dev. 36:237-51                                                                                                                                              |\n\n|    154 | Mathiowetz V, Volland G, Kashman N, Weber K. 1985. Adult norms for the Box and Block T est of manual dexterity. Am. J. Occup. Ther. 39:386-91                                                                                                                                                                                                          |\n\n|    155 | Hebert JS, Lewicke J. 2012. Case report of modified box and blocks test with motion capture to measure prosthetic function. J. Rehabil. Res. Dev. 49:1163-74                                                                                                                                                                                           |\n\n|    156 | Hebert JS, Lewicke J, Williams TR, Vette AH. 2014. Normative data for modified box and blocks test measuring upper-limb function via motion capture. J. Rehabil. Res. Dev. 51:919-31                                                                                                                                                                   |\n\n|    157 | Mathiowetz V, Weber K, Kashman N, Volland G. 1985. Adult norms for the Nine Hole Peg T est of finger dexterity. Occup. Ther. J. Res. 5:24-38                                                                                                                                                                                                           |\n\n- 158. Lambercy O,Fluet MC,Lamers I,Kerkhofs L,Feys P, Gassert R. 2013. Assessment of upper limb motor function in patients with multiple sclerosis using the Virtual Peg Insertion T est: a pilot study. In 2013 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/\n",
    "topic": "Challenges and solutions to electrode displacement and inter-session variability in myoelectric control systems.",
    "response": "<document_analysis>\nThe context consists of an extensive literature citation list from a comprehensive review related to robotic and prosthetic hands, myoelectric control, neural interfaces, sensory feedback, and related neuroprosthetic technologies. Within this collection, several references (e.g., 84, 85, 86, 98, 99) address issues related to electrode displacement and inter-session variability in electromyography (EMG)-based myoelectric control systems. These references discuss the impact of electrode shift on pattern recognition accuracy and propose methods such as structural similarity, spatial correlation, and deep domain adaptation or transfer learning to mitigate these issues.\n\nThe central theme relevant to the question topic is the challenge of robustness and reliability in myoelectric control systems caused by electrode displacement or variability across sessions, which can degrade prosthetic control performance. The citations indicate that solutions involve advanced signal processing, pattern recognition algorithms, and machine learning approaches to enhance robustness and adaptability.\n\nDifficulty is rated at 8 out of 10 because understanding these challenges and solutions requires expert knowledge of signal processing, neural engineering, machine learning, and prosthetic control systems. The question can invite critical reflection on how these issues affect real-world prosthesis usability and the efficacy of proposed mitigation strategies.\n\nThe context is meaningful and contains detailed scholarly references directly relevant to the question topic, enabling a challenging and insightful question-answer pair to be developed.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do electrode displacement and inter-session variability affect the accuracy of myoelectric pattern recognition for prosthetic control, and what advanced computational strategies have been demonstrated to mitigate these challenges effectively?\n\nExplanation: Electrode displacement and inter-session variability alter the recorded EMG signal patterns, reducing classification accuracy and prosthesis control reliability. Advanced strategies such as structural similarity features, spatial correlation of high-density EMG, and deep domain adaptation or transfer learning have been demonstrated to reduce sensitivity to electrode shift and improve robustness across sessions.\n\nCorrect Answer: They degrade EMG pattern recognition accuracy by altering signal features, and mitigation is achieved through structural similarity measures, spatial correlation features, and deep learning-based domain adaptation or transfer learning techniques. \n</output_format>",
    "question": "How do electrode displacement and inter-session variability affect the accuracy of myoelectric pattern recognition for prosthetic control, and what advanced computational strategies have been demonstrated to mitigate these challenges effectively?",
    "answer": "They degrade EMG pattern recognition accuracy by altering signal features, and mitigation is achieved through structural similarity measures, spatial correlation features, and deep learning-based domain adaptation or transfer learning techniques.",
    "explanation": "Electrode displacement and inter-session variability alter the recorded EMG signal patterns, reducing classification accuracy and prosthesis control reliability. Advanced strategies such as structural similarity features, spatial correlation of high-density EMG, and deep domain adaptation or transfer learning have been demonstrated to reduce sensitivity to electrode shift and improve robustness across sessions.",
    "question_token_count": 36,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 37
  },
  {
    "context": "## 4.3. Decoding Motor Intention via Implanted Electrodes\nSurface electrodes cannot precisely record the signal from deep muscles; to overcome this issue, several groups have focused on iEMG electrodes. This technique is more invasive but allows one to record EMG signals (51) uncorrelated from the underlying musculature and avoids the daily placement of electrodes. iEMG is robust against electrode shift (e.g., socket rotation) and change in skin impedance and sweat. Several studies have demonstrated the performance of simultaneous wrist and hand motions (three DOFs) using six to eight iEMG electrodes; Smith &amp; Hargrove (51) showed that iEMG has better decoding performance than sEMG. High decoding performance is reported in real time (106), and in fully implanted setups, the results are stable for several days (107).\n\nOnthe other hand, Farrell &amp; Weir (52) compared the pattern recognition-based grasp classification performance of iEMG and sEMG on 12 movement classes with eight channels and did not find a statistical difference between electrode types. They concluded that the choice of electrode should be based not on classification accuracy but rather on signal consistency over time and robustness to electrode lift-off. Zia ur Rehman et al. (108) compared a standard linear discriminant analysis with a deep network for grasp classification. They performed a multiday analysis comparing six iEMG and six sEMG electrodes, and their results showed that deep learning had better decoding performance and was more stable over time.\n\nKamavuako et al. (109) investigated the effect of combining iEMG to target deep muscles with sEMG on myoelectric control. They showed that the combined solution improved offline and real-time control performance compared with sEMG alone.\n\nWith 32 iEMG electrodes, Dantas et al. (110) compared different decoding methods for the continuous control of five DOFs corresponding to the flexion and extension of each digit. Using a data set aggregation algorithm, they showed a normalized mean squared error as low as 0.033 with a deep convolutional neural network. They also investigated signal stability for 150 days after training, showing a small degradation during the first month (0.003 normalized mean squared error per day with a convolutional neural network), but that degradation stopped in the next four months.\n\nFor transradial amputees, an alternative to using EMG signals to control hand prostheses is decoding from peripheral nerve signals. Different grasp types can be decoded from peripheral nerve signals with high accuracy using different interfaces, both offline and in real time (54, 111113). Implanted peripheral nerve recordings are more invasive than sEMG but are more stable over time. Indeed, donning and doffing the prosthesis does not move these electrodes as much as it does sEMG electrodes. Recently, Cracchiolo et al. (53) decoded up to 11 class states using TIMEs on an amputee subject and showed that the active sites chosen on the first day could also be used in the following sessions, for up to seven days (80% accuracy, compared with 83% by selecting active sites every session). However, this modality is generally used to provide sensory\n\nfeedback (64, 114-116). Therefore the development of new approaches to record neural signals during peripheral stimulation [e.g., artifact removal (117)] is necessary.\n\nVu et al. (39) recently developed a regenerative peripheral nerve interface to increase signal specificity and long-term stability. They implanted transected peripheral nerves into a free muscle graft. After regeneration, revascularization, and reinnervation, the graft becomes a nerve bioamplifier that creates EMG signals. Using chronically implanted iEMG to record from these grafts, they performed five-class decoding in real time with up to 98.2% accuracy with two transradial amputees in a virtual hand environment. They also showed results from a Box and Block T est using an RPH that provided continuous control of two DOFs of thumb motions through their interface combined with a third DOF based on sEMG.\n",
    "topic": "The trade-offs between invasiveness and functional benefits in choosing electrode types for neuroprosthetic control in transradial amputees.",
    "response": "<document_analysis>\nThe context focuses on implanted electromyography (iEMG) electrodes and peripheral nerve interfaces as invasive methods for decoding motor intentions to control prosthetic hands in transradial amputees. The main themes include comparison of iEMG with surface EMG (sEMG) in terms of signal stability, decoding accuracy, robustness, and long-term usability; the integration of iEMG and sEMG; and the emerging use of peripheral nerve interfaces, including regenerative peripheral nerve interfaces, for improved specificity and stability. Implicit assumptions involve the trade-offs between invasiveness and signal quality/stability, the challenges posed by electrode placement variability with sEMG, and the potential of deep learning methods to improve decoding performance. The text suggests that while iEMG and nerve interfaces are more invasive, they offer robustness to electrode shift, greater signal stability over time, and better functional decoding performance, which are critical for daily prosthetic use. The topic invites deep reflection on how these technical and biological factors weigh against each other when selecting electrode types for neuroprosthetic control, especially considering patient comfort, surgical risks, and device reliability. Difficulty is rated 9 due to the complex interplay of bioengineering, neurophysiology, and clinical considerations involved. The question can provoke expert-level analysis on balancing invasiveness with functional gains and long-term usability in prosthetic control.\n\n</document_analysis>\n<output_format>\nQuestion: How do the trade-offs between invasiveness and functional benefits influence the choice between implanted electromyography (iEMG) electrodes, surface EMG (sEMG), and peripheral nerve interfaces for neuroprosthetic control in transradial amputees, considering factors like signal stability, decoding accuracy, and usability over time?\n\nExplanation: The choice is influenced by the fact that iEMG and peripheral nerve interfaces, although more invasive, provide more stable and specific signals less affected by electrode shift or skin impedance changes, leading to higher and more consistent decoding accuracy and robustness over time; in contrast, sEMG is less invasive but more susceptible to variability and less stable signal quality, which can impair control performance and reliability in daily use. Peripheral nerve interfaces also offer sensory feedback capabilities but require advanced signal processing to handle stimulation artifacts. Thus, invasiveness is accepted for improved long-term functionality and user experience in prosthetic control.\n\nCorrect Answer: Greater invasiveness of iEMG and peripheral nerve interfaces is justified by their superior signal stability, decoding accuracy, and robustness over time compared to sEMG, making them preferable for reliable, long-term neuroprosthetic control despite higher surgical risks.\n</output_format>",
    "question": "How do the trade-offs between invasiveness and functional benefits influence the choice between implanted electromyography (iEMG) electrodes, surface EMG (sEMG), and peripheral nerve interfaces for neuroprosthetic control in transradial amputees, considering factors like signal stability, decoding accuracy, and usability over time?",
    "answer": "Greater invasiveness of iEMG and peripheral nerve interfaces is justified by their superior signal stability, decoding accuracy, and robustness over time compared to sEMG, making them preferable for reliable, long-term neuroprosthetic control despite higher surgical risks.",
    "explanation": "The choice is influenced by the fact that iEMG and peripheral nerve interfaces, although more invasive, provide more stable and specific signals less affected by electrode shift or skin impedance changes, leading to higher and more consistent decoding accuracy and robustness over time; in contrast, sEMG is less invasive but more susceptible to variability and less stable signal quality, which can impair control performance and reliability in daily use. Peripheral nerve interfaces also offer sensory feedback capabilities but require advanced signal processing to handle stimulation artifacts. Thus, invasiveness is accepted for improved long-term functionality and user experience in prosthetic control.",
    "question_token_count": 65,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 50
  },
  {
    "context": "## 5.5. Perspectives\nWe believe that sensorization will play a significant role in the next generation of RPHs. Here, we discuss three main directions influenced by sensorization: embedded sensorization, improved stimulation strategies, and new computational architectures.\n\n5.5.1. Embedded sensorization. Sensorized hands are not yet prevalent in the literature but are starting to draw interest, especially with the improvement of interfaces for bidirectional prostheses (for a list of RPHs with sensorized fingertips, see Supplemental Tables 1 and 2 ). As a recent example, Controzzi et al. (141) developed the Mia hand (Prensilia, Italy), which is integrated with sensors that can measure normal and tangential forces at the fingertips. Sensorization of RPHs is a design requirement that should be considered as important as other functional requirements for hand prostheses, such as weight or dexterity. T o improve RPH performance and sensor integration, next-generation RPHs should then be designed with their sensorization in mind. Information about hand state (joint position, forces, and touch) can also be beneficial to increase the dexterity of such hands, enabling automatic adjustments such as catching slipping objects (e.g., the bebionic3 hand) and shared-control strategies (see Section 4).\n\n5.5.2. Improved stimulation strategies. Biomimicry is one of the strongest trends in nerve stimulation strategies, as it promises to deliver biologically plausible stimulation patterns to evoke more natural sensations. Biomimetic approaches rely on bio-inspired models to compute the stimulation patterns, so new iterations of these models, based on the current experience in stimulation and neural recording, are needed to improve the quality of elicited sensations.\n\nThese model-based approaches permit simpler modulation strategies that increase the naturalness of sensations. T an et al. (38), for example, proved that a sinusoidal modulation of the pulse width improves the naturalness of the sensation. Formento et al. (142) instead designed a strategy to activate asynchronously stimulated fibers, mimicking healthy neural activity; in their work, they replaced classical biphasic stimulation with a high-frequency burst of pulses that slowly increased in amplitude, and confirmed their hypothesis in ex vivo experiments. Stimulation patterns that try to overcome the physical limits of present neural interfaces (as in 142) while paving the way for more natural evoked sensations also suggest the requirements for the future generation of neural interfaces and stimulators for sensory feedback: increase reaching without losing discrimination.\n\n5.5.3. New computational architectures. Neuromorphic architectures have the potential to represent a paradigm shift in the design of the control systems for bidirectional hand prostheses, going toward distributed systems and edge computing. Both sensor acquisition and stimulation can benefit from these trends because they lead to more reliable systems that scale well with the increase of sensors and stimulation active sites. If the next generation of neuromorphic hardware promotes portability and lower power consumption, it could lead to broader implementation and adoption of neuromorphic systems in bidirectional hand prostheses.\n\nMany RPHs rely on advanced encoding and decoding algorithms implemented with neural networks (62), which are more computationally demanding than traditional approaches. It is interesting that even deep learning networks can be translated into spiking neural networks (143), possibly enabling full neuromorphic hardware encoding and decoding in future prostheses.\n",
    "topic": "Comparative analysis of classical biphasic stimulation versus high-frequency burst stimulation patterns for asynchronous activation of neural fibers.",
    "response": "<document_analysis>\nThe context discusses future directions in sensorized robotic prosthetic hands (RPHs), emphasizing embedded sensorization, improved stimulation strategies, and new computational architectures. The section on stimulation strategies highlights biomimicry and model-based stimulation patterns to evoke natural sensations. Specifically, it contrasts classical biphasic stimulation with a newer approach involving high-frequency bursts of pulses with gradually increasing amplitude to asynchronously activate nerve fibers, mimicking healthy neural activity. This method aims to overcome physical limits of neural interfaces while enhancing the naturalness and discrimination of sensations.\n\nImplicit in this discussion is the challenge of replicating natural neural firing patterns to improve sensory feedback in prostheses. The classical biphasic stimulation, typically synchronous and uniform, contrasts with the biomimetic asynchronous high-frequency burst approach that seeks to emulate the temporal variability of natural neural activation. This comparison touches on neural encoding, stimulation efficacy, and the potential for improved perception and control in prosthetics.\n\nDifficulty rating: 9/10. The question demands expert knowledge in neural engineering, neurostimulation techniques, and prosthetic sensory feedback systems. It requires understanding of neural fiber activation patterns, stimulation waveform design, and the implications for sensory naturalness and discrimination.\n\nThe question will encourage deep reflection on how different stimulation paradigms affect neural recruitment and perception, the limitations of traditional methods, and the innovations enabled by biomimetic approaches. It probes the understanding of asynchronous versus synchronous activation and the technical strategies used to achieve more natural sensory experiences.\n\nHence, the question focuses on a high-level comparative analysis of these two stimulation paradigms and their implications for neural fiber activation in prosthetic sensory feedback systems.\n</document_analysis>\n\n<output_format>\nQuestion: How does the high-frequency burst stimulation pattern with gradually increasing amplitude achieve asynchronous activation of neural fibers compared to classical biphasic stimulation, and what implications does this have for the naturalness and discrimination of evoked sensations in prosthetic sensory feedback?\n\nExplanation: The high-frequency burst stimulation pattern mimics healthy neural activity by asynchronously activating fibers through pulses that slowly increase in amplitude, unlike classical biphasic stimulation which activates fibers synchronously with uniform pulses. This asynchronous recruitment enhances the naturalness of sensations and improves sensory discrimination by more closely replicating physiological neural firing patterns, overcoming physical limitations of traditional neural interfaces.\n\nCorrect Answer: It asynchronously activates fibers via gradually increasing amplitude bursts, enhancing naturalness and discrimination by mimicking physiological neural firing patterns unlike synchronous classical biphasic stimulation.\n</output_format>",
    "question": "How does the high-frequency burst stimulation pattern with gradually increasing amplitude achieve asynchronous activation of neural fibers compared to classical biphasic stimulation, and what implications does this have for the naturalness and discrimination of evoked sensations in prosthetic sensory feedback?",
    "answer": "It asynchronously activates fibers via gradually increasing amplitude bursts, enhancing naturalness and discrimination by mimicking physiological neural firing patterns unlike synchronous classical biphasic stimulation.",
    "explanation": "The high-frequency burst stimulation pattern mimics healthy neural activity by asynchronously activating fibers through pulses that slowly increase in amplitude, unlike classical biphasic stimulation which activates fibers synchronously with uniform pulses. This asynchronous recruitment enhances the naturalness of sensations and improves sensory discrimination by more closely replicating physiological neural firing patterns, overcoming physical limitations of traditional neural interfaces.",
    "question_token_count": 49,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 31
  },
  {
    "context": "## 5.3. Sensory Architectures\nTheproblem of handling many sensors at the same time has been addressed successfully in the past by using time-sharing (multiplexing) and space-sharing (matrix arrangement) techniques, minimizing wiring complexity while keeping read latency in an acceptable range. Nevertheless, this approach does not scale well in terms of covering the whole hand with a sensor density comparable to that of the human hand. Additionally, the unavoidable increase in the number of electrical connections makes the system highly susceptible to breakage.\n\nEvent-based architectures rely on the concept of send-on-delta (123), where each sensor (comprising an analog front end and an analog-to-digital converter), instead of signaling its value at a constant rate, does so only when the value changes by more than a certain threshold. These architectures have many advantages owing to the sparsity of the data representation. In other words, the communication line does not need to be capable of handling all the sensors simultaneously (as an interaction where all the sensors are triggered in the same moment is unlikely); instead, single sensors are polled at a high rate, which preserves the time structure of the stimulus.\n\nThe underlying idea of event-based systems is inspired by how neurons communicate information to each other, sending a train of spikes instead of continuous value. In earlier implementations, data flowed from sensors to the central unit through digital communication lines using well-known protocols such as Universal Asynchronous Transmitter Receiver (UART), Ethernet, and the Controller Area Network (CAN) bus. Some groups have designed communication paradigms by mimicking information encoding by the nerves; using pulses of 20 ns, Bartolozzi et al. (124) showed a 94% improvement in data rate over traditional protocols.\n\nAn even more advanced step was made in the work of Lee et al. (125), where the sensors communicate with spikes through the same conductive surface without any flow control, reducing the wires needed to two (data and ground). In this way, at the cost of a decoding stage for sensor value acquisition, the performance of the architecture increased, reaching up to 100,000 sensors sharing the same bus.\n",
    "topic": "Critical evaluation of the trade-offs between wiring complexity, sensor density, communication protocol choice, and system robustness in high-density tactile sensor arrays.",
    "response": "<document_analysis>\nThe provided text discusses different architectural approaches to managing high-density tactile sensor arrays, focusing on the challenges and trade-offs related to wiring complexity, sensor density, communication protocols, and system robustness. Traditional multiplexing and matrix arrangements reduce wiring but do not scale well to human-hand-level sensor density and increase susceptibility to failure due to the high number of electrical connections. Event-based architectures using send-on-delta signaling reduce data transmission by only reporting significant changes, inspired by neural spike communication, preserving temporal information and reducing bandwidth requirements. Different communication protocols (UART, Ethernet, CAN bus) have been employed, with advancements including nerve-inspired pulse encoding improving data rates significantly. Lee et al.\u2019s approach further minimizes wiring to just two lines via spike communication on a conductive surface without flow control, enabling up to 100,000 sensors on one bus at the cost of additional decoding complexity.\n\nImplicit assumptions include that reducing wiring improves robustness but may demand more complex decoding, and that event-driven communication better matches sparse sensor activation patterns than constant-rate sampling. The trade-offs involve balancing wiring complexity (and thus mechanical robustness) against communication complexity and latency. The text highlights that while traditional methods struggle with scale and robustness, event-based and spike-based methods can handle large sensor counts efficiently but require sophisticated decoding and protocol design.\n\nDifficulty is rated 9/10 due to the need for deep understanding of sensor architectures, communication protocols, and robustness issues in tactile sensor arrays. The question should encourage synthesis of how wiring complexity, sensor density, communication methods, and robustness interact, reflecting on the engineering trade-offs and implications for scalable tactile sensing.\n\nThe question is intentionally designed to provoke critical evaluation of these intertwined factors, requiring expert-level insight into tactile sensor system design.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do event-based communication architectures mitigate wiring complexity and robustness issues in high-density tactile sensor arrays compared to traditional multiplexing methods, and what are the critical trade-offs involving sensor density, communication protocol complexity, and signal decoding that must be considered for scalable system design?\n\nExplanation: Event-based architectures reduce wiring and improve robustness by transmitting data only when sensor values change significantly, thus lowering bandwidth and wiring needs compared to traditional multiplexing that samples all sensors constantly. This sparse event-driven communication allows fewer wires and less susceptibility to failure. However, achieving high sensor densities requires complex communication protocols (e.g., nerve-inspired spike encoding) and advanced decoding to interpret signals from many sensors sharing the same bus, trading off simplicity for scalability and performance.\n\nCorrect Answer: Event-based architectures reduce wiring and improve robustness by transmitting only significant sensor changes, but scaling to high sensor densities requires complex spike-based protocols and decoding, balancing reduced wiring against increased communication and processing complexity.\n</output_format>",
    "question": "How do event-based communication architectures mitigate wiring complexity and robustness issues in high-density tactile sensor arrays compared to traditional multiplexing methods, and what are the critical trade-offs involving sensor density, communication protocol complexity, and signal decoding that must be considered for scalable system design?",
    "answer": "Event-based architectures reduce wiring and improve robustness by transmitting only significant sensor changes, but scaling to high sensor densities requires complex spike-based protocols and decoding, balancing reduced wiring against increased communication and processing complexity.",
    "explanation": "Event-based architectures reduce wiring and improve robustness by transmitting data only when sensor values change significantly, thus lowering bandwidth and wiring needs compared to traditional multiplexing that samples all sensors constantly. This sparse event-driven communication allows fewer wires and less susceptibility to failure. However, achieving high sensor densities requires complex communication protocols (e.g., nerve-inspired spike encoding) and advanced decoding to interpret signals from many sensors sharing the same bus, trading off simplicity for scalability and performance.",
    "question_token_count": 53,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 40
  },
  {
    "context": "## 5. RESTORING SENSORY FEEDBACK\nSensory information plays a critical role in both the exploration of the external environment and in any manipulation task. When an individual interacts with surrounding objects, tactile sensations are used to infer features such as size, compliance, temperature, and texture, while the same sensations are exploited to handle them properly or use them as tools. From this perspective, aiming to restore afferent sensory channels from a hand prosthesis is a critical step in designing a device that ensures two key aspects: dexterous manipulation and embodiment of the prosthetic device.\n\nThe design of a sensory feedback system that can successfully deliver information relies on three fundamental blocks working together: ( a ) sensor readings, processed by ( ) an encoding b strategy capable of translating meaningful information to the user, through ( ) an interface. Prec vious sections have described the different available interfaces; here, we present the encoding techniques and sensors relevant to the design of modern hand prostheses ( Table 1 ).\n\nSensors mounted on a robotic hand should ideally record the whole spectrum of available human sensations, from both external and internal sources. Indeed, sensory information from the human hand covers both interactions with the external world (tactile perception, thermal perception, and nociception, i.e., perception of pain) and internal perception of the positions of the joints and the length and forces exerted by the muscles, together known as proprioception. Table 2 shows examples of sensor placements on RPHs from recent studies.\n",
    "topic": "The implications of integrating nociceptive feedback (pain perception) into prosthetic sensory systems and its potential impact on user safety and device functionality.",
    "response": "<document_analysis>\nThe provided context discusses the critical importance of restoring sensory feedback in hand prostheses to enable dexterous manipulation and embodiment. It outlines that sensory feedback systems depend on sensor readings, encoding strategies, and interfaces. The sensors ideally capture the full spectrum of human sensations, including tactile, thermal, and nociceptive (pain) perceptions, as well as proprioceptive inputs. The mention of nociception is notable because it introduces an often overlooked but vital sensory modality that signals harm or potential injury.\n\nIntegrating nociceptive feedback into prosthetic devices has complex implications. It could enhance user safety by alerting the user to damaging stimuli, thus preventing injury to the prosthetic or the user\u2019s residual limb. However, implementing nociceptive feedback also presents challenges, such as how to encode and deliver pain signals in a manner that is informative without causing discomfort or distress. It may affect device functionality by potentially triggering protective reflexes or cautionary behaviors, influencing how users interact with their environment.\n\nThe difficulty level of a question exploring these implications is high (around 8-9) because it requires understanding sensory neurophysiology, prosthetic design constraints, human factors, and the balance between functional benefit and user experience. The question should prompt reflection on both technical and ethical considerations, pushing domain experts to think critically about the trade-offs and design strategies.\n\nTherefore, a question focused on the implications and impact of integrating nociceptive feedback would stimulate deep engagement with the content and its broader consequences.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the key challenges and potential benefits of integrating nociceptive (pain) feedback into hand prosthetic sensory systems, and how might this integration influence both user safety and the functional interaction between the prosthesis and its environment?\n\nExplanation: Integrating nociceptive feedback can enhance user safety by alerting to harmful stimuli, preventing injury to the user and device. However, challenges include encoding pain signals without causing distress and managing how such feedback affects user behavior and device control. This integration may lead to more cautious manipulation but requires careful design to balance informative pain perception with usability and embodiment.\n\nCorrect Answer: Integrating nociceptive feedback improves safety by signaling harmful stimuli but poses challenges in encoding pain without discomfort, influencing user behavior and device control to balance protection and functional use.\n</output_format>",
    "question": "What are the key challenges and potential benefits of integrating nociceptive (pain) feedback into hand prosthetic sensory systems, and how might this integration influence both user safety and the functional interaction between the prosthesis and its environment?",
    "answer": "Integrating nociceptive feedback improves safety by signaling harmful stimuli but poses challenges in encoding pain without discomfort, influencing user behavior and device control to balance protection and functional use.",
    "explanation": "Integrating nociceptive feedback can enhance user safety by alerting to harmful stimuli, preventing injury to the user and device. However, challenges include encoding pain signals without causing distress and managing how such feedback affects user behavior and device control. This integration may lead to more cautious manipulation but requires careful design to balance informative pain perception with usability and embodiment.",
    "question_token_count": 46,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 8,
    "question_groundedness_score": 7,
    "avg_answer_token_count": 35
  },
  {
    "context": "## Current Solutions and Future Trends for Robotic Prosthetic Hands\nVincent Mendez, 1, \u2217 Francesco Iberite, 2, \u2217 Solaiman Shokur, 1,\u2020 and Silvestro Micera 1,2,\u2020\n\n1 Center for Neuroprosthetics and Institute of Bioengineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1202 Gen\u00e8ve, Switzerland; email: silvestro.micera@epfl.ch\n\n2 BioRobotics Institute and Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, 56127 Pisa, Italy\n\n\n## Keywords\nhand, prosthesis, neuroprostheses, sensory feedback, electromyography, EMG\n\n\n## Abstract\nThe desire for functional replacement of a missing hand is an ancient one. Historically, humans have replaced a missing limb with a prosthesis for cosmetic, vocational, or personal autonomy reasons. The hand is a powerful tool, and its loss causes severe physical and often mental debilitation. Technological advancements have allowed the development of increasingly effective artificial hands, which can improve the quality of life of people who suffered a hand amputation. Here, we review the state of the art of robotic prosthetic hands (RPHs), with particular attention to the potential and current limits of their main building blocks: the hand itself, approaches to decoding voluntary commands and controlling the hand, and systems and methods for providing sensory feedback to the user. We also briefly describe existing approaches to characterizing the performance of subjects using RPHs for grasping tasks and provide perspectives on the future of different components and the overall field of RPH development.\n",
    "topic": "The potential impact of improved sensory feedback on the embodiment and intuitive use of robotic prosthetic hands.",
    "response": "<document_analysis>\nThe provided context is an abstract from a scholarly review on robotic prosthetic hands (RPHs). It highlights the historical importance of prosthetic hands, the severe consequences of hand loss, and the technological progress enabling increasingly effective artificial hands. The abstract emphasizes three key building blocks of RPHs: the prosthetic hand hardware itself, the decoding and control of voluntary commands, and sensory feedback systems. It also mentions the evaluation of performance in grasping tasks and future perspectives on the field.\n\nThe topic for question generation is the potential impact of improved sensory feedback on embodiment and intuitive use of robotic prosthetic hands. Sensory feedback is critical for natural and intuitive prosthetic control because it enables users to perceive the prosthesis as part of their body (embodiment) and to control it more effectively without visual monitoring. The abstract mentions sensory feedback as one of the main building blocks and its potential and current limits, signaling its importance.\n\nImplicit assumptions and subtleties include that sensory feedback can enhance the user's perception and control of the prosthesis, but there are technological and biological challenges to implementing effective feedback systems. The relationship between sensory feedback and embodiment is complex, involving neurophysiological integration and user adaptation.\n\nRating difficulty: 9/10. The question requires expert understanding of neuroprosthetics, sensorimotor integration, and prosthetic design, encouraging deep reflection on how sensory feedback influences the user's psychological and functional experience with RPHs.\n\nThe question should invite critical analysis of how sensory feedback improvements could transform user experience and prosthesis performance, touching on neuroengineering, control strategies, and clinical outcomes.\n\nHence, the planned question will focus on analyzing the role of sensory feedback in enhancing embodiment and intuitive control, encouraging synthesis of neuroprosthetic principles and future technological implications.\n\nThis is meaningful content with rich educational value for domain experts.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does enhanced sensory feedback in robotic prosthetic hands contribute to the embodiment of the prosthesis and improve the intuitive control during grasping tasks?\n\nExplanation: Enhanced sensory feedback provides users with real-time tactile and proprioceptive information from the prosthetic hand, which facilitates the brain's integration of the device into the body schema, leading to a sense of embodiment. This integration reduces cognitive load by allowing users to rely less on visual cues and more on natural sensory inputs, thus enabling more intuitive and precise control during grasping. Without effective sensory feedback, control remains cumbersome and less natural, limiting functional performance and user acceptance.\n\nCorrect Answer: It provides tactile and proprioceptive information that integrates the prosthesis into the user's body schema, enabling intuitive, less visually dependent control and a stronger sense of embodiment during grasping.\n</output_format>",
    "question": "How does enhanced sensory feedback in robotic prosthetic hands contribute to the embodiment of the prosthesis and improve the intuitive control during grasping tasks?",
    "answer": "It provides tactile and proprioceptive information that integrates the prosthesis into the user's body schema, enabling intuitive, less visually dependent control and a stronger sense of embodiment during grasping.",
    "explanation": "Enhanced sensory feedback provides users with real-time tactile and proprioceptive information from the prosthetic hand, which facilitates the brain's integration of the device into the body schema, leading to a sense of embodiment. This integration reduces cognitive load by allowing users to rely less on visual cues and more on natural sensory inputs, thus enabling more intuitive and precise control during grasping. Without effective sensory feedback, control remains cumbersome and less natural, limiting functional performance and user acceptance.",
    "question_token_count": 29,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 6,
    "avg_answer_token_count": 36
  },
  {
    "context": "## 5.1. Sensors for Proprioception\nProprioception is not only fundamental for a dexterous hand prosthesis, enabling vision-free manipulation and multitasking, but is also the key to a properly embodied device (64). Usually, kinematic parameters of the robotic hand and (when available) the force exerted are needed to implement low-level control of the actuators, so they are measured with well-established systems, such as rotary encoders or the motor's current draw.\n\n\n## 5.2. Tactile Sensors\nDespite improvements in sensor miniaturization,computational power,and knowledge of the neurophysiology of somatosensation (tactile sensation and proprioception), the capabilities of sensorized RPHs remain far from those of a natural hand. Overcoming this limitation will require satisfying three conditions: The sensors must match the skin's sensing ability, a sufficient number of sensors must be embedded on the surface of the hand, and it must be possible to reliably read information from them. The first condition can be addressed with current technology, as the resolution of existing force and pressure sensors already matches human skin performance (120). However, fulfilling the second and third conditions is another matter, and we need to push the boundaries of circuit integration in order to create an RPH with many sensors and a way to communicate with them.\n\nThe classical solution of using general-purpose sensors developed separately from the signal conditioning circuit and the subsequent signal processing has shown its limit. Instead, efforts are being made to optimize these devices with prosthetics in mind. For example, borrowing the concept of morphological computation from robotics (121), sensors can be optimized for specific tasks by tuning the features of their mechanical structures accordingly. Indeed, exploiting the low-pass filtering effect of a compliant material or surfaces with specific structures can increase texture discrimination (61, 115). Another example comes from Kim et al. (122), who measured forces using sensors embedded in a soft substrate.\n\n)\n\nContinued\n\n(\n\n| Sensor distribution a                       |            |             |             |             |                  |              |                 |              |\n\n|---------------------------------------------|------------|-------------|-------------|-------------|------------------|--------------|-----------------|--------------|\n\n| Interface                                   | G10 tactor | TIME        | TENS        | TIME        | FINE             | TIME         | Vibrators       | TENS         |\n\n| Electrical stimulation encoding Pulse width | -          | Fixed       | Linear      | Fixed       | Time variant     | Fixed        | -               | Neuromorphic |\n\n| Amplitude                                   | -          | Linear      | Fixed       | Model based | Fixed            | Fixed        | -               | Fixed        |\n\n| Frequency                                   | -          | Fixed       | Fixed       | Model based | Linear           | Neuromorphic | -               | Neuromorphic |\n\n| Mechanical stimulation encoding             | Linear     | -           | -           | -           | -                | -            | Discrete events | -            |\n\n| RPH model                                   | Passive    | IH2 Azzurra | IH2 Azzurra | IH2 Azzurra | SensorHand Speed | IH2 Azzurra  | Various         | bebionic     |\n\n| Reference                                   | 4          | 6           | 60          | 62          | 38               | 61           | 129             | 59           |\n\n| Year                                        | 2011       | 2014        | 2017        | 2018        | 2014             | 2016         | 2016            | 2018         |\n",
    "topic": "Comparative analysis of different electrical and mechanical stimulation encoding strategies for sensory feedback in prosthetic hands and their integration with specific prosthetic models.",
    "response": "<document_analysis>\nThe provided context discusses sensory feedback systems in robotic prosthetic hands (RPHs), focusing particularly on proprioception and tactile sensors. It emphasizes the challenges of replicating natural hand sensory capabilities, highlighting the requirements of sensor resolution, sensor distribution, and reliable data communication. A table summarizes various prosthetic hand models, their sensory interfaces, and the encoding strategies used for electrical and mechanical stimulation feedback.\n\nKey points include:\n- Proprioception sensors (rotary encoders, motor current) are standard for actuator control.\n- Tactile sensors require matching human skin resolution, high sensor density, and effective communication.\n- Morphological computation and mechanical structure tuning improve texture discrimination.\n- Various encoding strategies are used for electrical stimulation feedback: pulse width, amplitude, and frequency modulation with fixed, linear, time-variant, or neuromorphic schemes.\n- Mechanical stimulation encoding is mostly linear or event-based.\n- Different prosthetic models (e.g., IH2 Azzurra, SensorHand Speed, bebionic) adopt different combinations of stimulation encoding, reflecting design trade-offs.\n\nThis context is rich in nuanced information about the interplay between sensor encoding modalities and prosthetic models, offering fertile ground for complex comparative questions.\n\nDifficulty rating: 9/10 due to integration of neurophysiological, engineering, and computational principles in sensory feedback systems for prosthetics.\n\nThe question should prompt analysis of the trade-offs and rationales behind different encoding methods (pulse width, amplitude, frequency, mechanical) and their adaptation to specific prosthetic platforms, encouraging reflection on how these strategies influence the embodiment and performance of prosthetic hands.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the variations in electrical stimulation encoding strategies\u2014specifically differences in pulse width, amplitude, and frequency modulation\u2014and mechanical stimulation encoding approaches correlate with the design and functional objectives of specific robotic prosthetic hand models such as IH2 Azzurra, SensorHand Speed, and bebionic, and what implications do these correlations have for optimizing sensory feedback integration in prosthetic hand technology?\n\nExplanation: Different prosthetic hand models employ distinct combinations of electrical stimulation encoding (pulse width, amplitude, frequency modulation) and mechanical stimulation encoding to balance complexity, reliability, and biomimicry according to their design goals; for instance, IH2 Azzurra uses fixed and model-based modulations to tailor feedback precision, SensorHand Speed employs fixed linear amplitude and frequency to optimize for real-time control, while bebionic integrates neuromorphic encoding for advanced sensory processing. These correlations highlight that encoding strategies must be chosen to align with the prosthesis\u2019s mechanical design, control algorithms, and intended sensory fidelity, directly impacting the effectiveness of sensory feedback and the user\u2019s embodiment experience.\n\nCorrect Answer: Encoding strategies are tailored to each prosthetic model\u2019s design goals\u2014IH2 Azzurra uses fixed and model-based modulations for precise feedback, SensorHand Speed uses fixed linear encoding for real-time control, and bebionic employs neuromorphic encoding for advanced sensory processing\u2014demonstrating that matching encoding methods with prosthetic architecture optimizes sensory feedback integration and embodiment.\n</output_format>",
    "question": "How do the variations in electrical stimulation encoding strategies\u2014specifically differences in pulse width, amplitude, and frequency modulation\u2014and mechanical stimulation encoding approaches correlate with the design and functional objectives of specific robotic prosthetic hand models such as IH2 Azzurra, SensorHand Speed, and bebionic, and what implications do these correlations have for optimizing sensory feedback integration in prosthetic hand technology?",
    "answer": "Encoding strategies are tailored to each prosthetic model\u2019s design goals\u2014IH2 Azzurra uses fixed and model-based modulations for precise feedback, SensorHand Speed uses fixed linear encoding for real-time control, and bebionic employs neuromorphic encoding for advanced sensory processing\u2014demonstrating that matching encoding methods with prosthetic architecture optimizes sensory feedback integration and embodiment.",
    "explanation": "Different prosthetic hand models employ distinct combinations of electrical stimulation encoding (pulse width, amplitude, frequency modulation) and mechanical stimulation encoding to balance complexity, reliability, and biomimicry according to their design goals; for instance, IH2 Azzurra uses fixed and model-based modulations to tailor feedback precision, SensorHand Speed employs fixed linear amplitude and frequency to optimize for real-time control, while bebionic integrates neuromorphic encoding for advanced sensory processing. These correlations highlight that encoding strategies must be chosen to align with the prosthesis\u2019s mechanical design, control algorithms, and intended sensory fidelity, directly impacting the effectiveness of sensory feedback and the user\u2019s embodiment experience.",
    "question_token_count": 76,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 72
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "The role, working principles, and integration challenges of innovative actuation systems such as McKibben pneumatic muscles, granular jamming, and electro-conjugate fluids in soft robotics.",
    "response": "<document_analysis>\nThe context discusses the emerging trend of flexible, soft robotic systems as alternatives to traditional rigid robotic architectures, focusing on their advantages in safe human-robot interaction and adaptability. It highlights specific innovative actuation technologies\u2014McKibben pneumatic muscles, granular jamming, and electro-conjugate fluids\u2014that are closely associated with soft robotic devices. These actuation mechanisms represent novel methods to achieve movement and force generation in soft robots, differing fundamentally from conventional rigid actuators. The text also emphasizes that these technologies are in early development stages, requiring significant integration efforts to become viable for portable applications. The passage implicitly suggests that the working principles of these actuators leverage compliance and novel physical properties (e.g., pneumatic inflation, particle jamming, electrohydrodynamic effects) to enable soft manipulation, but their incorporation into compact, efficient, and sensorized devices remains a major challenge. The table and surrounding text add context on maturity levels of related technologies but focus less on actuation details.\n\nThe question should probe an expert's understanding of these innovative actuators\u2019 mechanical principles, their advantages for soft robotic designs, and the integration hurdles (such as embedding sensors, ensuring safety, achieving portability). It should stimulate reflection on why these actuators are promising yet challenging, encouraging synthesis of soft robotics fundamentals with actuator technology.\n\nDifficulty is rated 9/10 due to the need for in-depth knowledge of soft actuator physics, robotics integration challenges, and current research status.\n\nThe question is planned to elicit explanation of the fundamental working principles of these actuation methods, how they contribute to the compliant behavior of soft robots, and what technical barriers exist in implementing them in portable, sensor-rich prosthetic hands or devices.\n\nThis question will encourage experts to critically engage with the cutting-edge actuation mechanisms, their role in advancing soft robotic systems, and the technical integration complexities that must be overcome for practical deployment.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do McKibben pneumatic muscles, granular jamming, and electro-conjugate fluid actuation mechanisms fundamentally enable compliance and adaptability in soft robotic systems, and what are the principal challenges in integrating these actuators into portable, sensorized soft robotic prostheses?\n\nExplanation: McKibben pneumatic muscles use pressurized air to contract like biological muscles, enabling smooth and compliant motion; granular jamming stiffens or softens structures by changing particle packing states, allowing variable rigidity; electro-conjugate fluids generate flow under electric fields to produce soft actuation. These mechanisms intrinsically provide compliance crucial for safe human-robot interaction. However, integrating them into portable prostheses demands overcoming challenges like miniaturization, reliable and efficient power supply, embedding robust sensing for feedback and control, and ensuring overall device safety and durability.\n\nCorrect Answer: They enable compliance through fluidic or particulate-based actuation that mimics biological flexibility, but integration challenges include miniaturization, power efficiency, sensor embedding, and maintaining safety in portable devices.\n</output_format>",
    "question": "How do McKibben pneumatic muscles, granular jamming, and electro-conjugate fluid actuation mechanisms fundamentally enable compliance and adaptability in soft robotic systems, and what are the principal challenges in integrating these actuators into portable, sensorized soft robotic prostheses?",
    "answer": "They enable compliance through fluidic or particulate-based actuation that mimics biological flexibility, but integration challenges include miniaturization, power efficiency, sensor embedding, and maintaining safety in portable devices.",
    "explanation": "McKibben pneumatic muscles use pressurized air to contract like biological muscles, enabling smooth and compliant motion; granular jamming stiffens or softens structures by changing particle packing states, allowing variable rigidity; electro-conjugate fluids generate flow under electric fields to produce soft actuation. These mechanisms intrinsically provide compliance crucial for safe human-robot interaction. However, integrating them into portable prostheses demands overcoming challenges like miniaturization, reliable and efficient power supply, embedding robust sensing for feedback and control, and ensuring overall device safety and durability.",
    "question_token_count": 53,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 4,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 39
  },
  {
    "context": "## DISCLOSURE STATEMENT\nS.M. holds shares in SensArs, which aims to develop bionic limbs for amputees.\n\n\n## ACKNOWLEDGMENTS\nThe authors would like to thank Iason Batzianoulis for his valuable help on robotic hand control. This review was partly funded by the Swiss National Science Foundation through the National Centre of Competence in Research (NCCR) Robotics, the CHRONOS project, the Wyss Center for Bio and Neuroengineering, and the Bertarelli Foundation.\n\n\n## LITERATURE CITED\n- 1. Piazza C, Grioli G, Catalano MG, Bicchi A. 2019. A century of robotic hands. Annu. Rev. Control Robot. Auton. Syst. 2:1-32\n\n- 2. Castiello U. 2005. The neuroscience of grasping. Nat. Rev. Neurosci. 6:726-36\n\n- 3. Bicchi A. 2000. Hands for dexterous manipulation and robust grasping: a difficult road toward simplicity. IEEE Trans. Robot. Autom. 16:652-62\n\n- 4. Marasco PD, Kim K, Colgate JE, Peshkin MA, Kuiken TA. 2011. Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees. Brain 134:747-58\n\n- 5. Ehrsson HH, Rosen B, Stockselius A, Ragno C, Kohler P, Lundborg G. 2008. Upper limb amputees can be induced to experience a rubber hand as their own. Brain 131:3443-52\n\n- 6. Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, et al. 2014. Restoring natural sensory feedback in real-time bidirectional hand prostheses. Sci. Transl. Med. 6:222ra19\n\n- 7. Kyberd PJ, Hill W. 2011. Survey of upper limb prosthesis users in Sweden, the United Kingdom and Canada. Prosthet. Orthot. Int. 35:234-41\n\n- 8. Dubernard JM, Owen E, Herzberg G, Lanzetta M, Martin X, et al. 1999. Human hand allograft: report on first 6 months. Lancet 353:1315-20\n\n- 9. Piazza C, Catalano MG, Godfrey SG, Rossi M, Grioli G, et al. 2017. The SoftHand Pro-H. IEEE Robot. Autom. Mag. 24(4):87-101\n\n- 10. Smit G, Plettenburg DH, Van Der Helm FCT. 2015. The lightweight Delft Cylinder hand: first multiarticulating hand that meets the basic user requirements. IEEE Trans. Neural Syst. Rehabil. Eng. 23:431-40\n\n- 11. Baril M, Lalibert\u00e9 T, Gosselin C, Routhier F. 2013. On the design of a mechanically programmable underactuated anthropomorphic prosthetic gripper. J. Mech. Des. 135:121008\n\n- 12. Smit G, Plettenburg DH. 2010. Efficiency of voluntary closing hand and hook prostheses. Prosthet. Orthot. Int. 34:411-27\n\n- 13. Biddiss E, Chau T. 2007. Upper limb prosthesis use and abandonment: a survey of the last 25 years. Prosthet. Orthot. Int. 31:236-57\n\n- 14. Lotti F, Tiezzi P, Vassura G, Biagiotti L, Palli G, Melchiorri C. 2005. Development of UB Hand 3: early results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 4488-93. Piscataway, NJ: IEEE\n\n- 15. Honda Y, Miyazaki F, Nishikawa A. 2010. Control of pneumatic five-fingered robot hand using antagonistic muscle ratio and antagonistic muscle activity. In 2010 3rd IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics , pp. 337-42. Piscataway, NJ: IEEE\n\n- 16. Cordella F, Ciancio AL, Sacchetti R, Davalli A, Cutti AG, et al. 2016. Literature review on needs of upper limb prosthesis users. Front. Neurosci. 10:209\n\n- 17. Melchiorri C, Palli G, Berselli G, Vassura G. 2013. Development of the UB Hand IV: overview of design solutions and enabling technologies. IEEE Robot. Autom. Mag. 20(3):72-81\n\n- 18. Pfeifer R, Gomez G. 2009. Morphological computation - connecting brain, body, and environment. In Creating Brain-Like Intelligence , ed. B Sendhoff, E K\u00f6rner, O Sporns, H Ritter, K Doya, pp. 66-83. Berlin: Springer\n\n- 19. Jing X, Yong X, Jiang Y, Li G, Yokoi H. 2019. Anthropomorphic prosthetic hand with combination of light weight and diversiform motions. Appl. Sci. 9:4203\n\n- 20. Mohammadi A, Lavranos J, Zhou H, Mutlu R, Alici G, et al. 2020. A practical 3D-printed soft robotic prosthetic hand with multi-articulating capabilities. PLOS ONE 15:e0232766\n\n- 21. Chamara RPDD, Gopura RARC. 2019. An under-actuated mechanism for anthropomorphic robotic prosthetic hand. In 2019 5th International Conference on Control, Automation and Robotics , pp. 162-66. Piscataway, NJ: IEEE\n\n- 22. Pozzobon LA,Da Silva Guerra R, Librelotto GR. 2019. A low-cost, compliant, underactuated prosthetic hand with custom flex sensors for finger bending estimation. In 2019 19th International Conference on Advanced Robotics , pp. 69-74. Piscataway, NJ: IEEE\n\n- 23. Fajardo J, Ferman V, Cardona D, Maldonado G, Lemus A, Rohmer E. 2020. Galileo Hand: an anthropomorphic and affordable upper-limb prosthesis. IEEE Access 8:81365-77\n\n- 24. Abayasiri RAM, Abayasiri RST, Gunawardhana RAGM, Premakumara RMC, Mallikarachchi S, et al. 2020. An under-actuated hand prosthesis with finger abduction and adduction for human like grasps. In 2020 6th International Conference on Control, Automation and Robotics , pp. 574-80. Piscataway, NJ: IEEE\n\n- 25. Yong X, Jing X, Wu X, Jiang J, Yokoi H. 2019. Development of an adaptive prosthetic hand. In 2019 IEEE International Conference on Robotics and Biomimetics , pp. 2800-5. Piscataway, NJ: IEEE\n\n- 26. Weiner P, Starke J, Hundhausen F, Beil J, Asfour T. 2018. The KIT prosthetic hand: design and control. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 3328-34. Piscataway, NJ: IEEE\n\n- 27. Nemoto Y, Ogawa K, Yoshikawa M. 2020. F3Hand II: a flexible five-fingered prosthetic hand using curved pneumatic artificial muscles. In 2020 IEEE/SICE International Symposium on System Integration , pp. 99-104. Piscataway, NJ: IEEE\n\n- 28. Controzzi M, Cipriani C, Carrozza MC. 2008. Mechatronic design of a transradial cybernetic hand. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 576-81. Piscataway, NJ: IEEE\n\n- 29. Trivedi D, Rahn CD, Kier WM, Walker ID. 2008. Soft robotics: biological inspiration, state of the art, and future research. Appl. Bionics Biomech. 5:520417\n\n- 30. Hirose S, Ma S. 1991. Coupled tendon-driven multijoint manipulator. In 1991 IEEE International Conference on Robotics and Automation , pp. 1268-75. Piscataway, NJ: IEEE\n\n- 31. Carrozza MC, Cappiello G, Stellin G, Zaccone F, Vecchi F, et al. 2005. A cosmetic prosthetic hand with tendon driven under-actuated mechanism and compliant joints: ongoing research and preliminary results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 2661-66. Piscataway, NJ: IEEE\n\n- 32. Godfrey SB, Zhao KD, Theuer A, Catalano MG, Bianchi M, et al. 2018. The SoftHand Pro: functional evaluation of a novel, flexible, and robust myoelectric prosthesis. PLOS ONE 13:13e0205653\n\n- 33. Amend J, Lipson H. 2017. The JamHand: dexterous manipulation with minimal actuation. Soft Robot . 4:70-80\n\n- 34. Yamaguchi A, Takemura K, Yokota S, Edamura K. 2011. A robot hand using electro-conjugate fluid. In 2011 IEEE International Conference on Robotics and Automation , pp. 5923-28. Piscataway, NJ: IEEE\n\n- 35. Zhao H, O'Brien K, Li S, Shepherd RF. 2016. Optoelectronically innervated soft prosthetic hand via stretchable optical waveguides. Sci. Robot. 1:eaai7529\n\n- 36. Yoshida K, Bertram MJ, Cox TGH, Riso RR. 2017. Peripheral nerve recording electrodes and techniques. In Neuroprosthetics: Theory and Practice , ed. K Yoshida, MJ Bertram, TG Hunter Cox, RR Riso, pp. 377-466. Singapore: World Sci.\n\n- 37. Navarro X,Valderrama E,Stieglitz T,Sch\u00fcttler M.2001.Selective fascicular stimulation of the rat sciatic nerve with multipolar polyimide cuff electrodes. Restor. Neurol. Neurosci. 18:9-21\n\n- 38. Tan DW, Schiefer MA, Keith MW, Anderson JR, Tyler J, Tyler DJ. 2014. A neural interface provides long-term stable natural touch perception. Sci. Transl. Med. 6:257ra138\n\n- 39. Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, et al. 2020. A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees. Sci. Transl. Med. 12:eaay2857\n\n- 40. Raspopovic S, Cimolato A, Panarese A, Vallone F, del Valle J, et al. 2020. Neural signal recording and processing in somatic neuroprosthetic applications. A review. J. Neurosci. Methods 337:108653\n\n- 41. Navarro X,Krueger TB,Lago N,Micera S,Stieglitz T,Dario P.2005.A critical review of interfaces with the peripheral nervous system for the control of neuroprostheses and hybrid bionic systems. J. Peripher. Nerv. Syst. 258:229-58\n\n- 42. Boretius T, Badia J, Pascual-Font A, Schuettler M, Navarro X, et al. 2010. A transverse intrafascicular multichannel electrode (TIME) to interface with the peripheral nerve. Biosens. Bioelectron. 26:62-69\n\n- 43. Yoshida K, Pellinen D, Pivin D, Rousche P, Kipke D. 2000. Development of the thin-film longitudinal intra-fascicular electrode. In Proceedings of the 5th Annual Conference of the International Functional Electrical Stimulation Society , pp. 279-84. Graz, Austria: Int. Funct. Electr. Stimul. Soc.\n\n- 44. Badia J, Boretius T, Andreu D, Azevedo-Coste C, Stieglitz T, Navarro X. 2011. Comparative analysis of transverse intrafascicular multichannel, longitudinal intrafascicular and multipolar cuff electrodes for the selective stimulation of nerve fascicles. J. Neural Eng. 8:036023\n\n- 45. Howell B, Grill WM. 2015. Design of electrodes for stimulation and recording. In Implantable Neuroprostheses for Restoring Function , ed. K Kilgore, pp. 59-93. Amsterdam: Elsevier\n\n- 46. Cui X, Wiler J, Dzaman M, Altschuler RA, Martin DC. 2003. In vivo studies of polypyrrole/peptide coated neural probes. Biomaterials 24:777-87\n\n- 47. Kennedy PR, Bakay RAE, Sharpe SM. 1992. Behavioral correlates of action potentials recorded chronically inside the cone electrode. Neuroreport 3:605-8\n\n- 48. Lacour SP, Courtine G, Guck J. 2016. Materials and technologies for soft implantable neuroprostheses. Nat. Rev. Mater. 1:16063\n\n- 49. Kipke DR. 2004. Implantable neural probe systems for cortical neuroprostheses. In 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5344-47. Piscataway, NJ: IEEE\n\n- 50. Merletti R, Holobar A, Farina D. 2008. Analysis of motor units with high-density surface electromyography. J. Electromyogr. Kinesiol. 18:879-90\n\n- 51. Smith LH, Hargrove LJ. 2013. Comparison of surface and intramuscular EMG pattern recognition for simultaneous wrist/hand motion classification. In 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4223-6. Piscataway, NJ: IEEE\n\n- 52. Farrell TR, Weir RF. 2008. A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control. IEEE Trans. Biomed. Eng. 55:2198-211\n\n- 53. Cracchiolo M, Valle G, Petrini F, Strauss I, Granata G, et al. 2020. Decoding of grasping tasks from intraneural recordings in trans-radial amputee. J. Neural Eng. 17:026034\n\n- 54. Wendelken S, Page DM, Davis T, Wark HAC, Kluger DT, et al. 2017. Restoration of motor control and proprioceptive and cutaneous sensation in humans with prior upper-limb amputation via multiple Utah Slanted Electrode Arrays (USEAs) implanted in residual peripheral arm nerves. J. Neuroeng. Rehabil. 14:121\n\n- 55. Cipriani C, Dalonzo M, Carrozza MC. 2012. A miniature vibrotactile sensory substitution device for multifingered hand prosthetics. IEEE Trans. Biomed. Eng. 59:400-8\n\n- 56. Chen B, Feng Y, Wang Q. 2016. Combining vibrotactile feedback with volitional myoelectric control for robotic transtibial prostheses. Front. Neurorobot. 10:8\n\n- 57. Antfolk C, D'Alonzo M, Controzzi M, Lundborg G, Rosen B, et al. 2013. Artificial redirection of sensation from prosthetic fingers to the phantom hand map on transradial amputees: vibrotactile versus mechanotactile sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 21:112-20\n\n- 58. Gonzalez J, Soma H, Sekine M, Yu W. 2012. Psycho-physiological assessment of a prosthetic hand sensory feedback system based on an auditory display: a preliminary study. J. Neuroeng. Rehabil. 9:33\n\n- 59. Osborn L, Betthauser J, Kaliki R, Thakor N. 2018. T argeted transcutaneous electrical nerve stimulation for phantom limb sensory feedback. In 2017 IEEE Biomedical Circuits and Systems Conference . Piscataway, NJ: IEEE. https://doi.org/10.1109/BIOCAS.2017.8325200\n\n- 60. D'Anna E, Petrini FM, Artoni F, Popovic I, Simani\u00b4 c I, et al. 2017. A somatotopic bidirectional hand prosthesis with transcutaneous electrical nerve stimulation based sensory feedback. Sci. Rep. 7:10930\n\n- 61. Oddo CM, Raspopovic S, Artoni F, Mazzoni A, Spigler G, et al. 2016. Intraneural stimulation elicits discrimination of textural features by artificial fingertip in intact and amputee humans. eLife 5:e09148\n\n- 62. Valle G, Mazzoni A, Iberite F, D'Anna E, Strauss I, et al. 2018. Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis. Neuron 100:37-45.e7\n\n- 63. Valle G, D'Anna E, Strauss I, Clemente F, Granata G, et al. 2020. Hand control with invasive feedback is not impaired by increased cognitive load. Front. Bioeng. Biotechnol. 8:287\n\n- 64. D'Anna E, Valle G, Mazzoni A, Strauss I, Iberite F, et al. 2019. A closed-loop hand prosthesis with simultaneous intraneural tactile and position feedback. Sci. Robot. 4:eaau8892\n\n- 65. Shokur S, Gallo S, Moioli RC, Donati ARC, Morya E, et al. 2016. Assimilation of virtual legs and perception of floor texture by complete paraplegic patients receiving artificial tactile feedback. Sci. Rep. 6:32293\n\n- 66. Geethanjali P . 2016. Myoelectric control of prosthetic hands: state-of-the-art review. Med. Devices Evid. Res. 9:247-55\n\n- 67. Farina D, Jiang N, Rehbaum H, Holobar A, Graimann B, et al. 2014. The extraction of neural information from the surface EMG for the control of upper-limb prostheses: emerging avenues and challenges. IEEE Trans. Neural Syst. Rehabil. Eng. 22:797-809\n\n- 68. Ferguson S, Dunlop GR. 2002. Grasp recognition from myoelectric signals. In Proceedings of the Australasian Conference on Robotics and Automation , ed. W Friedrich, P Lim, pp. 83-87. Sydney: Aust. Robot. Autom. Assoc.\n\n- 69. Martelloni C, Carpaneto J, Micera S. 2008. Classification of upper arm EMG signals during objectspecific grasp. In 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5061-64. Piscataway, NJ: IEEE\n\n- 70. Kakoty NM, Hazarika SM. 2011. Recognition of grasp types through principal components of DWT based EMG features. In 2011 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/ICORR.2011.5975398\n\n- 71. Castellini C, Van Der Smagt P . 2009. Surface EMG in advanced hand prosthetics. Biol. Cybern. 100:35-47\n\n- 72. Atzori M, Cognolato M, M\u00fcller H. 2016. Deep learning with convolutional neural networks applied to electromyography data: a resource for the classification of movements for prosthetic hands. Front. Neurorobot. 10:9\n\n- 73. Tenore FVG, Ramos A, Fahmy A, Acharya S, Etienne-Cummings R, Thakor NV. 2009. Decoding of individuated finger movements using surface electromyography. IEEE Trans. Biomed. Eng. 56:1427-34\n\n- 74. Bhattachargee CK, Sikder N, Hasan MT, Nahid A. 2019. Finger movement classification based on statistical and frequency features extracted from surface EMG signals. In 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering . Piscataway, NJ: IEEE. https://doi.org/10.1109/IC4ME247184.2019.9036671\n\n- 75. Bhagwat S,Mukherji P.2020.Electromyogram (EMG) based fingers movement recognition using sparse filtering of wavelet packet coefficients. S\u00af adhan\u00af a 45:3\n\n- 76. Muceli S, Farina D. 2012. Simultaneous and proportional estimation of hand kinematics from EMG during mirrored movements at multiple degrees-of-freedom. IEEE Trans. Neural Syst. Rehabil. Eng. 20:37178\n\n- 77. Jiang N, Vest-Nielsen JL, Muceli S, Farina D. 2012. EMG-based simultaneous and proportional estimation of wrist/hand kinematics in uni-lateral trans-radial amputees. J. Neuroeng. Rehabil. 9:42\n\n- 78. Hioki M, Kawasaki H. 2012. Estimation of finger joint angles from sEMG using a neural network including time delay factor and recurrent structure. ISRN Rehabil . 2012:604314\n\n- 79. Zhuang KZ,Sommer N,Mendez V,Aryan S,Formento E,et al.2019.Shared human-robot proportional control of a dexterous myoelectric prosthesis. Nat. Mach. Intell. 1:400-11\n\n- 80. Mussa-Ivaldi FA, Casadio M, Danziger ZC, Mosier KM, Scheidt RA. 2011. Sensory motor remapping of space in human-machine interfaces. Prog. Brain Res. 191:45-64\n\n- 81. Dyson M, Barnes J, Nazarpour K. 2018. Myoelectric control with abstract decoders. J. Neural Eng. 15:056003\n\n- 82. Dyson M, Dupan S, Jones H, Nazarpour K. 2020. Learning, generalization, and scalability of abstract myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:1539-47\n\n- 83. Daley H,Englehart K,Hargrove L,Kuruganti U.2012.High density electromyography data of normally limbed and transradial amputee subjects for multifunction prosthetic control. J. Electromyogr. Kinesiol. 22:478-84\n\n- 84. Hargrove L,Englehart K,Hudgins B.2006.The effect of electrode displacements on pattern recognition based myoelectric control. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 2203-6. Piscataway, NJ: IEEE\n\n- 85. Boschmann A, Platzner M. 2014. T owards robust HD EMG pattern recognition: reducing electrode displacement effect using structural similarity. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4547-50. Piscataway, NJ: IEEE\n\n- 86. Stango A, Negro F, Farina D. 2015. Spatial correlation of high density EMG signals provides features robust to electrode number and shift in pattern recognition for myocontrol. IEEE Trans. Neural Syst. Rehabil. Eng. 23:189-98\n\n- 87. Farina D, Holobar A, Merletti R, Enoka RM. 2010. Decoding the neural drive to muscles from the surface electromyogram. Clin. Neurophysiol. 121:1616-23\n\n- 88. Kapelner T, Negro F, Aszmann OC, Farina D. 2018. Decoding motor unit activity from forearm muscles: perspectives for myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 26:244-51\n\n- 89. Dai C, Hu X. 2020. Finger joint angle estimation based on motoneuron discharge activities. IEEE J. Biomed. Heal. Inform. 24:760-67\n\n- 90. Hu Y, Wong Y, Wei W, Du Y, Kankanhalli M, Geng W. 2018. A novel attention-based hybrid CNNRNNarchitecture for sEMG-based gesture recognition. PLOS ONE 13:e0206049\n\n- 91. Olsson AE, Sager P, Andersson E, Bj\u00f6rkman A, Male\u0161evi\u00b4 c N, Antfolk C. 2019. Extraction of multilabelled movement information from the raw HD-sEMG image with time-domain depth. Sci. Rep. 9:7244\n\n- 92. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. Regression convolutional neural network for improved simultaneous EMG control. J. Neural Eng. 16:036015\n\n- 93. Xia P, Hu J, Peng Y. 2018. EMG-based estimation of limb movement using deep learning with recurrent convolutional neural networks. Artif. Organs 42:E67-77\n\n- 94. Alom MZ, Taha TM, Yakopcic C, Westberg S, Sidike P, et al. 2018. The history began from AlexNet: a comprehensive survey on deep learning approaches. arXiv:1803.01164 [cs.CV]\n\n- 95. Patricia N, Caputo B. 2014. Learning to learn, from transfer learning to domain adaptation: a unifying perspective. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , pp. 1442-49. Piscataway, NJ: IEEE\n\n- 96. Tommasi T, Orabona F, Castellini C, Caputo B. 2013. Improving control of dexterous hand prostheses using adaptive learning. IEEE Trans. Robot. 29:207-19\n\n- 97. C\u00f4t\u00e9-Allard U, Fall CL, Drouin A, Campeau-Lecours A, Gosselin C, et al. 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans. Neural Syst. Rehabil. Eng. 27:760-71\n\n- 98. Du Y, Jin W, Wei W, Hu Y, Geng W. 2017. Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation. Sensors 17:6-9\n\n- 99. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:370-79\n\n- 100. Phinyomark A, Scheme E. 2018. EMG pattern recognition in the era of big data and deep learning. Big Data Cogn. Comput. 2:21\n\n- 101. Khamparia A, Singh KM. 2019. A systematic review on deep learning architectures and applications. Expert Syst . 36:e12400\n\n- 102. Biddiss E, Chau T. 2007. Upper-limb prosthetics: critical factors in device abandonment. Am. J. Phys. Med. Rehabil. 86:977-87\n\n- 103. Do\u0161en S, Cipriani C, Kosti\u00b4 c M, Controzzi M, Carrozza MC, Popovi\u02c7 c DB. 2010. Cognitive vision system for control of dexterous prosthetic hands: experimental evaluation. J. Neuroeng. Rehabil. 7:42\n\n- 104. Light CM, Chappell PH, Hudgins B, Engelhart K. 2002. Intelligent multifunction myoelectric control of hand prostheses. J. Med. Eng. Technol. 26:139-46\n\n- 105. Fani S, Bianchi M, Jain S, Neto JSP, Boege S, et al. 2016. Assessment of myoelectric controller performance and kinematic behavior of a novel soft synergy-inspired robotic hand for prosthetic applications. Front. Neurorobot. 10:11\n\n- 106. Smith LH, Kuiken TA, Hargrove LJ. 2014. Real-time simultaneous and proportional myoelectric control using intramuscular EMG. J. Neural Eng. 11:066013\n\n- 107. Pasquina PF, Evangelista M, Carvalho AJ, Lockhart J, Griffin S, et al. 2015. First-in-man demonstration of a fully implanted myoelectric sensors system to control an advanced electromechanical prosthetic hand. J. Neurosci. Methods 244:85-93\n\n- 108. Zia ur Rehman M, Gilani S, Waris A, Niazi I, Slabaugh G, et al. 2018. Stacked sparse autoencoders for EMG-based classification of hand motions: a comparative multi day analyses between surface and intramuscular EMG. Appl. Sci. 8:1126\n\n- 109. Kamavuako EN, Scheme EJ, Englehart KB. 2014. Combined surface and intramuscular EMG for improved real-time myoelectric control performance. Biomed. Signal. Process. Control 10:102-7\n\n- 110. Dantas H, Warren DJ, Wendelken SM, Davis TS, Clark GA, Mathews VJ. 2019. Deep learning movement intent decoders trained with dataset aggregation for prosthetic limb control. IEEE Trans. Biomed. Eng. 66:3192-203\n\n- 111. Petrini FM, Mazzoni A, Rigosa J, Giambattistelli F, Granata G, et al. 2019. Microneurography as a tool to develop decoding algorithms for peripheral neuro-controlled hand prostheses. BioMed. Eng. OnLine 18:44\n\n- 112. Rossini PM, Micera S, Benvenuto A, Carpaneto J, Cavallo G, et al. 2010. Double nerve intraneural interface implant on a human amputee for robotic hand control. Clin. Neurophysiol. 121:777-83\n\n- 113. Davis TS, Wark HAC, Hutchinson DT, Warren DJ, O'Neill K, et al. 2016. Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves. J. Neural Eng. 13:036001\n\n- 114. Petrini FM, Valle G, Strauss I, Granata G, Di Iorio R, et al. 2019. Six-month assessment of a hand prosthesis with intraneural tactile feedback. Ann. Neurol. 85:137-54\n\n- 115. Mazzoni A, Oddo CM, Valle G, Camboni D, Strauss I, et al. 2020. Morphological neural computation restores discrimination of naturalistic textures in trans-radial amputees. Sci. Rep. 10:527\n\n- 116. Graczyk EL, Schiefer MA, Saal HP, Delhaye BP, Bensmaia SJ, Tyler DJ. 2016. The neural basis of perceived intensity in natural and artificial touch. Sci. Transl. Med. 8:362ra142\n\n- 117. Kogler V, Nguyen TAK, Digiovanna J, Micera S. 2011. Recording vestibular evoked potentials induced by electrical stimulation of the horizontal semicircular canal in guinea pig. In 2011 5th International IEEE/EMBS Conference on Neural Engineering , pp. 261-64. Piscataway, NJ: IEEE\n\n- 118. Micera S, Carpaneto J, Raspopovic S. 2010. Control of hand prostheses using peripheral information. IEEE Rev. Biomed. Eng. 3:48-68\n\n- 119. Englehart K,Hudgins B.2003.A robust,real-time control scheme for multifunction myoelectric control. IEEE Trans. Biomed. Eng. 50:848-54\n\n- 120. Park M, Bok BG, Ahn JH, Kim MS. 2018. Recent advances in tactile sensing technology. Micromachines 9:321\n\n- 121. Pfeifer R, Iida F, G\u00f3mez G. 2006. Morphological computation for adaptive behavior and cognition. Int. Congr. Ser. 1291:22-9\n\n- 122. Kim Y, Chortos A, Xu W, Liu Y, Oh JY, et al. 2018. A bioinspired flexible organic artificial afferent nerve. Science 360:998-1003\n\n- 123. WuJ, Jia QS, Johansson KH, Shi L. 2013. Event-based sensor data scheduling: trade-off between communication rate and estimation quality. IEEE Trans. Autom. Control 58:1041-6\n\n- 124. Bartolozzi C, Ros PM, Diotalevi F, Jamali N, Natale L, et al. 2017. Event-driven encoding of off-theshelf tactile sensors for compression and latency optimisation for robotic skin. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 166-73. Piscataway, NJ: IEEE\n\n- 125. Lee WW,Tan YJ,Yao H,Li S,See HH,et al. 2019. A neuro-inspired artificial peripheral nervous system for scalable electronic skins. Sci. Robot. 4:eaax2198\n\n- 126. Antfolk C, D'Alonzo M, Ros\u00e9n B, Lundborg G, Sebelius F, Cipriani C. 2013. Sensory feedback in upper limb prosthetics. Expert Rev. Med. Devices 10:45-54\n\n- 127. Mann RW, Reimers SD. 1970. Kinesthetic sensing for the EMG controlled 'Boston Arm.' IEEE Trans. Man-Mach. Syst. 11:110-15\n\n- 128. Patterson PE, Katz JA. 1992. Design and evaluation of a sensory feedback system that provides grasping pressure in a myoelectric hand. J. Rehabil. Res. Dev. 29:1-8\n\n- 129. Clemente F, D'Alonzo M, Controzzi M, Edin BB, Cipriani C. 2016. Non-invasive, temporally discrete feedback of object contact and release improves grasp control of closed-loop myoelectric transradial prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 24:1314-22\n\n- 130. D'Alonzo M, Clemente F, Cipriani C. 2015. Vibrotactile stimulation promotes embodiment of an alien hand in amputees with phantom sensations. IEEE Trans. Neural Syst. Rehabil. Eng. 23:450-57\n\n- 131. Stephens-Fripp B, Alici G, Mutlu R. 2018. A review of non-invasive sensory feedback methods for transradial prosthetic hands. IEEE Access 6:6878-99\n\n- 132. Dosen S, Markovic M, Strbac M, Belic M, Kojic V, et al. 2017. Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 25:183-95\n\n- 133. Geng B,Dong J,Jensen W,Dosen S,Farina D,Kamavuako EN.2018.Psychophysical evaluation of subdermal electrical stimulation in relation to prosthesis sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 26:709-15\n\n- 134. Dong J, Geng B, Niazi IK, Amjad I, Dosen S, et al. 2020. The variability of psychophysical parameters following surface and subdermal stimulation: a multiday study in amputees. IEEE Trans. Neural Syst. Rehabil. Eng. 28:174-80\n\n- 135. Flesher SN, Downey JE, Weiss JM, Hughes CL, Herrera AJ, et al. 2019. Restored tactile sensation improves neuroprosthetic arm control. bioRxiv 653428. https://doi.org/10.1101/653428\n\n- 136. Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ. 2018. Home use of a neural-connected sensory prosthesis provides the functional and psychosocial experience of having a hand again. Sci. Rep. 8:9866\n\n|   137. | George JA, Page DM, Davis TS, Duncan CC, Hutchinson T, et al. 2020. Long-term performance of Utah Slanted Electrode Arrays and intramuscular electromyographic leads implanted chronically in human arm nerves and muscles. bioRxiv 2020.03.30.016683. https://doi.org/10.1101/2020.03.30. 016683                                                      |\n\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n|    138 | Ortiz-Catalan M, Mastinu E, Sassu P, Aszmann O, Br\u00e5nemark R. 2020. Self-contained neuromuscu- loskeletal arm prostheses. N. Engl. J. Med. 382:1732-38                                                                                                                                                                                                  |\n\n|    139 | George JA, Kluger DT,Davis TS,Wendelken SM,Okorokova EV,et al.2019.Biomimetic sensory feed- back through peripheral nerve stimulation improves dexterous use of a bionic hand. Sci. Robot. 4:eaax2352                                                                                                                                                  |\n\n|    140 | Chandrasekaran S,Nanivadekar AC,McKernan G,Helm ER,Boninger ML,et al.2020.Sensory restora- tion by epidural stimulation of the lateral spinal cord in upper-limb amputees. eLife 9:e54349                                                                                                                                                              |\n\n|    141 | Controzzi M, Clemente F, Barone D, Luciani LB, Pierotti N, et al. 2019. Progress towards the devel- opment of the DeTOP hand prosthesis: a sensorized transradial prosthesis for clinical use. In Converg- ing Clinical and Engineering Research on Neurorehabilitation III , ed. L Masia, S Micera, M Akay, J Pons, pp. 103-6. Cham, Switz.: Springer |\n\n|    142 | Formento E,D'Anna E,Gribi S,Lacour SP,Micera S.2019.A biomimetic electrical stimulation strategy to induce asynchronous stochastic neural activity. J. Neural Eng. 17:046019                                                                                                                                                                           |\n\n|    143 | Sengupta A, Ye Y, Wang R, Liu C, Roy K. 2019. Going deeper in spiking neural networks: VGG and residual architectures. Front Neurosci . 13:95                                                                                                                                                                                                          |\n\n|    144 | Lindner HYN, N\u00e4tterlund BS, Hermansson LMN. 2010. Upper limb prosthetic outcome measures: review and content comparison based on International Classification of Functioning, Disability and Health. Prosthet. Orthot. Int. 34:109-28                                                                                                                  |\n\n|    145 | Hill W, Stavdahl \u00d8, Hermansson LN, Kyberd P, Swanson S, Hubbard S. 2009. Functional outcomes in the WHO-ICF model: establishment of the upper limb prosthetic outcome measures group. J. Prosthet. Orthot. 21:115-19                                                                                                                                   |\n\n|    146 | Hudak PL, Amadio PC, Bombardier C. 1996. Development of an upper extremity outcome measure: the DASH (Disabilities of the Arm, Shoulder, and Head). Am. J. Ind. Med. 29:602-8                                                                                                                                                                          |\n\n|    147 | Beaton DE, Wright JG, Katz JN, Amadio P, Bombardier C, et al. 2005. Development of the Quick- DASH: comparison of three item-reduction approaches. J. Bone Jt. Surg. A 87:1038-46                                                                                                                                                                      |\n\n|    148 | Harper A, Power M, Orley J, Herrman H, Schofield H, et al. 1998. Development of the World Health Organization WHOQOL-BREF quality of life assessment. Psychol. Med. 28:551-58                                                                                                                                                                          |\n\n|    149 | Burckhardt CS, Anderson KL. 2003. The Quality of Life Scale (QOLS): reliability, validity, and utiliza- tion. Health Qual. Life Outcomes 1:60                                                                                                                                                                                                          |\n\n|    150 | Heinemann AW, Bode RK, O'Reilly C. 2003. Development and measurement properties of the Or- thotics and Prosthetics User's Survey (OPUS): a comprehensive set of clinical outcome instruments. Prosthet. Orthot. Int. 27:191-206                                                                                                                        |\n\n|    151 | Lendaro E,Middleton A,Brown S,Ortiz-Catalan M.2020.Out of the clinic, into the home: the in-home use of phantom motor execution aided by machine learning and augmented reality for the treatment of phantom limb pain. J. Pain Res. 13:195-209                                                                                                        |\n\n|    152 | Johansson RS, Flanagan JR. 2009. Coding and use of tactile signals from the fingertips in object manip- ulation tasks. Nat. Rev. Neurosci. 10:345-59                                                                                                                                                                                                   |\n\n|    153 | Taub E, Uswatte G, Pidikiti R. 1999. Constraint-induced movement therapy: a new family of techniques with broad application to physical rehabilitation-a clinical review. J. Rehabil. Res. Dev. 36:237-51                                                                                                                                              |\n\n|    154 | Mathiowetz V, Volland G, Kashman N, Weber K. 1985. Adult norms for the Box and Block T est of manual dexterity. Am. J. Occup. Ther. 39:386-91                                                                                                                                                                                                          |\n\n|    155 | Hebert JS, Lewicke J. 2012. Case report of modified box and blocks test with motion capture to measure prosthetic function. J. Rehabil. Res. Dev. 49:1163-74                                                                                                                                                                                           |\n\n|    156 | Hebert JS, Lewicke J, Williams TR, Vette AH. 2014. Normative data for modified box and blocks test measuring upper-limb function via motion capture. J. Rehabil. Res. Dev. 51:919-31                                                                                                                                                                   |\n\n|    157 | Mathiowetz V, Weber K, Kashman N, Volland G. 1985. Adult norms for the Nine Hole Peg T est of finger dexterity. Occup. Ther. J. Res. 5:24-38                                                                                                                                                                                                           |\n\n- 158. Lambercy O,Fluet MC,Lamers I,Kerkhofs L,Feys P, Gassert R. 2013. Assessment of upper limb motor function in patients with multiple sclerosis using the Virtual Peg Insertion T est: a pilot study. In 2013 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/\n",
    "topic": "Advanced machine learning and deep learning architectures applied to EMG signal classification and regression for simultaneous and proportional prosthetic control.",
    "response": "<document_analysis>\nThe provided context is a comprehensive literature citation list from a scholarly review or meta-analysis on upper limb prosthetic hands and their control technologies, with a strong emphasis on electromyography (EMG)-based control systems. Within this extensive reference list, several citations (notably refs 72, 90, 92, 93, 97, 98, 99, 100, 101, 110) explicitly address advanced machine learning (ML) and deep learning (DL) architectures applied to EMG signal processing for hand prosthetic control. These works cover convolutional neural networks (CNNs), recurrent neural networks (RNNs), hybrid CNN-RNN models, transfer learning, domain adaptation, stacked sparse autoencoders, and deep transfer learning aimed at mitigating issues such as electrode displacement and session-to-session variability. The references also mention challenges like robustness, generalization, and real-time performance in multifunction prosthetic control.\n\nThe central ideas include:\n\n- Application of deep learning architectures (CNN, RNN, hybrid models) for EMG-based gesture classification and movement regression.\n- Use of transfer learning and domain adaptation to improve model robustness across sessions and electrode shifts.\n- The challenge of simultaneous and proportional control for dexterous hand prostheses.\n- Methods to decode complex hand kinematics from EMG signals using advanced ML techniques.\n- The educational value lies in understanding the state-of-the-art ML/DL strategies, their benefits, limitations, and implications for future prosthetic control systems.\n\nImplicit assumptions include that advanced ML/DL can significantly improve prosthetic control accuracy and robustness and that overcoming nonstationarities in EMG data is key for practical deployment.\n\nThe difficulty rating is 9/10 due to the complexity of integrating neurophysiological signal processing with cutting-edge ML/DL architectures, plus the nuance of addressing real-world control challenges.\n\nThe question should challenge a domain expert to synthesize understanding of deep learning architectures, their application to EMG classification/regression, and the implications for simultaneous and proportional control in prosthetics, including challenges like electrode shift and session variability. It should prompt reflection on how these architectures impact functional prosthesis control and what strategies improve robustness and generalization.\n\nThis question will invite critical engagement with both the technical aspects of ML/DL models and their practical translation to prosthetic control, fostering deep insight.\n\nHence, I will formulate a question that probes the expert's grasp on how advanced deep learning architectures and transfer learning approaches address the challenges of EMG-based simultaneous and proportional control for multifunction prosthetic hands, including robustness to electrode shift and session variability.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do advanced deep learning architectures, such as hybrid CNN-RNN models combined with transfer learning techniques, enhance the simultaneous and proportional control of multifunction prosthetic hands from EMG signals, particularly in addressing challenges like electrode displacement and inter-session variability?\n\nExplanation: Hybrid CNN-RNN models leverage CNNs to extract spatial features and RNNs to capture temporal dependencies in EMG signals, enabling more accurate decoding of complex hand movements for simultaneous and proportional control. Transfer learning and domain adaptation techniques improve model robustness by adapting to variations caused by electrode displacement and session-to-session differences without requiring extensive retraining, thereby enhancing generalization and real-time usability in prosthetic control.\n\nCorrect Answer: By combining spatial and temporal feature extraction with transfer learning for domain adaptation, these architectures improve decoding accuracy and robustness against electrode displacement and session variability, enabling reliable simultaneous and proportional prosthetic hand control.\n</output_format>",
    "question": "How do advanced deep learning architectures, such as hybrid CNN-RNN models combined with transfer learning techniques, enhance the simultaneous and proportional control of multifunction prosthetic hands from EMG signals, particularly in addressing challenges like electrode displacement and inter-session variability?",
    "answer": "By combining spatial and temporal feature extraction with transfer learning for domain adaptation, these architectures improve decoding accuracy and robustness against electrode displacement and session variability, enabling reliable simultaneous and proportional prosthetic hand control.",
    "explanation": "Hybrid CNN-RNN models leverage CNNs to extract spatial features and RNNs to capture temporal dependencies in EMG signals, enabling more accurate decoding of complex hand movements for simultaneous and proportional control. Transfer learning and domain adaptation techniques improve model robustness by adapting to variations caused by electrode displacement and session-to-session differences without requiring extensive retraining, thereby enhancing generalization and real-time usability in prosthetic control.",
    "question_token_count": 50,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 39
  },
  {
    "context": "## 5. RESTORING SENSORY FEEDBACK\nSensory information plays a critical role in both the exploration of the external environment and in any manipulation task. When an individual interacts with surrounding objects, tactile sensations are used to infer features such as size, compliance, temperature, and texture, while the same sensations are exploited to handle them properly or use them as tools. From this perspective, aiming to restore afferent sensory channels from a hand prosthesis is a critical step in designing a device that ensures two key aspects: dexterous manipulation and embodiment of the prosthetic device.\n\nThe design of a sensory feedback system that can successfully deliver information relies on three fundamental blocks working together: ( a ) sensor readings, processed by ( ) an encoding b strategy capable of translating meaningful information to the user, through ( ) an interface. Prec vious sections have described the different available interfaces; here, we present the encoding techniques and sensors relevant to the design of modern hand prostheses ( Table 1 ).\n\nSensors mounted on a robotic hand should ideally record the whole spectrum of available human sensations, from both external and internal sources. Indeed, sensory information from the human hand covers both interactions with the external world (tactile perception, thermal perception, and nociception, i.e., perception of pain) and internal perception of the positions of the joints and the length and forces exerted by the muscles, together known as proprioception. Table 2 shows examples of sensor placements on RPHs from recent studies.\n",
    "topic": "The interplay between sensor technology and interface design in achieving effective sensory feedback and its challenges in real-world prosthetic applications.",
    "response": "<document_analysis>\nThe provided context highlights the critical importance of restoring sensory feedback in hand prostheses to enable dexterous manipulation and embodiment. It emphasizes that an effective sensory feedback system depends on three integrated components: sensors that capture relevant sensory data, encoding strategies that translate this data into meaningful user information, and interfaces that deliver the feedback to the user. The context also underscores the complexity of replicating the broad range of human hand sensations, including tactile, thermal, nociceptive, and proprioceptive inputs, which originate from both external and internal sources. This multi-dimensional sensory input presents significant challenges for sensor technology, encoding methods, and interface design to work cohesively in real-world prosthetic applications. The question should therefore probe the complex interplay between these components, focusing on the technical and practical challenges that arise when integrating sensor technology with interface design to restore effective sensory feedback. The difficulty is rated 9/10 due to the need for deep understanding of sensor modalities, encoding, and human-machine interface constraints, as well as the implications for prosthetic embodiment and manipulation.\n\nThe question will encourage critical reflection on how sensor selection and data encoding affect interface efficacy and user experience in real prosthetic use, addressing issues like fidelity, latency, sensor placement, and user perception. This invites synthesis of knowledge across robotics, neuroscience, and human factors engineering, promoting a comprehensive grasp of the challenges in restoring realistic sensory feedback through prostheses.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the technical limitations of sensor modalities and encoding strategies influence the design and effectiveness of user interfaces in delivering realistic and functional sensory feedback in hand prostheses, and what are the primary challenges in achieving seamless integration for naturalistic embodiment and dexterous manipulation in real-world applications?\n\nExplanation: Sensor modalities must capture diverse human sensory inputs accurately, but limitations in sensor sensitivity, range, and placement affect data quality. Encoding strategies must translate complex, multidimensional sensor data into interpretable signals without loss or delay, which is challenging given bandwidth and processing constraints. These factors directly impact interface design, determining how feedback is presented to the user in a way that feels natural and informative. The primary challenges include replicating the full spectrum of tactile, thermal, nociceptive, and proprioceptive sensations, minimizing latency, avoiding sensory overload or ambiguity, and ensuring the feedback integrates seamlessly with the user's perception to enable embodiment and precise manipulation.\n\nCorrect Answer: Sensor and encoding constraints limit data fidelity and timing, complicating interface design and causing challenges in delivering naturalistic, multidimensional feedback essential for embodiment and dexterous prosthetic use.\n</output_format>",
    "question": "How do the technical limitations of sensor modalities and encoding strategies influence the design and effectiveness of user interfaces in delivering realistic and functional sensory feedback in hand prostheses, and what are the primary challenges in achieving seamless integration for naturalistic embodiment and dexterous manipulation in real-world applications?",
    "answer": "Sensor and encoding constraints limit data fidelity and timing, complicating interface design and causing challenges in delivering naturalistic, multidimensional feedback essential for embodiment and dexterous prosthetic use.",
    "explanation": "Sensor modalities must capture diverse human sensory inputs accurately, but limitations in sensor sensitivity, range, and placement affect data quality. Encoding strategies must translate complex, multidimensional sensor data into interpretable signals without loss or delay, which is challenging given bandwidth and processing constraints. These factors directly impact interface design, determining how feedback is presented to the user in a way that feels natural and informative. The primary challenges include replicating the full spectrum of tactile, thermal, nociceptive, and proprioceptive sensations, minimizing latency, avoiding sensory overload or ambiguity, and ensuring the feedback integrates seamlessly with the user's perception to enable embodiment and precise manipulation.",
    "question_token_count": 56,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 36
  },
  {
    "context": "## 4. MOTOR CONTROL\nDespite the advances in techniques for voluntary motor decoding and the increased sophistication of the available RPHs, body-powered prostheses are still the most robust control approach. The mechanism of these devices is based on a cable actuated by movements of the shoulder to control one DOF. The vast majority of commercially available RPHs use simple threshold-based sEMG decoding over a few surface electrodes and also generally control one DOF (66); in some cases, the RPH provides more DOFs, but this comes at the cost of a nonintuitive command scheme. These systems also offer no possibility to control several DOFs at the same time. The current situation is, therefore, increasingly sophisticated RPH mechanics with unchanged control strategies. As such, patients often abandon myoelectric prostheses, in part because the small functional improvement does not justify their price and complexity (13, 67).\n\nHere, we describe recent advances in control strategies in terms of decoding type (classification or continuous control) and functional achievement (e.g., number of DOFs, grasping, or single-finger decoding) and compare them with the classical direct control approach. Section 4.1 details different algorithmic approaches to decode motor functions, with an emphasis on sEMG; Section 4.2 discusses the addition of robotic automation to improve grasp robustness; Section 4.3 compares implanted methods to extract the user's intentions; and finally, Section 4.4 presents a perspective on the broader adoption of these techniques by patients. Table 1 includes the different decoding strategies and their level of maturity.\n",
    "topic": "Critically analyze the trade-offs between control intuitiveness, functional improvement, and system complexity in the design of myoelectric prostheses.",
    "response": "<document_analysis>\nThe provided context discusses the current state and challenges of motor control in myoelectric prostheses, specifically focusing on the trade-offs between control intuitiveness, functional improvement, and system complexity. It highlights that despite advances in robotic prosthetic hands (RPHs) mechanics and voluntary motor decoding techniques, body-powered prostheses remain more robust due to their simplicity. Most commercially available RPHs rely on simple threshold-based sEMG decoding, controlling typically only one degree of freedom (DOF), and attempts to increase DOFs often result in nonintuitive control schemes. This disconnect between increasingly sophisticated mechanics and largely unchanged control strategies leads to limited functional improvements that do not justify the higher price or complexity, causing patient abandonment.\n\nThe text also outlines the scope of the chapter, including detailed descriptions of algorithmic decoding approaches (classification vs. continuous control), robotic automation to enhance grasping, implanted methods for intention extraction, and perspectives on patient adoption. The trade-offs are implicit in the juxtaposition of device complexity, control scheme sophistication, and usability outcomes.\n\nDifficulty rating: 9/10, given the need to understand nuanced engineering, neurophysiological decoding, human factors, and clinical adoption issues. The question targets critical evaluation of competing design priorities, encouraging reflection on why more advanced prosthetic mechanics do not necessarily translate into better patient outcomes due to control challenges.\n\nThe question invites experts to synthesize knowledge about sEMG signal processing, DOF control, user interface design, and cost-benefit considerations in prosthetic technology development. It promotes deeper insight into how these factors interact to affect patient satisfaction and system viability.\n\nHence, the content is meaningful, coherent, and rich for generating a high-level, technical, and reflective question-answer pair that probes expert understanding of prosthetic control trade-offs.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the trade-offs between control intuitiveness, functional improvement in degrees of freedom, and system complexity influence patient adoption and abandonment of myoelectric prostheses?\n\nExplanation: Increasing the number of controllable degrees of freedom in myoelectric prostheses often requires more complex and less intuitive control schemes (e.g., beyond simple threshold-based sEMG decoding), which complicates user operation; this complexity tends to yield only small functional improvements that fail to justify the higher cost and effort, leading many patients to abandon these devices in favor of simpler, more robust body-powered prostheses.\n\nCorrect Answer: More complex, less intuitive control schemes with marginal functional gains increase system complexity and cost, causing patients to prefer simpler, more robust prostheses and often abandon myoelectric devices.\n</output_format>",
    "question": "How do the trade-offs between control intuitiveness, functional improvement in degrees of freedom, and system complexity influence patient adoption and abandonment of myoelectric prostheses?",
    "answer": "More complex, less intuitive control schemes with marginal functional gains increase system complexity and cost, causing patients to prefer simpler, more robust prostheses and often abandon myoelectric devices.",
    "explanation": "Increasing the number of controllable degrees of freedom in myoelectric prostheses often requires more complex and less intuitive control schemes (e.g., beyond simple threshold-based sEMG decoding), which complicates user operation; this complexity tends to yield only small functional improvements that fail to justify the higher cost and effort, leading many patients to abandon these devices in favor of simpler, more robust body-powered prostheses.",
    "question_token_count": 33,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 35
  },
  {
    "context": "## 2.1. Existing Robotic Prosthetic Hands\nNumerous commercially available RPH solutions use underactuated mechanisms ( Supplemental Table 1 ), including the Michelangelo prosthetic hand (Ottobock, Germany), the i-Limb Ultra (\u00d6ssur, Iceland), the bebionic hand (Ottobock), and the VINCENT evolution 3 (Vincent Systems, Germany). Despite remarkable advances, there is still arguably a trade-off between dexterity and weight in these solutions, with companies usually emphasizing one aspect or the other.\n\nMany research groups are currently working on innovative solutions to tackle the dexterity/ weight dilemma (19), such as the use of a monolithic 3D-printed soft material (20) or mechanical solutions to implement finger synergies via clutches (21). For example, Jing et al. (19) proposed an anthropomorphic RPH using only three motors that could achieve 13 grasp types while weighing only approximately 130 g.\n\nThe price of RPHs is an additional limiting factor for broader adoption by patients. With most advanced solutions costing $10,000-20,000, many researchers advocate for cheaper solutions, particularly for emerging countries (e.g., 22).\n\nOpen source RPHs are an exciting alternative to dramatically reduce the cost of development and distribution. One particularly interesting aspect of such hands is simplified maintenance and repairs (using, e.g., 3D printing) that do not rely on specific suppliers. For example, Open\n\nBionics (United Kingdom) commercializes solutions for transradial amputees (e.g., the medically certified Hero Arm) but also provides the source files for some of their designs, and e-NABLE ( https://enablingthefuture.org ) reports 8,000 recipients of their prosthetics, which were built by volunteers around the world. Open source RPHs also enable users to alter the design to meet their unique needs; for example, the Galileo Hand (23) allows easy customization of the types of movements and number of electromyography (EMG) electrodes.\n\nResearchers are also working on better mechanical solutions to improve RPH dexterity. An underactuated hand prosthesis designed by Abayasiri et al. (24) has finger abduction and adduction to enable it to grasp larger objects, and an adaptive prosthetic hand designed by Yong et al. (25) adds DOFs in the palm with movable metacarpals. The Karlsruhe Institute of T echnology (KIT) prosthetic hand (26) has an embedded camera and real-time object recognition, enabling the hand to be preshaped. Pneumatic artificial muscle (27) permits the development of light, compact solutions. Finally, biomimetic actuation is used for muscle-like actuators (15).\n\nIn addition to the hardware aspect, there are also innovations in RPH control and sensorization. Low-level controllers use information about the state of the device and eventually activate the actuation to meet the desired state imposed by the user's intentions. The choice of the state variable has a strong influence on how the device works. Position or speed can be read through encoders of each joint and controlled; these are straightforward approaches that have been used broadly in robotic applications. When the interaction of the hand with the external environment is of interest, more advanced control systems are implemented, such as torque or impedance control. Both approaches measure the force applied by the actuator, controlling it directly in the first case and simulating compliance in the second. Advanced control strategies enable complex manipulation and smoother gestures at the expense of a bulkier mechanical structure and a more complex control system. Therefore, enabling more sophisticated control requires integrated force and position sensors, which have been previously developed mainly to close the robotic control loop (28).\n\nIn summary, low-cost and light hands have flourished over the last few years. The race to simplify designs and reduce costs through 3D printing should not impact the dexterity of RPHs. For now, underactuated mechanisms are the best solution for RPHs and innovative designs based on synergy mechanisms or friction, the latter of which can help increase the number of DOAs without increasing the number of motors.\n",
    "topic": "Explore how embedded intelligence, such as real-time object recognition for preshaping, can augment robotic prosthetic hand performance and usability.",
    "response": "<document_analysis>\nThe context provides a comprehensive overview of current robotic prosthetic hands (RPHs), focusing on the balance between dexterity and weight, cost limitations, underactuation mechanisms, advances in mechanical design, and control strategies. Notably, it mentions the Karlsruhe Institute of Technology (KIT) prosthetic hand, which integrates embedded intelligence through an embedded camera and real-time object recognition to enable preshaping of the hand. This innovation represents a significant step toward augmenting RPH usability and performance by automating part of the grasp preparation process, potentially reducing cognitive load on the user and improving grasp success rates.\n\nThe text also explains the importance of sensor integration and advanced control schemes (torque and impedance control) that facilitate complex, smooth manipulation but require more sophisticated hardware and software. Embedded intelligence, such as real-time object recognition, combines sensing, processing, and control, allowing the prosthesis to anticipate and adapt to objects before contact, thus improving dexterity and naturalness of motion. This introduces implications for usability, cognitive demand, and the trade-offs in mechanical complexity and cost.\n\nDifficulty level is high (around 8-9) because understanding this requires knowledge of robotics, control theory, sensor fusion, and prosthetic design trade-offs. The question encourages reflection on how embedded intelligence systems transform prosthetic hand function beyond mechanical design, touching on integrated sensing, control strategies, and user experience improvements.\n\nThe question is purposeful in that it invites examination of the impact of embedding perception and decision-making capabilities directly within the prosthetic device, a cutting-edge approach that challenges traditional prosthetic control paradigms. It also highlights the balance between technological sophistication and practical usability.\n\nThus, the content is meaningful, coherent, and technically rich, warranting a challenging, insightful question on embedded intelligence's role in robotic prosthetic hand performance and usability.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does embedding real-time object recognition and preshaping capabilities within a robotic prosthetic hand enhance its functional performance and user experience, and what are the trade-offs associated with integrating such embedded intelligence?\n\nExplanation: Embedding real-time object recognition allows the prosthetic hand to autonomously identify objects and preshape its configuration before contact, improving the speed, accuracy, and naturalness of grasps; this reduces the cognitive load on users by automating part of the control process. However, integrating such intelligence requires additional sensors (e.g., cameras), processing power, and more complex control algorithms, which can increase the device's weight, mechanical complexity, energy consumption, and cost, potentially impacting portability and reliability.\n\nCorrect Answer: It enables autonomous grasp preshaping for faster and more natural manipulation, improving usability while introducing increased mechanical complexity, weight, and cost due to added sensors and processing requirements.\n</output_format>",
    "question": "How does embedding real-time object recognition and preshaping capabilities within a robotic prosthetic hand enhance its functional performance and user experience, and what are the trade-offs associated with integrating such embedded intelligence?",
    "answer": "It enables autonomous grasp preshaping for faster and more natural manipulation, improving usability while introducing increased mechanical complexity, weight, and cost due to added sensors and processing requirements.",
    "explanation": "Embedding real-time object recognition allows the prosthetic hand to autonomously identify objects and preshape its configuration before contact, improving the speed, accuracy, and naturalness of grasps; this reduces the cognitive load on users by automating part of the control process. However, integrating such intelligence requires additional sensors (e.g., cameras), processing power, and more complex control algorithms, which can increase the device's weight, mechanical complexity, energy consumption, and cost, potentially impacting portability and reliability.",
    "question_token_count": 40,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 35
  },
  {
    "context": "## DISCLOSURE STATEMENT\nS.M. holds shares in SensArs, which aims to develop bionic limbs for amputees.\n\n\n## ACKNOWLEDGMENTS\nThe authors would like to thank Iason Batzianoulis for his valuable help on robotic hand control. This review was partly funded by the Swiss National Science Foundation through the National Centre of Competence in Research (NCCR) Robotics, the CHRONOS project, the Wyss Center for Bio and Neuroengineering, and the Bertarelli Foundation.\n\n\n## LITERATURE CITED\n- 1. Piazza C, Grioli G, Catalano MG, Bicchi A. 2019. A century of robotic hands. Annu. Rev. Control Robot. Auton. Syst. 2:1-32\n\n- 2. Castiello U. 2005. The neuroscience of grasping. Nat. Rev. Neurosci. 6:726-36\n\n- 3. Bicchi A. 2000. Hands for dexterous manipulation and robust grasping: a difficult road toward simplicity. IEEE Trans. Robot. Autom. 16:652-62\n\n- 4. Marasco PD, Kim K, Colgate JE, Peshkin MA, Kuiken TA. 2011. Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees. Brain 134:747-58\n\n- 5. Ehrsson HH, Rosen B, Stockselius A, Ragno C, Kohler P, Lundborg G. 2008. Upper limb amputees can be induced to experience a rubber hand as their own. Brain 131:3443-52\n\n- 6. Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, et al. 2014. Restoring natural sensory feedback in real-time bidirectional hand prostheses. Sci. Transl. Med. 6:222ra19\n\n- 7. Kyberd PJ, Hill W. 2011. Survey of upper limb prosthesis users in Sweden, the United Kingdom and Canada. Prosthet. Orthot. Int. 35:234-41\n\n- 8. Dubernard JM, Owen E, Herzberg G, Lanzetta M, Martin X, et al. 1999. Human hand allograft: report on first 6 months. Lancet 353:1315-20\n\n- 9. Piazza C, Catalano MG, Godfrey SG, Rossi M, Grioli G, et al. 2017. The SoftHand Pro-H. IEEE Robot. Autom. Mag. 24(4):87-101\n\n- 10. Smit G, Plettenburg DH, Van Der Helm FCT. 2015. The lightweight Delft Cylinder hand: first multiarticulating hand that meets the basic user requirements. IEEE Trans. Neural Syst. Rehabil. Eng. 23:431-40\n\n- 11. Baril M, Lalibert\u00e9 T, Gosselin C, Routhier F. 2013. On the design of a mechanically programmable underactuated anthropomorphic prosthetic gripper. J. Mech. Des. 135:121008\n\n- 12. Smit G, Plettenburg DH. 2010. Efficiency of voluntary closing hand and hook prostheses. Prosthet. Orthot. Int. 34:411-27\n\n- 13. Biddiss E, Chau T. 2007. Upper limb prosthesis use and abandonment: a survey of the last 25 years. Prosthet. Orthot. Int. 31:236-57\n\n- 14. Lotti F, Tiezzi P, Vassura G, Biagiotti L, Palli G, Melchiorri C. 2005. Development of UB Hand 3: early results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 4488-93. Piscataway, NJ: IEEE\n\n- 15. Honda Y, Miyazaki F, Nishikawa A. 2010. Control of pneumatic five-fingered robot hand using antagonistic muscle ratio and antagonistic muscle activity. In 2010 3rd IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics , pp. 337-42. Piscataway, NJ: IEEE\n\n- 16. Cordella F, Ciancio AL, Sacchetti R, Davalli A, Cutti AG, et al. 2016. Literature review on needs of upper limb prosthesis users. Front. Neurosci. 10:209\n\n- 17. Melchiorri C, Palli G, Berselli G, Vassura G. 2013. Development of the UB Hand IV: overview of design solutions and enabling technologies. IEEE Robot. Autom. Mag. 20(3):72-81\n\n- 18. Pfeifer R, Gomez G. 2009. Morphological computation - connecting brain, body, and environment. In Creating Brain-Like Intelligence , ed. B Sendhoff, E K\u00f6rner, O Sporns, H Ritter, K Doya, pp. 66-83. Berlin: Springer\n\n- 19. Jing X, Yong X, Jiang Y, Li G, Yokoi H. 2019. Anthropomorphic prosthetic hand with combination of light weight and diversiform motions. Appl. Sci. 9:4203\n\n- 20. Mohammadi A, Lavranos J, Zhou H, Mutlu R, Alici G, et al. 2020. A practical 3D-printed soft robotic prosthetic hand with multi-articulating capabilities. PLOS ONE 15:e0232766\n\n- 21. Chamara RPDD, Gopura RARC. 2019. An under-actuated mechanism for anthropomorphic robotic prosthetic hand. In 2019 5th International Conference on Control, Automation and Robotics , pp. 162-66. Piscataway, NJ: IEEE\n\n- 22. Pozzobon LA,Da Silva Guerra R, Librelotto GR. 2019. A low-cost, compliant, underactuated prosthetic hand with custom flex sensors for finger bending estimation. In 2019 19th International Conference on Advanced Robotics , pp. 69-74. Piscataway, NJ: IEEE\n\n- 23. Fajardo J, Ferman V, Cardona D, Maldonado G, Lemus A, Rohmer E. 2020. Galileo Hand: an anthropomorphic and affordable upper-limb prosthesis. IEEE Access 8:81365-77\n\n- 24. Abayasiri RAM, Abayasiri RST, Gunawardhana RAGM, Premakumara RMC, Mallikarachchi S, et al. 2020. An under-actuated hand prosthesis with finger abduction and adduction for human like grasps. In 2020 6th International Conference on Control, Automation and Robotics , pp. 574-80. Piscataway, NJ: IEEE\n\n- 25. Yong X, Jing X, Wu X, Jiang J, Yokoi H. 2019. Development of an adaptive prosthetic hand. In 2019 IEEE International Conference on Robotics and Biomimetics , pp. 2800-5. Piscataway, NJ: IEEE\n\n- 26. Weiner P, Starke J, Hundhausen F, Beil J, Asfour T. 2018. The KIT prosthetic hand: design and control. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 3328-34. Piscataway, NJ: IEEE\n\n- 27. Nemoto Y, Ogawa K, Yoshikawa M. 2020. F3Hand II: a flexible five-fingered prosthetic hand using curved pneumatic artificial muscles. In 2020 IEEE/SICE International Symposium on System Integration , pp. 99-104. Piscataway, NJ: IEEE\n\n- 28. Controzzi M, Cipriani C, Carrozza MC. 2008. Mechatronic design of a transradial cybernetic hand. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 576-81. Piscataway, NJ: IEEE\n\n- 29. Trivedi D, Rahn CD, Kier WM, Walker ID. 2008. Soft robotics: biological inspiration, state of the art, and future research. Appl. Bionics Biomech. 5:520417\n\n- 30. Hirose S, Ma S. 1991. Coupled tendon-driven multijoint manipulator. In 1991 IEEE International Conference on Robotics and Automation , pp. 1268-75. Piscataway, NJ: IEEE\n\n- 31. Carrozza MC, Cappiello G, Stellin G, Zaccone F, Vecchi F, et al. 2005. A cosmetic prosthetic hand with tendon driven under-actuated mechanism and compliant joints: ongoing research and preliminary results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 2661-66. Piscataway, NJ: IEEE\n\n- 32. Godfrey SB, Zhao KD, Theuer A, Catalano MG, Bianchi M, et al. 2018. The SoftHand Pro: functional evaluation of a novel, flexible, and robust myoelectric prosthesis. PLOS ONE 13:13e0205653\n\n- 33. Amend J, Lipson H. 2017. The JamHand: dexterous manipulation with minimal actuation. Soft Robot . 4:70-80\n\n- 34. Yamaguchi A, Takemura K, Yokota S, Edamura K. 2011. A robot hand using electro-conjugate fluid. In 2011 IEEE International Conference on Robotics and Automation , pp. 5923-28. Piscataway, NJ: IEEE\n\n- 35. Zhao H, O'Brien K, Li S, Shepherd RF. 2016. Optoelectronically innervated soft prosthetic hand via stretchable optical waveguides. Sci. Robot. 1:eaai7529\n\n- 36. Yoshida K, Bertram MJ, Cox TGH, Riso RR. 2017. Peripheral nerve recording electrodes and techniques. In Neuroprosthetics: Theory and Practice , ed. K Yoshida, MJ Bertram, TG Hunter Cox, RR Riso, pp. 377-466. Singapore: World Sci.\n\n- 37. Navarro X,Valderrama E,Stieglitz T,Sch\u00fcttler M.2001.Selective fascicular stimulation of the rat sciatic nerve with multipolar polyimide cuff electrodes. Restor. Neurol. Neurosci. 18:9-21\n\n- 38. Tan DW, Schiefer MA, Keith MW, Anderson JR, Tyler J, Tyler DJ. 2014. A neural interface provides long-term stable natural touch perception. Sci. Transl. Med. 6:257ra138\n\n- 39. Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, et al. 2020. A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees. Sci. Transl. Med. 12:eaay2857\n\n- 40. Raspopovic S, Cimolato A, Panarese A, Vallone F, del Valle J, et al. 2020. Neural signal recording and processing in somatic neuroprosthetic applications. A review. J. Neurosci. Methods 337:108653\n\n- 41. Navarro X,Krueger TB,Lago N,Micera S,Stieglitz T,Dario P.2005.A critical review of interfaces with the peripheral nervous system for the control of neuroprostheses and hybrid bionic systems. J. Peripher. Nerv. Syst. 258:229-58\n\n- 42. Boretius T, Badia J, Pascual-Font A, Schuettler M, Navarro X, et al. 2010. A transverse intrafascicular multichannel electrode (TIME) to interface with the peripheral nerve. Biosens. Bioelectron. 26:62-69\n\n- 43. Yoshida K, Pellinen D, Pivin D, Rousche P, Kipke D. 2000. Development of the thin-film longitudinal intra-fascicular electrode. In Proceedings of the 5th Annual Conference of the International Functional Electrical Stimulation Society , pp. 279-84. Graz, Austria: Int. Funct. Electr. Stimul. Soc.\n\n- 44. Badia J, Boretius T, Andreu D, Azevedo-Coste C, Stieglitz T, Navarro X. 2011. Comparative analysis of transverse intrafascicular multichannel, longitudinal intrafascicular and multipolar cuff electrodes for the selective stimulation of nerve fascicles. J. Neural Eng. 8:036023\n\n- 45. Howell B, Grill WM. 2015. Design of electrodes for stimulation and recording. In Implantable Neuroprostheses for Restoring Function , ed. K Kilgore, pp. 59-93. Amsterdam: Elsevier\n\n- 46. Cui X, Wiler J, Dzaman M, Altschuler RA, Martin DC. 2003. In vivo studies of polypyrrole/peptide coated neural probes. Biomaterials 24:777-87\n\n- 47. Kennedy PR, Bakay RAE, Sharpe SM. 1992. Behavioral correlates of action potentials recorded chronically inside the cone electrode. Neuroreport 3:605-8\n\n- 48. Lacour SP, Courtine G, Guck J. 2016. Materials and technologies for soft implantable neuroprostheses. Nat. Rev. Mater. 1:16063\n\n- 49. Kipke DR. 2004. Implantable neural probe systems for cortical neuroprostheses. In 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5344-47. Piscataway, NJ: IEEE\n\n- 50. Merletti R, Holobar A, Farina D. 2008. Analysis of motor units with high-density surface electromyography. J. Electromyogr. Kinesiol. 18:879-90\n\n- 51. Smith LH, Hargrove LJ. 2013. Comparison of surface and intramuscular EMG pattern recognition for simultaneous wrist/hand motion classification. In 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4223-6. Piscataway, NJ: IEEE\n\n- 52. Farrell TR, Weir RF. 2008. A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control. IEEE Trans. Biomed. Eng. 55:2198-211\n\n- 53. Cracchiolo M, Valle G, Petrini F, Strauss I, Granata G, et al. 2020. Decoding of grasping tasks from intraneural recordings in trans-radial amputee. J. Neural Eng. 17:026034\n\n- 54. Wendelken S, Page DM, Davis T, Wark HAC, Kluger DT, et al. 2017. Restoration of motor control and proprioceptive and cutaneous sensation in humans with prior upper-limb amputation via multiple Utah Slanted Electrode Arrays (USEAs) implanted in residual peripheral arm nerves. J. Neuroeng. Rehabil. 14:121\n\n- 55. Cipriani C, Dalonzo M, Carrozza MC. 2012. A miniature vibrotactile sensory substitution device for multifingered hand prosthetics. IEEE Trans. Biomed. Eng. 59:400-8\n\n- 56. Chen B, Feng Y, Wang Q. 2016. Combining vibrotactile feedback with volitional myoelectric control for robotic transtibial prostheses. Front. Neurorobot. 10:8\n\n- 57. Antfolk C, D'Alonzo M, Controzzi M, Lundborg G, Rosen B, et al. 2013. Artificial redirection of sensation from prosthetic fingers to the phantom hand map on transradial amputees: vibrotactile versus mechanotactile sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 21:112-20\n\n- 58. Gonzalez J, Soma H, Sekine M, Yu W. 2012. Psycho-physiological assessment of a prosthetic hand sensory feedback system based on an auditory display: a preliminary study. J. Neuroeng. Rehabil. 9:33\n\n- 59. Osborn L, Betthauser J, Kaliki R, Thakor N. 2018. T argeted transcutaneous electrical nerve stimulation for phantom limb sensory feedback. In 2017 IEEE Biomedical Circuits and Systems Conference . Piscataway, NJ: IEEE. https://doi.org/10.1109/BIOCAS.2017.8325200\n\n- 60. D'Anna E, Petrini FM, Artoni F, Popovic I, Simani\u00b4 c I, et al. 2017. A somatotopic bidirectional hand prosthesis with transcutaneous electrical nerve stimulation based sensory feedback. Sci. Rep. 7:10930\n\n- 61. Oddo CM, Raspopovic S, Artoni F, Mazzoni A, Spigler G, et al. 2016. Intraneural stimulation elicits discrimination of textural features by artificial fingertip in intact and amputee humans. eLife 5:e09148\n\n- 62. Valle G, Mazzoni A, Iberite F, D'Anna E, Strauss I, et al. 2018. Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis. Neuron 100:37-45.e7\n\n- 63. Valle G, D'Anna E, Strauss I, Clemente F, Granata G, et al. 2020. Hand control with invasive feedback is not impaired by increased cognitive load. Front. Bioeng. Biotechnol. 8:287\n\n- 64. D'Anna E, Valle G, Mazzoni A, Strauss I, Iberite F, et al. 2019. A closed-loop hand prosthesis with simultaneous intraneural tactile and position feedback. Sci. Robot. 4:eaau8892\n\n- 65. Shokur S, Gallo S, Moioli RC, Donati ARC, Morya E, et al. 2016. Assimilation of virtual legs and perception of floor texture by complete paraplegic patients receiving artificial tactile feedback. Sci. Rep. 6:32293\n\n- 66. Geethanjali P . 2016. Myoelectric control of prosthetic hands: state-of-the-art review. Med. Devices Evid. Res. 9:247-55\n\n- 67. Farina D, Jiang N, Rehbaum H, Holobar A, Graimann B, et al. 2014. The extraction of neural information from the surface EMG for the control of upper-limb prostheses: emerging avenues and challenges. IEEE Trans. Neural Syst. Rehabil. Eng. 22:797-809\n\n- 68. Ferguson S, Dunlop GR. 2002. Grasp recognition from myoelectric signals. In Proceedings of the Australasian Conference on Robotics and Automation , ed. W Friedrich, P Lim, pp. 83-87. Sydney: Aust. Robot. Autom. Assoc.\n\n- 69. Martelloni C, Carpaneto J, Micera S. 2008. Classification of upper arm EMG signals during objectspecific grasp. In 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5061-64. Piscataway, NJ: IEEE\n\n- 70. Kakoty NM, Hazarika SM. 2011. Recognition of grasp types through principal components of DWT based EMG features. In 2011 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/ICORR.2011.5975398\n\n- 71. Castellini C, Van Der Smagt P . 2009. Surface EMG in advanced hand prosthetics. Biol. Cybern. 100:35-47\n\n- 72. Atzori M, Cognolato M, M\u00fcller H. 2016. Deep learning with convolutional neural networks applied to electromyography data: a resource for the classification of movements for prosthetic hands. Front. Neurorobot. 10:9\n\n- 73. Tenore FVG, Ramos A, Fahmy A, Acharya S, Etienne-Cummings R, Thakor NV. 2009. Decoding of individuated finger movements using surface electromyography. IEEE Trans. Biomed. Eng. 56:1427-34\n\n- 74. Bhattachargee CK, Sikder N, Hasan MT, Nahid A. 2019. Finger movement classification based on statistical and frequency features extracted from surface EMG signals. In 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering . Piscataway, NJ: IEEE. https://doi.org/10.1109/IC4ME247184.2019.9036671\n\n- 75. Bhagwat S,Mukherji P.2020.Electromyogram (EMG) based fingers movement recognition using sparse filtering of wavelet packet coefficients. S\u00af adhan\u00af a 45:3\n\n- 76. Muceli S, Farina D. 2012. Simultaneous and proportional estimation of hand kinematics from EMG during mirrored movements at multiple degrees-of-freedom. IEEE Trans. Neural Syst. Rehabil. Eng. 20:37178\n\n- 77. Jiang N, Vest-Nielsen JL, Muceli S, Farina D. 2012. EMG-based simultaneous and proportional estimation of wrist/hand kinematics in uni-lateral trans-radial amputees. J. Neuroeng. Rehabil. 9:42\n\n- 78. Hioki M, Kawasaki H. 2012. Estimation of finger joint angles from sEMG using a neural network including time delay factor and recurrent structure. ISRN Rehabil . 2012:604314\n\n- 79. Zhuang KZ,Sommer N,Mendez V,Aryan S,Formento E,et al.2019.Shared human-robot proportional control of a dexterous myoelectric prosthesis. Nat. Mach. Intell. 1:400-11\n\n- 80. Mussa-Ivaldi FA, Casadio M, Danziger ZC, Mosier KM, Scheidt RA. 2011. Sensory motor remapping of space in human-machine interfaces. Prog. Brain Res. 191:45-64\n\n- 81. Dyson M, Barnes J, Nazarpour K. 2018. Myoelectric control with abstract decoders. J. Neural Eng. 15:056003\n\n- 82. Dyson M, Dupan S, Jones H, Nazarpour K. 2020. Learning, generalization, and scalability of abstract myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:1539-47\n\n- 83. Daley H,Englehart K,Hargrove L,Kuruganti U.2012.High density electromyography data of normally limbed and transradial amputee subjects for multifunction prosthetic control. J. Electromyogr. Kinesiol. 22:478-84\n\n- 84. Hargrove L,Englehart K,Hudgins B.2006.The effect of electrode displacements on pattern recognition based myoelectric control. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 2203-6. Piscataway, NJ: IEEE\n\n- 85. Boschmann A, Platzner M. 2014. T owards robust HD EMG pattern recognition: reducing electrode displacement effect using structural similarity. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4547-50. Piscataway, NJ: IEEE\n\n- 86. Stango A, Negro F, Farina D. 2015. Spatial correlation of high density EMG signals provides features robust to electrode number and shift in pattern recognition for myocontrol. IEEE Trans. Neural Syst. Rehabil. Eng. 23:189-98\n\n- 87. Farina D, Holobar A, Merletti R, Enoka RM. 2010. Decoding the neural drive to muscles from the surface electromyogram. Clin. Neurophysiol. 121:1616-23\n\n- 88. Kapelner T, Negro F, Aszmann OC, Farina D. 2018. Decoding motor unit activity from forearm muscles: perspectives for myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 26:244-51\n\n- 89. Dai C, Hu X. 2020. Finger joint angle estimation based on motoneuron discharge activities. IEEE J. Biomed. Heal. Inform. 24:760-67\n\n- 90. Hu Y, Wong Y, Wei W, Du Y, Kankanhalli M, Geng W. 2018. A novel attention-based hybrid CNNRNNarchitecture for sEMG-based gesture recognition. PLOS ONE 13:e0206049\n\n- 91. Olsson AE, Sager P, Andersson E, Bj\u00f6rkman A, Male\u0161evi\u00b4 c N, Antfolk C. 2019. Extraction of multilabelled movement information from the raw HD-sEMG image with time-domain depth. Sci. Rep. 9:7244\n\n- 92. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. Regression convolutional neural network for improved simultaneous EMG control. J. Neural Eng. 16:036015\n\n- 93. Xia P, Hu J, Peng Y. 2018. EMG-based estimation of limb movement using deep learning with recurrent convolutional neural networks. Artif. Organs 42:E67-77\n\n- 94. Alom MZ, Taha TM, Yakopcic C, Westberg S, Sidike P, et al. 2018. The history began from AlexNet: a comprehensive survey on deep learning approaches. arXiv:1803.01164 [cs.CV]\n\n- 95. Patricia N, Caputo B. 2014. Learning to learn, from transfer learning to domain adaptation: a unifying perspective. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , pp. 1442-49. Piscataway, NJ: IEEE\n\n- 96. Tommasi T, Orabona F, Castellini C, Caputo B. 2013. Improving control of dexterous hand prostheses using adaptive learning. IEEE Trans. Robot. 29:207-19\n\n- 97. C\u00f4t\u00e9-Allard U, Fall CL, Drouin A, Campeau-Lecours A, Gosselin C, et al. 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans. Neural Syst. Rehabil. Eng. 27:760-71\n\n- 98. Du Y, Jin W, Wei W, Hu Y, Geng W. 2017. Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation. Sensors 17:6-9\n\n- 99. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:370-79\n\n- 100. Phinyomark A, Scheme E. 2018. EMG pattern recognition in the era of big data and deep learning. Big Data Cogn. Comput. 2:21\n\n- 101. Khamparia A, Singh KM. 2019. A systematic review on deep learning architectures and applications. Expert Syst . 36:e12400\n\n- 102. Biddiss E, Chau T. 2007. Upper-limb prosthetics: critical factors in device abandonment. Am. J. Phys. Med. Rehabil. 86:977-87\n\n- 103. Do\u0161en S, Cipriani C, Kosti\u00b4 c M, Controzzi M, Carrozza MC, Popovi\u02c7 c DB. 2010. Cognitive vision system for control of dexterous prosthetic hands: experimental evaluation. J. Neuroeng. Rehabil. 7:42\n\n- 104. Light CM, Chappell PH, Hudgins B, Engelhart K. 2002. Intelligent multifunction myoelectric control of hand prostheses. J. Med. Eng. Technol. 26:139-46\n\n- 105. Fani S, Bianchi M, Jain S, Neto JSP, Boege S, et al. 2016. Assessment of myoelectric controller performance and kinematic behavior of a novel soft synergy-inspired robotic hand for prosthetic applications. Front. Neurorobot. 10:11\n\n- 106. Smith LH, Kuiken TA, Hargrove LJ. 2014. Real-time simultaneous and proportional myoelectric control using intramuscular EMG. J. Neural Eng. 11:066013\n\n- 107. Pasquina PF, Evangelista M, Carvalho AJ, Lockhart J, Griffin S, et al. 2015. First-in-man demonstration of a fully implanted myoelectric sensors system to control an advanced electromechanical prosthetic hand. J. Neurosci. Methods 244:85-93\n\n- 108. Zia ur Rehman M, Gilani S, Waris A, Niazi I, Slabaugh G, et al. 2018. Stacked sparse autoencoders for EMG-based classification of hand motions: a comparative multi day analyses between surface and intramuscular EMG. Appl. Sci. 8:1126\n\n- 109. Kamavuako EN, Scheme EJ, Englehart KB. 2014. Combined surface and intramuscular EMG for improved real-time myoelectric control performance. Biomed. Signal. Process. Control 10:102-7\n\n- 110. Dantas H, Warren DJ, Wendelken SM, Davis TS, Clark GA, Mathews VJ. 2019. Deep learning movement intent decoders trained with dataset aggregation for prosthetic limb control. IEEE Trans. Biomed. Eng. 66:3192-203\n\n- 111. Petrini FM, Mazzoni A, Rigosa J, Giambattistelli F, Granata G, et al. 2019. Microneurography as a tool to develop decoding algorithms for peripheral neuro-controlled hand prostheses. BioMed. Eng. OnLine 18:44\n\n- 112. Rossini PM, Micera S, Benvenuto A, Carpaneto J, Cavallo G, et al. 2010. Double nerve intraneural interface implant on a human amputee for robotic hand control. Clin. Neurophysiol. 121:777-83\n\n- 113. Davis TS, Wark HAC, Hutchinson DT, Warren DJ, O'Neill K, et al. 2016. Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves. J. Neural Eng. 13:036001\n\n- 114. Petrini FM, Valle G, Strauss I, Granata G, Di Iorio R, et al. 2019. Six-month assessment of a hand prosthesis with intraneural tactile feedback. Ann. Neurol. 85:137-54\n\n- 115. Mazzoni A, Oddo CM, Valle G, Camboni D, Strauss I, et al. 2020. Morphological neural computation restores discrimination of naturalistic textures in trans-radial amputees. Sci. Rep. 10:527\n\n- 116. Graczyk EL, Schiefer MA, Saal HP, Delhaye BP, Bensmaia SJ, Tyler DJ. 2016. The neural basis of perceived intensity in natural and artificial touch. Sci. Transl. Med. 8:362ra142\n\n- 117. Kogler V, Nguyen TAK, Digiovanna J, Micera S. 2011. Recording vestibular evoked potentials induced by electrical stimulation of the horizontal semicircular canal in guinea pig. In 2011 5th International IEEE/EMBS Conference on Neural Engineering , pp. 261-64. Piscataway, NJ: IEEE\n\n- 118. Micera S, Carpaneto J, Raspopovic S. 2010. Control of hand prostheses using peripheral information. IEEE Rev. Biomed. Eng. 3:48-68\n\n- 119. Englehart K,Hudgins B.2003.A robust,real-time control scheme for multifunction myoelectric control. IEEE Trans. Biomed. Eng. 50:848-54\n\n- 120. Park M, Bok BG, Ahn JH, Kim MS. 2018. Recent advances in tactile sensing technology. Micromachines 9:321\n\n- 121. Pfeifer R, Iida F, G\u00f3mez G. 2006. Morphological computation for adaptive behavior and cognition. Int. Congr. Ser. 1291:22-9\n\n- 122. Kim Y, Chortos A, Xu W, Liu Y, Oh JY, et al. 2018. A bioinspired flexible organic artificial afferent nerve. Science 360:998-1003\n\n- 123. WuJ, Jia QS, Johansson KH, Shi L. 2013. Event-based sensor data scheduling: trade-off between communication rate and estimation quality. IEEE Trans. Autom. Control 58:1041-6\n\n- 124. Bartolozzi C, Ros PM, Diotalevi F, Jamali N, Natale L, et al. 2017. Event-driven encoding of off-theshelf tactile sensors for compression and latency optimisation for robotic skin. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 166-73. Piscataway, NJ: IEEE\n\n- 125. Lee WW,Tan YJ,Yao H,Li S,See HH,et al. 2019. A neuro-inspired artificial peripheral nervous system for scalable electronic skins. Sci. Robot. 4:eaax2198\n\n- 126. Antfolk C, D'Alonzo M, Ros\u00e9n B, Lundborg G, Sebelius F, Cipriani C. 2013. Sensory feedback in upper limb prosthetics. Expert Rev. Med. Devices 10:45-54\n\n- 127. Mann RW, Reimers SD. 1970. Kinesthetic sensing for the EMG controlled 'Boston Arm.' IEEE Trans. Man-Mach. Syst. 11:110-15\n\n- 128. Patterson PE, Katz JA. 1992. Design and evaluation of a sensory feedback system that provides grasping pressure in a myoelectric hand. J. Rehabil. Res. Dev. 29:1-8\n\n- 129. Clemente F, D'Alonzo M, Controzzi M, Edin BB, Cipriani C. 2016. Non-invasive, temporally discrete feedback of object contact and release improves grasp control of closed-loop myoelectric transradial prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 24:1314-22\n\n- 130. D'Alonzo M, Clemente F, Cipriani C. 2015. Vibrotactile stimulation promotes embodiment of an alien hand in amputees with phantom sensations. IEEE Trans. Neural Syst. Rehabil. Eng. 23:450-57\n\n- 131. Stephens-Fripp B, Alici G, Mutlu R. 2018. A review of non-invasive sensory feedback methods for transradial prosthetic hands. IEEE Access 6:6878-99\n\n- 132. Dosen S, Markovic M, Strbac M, Belic M, Kojic V, et al. 2017. Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 25:183-95\n\n- 133. Geng B,Dong J,Jensen W,Dosen S,Farina D,Kamavuako EN.2018.Psychophysical evaluation of subdermal electrical stimulation in relation to prosthesis sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 26:709-15\n\n- 134. Dong J, Geng B, Niazi IK, Amjad I, Dosen S, et al. 2020. The variability of psychophysical parameters following surface and subdermal stimulation: a multiday study in amputees. IEEE Trans. Neural Syst. Rehabil. Eng. 28:174-80\n\n- 135. Flesher SN, Downey JE, Weiss JM, Hughes CL, Herrera AJ, et al. 2019. Restored tactile sensation improves neuroprosthetic arm control. bioRxiv 653428. https://doi.org/10.1101/653428\n\n- 136. Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ. 2018. Home use of a neural-connected sensory prosthesis provides the functional and psychosocial experience of having a hand again. Sci. Rep. 8:9866\n\n|   137. | George JA, Page DM, Davis TS, Duncan CC, Hutchinson T, et al. 2020. Long-term performance of Utah Slanted Electrode Arrays and intramuscular electromyographic leads implanted chronically in human arm nerves and muscles. bioRxiv 2020.03.30.016683. https://doi.org/10.1101/2020.03.30. 016683                                                      |\n\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n|    138 | Ortiz-Catalan M, Mastinu E, Sassu P, Aszmann O, Br\u00e5nemark R. 2020. Self-contained neuromuscu- loskeletal arm prostheses. N. Engl. J. Med. 382:1732-38                                                                                                                                                                                                  |\n\n|    139 | George JA, Kluger DT,Davis TS,Wendelken SM,Okorokova EV,et al.2019.Biomimetic sensory feed- back through peripheral nerve stimulation improves dexterous use of a bionic hand. Sci. Robot. 4:eaax2352                                                                                                                                                  |\n\n|    140 | Chandrasekaran S,Nanivadekar AC,McKernan G,Helm ER,Boninger ML,et al.2020.Sensory restora- tion by epidural stimulation of the lateral spinal cord in upper-limb amputees. eLife 9:e54349                                                                                                                                                              |\n\n|    141 | Controzzi M, Clemente F, Barone D, Luciani LB, Pierotti N, et al. 2019. Progress towards the devel- opment of the DeTOP hand prosthesis: a sensorized transradial prosthesis for clinical use. In Converg- ing Clinical and Engineering Research on Neurorehabilitation III , ed. L Masia, S Micera, M Akay, J Pons, pp. 103-6. Cham, Switz.: Springer |\n\n|    142 | Formento E,D'Anna E,Gribi S,Lacour SP,Micera S.2019.A biomimetic electrical stimulation strategy to induce asynchronous stochastic neural activity. J. Neural Eng. 17:046019                                                                                                                                                                           |\n\n|    143 | Sengupta A, Ye Y, Wang R, Liu C, Roy K. 2019. Going deeper in spiking neural networks: VGG and residual architectures. Front Neurosci . 13:95                                                                                                                                                                                                          |\n\n|    144 | Lindner HYN, N\u00e4tterlund BS, Hermansson LMN. 2010. Upper limb prosthetic outcome measures: review and content comparison based on International Classification of Functioning, Disability and Health. Prosthet. Orthot. Int. 34:109-28                                                                                                                  |\n\n|    145 | Hill W, Stavdahl \u00d8, Hermansson LN, Kyberd P, Swanson S, Hubbard S. 2009. Functional outcomes in the WHO-ICF model: establishment of the upper limb prosthetic outcome measures group. J. Prosthet. Orthot. 21:115-19                                                                                                                                   |\n\n|    146 | Hudak PL, Amadio PC, Bombardier C. 1996. Development of an upper extremity outcome measure: the DASH (Disabilities of the Arm, Shoulder, and Head). Am. J. Ind. Med. 29:602-8                                                                                                                                                                          |\n\n|    147 | Beaton DE, Wright JG, Katz JN, Amadio P, Bombardier C, et al. 2005. Development of the Quick- DASH: comparison of three item-reduction approaches. J. Bone Jt. Surg. A 87:1038-46                                                                                                                                                                      |\n\n|    148 | Harper A, Power M, Orley J, Herrman H, Schofield H, et al. 1998. Development of the World Health Organization WHOQOL-BREF quality of life assessment. Psychol. Med. 28:551-58                                                                                                                                                                          |\n\n|    149 | Burckhardt CS, Anderson KL. 2003. The Quality of Life Scale (QOLS): reliability, validity, and utiliza- tion. Health Qual. Life Outcomes 1:60                                                                                                                                                                                                          |\n\n|    150 | Heinemann AW, Bode RK, O'Reilly C. 2003. Development and measurement properties of the Or- thotics and Prosthetics User's Survey (OPUS): a comprehensive set of clinical outcome instruments. Prosthet. Orthot. Int. 27:191-206                                                                                                                        |\n\n|    151 | Lendaro E,Middleton A,Brown S,Ortiz-Catalan M.2020.Out of the clinic, into the home: the in-home use of phantom motor execution aided by machine learning and augmented reality for the treatment of phantom limb pain. J. Pain Res. 13:195-209                                                                                                        |\n\n|    152 | Johansson RS, Flanagan JR. 2009. Coding and use of tactile signals from the fingertips in object manip- ulation tasks. Nat. Rev. Neurosci. 10:345-59                                                                                                                                                                                                   |\n\n|    153 | Taub E, Uswatte G, Pidikiti R. 1999. Constraint-induced movement therapy: a new family of techniques with broad application to physical rehabilitation-a clinical review. J. Rehabil. Res. Dev. 36:237-51                                                                                                                                              |\n\n|    154 | Mathiowetz V, Volland G, Kashman N, Weber K. 1985. Adult norms for the Box and Block T est of manual dexterity. Am. J. Occup. Ther. 39:386-91                                                                                                                                                                                                          |\n\n|    155 | Hebert JS, Lewicke J. 2012. Case report of modified box and blocks test with motion capture to measure prosthetic function. J. Rehabil. Res. Dev. 49:1163-74                                                                                                                                                                                           |\n\n|    156 | Hebert JS, Lewicke J, Williams TR, Vette AH. 2014. Normative data for modified box and blocks test measuring upper-limb function via motion capture. J. Rehabil. Res. Dev. 51:919-31                                                                                                                                                                   |\n\n|    157 | Mathiowetz V, Weber K, Kashman N, Volland G. 1985. Adult norms for the Nine Hole Peg T est of finger dexterity. Occup. Ther. J. Res. 5:24-38                                                                                                                                                                                                           |\n\n- 158. Lambercy O,Fluet MC,Lamers I,Kerkhofs L,Feys P, Gassert R. 2013. Assessment of upper limb motor function in patients with multiple sclerosis using the Virtual Peg Insertion T est: a pilot study. In 2013 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/\n",
    "topic": "Non-invasive and invasive sensory feedback modalities such as vibrotactile, electrotactile, mechanotactile, and intraneural stimulation in closed-loop prosthetic systems.",
    "response": "<document_analysis>\nThe context provided is an extensive list of references from a comprehensive review on upper limb prosthetics, focusing heavily on advanced sensory feedback modalities and control strategies for prosthetic hands. Among the cited works are studies on non-invasive sensory feedback methods such as vibrotactile, electrotactile, and mechanotactile stimulation, as well as invasive methods like intraneural stimulation and peripheral nerve interfaces. The references include both fundamental research on neural interfaces (e.g., intraneural electrodes, peripheral nerve stimulation) and applied clinical studies demonstrating improved embodiment, dexterity, and functional outcomes with closed-loop feedback systems.\n\nKey themes include:\n- The integration of sensory feedback to enhance prosthetic control and embodiment.\n- Comparative evaluations of non-invasive versus invasive feedback approaches.\n- The impact of sensory feedback modalities on tactile sensitivity, manual dexterity, and cognitive load.\n- The technological and physiological challenges of implementing closed-loop control with naturalistic sensory feedback.\n- The role of biomimetic strategies in improving feedback naturalness and user experience.\n\nImplicit assumptions and subtle details:\n- Sensory feedback is critical for functional prosthetic use and reducing device abandonment.\n- Different modalities have trade-offs in invasiveness, fidelity, and user acceptance.\n- Advances in neural interface technology are enabling increasingly natural and intuitive prosthetic control.\n- Cognitive load considerations affect the usability of sensory feedback systems.\n- The combination of sensory feedback with myoelectric control is a growing research focus.\n\nDifficulty rating: 9/10. The question should engage experts familiar with neuroprosthetics, sensory neuroengineering, and rehabilitation engineering, requiring synthesis of knowledge about multiple feedback modalities and their comparative advantages and limitations in closed-loop prosthetic systems.\n\nThe question planned aims to provoke deep reflection on the comparative mechanisms, benefits, and challenges of non-invasive and invasive sensory feedback methods in prosthetics, encouraging critical evaluation of their impact on prosthetic embodiment, functionality, and user experience.\n\nThis content is highly meaningful and educationally valuable for domain experts. No irrelevant or bogus content was detected.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the physiological mechanisms and functional outcomes of invasive intraneural stimulation compare to non-invasive sensory feedback modalities like vibrotactile, electrotactile, and mechanotactile stimulation in closed-loop upper limb prosthetic systems, particularly in terms of embodiment, tactile sensitivity, manual dexterity, and cognitive load?\n\nExplanation: Invasive intraneural stimulation interfaces directly with peripheral nerves, providing biomimetic, localized, and naturalistic sensory feedback that enhances embodiment, tactile discrimination, and manual dexterity with minimal increase in cognitive load. Non-invasive methods like vibrotactile, electrotactile, and mechanotactile stimulation deliver sensory cues indirectly through the skin, often resulting in less natural sensation, lower spatial resolution, reduced tactile sensitivity, and potentially higher cognitive demand to interpret feedback, thereby limiting functional outcomes compared to intraneural approaches.\n\nCorrect Answer: Intraneural stimulation provides more natural, localized, and effective sensory feedback that improves embodiment, tactile sensitivity, dexterity, and imposes lower cognitive load compared to less natural, less precise, and cognitively demanding non-invasive vibrotactile, electrotactile, and mechanotactile feedback modalities.\n</output_format>",
    "question": "How do the physiological mechanisms and functional outcomes of invasive intraneural stimulation compare to non-invasive sensory feedback modalities like vibrotactile, electrotactile, and mechanotactile stimulation in closed-loop upper limb prosthetic systems, particularly in terms of embodiment, tactile sensitivity, manual dexterity, and cognitive load?",
    "answer": "Intraneural stimulation provides more natural, localized, and effective sensory feedback that improves embodiment, tactile sensitivity, dexterity, and imposes lower cognitive load compared to less natural, less precise, and cognitively demanding non-invasive vibrotactile, electrotactile, and mechanotactile feedback modalities.",
    "explanation": "Invasive intraneural stimulation interfaces directly with peripheral nerves, providing biomimetic, localized, and naturalistic sensory feedback that enhances embodiment, tactile discrimination, and manual dexterity with minimal increase in cognitive load. Non-invasive methods like vibrotactile, electrotactile, and mechanotactile stimulation deliver sensory cues indirectly through the skin, often resulting in less natural sensation, lower spatial resolution, reduced tactile sensitivity, and potentially higher cognitive demand to interpret feedback, thereby limiting functional outcomes compared to intraneural approaches.",
    "question_token_count": 65,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 62
  },
  {
    "context": "## 2.1. Existing Robotic Prosthetic Hands\nNumerous commercially available RPH solutions use underactuated mechanisms ( Supplemental Table 1 ), including the Michelangelo prosthetic hand (Ottobock, Germany), the i-Limb Ultra (\u00d6ssur, Iceland), the bebionic hand (Ottobock), and the VINCENT evolution 3 (Vincent Systems, Germany). Despite remarkable advances, there is still arguably a trade-off between dexterity and weight in these solutions, with companies usually emphasizing one aspect or the other.\n\nMany research groups are currently working on innovative solutions to tackle the dexterity/ weight dilemma (19), such as the use of a monolithic 3D-printed soft material (20) or mechanical solutions to implement finger synergies via clutches (21). For example, Jing et al. (19) proposed an anthropomorphic RPH using only three motors that could achieve 13 grasp types while weighing only approximately 130 g.\n\nThe price of RPHs is an additional limiting factor for broader adoption by patients. With most advanced solutions costing $10,000-20,000, many researchers advocate for cheaper solutions, particularly for emerging countries (e.g., 22).\n\nOpen source RPHs are an exciting alternative to dramatically reduce the cost of development and distribution. One particularly interesting aspect of such hands is simplified maintenance and repairs (using, e.g., 3D printing) that do not rely on specific suppliers. For example, Open\n\nBionics (United Kingdom) commercializes solutions for transradial amputees (e.g., the medically certified Hero Arm) but also provides the source files for some of their designs, and e-NABLE ( https://enablingthefuture.org ) reports 8,000 recipients of their prosthetics, which were built by volunteers around the world. Open source RPHs also enable users to alter the design to meet their unique needs; for example, the Galileo Hand (23) allows easy customization of the types of movements and number of electromyography (EMG) electrodes.\n\nResearchers are also working on better mechanical solutions to improve RPH dexterity. An underactuated hand prosthesis designed by Abayasiri et al. (24) has finger abduction and adduction to enable it to grasp larger objects, and an adaptive prosthetic hand designed by Yong et al. (25) adds DOFs in the palm with movable metacarpals. The Karlsruhe Institute of T echnology (KIT) prosthetic hand (26) has an embedded camera and real-time object recognition, enabling the hand to be preshaped. Pneumatic artificial muscle (27) permits the development of light, compact solutions. Finally, biomimetic actuation is used for muscle-like actuators (15).\n\nIn addition to the hardware aspect, there are also innovations in RPH control and sensorization. Low-level controllers use information about the state of the device and eventually activate the actuation to meet the desired state imposed by the user's intentions. The choice of the state variable has a strong influence on how the device works. Position or speed can be read through encoders of each joint and controlled; these are straightforward approaches that have been used broadly in robotic applications. When the interaction of the hand with the external environment is of interest, more advanced control systems are implemented, such as torque or impedance control. Both approaches measure the force applied by the actuator, controlling it directly in the first case and simulating compliance in the second. Advanced control strategies enable complex manipulation and smoother gestures at the expense of a bulkier mechanical structure and a more complex control system. Therefore, enabling more sophisticated control requires integrated force and position sensors, which have been previously developed mainly to close the robotic control loop (28).\n\nIn summary, low-cost and light hands have flourished over the last few years. The race to simplify designs and reduce costs through 3D printing should not impact the dexterity of RPHs. For now, underactuated mechanisms are the best solution for RPHs and innovative designs based on synergy mechanisms or friction, the latter of which can help increase the number of DOAs without increasing the number of motors.\n",
    "topic": "Explain the advantages and challenges of underactuated mechanisms in robotic prosthetic hand design, including their role in balancing complexity, weight, and functionality.",
    "response": "<document_analysis>\nThe context discusses existing robotic prosthetic hands (RPHs), with emphasis on underactuated mechanisms as a prevalent design choice. It highlights the trade-offs between dexterity and weight, noting that underactuation helps simplify the mechanical complexity and reduce weight, but may limit full dexterity. The text mentions innovations to overcome these limitations, such as synergy-based designs and friction mechanisms that increase degrees of actuation (DOA) without increasing motor count. There are references to research efforts to enhance dexterity while maintaining lightweight design, including novel materials, clutch-based finger synergies, and biomimetic actuation. Control strategies and sensor integration are also noted to influence functional performance and complexity, where advanced controls require more sensors and result in bulkier systems. Cost and accessibility considerations are also important, with open-source and 3D-printed designs aiming to reduce price without sacrificing dexterity. Overall, underactuated mechanisms strike a balance between mechanical simplicity and functional capability but pose challenges in achieving high dexterity. The question should probe understanding of how underactuation manages these trade-offs, including its advantages in weight and simplicity and the inherent challenges in dexterity and control complexity.\n\nDifficulty rating: 9/10 (requires deep technical understanding of mechanical design trade-offs, control strategies, and material/actuation innovations in prosthetic hands)\n\nThe question will encourage reflection on the fundamental design compromises in robotic prosthetic hands, requiring synthesis of mechanical, control, and functional aspects, suitable for a domain expert.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do underactuated mechanisms in robotic prosthetic hands contribute to reducing weight and mechanical complexity while simultaneously imposing challenges on dexterity and control sophistication, and what innovative design strategies have been proposed to mitigate these challenges without increasing the number of motors?\n\nExplanation: Underactuated mechanisms reduce the number of motors needed by mechanically coupling multiple joints, which lowers weight and simplifies the mechanical structure. However, this coupling limits independent joint movements, reducing dexterity and fine manipulation ability. To overcome these limitations, innovative designs such as synergy-based mechanisms, friction/clutch systems, and biomimetic actuators have been proposed; these approaches increase the degrees of actuation or functional range without adding motors, preserving lightness and simplicity while enhancing dexterity and control capability.\n\nCorrect Answer: Underactuated mechanisms reduce weight and complexity by using fewer motors to control multiple joints but limit dexterity due to joint coupling; innovations like synergy mechanisms, friction clutches, and biomimetic actuators enhance dexterity without increasing motor count.\n</output_format>",
    "question": "How do underactuated mechanisms in robotic prosthetic hands contribute to reducing weight and mechanical complexity while simultaneously imposing challenges on dexterity and control sophistication, and what innovative design strategies have been proposed to mitigate these challenges without increasing the number of motors?",
    "answer": "Underactuated mechanisms reduce weight and complexity by using fewer motors to control multiple joints but limit dexterity due to joint coupling; innovations like synergy mechanisms, friction clutches, and biomimetic actuators enhance dexterity without increasing motor count.",
    "explanation": "Underactuated mechanisms reduce the number of motors needed by mechanically coupling multiple joints, which lowers weight and simplifies the mechanical structure. However, this coupling limits independent joint movements, reducing dexterity and fine manipulation ability. To overcome these limitations, innovative designs such as synergy-based mechanisms, friction/clutch systems, and biomimetic actuators have been proposed; these approaches increase the degrees of actuation or functional range without adding motors, preserving lightness and simplicity while enhancing dexterity and control capability.",
    "question_token_count": 49,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 49
  },
  {
    "context": "## Figure 1\nExamples of functioning hand replacement. ( a ) A personalized cosmetic hand solution (ITOP , Italy) provides a natural look. Photos adapted with permission from ITOP and Procosil. ( ) A body-powered prosthetic solution (Ottobock, Germany) is a common approach b for people with an upper-limb amputation. Photo reproduced with permission from Ottobock. ( ) An sEMG-based pattern recognition c system (Gen2, Coapt, USA) allows grasp classification. Photo adapted courtesy of Coapt LLC ( http://www.coaptengineering.com ). ( d ) sEMG control and extracellular stimulation via an implanted FINE were used to convey sensory feedback for home-use applications. The implant was stable for more than five years, and home-use electrical stimulation for sensory feedback was investigated for up to 13 days (116). Panel adapted from Reference 116 (CC BY-SA 4.0). ( ) Fully implanted myoelectric sensors provide stronger e and more reliable signals that do not change with arm positioning, socket rotation, or sweating (107). Panel adapted with permission from Reference 107. ( f ) Six-DOF prosthetic hand control (i-Limb Ultra, \u00d6ssur, Iceland) uses threshold-based sEMG control and cocontraction to switch between grasps. ( g ) Sensory feedback conveyed via intraneural TIMEs enables the encoding of objects' shape and stiffness (6). Panel reproduced with permission; copyright 2014 Lifehand 2 / Patrizia T occi. ( h ) Hand transplantation is a promising technique that has not yet become a standard procedure due to several surgical and clinical difficulties. Panel adapted with permission from Reference 177. Abbreviations: DOF, degree of freedom; FINE, flat interface nerve electrode; sEMG, surface electromyography; TIME, transverse intrafascicular multichannel electrode.\n\nsurvey of below-elbow amputees from Sweden, the United Kingdom, and Canada (7), 53% of the respondents wore a cosmetic prosthesis, 13% used a hook, 4% used a cable hand, and 30% used a myoelectric RPH. Despite encouraging results in the late 1990s (8), hand transplantation ( Figure 1 h ) encountered significant surgical and clinical difficulties (rejection and immunosuppression); it has therefore been tested in only a few patients and is not yet considered one of the available options.\n",
    "topic": "Comparative analysis of prosthetic hand solutions including cosmetic prostheses, body-powered devices, myoelectric prostheses, and fully implanted systems in terms of functionality, user adoption, and patient outcomes.",
    "response": "<document_analysis>\nThe provided context presents a detailed overview of various prosthetic hand solutions, illustrating a spectrum from cosmetic prostheses to advanced fully implanted myoelectric systems with sensory feedback. It highlights both technological diversity and user adoption patterns, including statistical data on usage rates from a survey of below-elbow amputees. Key themes include functional capabilities (e.g., degrees of freedom, control strategies like sEMG and pattern recognition), clinical challenges (such as those affecting hand transplantation), and the impact of device design on user experience (e.g., signal reliability in fully implanted sensors versus surface sensors). The text also references the long-term stability and sensory feedback potential of implanted electrodes, which are advanced features compared to simpler body-powered or cosmetic solutions. The contrast between widespread use of cosmetic prostheses (53%) and limited adoption of more functional but complex options like myoelectric RPH (30%) or transplantation (rare due to surgical challenges) invites critical analysis of trade-offs between appearance, functionality, and clinical viability. Implicit assumptions relate to the balance between usability, technological complexity, and patient outcomes.\n\nDifficulty rating: 9/10 due to requiring integration of clinical, technological, and user adoption factors, as well as understanding nuanced functional differences and implications for patient outcomes.\n\nThe question should encourage synthesis of functional characteristics, user preferences, and clinical challenges, urging reflection on why certain prostheses are favored despite technological advances and how the design influences patient quality of life.\n\nTherefore, a highly challenging question could probe the comparative advantages and limitations of these prosthetic types in real-world adoption and functional efficacy, including the impact of sensory feedback and surgical barriers.\n\n</document_analysis>\n\n<output_format>\nQuestion: Considering the range of prosthetic hand solutions from cosmetic prostheses and body-powered devices to myoelectric and fully implanted systems, how do differences in control mechanisms, sensory feedback integration, and clinical challenges influence their functional efficacy, user adoption rates, and overall patient outcomes?\n\nExplanation: The control mechanisms vary from simple mechanical (body-powered) to advanced myoelectric systems with pattern recognition and fully implanted sensors providing stable signals and sensory feedback; these technological differences affect functional capabilities like degrees of freedom and reliability. Sensory feedback integration enhances object manipulation and user embodiment but is limited by surgical complexity and implant stability requirements. Clinical challenges, especially in hand transplantation, including rejection and immunosuppression, restrict adoption despite potential functional gains. Consequently, cosmetic prostheses dominate adoption due to appearance and simplicity, while advanced systems face barriers despite superior function, influencing patient outcomes by balancing usability, complexity, and clinical risks.\n\nCorrect Answer: Functional efficacy and patient outcomes improve with advanced control and sensory feedback but are offset by clinical and surgical challenges, resulting in higher adoption of simpler, less functional prostheses like cosmetic and body-powered devices.\n</output_format>",
    "question": "Considering the range of prosthetic hand solutions from cosmetic prostheses and body-powered devices to myoelectric and fully implanted systems, how do differences in control mechanisms, sensory feedback integration, and clinical challenges influence their functional efficacy, user adoption rates, and overall patient outcomes?",
    "answer": "Functional efficacy and patient outcomes improve with advanced control and sensory feedback but are offset by clinical and surgical challenges, resulting in higher adoption of simpler, less functional prostheses like cosmetic and body-powered devices.",
    "explanation": "The control mechanisms vary from simple mechanical (body-powered) to advanced myoelectric systems with pattern recognition and fully implanted sensors providing stable signals and sensory feedback; these technological differences affect functional capabilities like degrees of freedom and reliability. Sensory feedback integration enhances object manipulation and user embodiment but is limited by surgical complexity and implant stability requirements. Clinical challenges, especially in hand transplantation, including rejection and immunosuppression, restrict adoption despite potential functional gains. Consequently, cosmetic prostheses dominate adoption due to appearance and simplicity, while advanced systems face barriers despite superior function, influencing patient outcomes by balancing usability, complexity, and clinical risks.",
    "question_token_count": 53,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 40
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "Challenges and strategies for simultaneous control of multiple functions in bionic hand prostheses focusing on performance and robustness in end users.",
    "response": "<document_analysis>\nThe provided context is a list of scientific references from various studies related to prosthetics, sensory feedback, neuromuscular control, peripheral nerve surgery, and functional assessments of prosthetic devices. Among these, reference 184 directly addresses the simultaneous control of multiple functions in bionic hand prostheses, focusing on performance and robustness in end users. This particular reference (Hahne JM et al., 2018) is highly relevant to the question topic, providing a basis for exploring the challenges and strategies involved in simultaneous multi-function control in advanced prosthetic hands.\n\nThe other references contribute indirectly by discussing sensory feedback integration, intraneural stimulation, neuromyoelectric control methods, embodiment, and functional assessments that underpin the development and enhancement of prosthetic control systems. These collectively highlight the complexity of achieving intuitive, reliable control of multiple degrees of freedom in prosthetic hands.\n\nImplicit assumptions include the need for robust signal processing, decoding algorithms, and user adaptability to achieve simultaneous multi-function control. Challenges likely involve mitigating signal cross-talk, ensuring stable and intuitive control, and integrating sensory feedback to improve performance. Strategies may include advanced pattern recognition, modified Kalman filters, intraneural feedback, and multisensory integration to enhance embodiment and control robustness.\n\nThe difficulty level for a question probing these topics is high (8-9/10), as it requires comprehensive understanding of neuroprosthetics, control algorithms, sensorimotor integration, and user-centric performance evaluation.\n\nThe question will be planned to prompt an expert to synthesize knowledge about the major technical and clinical challenges faced in simultaneous control of multiple prosthetic functions, and the cutting-edge strategies employed to overcome these, emphasizing how performance and robustness are balanced in real-world end-user applications.\n\nThus, the question will encourage deep reflection on algorithmic complexity, sensorimotor integration, neurophysiological constraints, and practical deployment in prosthetic control systems, fostering nuanced understanding beyond superficial descriptions.\n\nGiven the meaningful and coherent content directly related to the question topic, it is appropriate and valuable to generate a highly challenging, insightful question-answer pair.\n</document_analysis>\n\n<output_format>\nQuestion: What are the primary technical and neurophysiological challenges in achieving simultaneous control of multiple functions in bionic hand prostheses, and which advanced strategies have proven most effective in enhancing both performance and robustness for end users?\n\nExplanation: Simultaneous multi-function control in bionic hands is challenged by signal complexity, cross-talk, non-stationary EMG patterns, and limited sensory feedback, which complicate intuitive and stable control. Neurophysiological factors such as muscle fatigue, variability in nerve signals, and the user's cognitive workload also impact performance. Advanced strategies that address these challenges include sophisticated pattern recognition algorithms, modified Kalman filters for intuitive decoding, integration of intraneural sensory feedback to improve embodiment and reduce cognitive load, and multisensory integration approaches. These methods improve decoding accuracy, reduce errors, and enhance user adaptability, thus increasing both performance and robustness in practical, real-world use.\n\nCorrect Answer: Signal complexity and variability, sensory feedback limitations, and cognitive load are key challenges; advanced pattern recognition, modified Kalman filters, and intraneural sensory feedback integration effectively enhance performance and robustness.\n</output_format>",
    "question": "What are the primary technical and neurophysiological challenges in achieving simultaneous control of multiple functions in bionic hand prostheses, and which advanced strategies have proven most effective in enhancing both performance and robustness for end users?",
    "answer": "Signal complexity and variability, sensory feedback limitations, and cognitive load are key challenges; advanced pattern recognition, modified Kalman filters, and intraneural sensory feedback integration effectively enhance performance and robustness.",
    "explanation": "Simultaneous multi-function control in bionic hands is challenged by signal complexity, cross-talk, non-stationary EMG patterns, and limited sensory feedback, which complicate intuitive and stable control. Neurophysiological factors such as muscle fatigue, variability in nerve signals, and the user's cognitive workload also impact performance. Advanced strategies that address these challenges include sophisticated pattern recognition algorithms, modified Kalman filters for intuitive decoding, integration of intraneural sensory feedback to improve embodiment and reduce cognitive load, and multisensory integration approaches. These methods improve decoding accuracy, reduce errors, and enhance user adaptability, thus increasing both performance and robustness in practical, real-world use.",
    "question_token_count": 43,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 38
  },
  {
    "context": "## DISCLOSURE STATEMENT\nS.M. holds shares in SensArs, which aims to develop bionic limbs for amputees.\n\n\n## ACKNOWLEDGMENTS\nThe authors would like to thank Iason Batzianoulis for his valuable help on robotic hand control. This review was partly funded by the Swiss National Science Foundation through the National Centre of Competence in Research (NCCR) Robotics, the CHRONOS project, the Wyss Center for Bio and Neuroengineering, and the Bertarelli Foundation.\n\n\n## LITERATURE CITED\n- 1. Piazza C, Grioli G, Catalano MG, Bicchi A. 2019. A century of robotic hands. Annu. Rev. Control Robot. Auton. Syst. 2:1-32\n\n- 2. Castiello U. 2005. The neuroscience of grasping. Nat. Rev. Neurosci. 6:726-36\n\n- 3. Bicchi A. 2000. Hands for dexterous manipulation and robust grasping: a difficult road toward simplicity. IEEE Trans. Robot. Autom. 16:652-62\n\n- 4. Marasco PD, Kim K, Colgate JE, Peshkin MA, Kuiken TA. 2011. Robotic touch shifts perception of embodiment to a prosthesis in targeted reinnervation amputees. Brain 134:747-58\n\n- 5. Ehrsson HH, Rosen B, Stockselius A, Ragno C, Kohler P, Lundborg G. 2008. Upper limb amputees can be induced to experience a rubber hand as their own. Brain 131:3443-52\n\n- 6. Raspopovic S, Capogrosso M, Petrini FM, Bonizzato M, Rigosa J, et al. 2014. Restoring natural sensory feedback in real-time bidirectional hand prostheses. Sci. Transl. Med. 6:222ra19\n\n- 7. Kyberd PJ, Hill W. 2011. Survey of upper limb prosthesis users in Sweden, the United Kingdom and Canada. Prosthet. Orthot. Int. 35:234-41\n\n- 8. Dubernard JM, Owen E, Herzberg G, Lanzetta M, Martin X, et al. 1999. Human hand allograft: report on first 6 months. Lancet 353:1315-20\n\n- 9. Piazza C, Catalano MG, Godfrey SG, Rossi M, Grioli G, et al. 2017. The SoftHand Pro-H. IEEE Robot. Autom. Mag. 24(4):87-101\n\n- 10. Smit G, Plettenburg DH, Van Der Helm FCT. 2015. The lightweight Delft Cylinder hand: first multiarticulating hand that meets the basic user requirements. IEEE Trans. Neural Syst. Rehabil. Eng. 23:431-40\n\n- 11. Baril M, Lalibert\u00e9 T, Gosselin C, Routhier F. 2013. On the design of a mechanically programmable underactuated anthropomorphic prosthetic gripper. J. Mech. Des. 135:121008\n\n- 12. Smit G, Plettenburg DH. 2010. Efficiency of voluntary closing hand and hook prostheses. Prosthet. Orthot. Int. 34:411-27\n\n- 13. Biddiss E, Chau T. 2007. Upper limb prosthesis use and abandonment: a survey of the last 25 years. Prosthet. Orthot. Int. 31:236-57\n\n- 14. Lotti F, Tiezzi P, Vassura G, Biagiotti L, Palli G, Melchiorri C. 2005. Development of UB Hand 3: early results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 4488-93. Piscataway, NJ: IEEE\n\n- 15. Honda Y, Miyazaki F, Nishikawa A. 2010. Control of pneumatic five-fingered robot hand using antagonistic muscle ratio and antagonistic muscle activity. In 2010 3rd IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics , pp. 337-42. Piscataway, NJ: IEEE\n\n- 16. Cordella F, Ciancio AL, Sacchetti R, Davalli A, Cutti AG, et al. 2016. Literature review on needs of upper limb prosthesis users. Front. Neurosci. 10:209\n\n- 17. Melchiorri C, Palli G, Berselli G, Vassura G. 2013. Development of the UB Hand IV: overview of design solutions and enabling technologies. IEEE Robot. Autom. Mag. 20(3):72-81\n\n- 18. Pfeifer R, Gomez G. 2009. Morphological computation - connecting brain, body, and environment. In Creating Brain-Like Intelligence , ed. B Sendhoff, E K\u00f6rner, O Sporns, H Ritter, K Doya, pp. 66-83. Berlin: Springer\n\n- 19. Jing X, Yong X, Jiang Y, Li G, Yokoi H. 2019. Anthropomorphic prosthetic hand with combination of light weight and diversiform motions. Appl. Sci. 9:4203\n\n- 20. Mohammadi A, Lavranos J, Zhou H, Mutlu R, Alici G, et al. 2020. A practical 3D-printed soft robotic prosthetic hand with multi-articulating capabilities. PLOS ONE 15:e0232766\n\n- 21. Chamara RPDD, Gopura RARC. 2019. An under-actuated mechanism for anthropomorphic robotic prosthetic hand. In 2019 5th International Conference on Control, Automation and Robotics , pp. 162-66. Piscataway, NJ: IEEE\n\n- 22. Pozzobon LA,Da Silva Guerra R, Librelotto GR. 2019. A low-cost, compliant, underactuated prosthetic hand with custom flex sensors for finger bending estimation. In 2019 19th International Conference on Advanced Robotics , pp. 69-74. Piscataway, NJ: IEEE\n\n- 23. Fajardo J, Ferman V, Cardona D, Maldonado G, Lemus A, Rohmer E. 2020. Galileo Hand: an anthropomorphic and affordable upper-limb prosthesis. IEEE Access 8:81365-77\n\n- 24. Abayasiri RAM, Abayasiri RST, Gunawardhana RAGM, Premakumara RMC, Mallikarachchi S, et al. 2020. An under-actuated hand prosthesis with finger abduction and adduction for human like grasps. In 2020 6th International Conference on Control, Automation and Robotics , pp. 574-80. Piscataway, NJ: IEEE\n\n- 25. Yong X, Jing X, Wu X, Jiang J, Yokoi H. 2019. Development of an adaptive prosthetic hand. In 2019 IEEE International Conference on Robotics and Biomimetics , pp. 2800-5. Piscataway, NJ: IEEE\n\n- 26. Weiner P, Starke J, Hundhausen F, Beil J, Asfour T. 2018. The KIT prosthetic hand: design and control. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 3328-34. Piscataway, NJ: IEEE\n\n- 27. Nemoto Y, Ogawa K, Yoshikawa M. 2020. F3Hand II: a flexible five-fingered prosthetic hand using curved pneumatic artificial muscles. In 2020 IEEE/SICE International Symposium on System Integration , pp. 99-104. Piscataway, NJ: IEEE\n\n- 28. Controzzi M, Cipriani C, Carrozza MC. 2008. Mechatronic design of a transradial cybernetic hand. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 576-81. Piscataway, NJ: IEEE\n\n- 29. Trivedi D, Rahn CD, Kier WM, Walker ID. 2008. Soft robotics: biological inspiration, state of the art, and future research. Appl. Bionics Biomech. 5:520417\n\n- 30. Hirose S, Ma S. 1991. Coupled tendon-driven multijoint manipulator. In 1991 IEEE International Conference on Robotics and Automation , pp. 1268-75. Piscataway, NJ: IEEE\n\n- 31. Carrozza MC, Cappiello G, Stellin G, Zaccone F, Vecchi F, et al. 2005. A cosmetic prosthetic hand with tendon driven under-actuated mechanism and compliant joints: ongoing research and preliminary results. In Proceedings of the 2005 IEEE International Conference on Robotics and Automation , pp. 2661-66. Piscataway, NJ: IEEE\n\n- 32. Godfrey SB, Zhao KD, Theuer A, Catalano MG, Bianchi M, et al. 2018. The SoftHand Pro: functional evaluation of a novel, flexible, and robust myoelectric prosthesis. PLOS ONE 13:13e0205653\n\n- 33. Amend J, Lipson H. 2017. The JamHand: dexterous manipulation with minimal actuation. Soft Robot . 4:70-80\n\n- 34. Yamaguchi A, Takemura K, Yokota S, Edamura K. 2011. A robot hand using electro-conjugate fluid. In 2011 IEEE International Conference on Robotics and Automation , pp. 5923-28. Piscataway, NJ: IEEE\n\n- 35. Zhao H, O'Brien K, Li S, Shepherd RF. 2016. Optoelectronically innervated soft prosthetic hand via stretchable optical waveguides. Sci. Robot. 1:eaai7529\n\n- 36. Yoshida K, Bertram MJ, Cox TGH, Riso RR. 2017. Peripheral nerve recording electrodes and techniques. In Neuroprosthetics: Theory and Practice , ed. K Yoshida, MJ Bertram, TG Hunter Cox, RR Riso, pp. 377-466. Singapore: World Sci.\n\n- 37. Navarro X,Valderrama E,Stieglitz T,Sch\u00fcttler M.2001.Selective fascicular stimulation of the rat sciatic nerve with multipolar polyimide cuff electrodes. Restor. Neurol. Neurosci. 18:9-21\n\n- 38. Tan DW, Schiefer MA, Keith MW, Anderson JR, Tyler J, Tyler DJ. 2014. A neural interface provides long-term stable natural touch perception. Sci. Transl. Med. 6:257ra138\n\n- 39. Vu PP, Vaskov AK, Irwin ZT, Henning PT, Lueders DR, et al. 2020. A regenerative peripheral nerve interface allows real-time control of an artificial hand in upper limb amputees. Sci. Transl. Med. 12:eaay2857\n\n- 40. Raspopovic S, Cimolato A, Panarese A, Vallone F, del Valle J, et al. 2020. Neural signal recording and processing in somatic neuroprosthetic applications. A review. J. Neurosci. Methods 337:108653\n\n- 41. Navarro X,Krueger TB,Lago N,Micera S,Stieglitz T,Dario P.2005.A critical review of interfaces with the peripheral nervous system for the control of neuroprostheses and hybrid bionic systems. J. Peripher. Nerv. Syst. 258:229-58\n\n- 42. Boretius T, Badia J, Pascual-Font A, Schuettler M, Navarro X, et al. 2010. A transverse intrafascicular multichannel electrode (TIME) to interface with the peripheral nerve. Biosens. Bioelectron. 26:62-69\n\n- 43. Yoshida K, Pellinen D, Pivin D, Rousche P, Kipke D. 2000. Development of the thin-film longitudinal intra-fascicular electrode. In Proceedings of the 5th Annual Conference of the International Functional Electrical Stimulation Society , pp. 279-84. Graz, Austria: Int. Funct. Electr. Stimul. Soc.\n\n- 44. Badia J, Boretius T, Andreu D, Azevedo-Coste C, Stieglitz T, Navarro X. 2011. Comparative analysis of transverse intrafascicular multichannel, longitudinal intrafascicular and multipolar cuff electrodes for the selective stimulation of nerve fascicles. J. Neural Eng. 8:036023\n\n- 45. Howell B, Grill WM. 2015. Design of electrodes for stimulation and recording. In Implantable Neuroprostheses for Restoring Function , ed. K Kilgore, pp. 59-93. Amsterdam: Elsevier\n\n- 46. Cui X, Wiler J, Dzaman M, Altschuler RA, Martin DC. 2003. In vivo studies of polypyrrole/peptide coated neural probes. Biomaterials 24:777-87\n\n- 47. Kennedy PR, Bakay RAE, Sharpe SM. 1992. Behavioral correlates of action potentials recorded chronically inside the cone electrode. Neuroreport 3:605-8\n\n- 48. Lacour SP, Courtine G, Guck J. 2016. Materials and technologies for soft implantable neuroprostheses. Nat. Rev. Mater. 1:16063\n\n- 49. Kipke DR. 2004. Implantable neural probe systems for cortical neuroprostheses. In 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5344-47. Piscataway, NJ: IEEE\n\n- 50. Merletti R, Holobar A, Farina D. 2008. Analysis of motor units with high-density surface electromyography. J. Electromyogr. Kinesiol. 18:879-90\n\n- 51. Smith LH, Hargrove LJ. 2013. Comparison of surface and intramuscular EMG pattern recognition for simultaneous wrist/hand motion classification. In 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4223-6. Piscataway, NJ: IEEE\n\n- 52. Farrell TR, Weir RF. 2008. A comparison of the effects of electrode implantation and targeting on pattern classification accuracy for prosthesis control. IEEE Trans. Biomed. Eng. 55:2198-211\n\n- 53. Cracchiolo M, Valle G, Petrini F, Strauss I, Granata G, et al. 2020. Decoding of grasping tasks from intraneural recordings in trans-radial amputee. J. Neural Eng. 17:026034\n\n- 54. Wendelken S, Page DM, Davis T, Wark HAC, Kluger DT, et al. 2017. Restoration of motor control and proprioceptive and cutaneous sensation in humans with prior upper-limb amputation via multiple Utah Slanted Electrode Arrays (USEAs) implanted in residual peripheral arm nerves. J. Neuroeng. Rehabil. 14:121\n\n- 55. Cipriani C, Dalonzo M, Carrozza MC. 2012. A miniature vibrotactile sensory substitution device for multifingered hand prosthetics. IEEE Trans. Biomed. Eng. 59:400-8\n\n- 56. Chen B, Feng Y, Wang Q. 2016. Combining vibrotactile feedback with volitional myoelectric control for robotic transtibial prostheses. Front. Neurorobot. 10:8\n\n- 57. Antfolk C, D'Alonzo M, Controzzi M, Lundborg G, Rosen B, et al. 2013. Artificial redirection of sensation from prosthetic fingers to the phantom hand map on transradial amputees: vibrotactile versus mechanotactile sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 21:112-20\n\n- 58. Gonzalez J, Soma H, Sekine M, Yu W. 2012. Psycho-physiological assessment of a prosthetic hand sensory feedback system based on an auditory display: a preliminary study. J. Neuroeng. Rehabil. 9:33\n\n- 59. Osborn L, Betthauser J, Kaliki R, Thakor N. 2018. T argeted transcutaneous electrical nerve stimulation for phantom limb sensory feedback. In 2017 IEEE Biomedical Circuits and Systems Conference . Piscataway, NJ: IEEE. https://doi.org/10.1109/BIOCAS.2017.8325200\n\n- 60. D'Anna E, Petrini FM, Artoni F, Popovic I, Simani\u00b4 c I, et al. 2017. A somatotopic bidirectional hand prosthesis with transcutaneous electrical nerve stimulation based sensory feedback. Sci. Rep. 7:10930\n\n- 61. Oddo CM, Raspopovic S, Artoni F, Mazzoni A, Spigler G, et al. 2016. Intraneural stimulation elicits discrimination of textural features by artificial fingertip in intact and amputee humans. eLife 5:e09148\n\n- 62. Valle G, Mazzoni A, Iberite F, D'Anna E, Strauss I, et al. 2018. Biomimetic intraneural sensory feedback enhances sensation naturalness, tactile sensitivity, and manual dexterity in a bidirectional prosthesis. Neuron 100:37-45.e7\n\n- 63. Valle G, D'Anna E, Strauss I, Clemente F, Granata G, et al. 2020. Hand control with invasive feedback is not impaired by increased cognitive load. Front. Bioeng. Biotechnol. 8:287\n\n- 64. D'Anna E, Valle G, Mazzoni A, Strauss I, Iberite F, et al. 2019. A closed-loop hand prosthesis with simultaneous intraneural tactile and position feedback. Sci. Robot. 4:eaau8892\n\n- 65. Shokur S, Gallo S, Moioli RC, Donati ARC, Morya E, et al. 2016. Assimilation of virtual legs and perception of floor texture by complete paraplegic patients receiving artificial tactile feedback. Sci. Rep. 6:32293\n\n- 66. Geethanjali P . 2016. Myoelectric control of prosthetic hands: state-of-the-art review. Med. Devices Evid. Res. 9:247-55\n\n- 67. Farina D, Jiang N, Rehbaum H, Holobar A, Graimann B, et al. 2014. The extraction of neural information from the surface EMG for the control of upper-limb prostheses: emerging avenues and challenges. IEEE Trans. Neural Syst. Rehabil. Eng. 22:797-809\n\n- 68. Ferguson S, Dunlop GR. 2002. Grasp recognition from myoelectric signals. In Proceedings of the Australasian Conference on Robotics and Automation , ed. W Friedrich, P Lim, pp. 83-87. Sydney: Aust. Robot. Autom. Assoc.\n\n- 69. Martelloni C, Carpaneto J, Micera S. 2008. Classification of upper arm EMG signals during objectspecific grasp. In 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 5061-64. Piscataway, NJ: IEEE\n\n- 70. Kakoty NM, Hazarika SM. 2011. Recognition of grasp types through principal components of DWT based EMG features. In 2011 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/ICORR.2011.5975398\n\n- 71. Castellini C, Van Der Smagt P . 2009. Surface EMG in advanced hand prosthetics. Biol. Cybern. 100:35-47\n\n- 72. Atzori M, Cognolato M, M\u00fcller H. 2016. Deep learning with convolutional neural networks applied to electromyography data: a resource for the classification of movements for prosthetic hands. Front. Neurorobot. 10:9\n\n- 73. Tenore FVG, Ramos A, Fahmy A, Acharya S, Etienne-Cummings R, Thakor NV. 2009. Decoding of individuated finger movements using surface electromyography. IEEE Trans. Biomed. Eng. 56:1427-34\n\n- 74. Bhattachargee CK, Sikder N, Hasan MT, Nahid A. 2019. Finger movement classification based on statistical and frequency features extracted from surface EMG signals. In 2019 International Conference on Computer, Communication, Chemical, Materials and Electronic Engineering . Piscataway, NJ: IEEE. https://doi.org/10.1109/IC4ME247184.2019.9036671\n\n- 75. Bhagwat S,Mukherji P.2020.Electromyogram (EMG) based fingers movement recognition using sparse filtering of wavelet packet coefficients. S\u00af adhan\u00af a 45:3\n\n- 76. Muceli S, Farina D. 2012. Simultaneous and proportional estimation of hand kinematics from EMG during mirrored movements at multiple degrees-of-freedom. IEEE Trans. Neural Syst. Rehabil. Eng. 20:37178\n\n- 77. Jiang N, Vest-Nielsen JL, Muceli S, Farina D. 2012. EMG-based simultaneous and proportional estimation of wrist/hand kinematics in uni-lateral trans-radial amputees. J. Neuroeng. Rehabil. 9:42\n\n- 78. Hioki M, Kawasaki H. 2012. Estimation of finger joint angles from sEMG using a neural network including time delay factor and recurrent structure. ISRN Rehabil . 2012:604314\n\n- 79. Zhuang KZ,Sommer N,Mendez V,Aryan S,Formento E,et al.2019.Shared human-robot proportional control of a dexterous myoelectric prosthesis. Nat. Mach. Intell. 1:400-11\n\n- 80. Mussa-Ivaldi FA, Casadio M, Danziger ZC, Mosier KM, Scheidt RA. 2011. Sensory motor remapping of space in human-machine interfaces. Prog. Brain Res. 191:45-64\n\n- 81. Dyson M, Barnes J, Nazarpour K. 2018. Myoelectric control with abstract decoders. J. Neural Eng. 15:056003\n\n- 82. Dyson M, Dupan S, Jones H, Nazarpour K. 2020. Learning, generalization, and scalability of abstract myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:1539-47\n\n- 83. Daley H,Englehart K,Hargrove L,Kuruganti U.2012.High density electromyography data of normally limbed and transradial amputee subjects for multifunction prosthetic control. J. Electromyogr. Kinesiol. 22:478-84\n\n- 84. Hargrove L,Englehart K,Hudgins B.2006.The effect of electrode displacements on pattern recognition based myoelectric control. In 2006 International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 2203-6. Piscataway, NJ: IEEE\n\n- 85. Boschmann A, Platzner M. 2014. T owards robust HD EMG pattern recognition: reducing electrode displacement effect using structural similarity. In 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , pp. 4547-50. Piscataway, NJ: IEEE\n\n- 86. Stango A, Negro F, Farina D. 2015. Spatial correlation of high density EMG signals provides features robust to electrode number and shift in pattern recognition for myocontrol. IEEE Trans. Neural Syst. Rehabil. Eng. 23:189-98\n\n- 87. Farina D, Holobar A, Merletti R, Enoka RM. 2010. Decoding the neural drive to muscles from the surface electromyogram. Clin. Neurophysiol. 121:1616-23\n\n- 88. Kapelner T, Negro F, Aszmann OC, Farina D. 2018. Decoding motor unit activity from forearm muscles: perspectives for myoelectric control. IEEE Trans. Neural Syst. Rehabil. Eng. 26:244-51\n\n- 89. Dai C, Hu X. 2020. Finger joint angle estimation based on motoneuron discharge activities. IEEE J. Biomed. Heal. Inform. 24:760-67\n\n- 90. Hu Y, Wong Y, Wei W, Du Y, Kankanhalli M, Geng W. 2018. A novel attention-based hybrid CNNRNNarchitecture for sEMG-based gesture recognition. PLOS ONE 13:e0206049\n\n- 91. Olsson AE, Sager P, Andersson E, Bj\u00f6rkman A, Male\u0161evi\u00b4 c N, Antfolk C. 2019. Extraction of multilabelled movement information from the raw HD-sEMG image with time-domain depth. Sci. Rep. 9:7244\n\n- 92. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. Regression convolutional neural network for improved simultaneous EMG control. J. Neural Eng. 16:036015\n\n- 93. Xia P, Hu J, Peng Y. 2018. EMG-based estimation of limb movement using deep learning with recurrent convolutional neural networks. Artif. Organs 42:E67-77\n\n- 94. Alom MZ, Taha TM, Yakopcic C, Westberg S, Sidike P, et al. 2018. The history began from AlexNet: a comprehensive survey on deep learning approaches. arXiv:1803.01164 [cs.CV]\n\n- 95. Patricia N, Caputo B. 2014. Learning to learn, from transfer learning to domain adaptation: a unifying perspective. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , pp. 1442-49. Piscataway, NJ: IEEE\n\n- 96. Tommasi T, Orabona F, Castellini C, Caputo B. 2013. Improving control of dexterous hand prostheses using adaptive learning. IEEE Trans. Robot. 29:207-19\n\n- 97. C\u00f4t\u00e9-Allard U, Fall CL, Drouin A, Campeau-Lecours A, Gosselin C, et al. 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans. Neural Syst. Rehabil. Eng. 27:760-71\n\n- 98. Du Y, Jin W, Wei W, Hu Y, Geng W. 2017. Surface EMG-based inter-session gesture recognition enhanced by deep domain adaptation. Sensors 17:6-9\n\n- 99. Ameri A, Akhaee MA, Scheme E, Englehart K. 2019. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. IEEE Trans. Neural Syst. Rehabil. Eng. 28:370-79\n\n- 100. Phinyomark A, Scheme E. 2018. EMG pattern recognition in the era of big data and deep learning. Big Data Cogn. Comput. 2:21\n\n- 101. Khamparia A, Singh KM. 2019. A systematic review on deep learning architectures and applications. Expert Syst . 36:e12400\n\n- 102. Biddiss E, Chau T. 2007. Upper-limb prosthetics: critical factors in device abandonment. Am. J. Phys. Med. Rehabil. 86:977-87\n\n- 103. Do\u0161en S, Cipriani C, Kosti\u00b4 c M, Controzzi M, Carrozza MC, Popovi\u02c7 c DB. 2010. Cognitive vision system for control of dexterous prosthetic hands: experimental evaluation. J. Neuroeng. Rehabil. 7:42\n\n- 104. Light CM, Chappell PH, Hudgins B, Engelhart K. 2002. Intelligent multifunction myoelectric control of hand prostheses. J. Med. Eng. Technol. 26:139-46\n\n- 105. Fani S, Bianchi M, Jain S, Neto JSP, Boege S, et al. 2016. Assessment of myoelectric controller performance and kinematic behavior of a novel soft synergy-inspired robotic hand for prosthetic applications. Front. Neurorobot. 10:11\n\n- 106. Smith LH, Kuiken TA, Hargrove LJ. 2014. Real-time simultaneous and proportional myoelectric control using intramuscular EMG. J. Neural Eng. 11:066013\n\n- 107. Pasquina PF, Evangelista M, Carvalho AJ, Lockhart J, Griffin S, et al. 2015. First-in-man demonstration of a fully implanted myoelectric sensors system to control an advanced electromechanical prosthetic hand. J. Neurosci. Methods 244:85-93\n\n- 108. Zia ur Rehman M, Gilani S, Waris A, Niazi I, Slabaugh G, et al. 2018. Stacked sparse autoencoders for EMG-based classification of hand motions: a comparative multi day analyses between surface and intramuscular EMG. Appl. Sci. 8:1126\n\n- 109. Kamavuako EN, Scheme EJ, Englehart KB. 2014. Combined surface and intramuscular EMG for improved real-time myoelectric control performance. Biomed. Signal. Process. Control 10:102-7\n\n- 110. Dantas H, Warren DJ, Wendelken SM, Davis TS, Clark GA, Mathews VJ. 2019. Deep learning movement intent decoders trained with dataset aggregation for prosthetic limb control. IEEE Trans. Biomed. Eng. 66:3192-203\n\n- 111. Petrini FM, Mazzoni A, Rigosa J, Giambattistelli F, Granata G, et al. 2019. Microneurography as a tool to develop decoding algorithms for peripheral neuro-controlled hand prostheses. BioMed. Eng. OnLine 18:44\n\n- 112. Rossini PM, Micera S, Benvenuto A, Carpaneto J, Cavallo G, et al. 2010. Double nerve intraneural interface implant on a human amputee for robotic hand control. Clin. Neurophysiol. 121:777-83\n\n- 113. Davis TS, Wark HAC, Hutchinson DT, Warren DJ, O'Neill K, et al. 2016. Restoring motor control and sensory feedback in people with upper extremity amputations using arrays of 96 microelectrodes implanted in the median and ulnar nerves. J. Neural Eng. 13:036001\n\n- 114. Petrini FM, Valle G, Strauss I, Granata G, Di Iorio R, et al. 2019. Six-month assessment of a hand prosthesis with intraneural tactile feedback. Ann. Neurol. 85:137-54\n\n- 115. Mazzoni A, Oddo CM, Valle G, Camboni D, Strauss I, et al. 2020. Morphological neural computation restores discrimination of naturalistic textures in trans-radial amputees. Sci. Rep. 10:527\n\n- 116. Graczyk EL, Schiefer MA, Saal HP, Delhaye BP, Bensmaia SJ, Tyler DJ. 2016. The neural basis of perceived intensity in natural and artificial touch. Sci. Transl. Med. 8:362ra142\n\n- 117. Kogler V, Nguyen TAK, Digiovanna J, Micera S. 2011. Recording vestibular evoked potentials induced by electrical stimulation of the horizontal semicircular canal in guinea pig. In 2011 5th International IEEE/EMBS Conference on Neural Engineering , pp. 261-64. Piscataway, NJ: IEEE\n\n- 118. Micera S, Carpaneto J, Raspopovic S. 2010. Control of hand prostheses using peripheral information. IEEE Rev. Biomed. Eng. 3:48-68\n\n- 119. Englehart K,Hudgins B.2003.A robust,real-time control scheme for multifunction myoelectric control. IEEE Trans. Biomed. Eng. 50:848-54\n\n- 120. Park M, Bok BG, Ahn JH, Kim MS. 2018. Recent advances in tactile sensing technology. Micromachines 9:321\n\n- 121. Pfeifer R, Iida F, G\u00f3mez G. 2006. Morphological computation for adaptive behavior and cognition. Int. Congr. Ser. 1291:22-9\n\n- 122. Kim Y, Chortos A, Xu W, Liu Y, Oh JY, et al. 2018. A bioinspired flexible organic artificial afferent nerve. Science 360:998-1003\n\n- 123. WuJ, Jia QS, Johansson KH, Shi L. 2013. Event-based sensor data scheduling: trade-off between communication rate and estimation quality. IEEE Trans. Autom. Control 58:1041-6\n\n- 124. Bartolozzi C, Ros PM, Diotalevi F, Jamali N, Natale L, et al. 2017. Event-driven encoding of off-theshelf tactile sensors for compression and latency optimisation for robotic skin. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems , pp. 166-73. Piscataway, NJ: IEEE\n\n- 125. Lee WW,Tan YJ,Yao H,Li S,See HH,et al. 2019. A neuro-inspired artificial peripheral nervous system for scalable electronic skins. Sci. Robot. 4:eaax2198\n\n- 126. Antfolk C, D'Alonzo M, Ros\u00e9n B, Lundborg G, Sebelius F, Cipriani C. 2013. Sensory feedback in upper limb prosthetics. Expert Rev. Med. Devices 10:45-54\n\n- 127. Mann RW, Reimers SD. 1970. Kinesthetic sensing for the EMG controlled 'Boston Arm.' IEEE Trans. Man-Mach. Syst. 11:110-15\n\n- 128. Patterson PE, Katz JA. 1992. Design and evaluation of a sensory feedback system that provides grasping pressure in a myoelectric hand. J. Rehabil. Res. Dev. 29:1-8\n\n- 129. Clemente F, D'Alonzo M, Controzzi M, Edin BB, Cipriani C. 2016. Non-invasive, temporally discrete feedback of object contact and release improves grasp control of closed-loop myoelectric transradial prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 24:1314-22\n\n- 130. D'Alonzo M, Clemente F, Cipriani C. 2015. Vibrotactile stimulation promotes embodiment of an alien hand in amputees with phantom sensations. IEEE Trans. Neural Syst. Rehabil. Eng. 23:450-57\n\n- 131. Stephens-Fripp B, Alici G, Mutlu R. 2018. A review of non-invasive sensory feedback methods for transradial prosthetic hands. IEEE Access 6:6878-99\n\n- 132. Dosen S, Markovic M, Strbac M, Belic M, Kojic V, et al. 2017. Multichannel electrotactile feedback with spatial and mixed coding for closed-loop control of grasping force in hand prostheses. IEEE Trans. Neural Syst. Rehabil. Eng. 25:183-95\n\n- 133. Geng B,Dong J,Jensen W,Dosen S,Farina D,Kamavuako EN.2018.Psychophysical evaluation of subdermal electrical stimulation in relation to prosthesis sensory feedback. IEEE Trans. Neural Syst. Rehabil. Eng. 26:709-15\n\n- 134. Dong J, Geng B, Niazi IK, Amjad I, Dosen S, et al. 2020. The variability of psychophysical parameters following surface and subdermal stimulation: a multiday study in amputees. IEEE Trans. Neural Syst. Rehabil. Eng. 28:174-80\n\n- 135. Flesher SN, Downey JE, Weiss JM, Hughes CL, Herrera AJ, et al. 2019. Restored tactile sensation improves neuroprosthetic arm control. bioRxiv 653428. https://doi.org/10.1101/653428\n\n- 136. Graczyk EL, Resnik L, Schiefer MA, Schmitt MS, Tyler DJ. 2018. Home use of a neural-connected sensory prosthesis provides the functional and psychosocial experience of having a hand again. Sci. Rep. 8:9866\n\n|   137. | George JA, Page DM, Davis TS, Duncan CC, Hutchinson T, et al. 2020. Long-term performance of Utah Slanted Electrode Arrays and intramuscular electromyographic leads implanted chronically in human arm nerves and muscles. bioRxiv 2020.03.30.016683. https://doi.org/10.1101/2020.03.30. 016683                                                      |\n\n|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\n|    138 | Ortiz-Catalan M, Mastinu E, Sassu P, Aszmann O, Br\u00e5nemark R. 2020. Self-contained neuromuscu- loskeletal arm prostheses. N. Engl. J. Med. 382:1732-38                                                                                                                                                                                                  |\n\n|    139 | George JA, Kluger DT,Davis TS,Wendelken SM,Okorokova EV,et al.2019.Biomimetic sensory feed- back through peripheral nerve stimulation improves dexterous use of a bionic hand. Sci. Robot. 4:eaax2352                                                                                                                                                  |\n\n|    140 | Chandrasekaran S,Nanivadekar AC,McKernan G,Helm ER,Boninger ML,et al.2020.Sensory restora- tion by epidural stimulation of the lateral spinal cord in upper-limb amputees. eLife 9:e54349                                                                                                                                                              |\n\n|    141 | Controzzi M, Clemente F, Barone D, Luciani LB, Pierotti N, et al. 2019. Progress towards the devel- opment of the DeTOP hand prosthesis: a sensorized transradial prosthesis for clinical use. In Converg- ing Clinical and Engineering Research on Neurorehabilitation III , ed. L Masia, S Micera, M Akay, J Pons, pp. 103-6. Cham, Switz.: Springer |\n\n|    142 | Formento E,D'Anna E,Gribi S,Lacour SP,Micera S.2019.A biomimetic electrical stimulation strategy to induce asynchronous stochastic neural activity. J. Neural Eng. 17:046019                                                                                                                                                                           |\n\n|    143 | Sengupta A, Ye Y, Wang R, Liu C, Roy K. 2019. Going deeper in spiking neural networks: VGG and residual architectures. Front Neurosci . 13:95                                                                                                                                                                                                          |\n\n|    144 | Lindner HYN, N\u00e4tterlund BS, Hermansson LMN. 2010. Upper limb prosthetic outcome measures: review and content comparison based on International Classification of Functioning, Disability and Health. Prosthet. Orthot. Int. 34:109-28                                                                                                                  |\n\n|    145 | Hill W, Stavdahl \u00d8, Hermansson LN, Kyberd P, Swanson S, Hubbard S. 2009. Functional outcomes in the WHO-ICF model: establishment of the upper limb prosthetic outcome measures group. J. Prosthet. Orthot. 21:115-19                                                                                                                                   |\n\n|    146 | Hudak PL, Amadio PC, Bombardier C. 1996. Development of an upper extremity outcome measure: the DASH (Disabilities of the Arm, Shoulder, and Head). Am. J. Ind. Med. 29:602-8                                                                                                                                                                          |\n\n|    147 | Beaton DE, Wright JG, Katz JN, Amadio P, Bombardier C, et al. 2005. Development of the Quick- DASH: comparison of three item-reduction approaches. J. Bone Jt. Surg. A 87:1038-46                                                                                                                                                                      |\n\n|    148 | Harper A, Power M, Orley J, Herrman H, Schofield H, et al. 1998. Development of the World Health Organization WHOQOL-BREF quality of life assessment. Psychol. Med. 28:551-58                                                                                                                                                                          |\n\n|    149 | Burckhardt CS, Anderson KL. 2003. The Quality of Life Scale (QOLS): reliability, validity, and utiliza- tion. Health Qual. Life Outcomes 1:60                                                                                                                                                                                                          |\n\n|    150 | Heinemann AW, Bode RK, O'Reilly C. 2003. Development and measurement properties of the Or- thotics and Prosthetics User's Survey (OPUS): a comprehensive set of clinical outcome instruments. Prosthet. Orthot. Int. 27:191-206                                                                                                                        |\n\n|    151 | Lendaro E,Middleton A,Brown S,Ortiz-Catalan M.2020.Out of the clinic, into the home: the in-home use of phantom motor execution aided by machine learning and augmented reality for the treatment of phantom limb pain. J. Pain Res. 13:195-209                                                                                                        |\n\n|    152 | Johansson RS, Flanagan JR. 2009. Coding and use of tactile signals from the fingertips in object manip- ulation tasks. Nat. Rev. Neurosci. 10:345-59                                                                                                                                                                                                   |\n\n|    153 | Taub E, Uswatte G, Pidikiti R. 1999. Constraint-induced movement therapy: a new family of techniques with broad application to physical rehabilitation-a clinical review. J. Rehabil. Res. Dev. 36:237-51                                                                                                                                              |\n\n|    154 | Mathiowetz V, Volland G, Kashman N, Weber K. 1985. Adult norms for the Box and Block T est of manual dexterity. Am. J. Occup. Ther. 39:386-91                                                                                                                                                                                                          |\n\n|    155 | Hebert JS, Lewicke J. 2012. Case report of modified box and blocks test with motion capture to measure prosthetic function. J. Rehabil. Res. Dev. 49:1163-74                                                                                                                                                                                           |\n\n|    156 | Hebert JS, Lewicke J, Williams TR, Vette AH. 2014. Normative data for modified box and blocks test measuring upper-limb function via motion capture. J. Rehabil. Res. Dev. 51:919-31                                                                                                                                                                   |\n\n|    157 | Mathiowetz V, Weber K, Kashman N, Volland G. 1985. Adult norms for the Nine Hole Peg T est of finger dexterity. Occup. Ther. J. Res. 5:24-38                                                                                                                                                                                                           |\n\n- 158. Lambercy O,Fluet MC,Lamers I,Kerkhofs L,Feys P, Gassert R. 2013. Assessment of upper limb motor function in patients with multiple sclerosis using the Virtual Peg Insertion T est: a pilot study. In 2013 IEEE International Conference on Rehabilitation Robotics . Piscataway, NJ: IEEE. https://doi.org/10.1109/\n",
    "topic": "Emerging technologies in sensor design, such as event-driven tactile sensors and flexible organic artificial afferent nerves, and their potential applications in prosthetics.",
    "response": "<document_analysis>\nThe provided context is a comprehensive list of literature citations related to robotics, prosthetic hands, neural interfaces, EMG control, sensory feedback, and related neuroprosthetic technologies. Among these numerous references, several specifically address emerging sensor technologies and bioinspired sensor designs with potential applications in prosthetics. Notably, references 123-125 discuss event-driven encoding and neuro-inspired artificial peripheral nervous systems for tactile sensing, highlighting advances in sensor data compression, latency optimization, and scalable electronic skins. Reference 122 mentions a bioinspired flexible organic artificial afferent nerve, which suggests a biomimetic approach to sensory feedback integration in prosthetic devices. These technologies represent cutting-edge approaches to enhance tactile feedback, reduce computational and communication overhead, and improve the naturalness and responsiveness of prosthetic limbs.\n\nImplicit in these references is the understanding that emerging sensor technologies must reconcile biological principles with engineering constraints to provide intuitive, real-time sensory feedback for prosthesis users. Event-driven sensors mimic biological spike-based signaling, enabling efficient and fast communication, while flexible organic afferent nerves replicate the function of natural peripheral nerves, potentially allowing seamless integration into the user's nervous system.\n\nDifficulty rating: 9/10 \u2014 The question requires expert understanding of advanced sensor technologies, neuroengineering principles, and their application in prosthetics, including the implications of event-driven encoding and bioinspired designs.\n\nThe question aims to probe deep comprehension of how these emerging sensor technologies function, their advantages over traditional sensors, and their potential to transform prosthetic sensory feedback. It encourages reflection on the integration challenges and the biological inspiration behind sensor design, fostering a critical and nuanced understanding relevant to domain experts.\n\nGiven the meaningful and highly technical content, generating a single challenging question-answer pair is fully justified.\n\n</document_analysis>\n<output_format>\nQuestion: How do event-driven tactile sensors and bioinspired flexible organic artificial afferent nerves improve sensory feedback in prosthetic hands, and what are the key advantages of these technologies compared to traditional continuous sensing methods?\n\nExplanation: Event-driven tactile sensors encode sensory information only upon changes or events, mimicking biological spike signaling, which reduces data redundancy and latency, enabling faster and more efficient tactile information processing. Flexible organic artificial afferent nerves replicate the physiological properties of natural peripheral nerves, providing scalable, compliant, and biomimetic pathways for transmitting sensory signals with high fidelity. Together, these technologies offer low-latency, energy-efficient, and naturalistic sensory feedback, overcoming limitations of traditional continuous sensing systems that generate large volumes of data and often lack biological compatibility.\n\nCorrect Answer: By mimicking biological spike-based signaling, event-driven sensors reduce data and latency, while flexible organic afferent nerves provide biomimetic, compliant signal transmission, together enabling faster, more efficient, and natural sensory feedback compared to traditional continuous sensing methods.\n</output_format>",
    "question": "How do event-driven tactile sensors and bioinspired flexible organic artificial afferent nerves improve sensory feedback in prosthetic hands, and what are the key advantages of these technologies compared to traditional continuous sensing methods?",
    "answer": "By mimicking biological spike-based signaling, event-driven sensors reduce data and latency, while flexible organic afferent nerves provide biomimetic, compliant signal transmission, together enabling faster, more efficient, and natural sensory feedback compared to traditional continuous sensing methods.",
    "explanation": "Event-driven tactile sensors encode sensory information only upon changes or events, mimicking biological spike signaling, which reduces data redundancy and latency, enabling faster and more efficient tactile information processing. Flexible organic artificial afferent nerves replicate the physiological properties of natural peripheral nerves, providing scalable, compliant, and biomimetic pathways for transmitting sensory signals with high fidelity. Together, these technologies offer low-latency, energy-efficient, and naturalistic sensory feedback, overcoming limitations of traditional continuous sensing systems that generate large volumes of data and often lack biological compatibility.",
    "question_token_count": 42,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 51
  },
  {
    "context": "## Figure 1\nExamples of functioning hand replacement. ( a ) A personalized cosmetic hand solution (ITOP , Italy) provides a natural look. Photos adapted with permission from ITOP and Procosil. ( ) A body-powered prosthetic solution (Ottobock, Germany) is a common approach b for people with an upper-limb amputation. Photo reproduced with permission from Ottobock. ( ) An sEMG-based pattern recognition c system (Gen2, Coapt, USA) allows grasp classification. Photo adapted courtesy of Coapt LLC ( http://www.coaptengineering.com ). ( d ) sEMG control and extracellular stimulation via an implanted FINE were used to convey sensory feedback for home-use applications. The implant was stable for more than five years, and home-use electrical stimulation for sensory feedback was investigated for up to 13 days (116). Panel adapted from Reference 116 (CC BY-SA 4.0). ( ) Fully implanted myoelectric sensors provide stronger e and more reliable signals that do not change with arm positioning, socket rotation, or sweating (107). Panel adapted with permission from Reference 107. ( f ) Six-DOF prosthetic hand control (i-Limb Ultra, \u00d6ssur, Iceland) uses threshold-based sEMG control and cocontraction to switch between grasps. ( g ) Sensory feedback conveyed via intraneural TIMEs enables the encoding of objects' shape and stiffness (6). Panel reproduced with permission; copyright 2014 Lifehand 2 / Patrizia T occi. ( h ) Hand transplantation is a promising technique that has not yet become a standard procedure due to several surgical and clinical difficulties. Panel adapted with permission from Reference 177. Abbreviations: DOF, degree of freedom; FINE, flat interface nerve electrode; sEMG, surface electromyography; TIME, transverse intrafascicular multichannel electrode.\n\nsurvey of below-elbow amputees from Sweden, the United Kingdom, and Canada (7), 53% of the respondents wore a cosmetic prosthesis, 13% used a hook, 4% used a cable hand, and 30% used a myoelectric RPH. Despite encouraging results in the late 1990s (8), hand transplantation ( Figure 1 h ) encountered significant surgical and clinical difficulties (rejection and immunosuppression); it has therefore been tested in only a few patients and is not yet considered one of the available options.\n",
    "topic": "The role and mechanism of implanted electrodes such as flat interface nerve electrodes (FINE) and transverse intrafascicular multichannel electrodes (TIME) in providing sensory feedback for prosthetic hand users.",
    "response": "<document_analysis>\nThe provided context offers a detailed overview of various prosthetic hand technologies, specifically highlighting the use of implanted electrodes like flat interface nerve electrodes (FINE) and transverse intrafascicular multichannel electrodes (TIME) for sensory feedback. The text mentions that FINE electrodes were used for stable, long-term home-use applications with electrical stimulation to convey sensory feedback, maintaining stability for over five years and functional sensory stimulation for up to 13 days. Additionally, TIME electrodes are noted for enabling the encoding of objects' shape and stiffness, indicating advanced sensory feedback capabilities. The context also contrasts implanted electrodes with surface electromyography (sEMG) approaches, emphasizing the improved reliability and signal strength of implanted sensors unaffected by arm position or sweating. The text briefly notes the clinical challenges of hand transplantation but focuses more heavily on prosthetic control and sensory restoration via implanted electrodes.\n\nImplicit in the context is the understanding that implanted electrodes interface directly with peripheral nerves to provide bidirectional communication\u2014motor command input and sensory feedback output\u2014which is crucial for intuitive prosthetic hand use. The FINE and TIME electrodes differ in design and interface but share the goal of restoring sensory modalities such as touch and proprioception, which are vital for dexterous manipulation.\n\nThe complexity of the question arises from requiring knowledge of neuroprosthetics, electrode design, nerve interface biology, and sensory encoding mechanisms. A high-level expert must integrate knowledge of how these electrodes achieve stable, long-term implantation, the neural coding strategies for sensory feedback, and the clinical implications of their use.\n\nDifficulty rating: 9/10, given the specialized technical knowledge required in neuroengineering and clinical prosthetics.\n\nThe planned question aims to probe an expert\u2019s deep understanding of how implanted electrodes function mechanistically to restore sensory feedback, the advantages over non-implanted systems, and the significance of encoding tactile features such as shape and stiffness. It encourages reflection on the implications of these technologies for prosthetic functionality and user experience.\n\nThis question is highly purposeful because sensory feedback is a critical frontier in prosthetic development, and understanding the role of implanted electrodes is key to advancing clinical solutions.\n\nNo irrelevant or bogus content was found; all information is coherent, meaningful, and valuable for generating a challenging question.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do implanted electrodes such as flat interface nerve electrodes (FINE) and transverse intrafascicular multichannel electrodes (TIME) mechanistically enable sensory feedback in prosthetic hand users, and what are the advantages of their neural interface designs in encoding tactile properties like object shape and stiffness compared to surface electromyography-based systems?\n\nExplanation: Implanted electrodes like FINE and TIME interface directly with peripheral nerves to deliver electrical stimulation that mimics natural sensory signals, enabling users to perceive tactile information such as shape and stiffness. Their designs allow stable, selective activation of nerve fibers, providing precise sensory encoding that is not influenced by external factors like arm position or sweating, unlike surface electromyography systems. This direct neural interface facilitates richer, more intuitive sensory feedback critical for advanced prosthetic control.\n\nCorrect Answer: By directly stimulating peripheral nerve fibers, FINE and TIME electrodes provide stable, selective sensory feedback encoding tactile features, offering more precise and reliable sensation than surface electromyography systems which lack direct nerve interfacing.\n</output_format>",
    "question": "How do implanted electrodes such as flat interface nerve electrodes (FINE) and transverse intrafascicular multichannel electrodes (TIME) mechanistically enable sensory feedback in prosthetic hand users, and what are the advantages of their neural interface designs in encoding tactile properties like object shape and stiffness compared to surface electromyography-based systems?",
    "answer": "By directly stimulating peripheral nerve fibers, FINE and TIME electrodes provide stable, selective sensory feedback encoding tactile features, offering more precise and reliable sensation than surface electromyography systems which lack direct nerve interfacing.",
    "explanation": "Implanted electrodes like FINE and TIME interface directly with peripheral nerves to deliver electrical stimulation that mimics natural sensory signals, enabling users to perceive tactile information such as shape and stiffness. Their designs allow stable, selective activation of nerve fibers, providing precise sensory encoding that is not influenced by external factors like arm position or sweating, unlike surface electromyography systems. This direct neural interface facilitates richer, more intuitive sensory feedback critical for advanced prosthetic control.",
    "question_token_count": 67,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 42
  },
  {
    "context": "## 4.4. Perspectives\nMotor decoding for RPHs is progressing in two main directions: Noninvasive approaches have seen advances in decoding algorithms using large data sets and increases in the number of recording points, and implanted electrodes (either muscular or intraneural) have seen improvements that enable better recording stability and more robust decoding. There is currently no consensus on which approach is best for transradial amputee patients, as they each have their own strengths and limitations. The need for daily signal and classification recalibration is a weak point of the classic sEMG approach, which is being addressed by several research groups developing, for example, HD-sEMG.And despite iEMG's promising control performance, which is robust to donning and doffing of the prosthesis, its overall performance gain, when compared with sEMG, may not currently be sufficient to justify an invasive surgery. The same reasoning can be applied to intraneural electrodes.\n\nOne can imagine a future where both invasive and noninvasive approaches will continue to progress and will target either patients who prefer a stable decoding setup or those who do not want to undergo surgery and will accept the need to calibrate their prosthesis on a regular basis (118). Another scenario can be a parallel development of invasive technologies for both sensory and motor functions. Indeed, as shown in Section 5, the approach using intraneural implanted electrodes has permitted unprecedented levels of somatosensory restoration; it might, therefore, be reasonable to perform a single surgery to restore both motor and sensory functions. For this reason, motor decoding using the intraneural interface can become a viable solution if these interfaces one day permit both providing sensory feedback and recording discriminative signals for motor decoding in parallel, but online artifact removal remains an important challenge.\n\nPower consumption is another critical issue: RPHs should embed small electronics because the size of the prosthesis limits the space available for batteries, but doing so usually comes at the cost of limited processing resources. Also, the electronics for the HD-sEMG remain cumbersome due to the large number of input channels and should be miniaturized and portable. Moreover, decoding model complexity is also limited by portable processing resources. In practice, an increased number of electrodes is already available in wearable systems (Sessantaquattro, OT Bioelettronica, Italy) and may become available for prostheses in the future.\n\nFinally, low latency is paramount for seamless prosthesis control [ &lt; 300 ms between user intention and real-time decoding (119)]. Among the studies discussed above, only a few performed analyses to show the feasibility of real-time control (without processing resource limitations), and even fewer included embedded electronics that would translate for home use. One possible solution for real-time decoding with complex models is to bypass embedded electronic limitations; this could be achieved by taking advantage of the computational power of cell phones or by relying on cloud computing and the next generations of wireless cellular networks for low-latency communication.\n",
    "topic": "Prospects and challenges of leveraging external computational resources such as smartphones or cloud computing to overcome embedded processing limitations and enable real-time complex decoding.",
    "response": "<document_analysis>\nThe context discusses the current state and future perspectives of motor decoding for robotic prosthetic hands (RPHs), focusing on the trade-offs between invasive and noninvasive methods, technical challenges such as signal stability and power consumption, and the critical requirement of low latency for seamless control. A key technical bottleneck highlighted is the limited processing resources embedded within the prosthesis due to size and power constraints, which restrict the complexity of decoding models that can be used onboard. To overcome this, the text suggests leveraging external computational resources like smartphones or cloud computing combined with advanced wireless networks to provide the necessary computational power for real-time complex decoding.\n\nThis introduces multiple nuanced challenges and implications: the feasibility of offloading intensive decoding computations externally, the latency constraints (<300 ms) required for effective control, the reliability and robustness of wireless communication, and potential trade-offs between embedded autonomy and external dependency. The possibility of integrating external devices to bypass embedded limitations invites critical reflection on system architecture, user experience, security, and the future trajectory of prosthetic control technologies.\n\nThe difficulty level for a question addressing these prospects and challenges is high (rated 9) because it requires understanding prosthetic system limitations, signal processing demands, wireless communication constraints, and the integration of external computational platforms in a real-time medical device context.\n\nThe question should encourage experts to synthesize knowledge of prosthetic control, embedded systems, wireless communication, and computational offloading to evaluate the feasibility, advantages, and drawbacks of such an approach.\n\nHence, the question will probe the interplay between external computational resources and embedded system constraints, focusing on the critical factors that influence the success of this approach in achieving low-latency, real-time complex decoding for prostheses.\n\n</document_analysis>\n\n<output_format>\nQuestion: What are the primary technical and practical challenges in utilizing external computational resources such as smartphones or cloud computing to achieve low-latency (<300 ms) real-time complex decoding for prosthetic hand control, and how might these challenges impact the reliability and user experience of robotic prosthetic hands?\n\nExplanation: The answer identifies the critical issues including latency constraints imposed by wireless communication, variability in network availability and stability, potential security concerns, dependence on external devices which may limit prosthesis autonomy, and how these factors influence decoding reliability and seamless user control.\n\nCorrect Answer: The main challenges include ensuring ultra-low latency communication to meet real-time control demands, maintaining reliable and stable wireless connectivity, addressing security and privacy risks, managing dependence on external devices which may reduce prosthesis autonomy, and overcoming potential interruptions that could degrade decoding reliability and user experience.\n</output_format>",
    "question": "What are the primary technical and practical challenges in utilizing external computational resources such as smartphones or cloud computing to achieve low-latency (<300 ms) real-time complex decoding for prosthetic hand control, and how might these challenges impact the reliability and user experience of robotic prosthetic hands?",
    "answer": "The main challenges include ensuring ultra-low latency communication to meet real-time control demands, maintaining reliable and stable wireless connectivity, addressing security and privacy risks, managing dependence on external devices which may reduce prosthesis autonomy, and overcoming potential interruptions that could degrade decoding reliability and user experience.",
    "explanation": "The answer identifies the critical issues including latency constraints imposed by wireless communication, variability in network availability and stability, potential security concerns, dependence on external devices which may limit prosthesis autonomy, and how these factors influence decoding reliability and seamless user control.",
    "question_token_count": 56,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 55
  },
  {
    "context": "## Transradial amputation:\nThe cosmetic solution is often used for the most distal amputations (e.g., fingers) but is not adapted for patients with a transradial amputation given the dramatic loss of functionality. Bodypowered mechanical hooks, mainly with one-DOF control, are popular solutions thanks to their the partial amputation of the arm below the elbow, at some point along the radial bone\n\nb\n\ne\n\nBattery pack\n\nc\n\nCoil (integrates with prosthetic frame)\n\nCable\n\n(for power and data transmission)\n\nCoil driver module\n\nProsthetic hand\n\nProsthetic control interface\n\nf\n\nBiomimetic: imitating natural processes in order to improve a technical solution\n\nlow price, light weight, and easy maintenance. This type of prosthesis is also well suited for highintensity work due to the control robustness. Also, because the subject must move their shoulder to open and close the hook, these systems have inherent proprioception feedback (9). However, one of the major limitations of the hook solution is the low level of dexterity and nonanthropomorphic appearance. Body-powered hands have solved the anthropomorphic aspect while keeping the robustness of body-powered solutions (10). For example, Baril et al. (11) developed a programmable body-powered hand that can perform different grasp types using a mechanical selector that blocks the closing of one or more fingers. Nevertheless, this solution has its drawback as well: Because of their low mechanical efficiency, body-powered prostheses require large amounts of energy (from 33 N for a hook to 131 N for a hand) to produce a relatively low pinch force (15 N) (12). This could explain their high rejection rate by patients, which ranges between 16% and 66% depending on the survey and time period (13).\n\nHere, we concentrate on RPHs because they potentially offer the most versatile, natural, and power-efficient replacement for amputated hands and could become the default solution for patients. We investigate the challenges in existing RPHs, considering both commercially available solutions ( Supplemental Table 1 ) and those in the research phase ( Supplemental Table 2 ).\n\nMimicking the biomechanics of a hand is not easy. Early prototypes (14) succeeded in designing fingers with skeleton-like structures, but biomimetic actuation was only recently properly implemented using muscle-like actuators (15). The challenge for RPH developers is to embed actuators, sensors, and electronic components into a prosthesis with the same size and weight as the replaced hand (14, 16, 17). Major system integration and miniaturization are necessary before these systems can be used by amputee patients.\n\nInstead, underactuation is a widespread approach to simplify the mechanics while keeping reasonable dexterity. An underactuated system is one where the number of degrees of actuation (DOAs) is smaller than the number of DOFs (see DOA/DOF &lt; 1 in Supplemental Tables 1 and 2 ). The passive (nonactuated) DOFs are exploited to adapt to the surface in contact, as suggested by the concept of morphological computation (18), and to enable a self-adjusting grip without the need to control each articulation. These systems reduce the number of motors needed in the RPH and therefore its complexity, weight, and price.\n",
    "topic": "Examine the role and implications of underactuation in robotic prosthetic hands, including how morphological computation aids in grip adaptability and system simplification.",
    "response": "<document_analysis>\nThe context discusses various prosthetic solutions for transradial amputations, emphasizing robotic prosthetic hands (RPHs) as promising due to their versatility, natural function, and power efficiency. It highlights the technical challenge of mimicking hand biomechanics within the size and weight constraints of a human hand, requiring significant miniaturization and integration of actuators, sensors, and electronics. The text introduces underactuation as a common mechanical design strategy, where the number of actuators (DOAs) is less than the degrees of freedom (DOFs) in the hand. This approach leverages passive joints to adapt to object surfaces, invoking the principle of morphological computation\u2014using the physical structure to simplify control. This reduces motor count, complexity, weight, and cost, but requires a nuanced understanding of the trade-offs between mechanical simplicity and dexterity. The content is highly technical and explores biomechanics, control theory, and engineering design principles in prosthetics. The question focuses on the role and implications of underactuation and morphological computation, which is a complex and current topic in prosthetic development. Difficulty is rated 9/10 due to the requirement for integrated knowledge of robotics, biomechanics, and control systems. The question encourages reflection on how underactuation balances dexterity versus mechanical complexity and how morphological computation enables adaptive gripping without fully actuating all joints. This probes deep understanding of prosthetic design strategies and their functional impact.\n\n</document_analysis>\n<output_format>\nQuestion: How does underactuation in robotic prosthetic hands leverage the principle of morphological computation to enable adaptive grip while reducing system complexity, and what are the key implications of this design choice on prosthetic dexterity and control requirements?\n\nExplanation: Underactuation means fewer actuators than degrees of freedom, so some joints move passively. Morphological computation uses the hand\u2019s mechanical structure to adapt to object surfaces without active control of every joint, allowing self-adjusting grips. This reduces the number of motors, weight, complexity, and cost, simplifying control but can limit the independent dexterity of fingers since some movements are not individually actuated.\n\nCorrect Answer: Underactuation exploits passive joints and morphological computation to enable self-adjusting grips that adapt mechanically to objects, reducing actuator count and control complexity at the cost of some loss in independent finger dexterity.\n</output_format>",
    "question": "How does underactuation in robotic prosthetic hands leverage the principle of morphological computation to enable adaptive grip while reducing system complexity, and what are the key implications of this design choice on prosthetic dexterity and control requirements?",
    "answer": "Underactuation exploits passive joints and morphological computation to enable self-adjusting grips that adapt mechanically to objects, reducing actuator count and control complexity at the cost of some loss in independent finger dexterity.",
    "explanation": "Underactuation means fewer actuators than degrees of freedom, so some joints move passively. Morphological computation uses the hand\u2019s mechanical structure to adapt to object surfaces without active control of every joint, allowing self-adjusting grips. This reduces the number of motors, weight, complexity, and cost, simplifying control but can limit the independent dexterity of fingers since some movements are not individually actuated.",
    "question_token_count": 45,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 40
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "Gesture recognition using surface electromyography (EMG) images and its application in intuitive prosthesis control.",
    "response": "<document_analysis>\nThe provided context is a list of academic references covering a broad range of topics related to prosthetics, sensory feedback, neural interfacing, and functional assessment tools for upper limb amputees and prosthesis users. Among these references, entry 179 specifically addresses \"Gesture recognition by instantaneous surface EMG images,\" which directly relates to the question topic of gesture recognition using surface EMG for intuitive prosthesis control.\n\nThis reference implies advanced techniques involving instantaneous EMG image processing for gesture recognition, suggesting a focus on real-time, high-resolution EMG signal analysis. The context also includes references related to neuromyoelectric control (182), sensory feedback integration (163, 164, 181), and multisensory embodiment (170, 173), which provide a broader framework for understanding how EMG-based gesture recognition might integrate with prosthetic control to enhance intuitiveness and functionality.\n\nGiven this, the question should probe the technical and conceptual challenges in using instantaneous surface EMG images for gesture recognition and their implications for intuitive prosthesis control. It should encourage critical thinking about signal processing, classification complexity, and the integration of sensory feedback to achieve naturalistic control.\n\nDifficulty is rated 9/10 due to the technical depth required, including understanding of EMG signal characteristics, machine learning or image processing methods, and prosthesis control integration.\n\nThe question will invite reflection on how instantaneous EMG images improve gesture recognition accuracy, the challenges involved, and how this advancement impacts the intuitive control of prostheses. This requires synthesis of knowledge across electrophysiology, signal processing, and prosthetic control systems.\n\nNo irrelevant or bogus content is detected; the references are coherent and relevant to the domain.\n\nHence, a highly challenging and insightful question-answer pair is justified and constructed accordingly.\n</document_analysis>\n\n<output_format>\nQuestion: How does the use of instantaneous surface electromyography (EMG) images enhance the accuracy and intuitiveness of gesture recognition in prosthetic control systems, and what are the primary technical challenges associated with implementing this method for real-time, multidimensional prosthesis control?\n\nExplanation: Instantaneous surface EMG images capture spatial patterns of muscle activity across the electrode array, providing richer, multidimensional data compared to traditional EMG features; this spatial information improves gesture classification accuracy and allows more intuitive control by directly mapping muscle activation patterns to intended movements. However, real-time implementation faces challenges including high-dimensional data processing demands, variability in EMG signal due to electrode shifts or muscle fatigue, and the need for robust algorithms capable of handling noisy, non-stationary signals while maintaining low latency for responsive prosthesis control.\n\nCorrect Answer: By capturing spatial muscle activation patterns, instantaneous surface EMG images provide richer data that improves gesture recognition accuracy and intuitiveness, but real-time use requires overcoming high-dimensional data processing, signal variability, and algorithm robustness challenges.\n</output_format>",
    "question": "How does the use of instantaneous surface electromyography (EMG) images enhance the accuracy and intuitiveness of gesture recognition in prosthetic control systems, and what are the primary technical challenges associated with implementing this method for real-time, multidimensional prosthesis control?",
    "answer": "By capturing spatial muscle activation patterns, instantaneous surface EMG images provide richer data that improves gesture recognition accuracy and intuitiveness, but real-time use requires overcoming high-dimensional data processing, signal variability, and algorithm robustness challenges.",
    "explanation": "Instantaneous surface EMG images capture spatial patterns of muscle activity across the electrode array, providing richer, multidimensional data compared to traditional EMG features; this spatial information improves gesture classification accuracy and allows more intuitive control by directly mapping muscle activation patterns to intended movements. However, real-time implementation faces challenges including high-dimensional data processing demands, variability in EMG signal due to electrode shifts or muscle fatigue, and the need for robust algorithms capable of handling noisy, non-stationary signals while maintaining low latency for responsive prosthesis control.",
    "question_token_count": 52,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 44
  },
  {
    "context": "## 6. PERFORMANCE ASSESSMENT\nGiven the increasing complexity of RPHs that integrate both sensory and motor functionalities, it is important to have standardized tools to measure the efficacy of novel technologies (144). While designing custom experiments to evaluate a technology might be tempting, there is a crucial need for well-established assessment tools to enable comparisons of different approaches on a common basis.\n\nCaregivers should assess how a technology solves patients' impairments (their body structures or functions), activity limitations (e.g., by improving their ability to grasp), and participation\n\n\n## Biphasic:\ncharacterized by a two-phase, bidirectional wave with one positive phase and one negative phase\n\nNeuromorphic system: a software or hardware implementation that mimics the nervous system in terms of computation and transmission of information\n\nrestrictions (e.g., by allowing them to participate in a sport). In addition, the impairment should be viewed not only from a biological perspective but also in terms of its psychosocial consequences; an effective RPH should promote autonomy and support the reintegration of the individual into society. The measurement of patients' health-related quality of life has now become a norm during the rehabilitation process (145). For example, the Disabilities of the Arm, Shoulder, and Head (DASH) questionnaire (146) and its shorter, 11-item version, QuickDASH (147), provide self-administered measurements that focus on patients' symptoms and physical, social, and psychological aspects in populations with upper-extremity musculoskeletal conditions ( Table 3 ). More generally, subjects' perception of their quality of life can be measured with the short version of the World Health Organization Quality of Life scale (WHOQOL-BREF) (148) or the Quality of Life Scale (QOLS) (149). The Orthotics and Prosthetics User's Survey (OPUS) (150) has also been used in upper-limb amputees (136). A recent study showed that long-term use of a sensorized prosthetic arm improved subjects' participation (e.g., skiing and fishing) (138); the authors performed semistructured interviews at patients' homes using a phenomenological approach to infer their experience with the prosthetic arm and to investigate the influence of a novel treatment within subjects' social groups (using an emic ethnographic approach) (151).\n\nAnother straightforward metric for evaluating the quality of a tool is patients' acceptance of the proposed protocol. Treatment adherence-measured by, for example, the number of sessions carried out by the patients per month, or the average session length-can help the experimenter develop tools that will be effectively used by the patients (151). In a study by Graczyk et al. (136) that compared the use of a prosthetic hand with and without tactile feedback, the subjects used a modified version of the OPUS Upper Extremity Functional Status module to report on a daily basis the difficulty of performing tasks such as brushing teeth or using a key in a lock.\n\nWhenconsidering RPHs,assessment of the motor (or sensorimotor) functions is clearly essential. As described above, somatosensory feedback is crucial to performing a dexterous motor task (152); therefore, functional tests for motor tasks also implicitly evaluate the sensory feedback. In other words, high performance in, for example, a pick-and-place task using a bidirectional RPH indicates both an accurate motor decoding and sensory feedback. Other assessments [e.g., the Virtual Egg T est (153)] target the somatosensory feedback more explicitly. Here, we describe both types of measurements.\n\nThe Box and Block T est (154) is a common evaluation of unilateral gross manual dexterity ( Figure 3 a ), where subjects must transport as many wooden blocks as possible from one compartment of a box to another within one minute. A modified version of this test with motion capture has been proposed (155) to evaluate eventual compensatory strategies of the shoulder or the trunk; a normative version using predefined positions of the blocks inside the box has also been proposed to facilitate kinematic analysis (156). The fine dexterity of fingers can be measured with the Nine Hole Peg T est, which involves the placing of small 1.3-cm-diameter dowels into nine holes (157). Variations of this test with motion tracking have also been proposed (158). The Clothespin Relocation T est ( Figure 3 b ) measures both grasping and pronation/supination functions (159).\n\nThe Action Research Arm T est ( Figure 3 c ) is one of the most widely used measurements for upper-extremity (arm and hand) functions (160). It assesses four basic movements: grasp, grip, pinch, and gross movements of extension and flexion at the elbow and shoulder. Variously sized and shaped objects from daily living (a cup, a washer, etc.) are used for the test, which provides a broad overview of patients' improvement in the activity and impairment domains. Finally, the Southampton Hand Assessment Procedure uses a set of abstract objects and activities of daily living with tasks specifically developed to assess the effectiveness of upper-limb prostheses (161).\n",
    "topic": "The use and interpretation of patient-reported outcome measures such as DASH, QuickDASH, WHOQOL-BREF, QOLS, and OPUS in assessing upper-limb prosthetic function and quality of life.",
    "response": "<document_analysis>\nThe context details the importance of standardized assessment tools for evaluating rehabilitative prosthetic hands (RPHs), emphasizing both functional and psychosocial impacts. It highlights the use of patient-reported outcome measures (PROMs) such as DASH, QuickDASH, WHOQOL-BREF, QOLS, and OPUS for capturing symptoms, physical, social, and psychological aspects, and quality of life in upper-limb prosthetic users. The text notes that these measures are self-administered, focus on multiple domains of impairment and participation, and have been validated in musculoskeletal and amputee populations. It further explains the psychosocial dimension, including autonomy and reintegration, which PROMs help quantify beyond biological impairments. Additionally, the text mentions how PROMs complement objective motor and sensorimotor tests by reflecting patients' subjective experiences and acceptance, thus providing a comprehensive evaluation framework.\n\nImplicit assumptions include that PROMs are necessary to understand the holistic impact of prosthetics, that functional improvements alone are insufficient without perceived quality of life and participation gains, and that such measures facilitate comparison across different technologies. Subtle details include the use of semistructured interviews and ethnographic approaches to enrich understanding of patient experience, indicating that PROMs are part of a broader mixed-methods assessment strategy.\n\nThe difficulty level is rated 8/10 due to the nuanced understanding required of PROMs\u2019 role in prosthetic assessment, their multidimensional nature, and their integration with clinical and biomechanical tests. The question should challenge experts to analyze the complementary roles and interpretive complexities of these tools, beyond simply naming or defining them.\n\nThe planned question will require synthesis of how these PROMs function both as quantitative and qualitative metrics, their domains of focus, and their implications for comprehensive prosthetic evaluation, thus encouraging deep reflection on their interpretative and practical significance in clinical research and rehabilitation.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do patient-reported outcome measures such as DASH, QuickDASH, WHOQOL-BREF, QOLS, and OPUS collectively contribute to a multidimensional evaluation of upper-limb prosthetic function and quality of life, and why is their integration critical alongside objective motor assessments in rehabilitation research?\n\nExplanation: These PROMs provide complementary insights by capturing patients' subjective experiences of symptoms, physical limitations, social participation, and psychological well-being, addressing both biological impairments and psychosocial consequences; integrating them with objective motor tests ensures a holistic assessment of prosthetic efficacy, encompassing functional performance and quality of life, which is essential for evaluating autonomy and societal reintegration.\n\nCorrect Answer: They capture subjective physical, social, and psychological impacts complementing objective motor tests, enabling holistic assessment of prosthetic efficacy and patient quality of life.\n</output_format>",
    "question": "How do patient-reported outcome measures such as DASH, QuickDASH, WHOQOL-BREF, QOLS, and OPUS collectively contribute to a multidimensional evaluation of upper-limb prosthetic function and quality of life, and why is their integration critical alongside objective motor assessments in rehabilitation research?",
    "answer": "They capture subjective physical, social, and psychological impacts complementing objective motor tests, enabling holistic assessment of prosthetic efficacy and patient quality of life.",
    "explanation": "These PROMs provide complementary insights by capturing patients' subjective experiences of symptoms, physical limitations, social participation, and psychological well-being, addressing both biological impairments and psychosocial consequences; integrating them with objective motor tests ensures a holistic assessment of prosthetic efficacy, encompassing functional performance and quality of life, which is essential for evaluating autonomy and societal reintegration.",
    "question_token_count": 60,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 30
  },
  {
    "context": "## 3. INTERFACES WITH THE NEUROMUSCULAR SYSTEM\nDecades of work on robotic prosthetics have led to numerous invasive and noninvasive solutions for interfacing with the body (for a review, see 36) ( Table 1 ). Here, we describe existing technologies and outline the ones we consider the most promising for the future.\n\n\n## 3.1. Taxonomy of Existing Interfaces\nTo classify and evaluate the quality of an interface, selectivity-defined as the ability to record from a specific location within the nerve-is the most straightforward metric. Both spatial and temporal selectivity are important, naturally, as they enable better motor decoding and more localized sensory feedback. Electrode invasiveness, by contrast, is categorized into two large classes, surface electrodes and implanted electrodes, the latter of which includes extraneural (i.e., around the nerve) (37, 38), intraneural (i.e., through the nerve) (6), and regenerative approaches (where the nerve regrows inside the electrode) (39; for reviews, see 36, 40). Invasiveness is often seen as a trade-off to selectivity, with the observation that higher selectivity comes at the cost of greater invasiveness (41). While this relationship continues to be true to a large extent, two amendments are necessary: First, there are a multitude of other dimensions to consider, and second, recent\n\nresults are suggesting that the relationship might not be the same in the motor and the sensory domains. We detail both aspects here.\n\nBeyond the selectivity of an interface, it is crucial to consider its reach and level of discrimination. For example, transverse intrafascicular multichannel electrodes (TIMEs) (42) and longitudinal intrafascicular electrodes (LIFEs) (43) can have a very similar selectivity, but TIMEs reach a more substantial proportion of the nerve and therefore can infer more information about the whole signal. Comparing muscle stimulation with different electrodes, Badia et al. (44) showed that a TIME could target three muscles, whereas they could not activate more than one muscle with a LIFE. Spatial discrimination of neural signals from nontarget signals is influenced not only by the electrode's invasiveness (how close it is to the source) but also by its geometry (e.g., a spherical point source targets a small volume), electrode material, and configuration (e.g., a cylindrical electrode better discriminates the axons perpendicular to the main axis) (45).\n\nSignal quality and stability are also important aspects that have been extensively studied. Work in this area has included interventions to improve the device-tissue interfaces [e.g., electrode coating (46) or a hollow glass cone that permits the ingrowth of cortical neurites in the electrodes (47)], electrode impedance, and filtering processes to increase the signal-to-noise ratio. The recording stability depends on biocompatibility, the electrode's robustness (resistance to physical manipulation), and the stability of the contact between the interface and neural tissue. Significant efforts have been made to develop soft, implantable electrodes (48) in order to reduce insertion trauma and physical mismatches between neural tissues and implantable interfaces. Finally, properly anchoring the electrodes with the neural tissues is also essential to maintain a steady recording or stimulation site over time. This is particularly important in the sensory domain, where the stability of the elicited sensation is paramount for continuous use.\n\nFinally, practicalities such as the cost of the technology and the difficulty of the implant must be considered. As such, an implantation procedure based on a known surgical procedure (49) has a better chance to be accepted and adopted by surgeons. The use of existing devices, materials, and mature technologies is also a way to reduce costs and risks. An example of such a strategy is the use of Utah Arrays, which use well-established electrodes for brain recording, to interface with the peripheral nervous system.\n\nFor motor decoding, surface EMG (sEMG) approaches are by far the most widely used technique to date. Recent implementations using a large number of electrodes [termed high-density sEMG (HD-sEMG) (50)] have shown unprecedented results in terms of accuracy and decoding robustness (for details, see Section 4). Implanted EMG (iEMG) has shown higher performance and stability than sEMG on the continuous control of three DOFs (51). However, studies have found no statistical difference in different electrodes' ability to differentiate among 12 types of grasps (52). Neural interfaces with the peripheral nerves have also shown promising results on grasp classification with TIMEs (53) and proportional control with a Utah Slanted Electrode Array (54). However, the development of real-time control and sensory feedback stimulation is still at an early stage (53, 54) and will need further investigation.\n\nIn the sensory domain, there is no current consensus for noninvasive approaches. T actile feedback using vibrotactile (55, 56), mechanotactile (57), or sensory substitution [e.g., audio (58)] has been proposed. Transcutaneous electrical nerve stimulation (TENS) is a viable noninvasive approach to induce close to natural sensation with amputee patients (59, 60). However, as detailed elsewhere in this review, current solutions using implanted electrodes (particularly intraneural interfaces) have shown levels of sensory recovery far superior to those of noninvasive approaches. This is true from a functional point of view [e.g., the possibility to encode texture (61) or shapes and stiffness (6)], phenomenologically [patients perceive the feedback as close to natural (62)], and in terms of cognitive load (63).\n",
    "topic": "The impact of electrode geometry, material, and configuration on spatial discrimination and recording specificity in peripheral nerve interfaces.",
    "response": "<document_analysis>\nThe context provides an in-depth overview of the current state and challenges of interfacing with the neuromuscular system, particularly focusing on electrode-based technologies. A key part of this is the discussion of selectivity\u2014both spatial and temporal\u2014and how it is influenced by factors beyond invasiveness, such as electrode geometry, material, and configuration. The text highlights that spatial discrimination is not solely dependent on invasiveness but also on the shape and arrangement of electrodes (e.g., spherical point source vs. cylindrical electrode), which affect targeting and discrimination of neural signals. This nuanced detail invites a complex technical question probing the interplay of physical electrode characteristics with functional outcomes in recording specificity.\n\nThe question can invite reflection on how electrode design parameters influence the fidelity of neural signal acquisition, which is critical for advanced prosthetic control and sensory feedback. It also challenges experts to consider the broader implications of electrode geometry and material science in optimizing interface performance.\n\nThe difficulty level of this question is high (8-9), as it demands understanding of neurophysiology, bioengineering, and materials science, and their integration in peripheral nerve interfaces. It requires synthesis beyond superficial knowledge, engaging with subtle design trade-offs and their direct impact on neural signal discrimination.\n\nThe question will encourage domain experts to articulate the mechanisms by which electrode geometry and material properties affect spatial selectivity and recording quality, reflecting deep expertise.\n\nGiven that the text contains rich, relevant, and coherent information about electrode characteristics and their functional consequences, it is suitable for generating a meaningful, challenging question-answer pair.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do electrode geometry, material, and configuration collectively influence spatial discrimination and recording specificity in peripheral nerve interfaces, and why are these factors critical beyond the invasiveness of the electrode?\n\nExplanation: Electrode geometry determines the volume of neural tissue targeted and the directional sensitivity of recordings (e.g., spherical electrodes target a small volume, while cylindrical electrodes better discriminate axons aligned perpendicularly). Electrode material affects biocompatibility, impedance, and signal quality, influencing the signal-to-noise ratio and recording stability. Configuration, such as electrode arrangement and shape, further refines the ability to distinguish neural signals from nontarget activity. These factors are critical because they improve spatial selectivity and signal fidelity without necessarily increasing invasiveness, thus optimizing interface performance while reducing tissue damage and instability.\n\nCorrect Answer: By shaping the targeted neural volume and directional sensitivity, electrode geometry, material biocompatibility and impedance, and electrode configuration together enhance spatial selectivity and signal fidelity, enabling more precise discrimination of neural signals beyond what invasiveness alone can achieve.\n</output_format>",
    "question": "How do electrode geometry, material, and configuration collectively influence spatial discrimination and recording specificity in peripheral nerve interfaces, and why are these factors critical beyond the invasiveness of the electrode?",
    "answer": "By shaping the targeted neural volume and directional sensitivity, electrode geometry, material biocompatibility and impedance, and electrode configuration together enhance spatial selectivity and signal fidelity, enabling more precise discrimination of neural signals beyond what invasiveness alone can achieve.",
    "explanation": "Electrode geometry determines the volume of neural tissue targeted and the directional sensitivity of recordings (e.g., spherical electrodes target a small volume, while cylindrical electrodes better discriminate axons aligned perpendicularly). Electrode material affects biocompatibility, impedance, and signal quality, influencing the signal-to-noise ratio and recording stability. Configuration, such as electrode arrangement and shape, further refines the ability to distinguish neural signals from nontarget activity. These factors are critical because they improve spatial selectivity and signal fidelity without necessarily increasing invasiveness, thus optimizing interface performance while reducing tissue damage and instability.",
    "question_token_count": 36,
    "answer_correctness_score": 10,
    "explanation_validity_score": 10,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 48
  },
  {
    "context": "## 5. RESTORING SENSORY FEEDBACK\nSensory information plays a critical role in both the exploration of the external environment and in any manipulation task. When an individual interacts with surrounding objects, tactile sensations are used to infer features such as size, compliance, temperature, and texture, while the same sensations are exploited to handle them properly or use them as tools. From this perspective, aiming to restore afferent sensory channels from a hand prosthesis is a critical step in designing a device that ensures two key aspects: dexterous manipulation and embodiment of the prosthetic device.\n\nThe design of a sensory feedback system that can successfully deliver information relies on three fundamental blocks working together: ( a ) sensor readings, processed by ( ) an encoding b strategy capable of translating meaningful information to the user, through ( ) an interface. Prec vious sections have described the different available interfaces; here, we present the encoding techniques and sensors relevant to the design of modern hand prostheses ( Table 1 ).\n\nSensors mounted on a robotic hand should ideally record the whole spectrum of available human sensations, from both external and internal sources. Indeed, sensory information from the human hand covers both interactions with the external world (tactile perception, thermal perception, and nociception, i.e., perception of pain) and internal perception of the positions of the joints and the length and forces exerted by the muscles, together known as proprioception. Table 2 shows examples of sensor placements on RPHs from recent studies.\n",
    "topic": "The role of proprioception in prosthetic hand control and how internal sensory feedback mechanisms can be restored through sensor technology.",
    "response": "<document_analysis>\nThe context focuses on the restoration of sensory feedback in hand prostheses, emphasizing the critical role of sensory information in environmental exploration and object manipulation. It highlights that tactile sensations provide essential information about object properties and manipulation strategies. The text outlines the importance of restoring afferent sensory channels to achieve dexterous manipulation and embodiment of prosthetic hands. It introduces the three components for sensory feedback systems: sensors, encoding strategies, and interfaces. The passage specifically notes that human hand sensations include both external (tactile, thermal, nociception) and internal (proprioception) sources, with proprioception relating to joint position and muscle forces. This internal feedback is crucial for nuanced control. The mention of sensor placements on robotic prosthetic hands for restoring these sensory modalities points toward the technological means of replicating proprioceptive feedback. The content is rich and coherent, suitable for generating a challenging question about the role and restoration of proprioception in prosthetic control.\n\nDifficulty rating: 9/10 due to the need for deep understanding of sensory feedback mechanisms, prosthetic technology, and proprioceptive encoding.\n\nThe question should invite reflection on how internal sensory feedback (proprioception) can be technically restored in prosthetic hands, requiring synthesis of knowledge about sensor types, encoding methods, and functional implications for control and embodiment.\n\n</document_analysis>\n\n<output_format>\nQuestion: How can proprioceptive feedback, which involves internal sensory information such as joint position and muscle force, be effectively restored in hand prostheses through sensor technology and encoding strategies, and why is this restoration critical for achieving dexterous manipulation and embodiment of the prosthetic device?\n\nExplanation: Proprioceptive feedback in hand prostheses is restored by integrating sensors that capture internal states such as joint angles and muscle forces, which are then translated into meaningful signals for the user through specialized encoding strategies and interfaces. This restoration is essential because proprioception provides the user with critical information about the position and force exertion of the prosthetic hand, enabling precise control and natural integration (embodiment) of the device, which are fundamental for dexterous manipulation.\n\nCorrect Answer: By employing sensors that detect joint positions and muscle forces combined with encoding methods that translate these signals into user-perceivable feedback, proprioception is restored, enabling precise control and embodiment critical for dexterous manipulation.\n</output_format>",
    "question": "How can proprioceptive feedback, which involves internal sensory information such as joint position and muscle force, be effectively restored in hand prostheses through sensor technology and encoding strategies, and why is this restoration critical for achieving dexterous manipulation and embodiment of the prosthetic device?",
    "answer": "By employing sensors that detect joint positions and muscle forces combined with encoding methods that translate these signals into user-perceivable feedback, proprioception is restored, enabling precise control and embodiment critical for dexterous manipulation.",
    "explanation": "Proprioceptive feedback in hand prostheses is restored by integrating sensors that capture internal states such as joint angles and muscle forces, which are then translated into meaningful signals for the user through specialized encoding strategies and interfaces. This restoration is essential because proprioception provides the user with critical information about the position and force exertion of the prosthetic hand, enabling precise control and natural integration (embodiment) of the device, which are fundamental for dexterous manipulation.",
    "question_token_count": 54,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 43
  },
  {
    "context": "## 5.4. Sensory Feedback\nIn basic myoelectric or body-powered prostheses, feedback is delivered mainly by visually inspecting the movements of the prosthesis and by the physical interaction between the device and the user (126), as with hook prostheses. Clearly, the goal of a modern RPH is to deliver richer information more intuitively.\n\nSensory feedback strategies are characterized by their precision and the coherence between the evoked sensation and the desired one in terms of timing (synchronicity), position (somatotopy), and modality (i.e., touch, vibration, and temperature). Feedback techniques encode sensor values to stimulation parameters, which in turn are strongly tied to the chosen stimulation interface ( Table 2 ). Here, we focus mainly on electrical interfaces for feedback, but we also briefly discuss the mechanical interfaces.\n\nNoninvasive feedback strategies are attractive approaches since they do not necessitate surgical interventions ( Figure 2 a ). Starting with the Boston Arm, which Mann &amp; Reimers (127) used to demonstrate that position feedback was needed for precise reaching movements, these techniques have improved in both mechanical and electrical interfaces with the user. Indeed, the intact mechanoreceptors in the skin of the arm can be stimulated with small linear (128) or vibrating (129) motors that vary in their driving amplitude and frequency. On the other hand, mechanical stimulation brings an unavoidable delay of approximately 400 ms in the delivery of the sensation (130), and the integration and miniaturization of mechanoreceptors are challenging. The miniaturization of noninvasive feedback approaches is also challenging.\n",
    "topic": "The historical significance and contributions of the Boston Arm in demonstrating the need for position feedback in prosthetic control.",
    "response": "<document_analysis>\nThe provided text discusses sensory feedback in prosthetic hands (RPH), emphasizing the limitations of basic prostheses and the goal of delivering richer, intuitive feedback. It highlights the characteristics of effective sensory feedback (precision, synchronicity, somatotopy, and modality) and focuses on electrical interfaces but also mentions mechanical interfaces. The text then introduces noninvasive feedback strategies, noting their advantages and challenges, such as delays and miniaturization difficulties. Importantly, the Boston Arm is cited historically as the first device used by Mann & Reimers to demonstrate that position feedback is necessary for precise reaching movements. This establishes a foundational understanding that without position feedback, control accuracy is impaired, marking the Boston Arm as a pivotal early experiment validating the critical role of feedback in prosthetics.\n\nThe central theme relevant to the question is the Boston Arm's historical and experimental role in illustrating the essential need for position feedback to achieve precise prosthetic control. This is a nuanced insight connecting early prosthetic engineering with the development of feedback systems.\n\nDifficulty rating: 8/10. The question demands not only knowledge of the Boston Arm but also understanding its experimental significance and implications for prosthetic feedback design, which requires domain expertise.\n\nThe question encourages deep reflection on how early prosthetic designs informed modern feedback strategies, linking historical experimentation with current technological challenges and goals.\n\nThis content is meaningful, coherent, and educationally valuable. No irrelevant or bogus information is present.\n\n</document_analysis>\n\n<output_format>\nQuestion: How did the Boston Arm experiment conducted by Mann & Reimers fundamentally demonstrate the necessity of position feedback for achieving precise reaching movements in prosthetic control, and what implications did this have for the evolution of sensory feedback strategies in modern prostheses?\n\nExplanation: The Boston Arm was used to show that without position feedback, users could not achieve precise control of reaching movements, highlighting the critical role of sensory feedback. This foundational demonstration influenced the development of more advanced feedback systems that aim to provide timely, spatially accurate, and modality-appropriate sensory information, thereby improving prosthetic functionality and user embodiment.\n\nCorrect Answer: The Boston Arm demonstrated that position feedback was essential for precise reaching movements, establishing the foundational importance of sensory feedback in prosthetic control and guiding the advancement of more sophisticated feedback strategies.\n</output_format>",
    "question": "How did the Boston Arm experiment conducted by Mann & Reimers fundamentally demonstrate the necessity of position feedback for achieving precise reaching movements in prosthetic control, and what implications did this have for the evolution of sensory feedback strategies in modern prostheses?",
    "answer": "The Boston Arm demonstrated that position feedback was essential for precise reaching movements, establishing the foundational importance of sensory feedback in prosthetic control and guiding the advancement of more sophisticated feedback strategies.",
    "explanation": "The Boston Arm was used to show that without position feedback, users could not achieve precise control of reaching movements, highlighting the critical role of sensory feedback. This foundational demonstration influenced the development of more advanced feedback systems that aim to provide timely, spatially accurate, and modality-appropriate sensory information, thereby improving prosthetic functionality and user embodiment.",
    "question_token_count": 48,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 36
  },
  {
    "context": "## 2. ROBOTIC HANDS\nFollowing a limb amputation, three solutions are generally considered: passive cosmetic limbs ( Figure 1 a ); mechanical hands, often with hooks ( Figure 1 b ); and RPHs ( Figure 1 c-g ). In a\n\n\n## SKIN MECHANORECEPTORS\nThe skin has four types of mechanoreceptors, which are sensitive to different stimuli and therefore involved in different sensory functions: Merkel disks (which sense skin indentation, fine touch, and texture perception), Ruffini capsules (which sense skin stretch), Pacinian corpuscles (which sense vibration), and Meissner corpuscles (which sense dynamic deformation and slipperiness). Merkel disks and Ruffini capsules are slow-adapting receptors, meaning that they fire continuously during tactile stimuli, with a firing rate related to the pressure applied in their receptive field. Pacinian corpuscles and Meissner corpuscles are fast-adapting receptors that respond mostly to changes in applied pressure or brief stimuli.\n\na\n\nd\n\nPercutaneous leads\n\nFINE\n\nAgonist/antagonist myoelectric control\n\nSingle-DOF\n\nprosthetic hand\n\nAperture sensor\n\nExternal\n\nPressure sensors stimulator\n\nh\n",
    "topic": "Clinical and neurophysiological implications of mechanoreceptor function for the development of intuitive and responsive prosthetic hand control systems.",
    "response": "<document_analysis>\nThe provided context discusses types of prosthetic hands following limb amputation and introduces four types of skin mechanoreceptors: Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles. Each mechanoreceptor type has distinct sensory roles and adaptation rates, important for tactile feedback. This information is directly relevant to designing prosthetic hands that aim to restore intuitive and responsive sensory feedback to users. The text implies a link between mechanoreceptor function and prosthetic control but does not explicitly detail clinical or neurophysiological applications, leaving room for a high-level, integrative question about how these receptor characteristics influence prosthetic design. The complexity of integrating mechanoreceptor signals into prosthetic control for restoring nuanced sensory perception and improving motor control is a challenging topic for domain experts.\n\nDifficulty rating: 9/10 due to requiring synthesis of neurophysiology, clinical prosthetics, and sensory feedback engineering.\n\nThe question should challenge experts to connect mechanoreceptor adaptation types and sensory modalities to the design of prosthetic control systems that are both intuitive and responsive, reflecting deep understanding of sensory encoding and clinical application.\n\nNo irrelevant or bogus information detected; content is coherent and educationally valuable.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the distinct adaptation properties and sensory modalities of Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles inform the design of feedback mechanisms in prosthetic hand control systems to achieve intuitive and responsive motor function?\n\nExplanation: Merkel disks and Ruffini capsules provide continuous pressure and stretch information through slow adaptation, essential for sustained tactile feedback, while Pacinian and Meissner corpuscles, being fast-adapting, detect dynamic changes like vibration and slip, critical for responsive adjustments; integrating these complementary signals into prosthetic feedback enables nuanced sensation and fine motor control, thus enhancing intuitiveness and responsiveness in prosthetic hands.\n\nCorrect Answer: By leveraging slow-adapting receptors for sustained pressure and stretch feedback and fast-adapting receptors for detecting dynamic stimuli like vibration and slip, prosthetic systems can provide continuous and transient tactile information, enabling intuitive and responsive motor control.\n</output_format>",
    "question": "How do the distinct adaptation properties and sensory modalities of Merkel disks, Ruffini capsules, Pacinian corpuscles, and Meissner corpuscles inform the design of feedback mechanisms in prosthetic hand control systems to achieve intuitive and responsive motor function?",
    "answer": "By leveraging slow-adapting receptors for sustained pressure and stretch feedback and fast-adapting receptors for detecting dynamic stimuli like vibration and slip, prosthetic systems can provide continuous and transient tactile information, enabling intuitive and responsive motor control.",
    "explanation": "Merkel disks and Ruffini capsules provide continuous pressure and stretch information through slow adaptation, essential for sustained tactile feedback, while Pacinian and Meissner corpuscles, being fast-adapting, detect dynamic changes like vibration and slip, critical for responsive adjustments; integrating these complementary signals into prosthetic feedback enables nuanced sensation and fine motor control, thus enhancing intuitiveness and responsiveness in prosthetic hands.",
    "question_token_count": 49,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 47
  },
  {
    "context": "## 2.2. Perspectives\nWhile rigid architectures are still the norm, there has been recent interest in the development of flexible systems that inherently permit safe robot-human interaction (29). Instead of using a rigid structure with mechanical joints, the compliant structures in soft designs enable them to bend continuously in any part. Since seminal work by Hirose &amp; Ma (30), there have been several attempts to develop soft underactuated hand prostheses (31) and soft body-powered devices (9). These architectures combine the advantages of simple actuation with the performance of an adaptable hand. Recent studies have proved that soft manipulators could match the performance of rigid systems in many applications (32). Further investigations are necessary to determine whether soft architectures are viable solutions for larger use.\n\nInnovative actuation systems such as McKibben pneumatic muscles, granular jamming (33), and electro-conjugate fluid (34), which are strongly tied to soft robotic devices, are another interesting direction. Soft RPHs have the advantage of exploiting the structure to embed and eventually improve sensorization, safety, and efficiency (e.g., 35). These systems are at the early stage and need massive integration before being deployed in portable devices.\n\nTable 1 Maturity levels of different technologies\n\n| Technology       | Most widespread                 | Mature, home use                                                                                | Cutting edge, laboratory use                                                                                            | Future directions                                                                                                         |\n\n|------------------|---------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n\n| Interface        | Body harness c                  | sEMG a iEMG (51) a Vibrotactile interface (178) b TENS b FINEs (136) b Osseointegration (138) c | HD-sEMG (179) a Regenerative electrodes (39) a TIMEs (6, 42) b LIFEs (43) b Sieve electrodes (180) b Utah Array (113) c | Noninvasive intraneural stimulation (ultrasound) b Soft neurotechnology (48) b                                            |\n\n| Motor decoding   | Body power Threshold-based sEMG | EMG-based pattern recognition (e.g., Ottobock Myo Plus, Coapt Gen2)                             | Simultaneous single-finger classification (75) Linear regression and shared control (79)                                | Advanced control using regenerative peripheral nerve interfaces (39) Deep learning for single-finger proportional control |\n\n| Sensory feedback | No feedback                     | Vibrotactile haptic feedback (129) Touch contact (138) Position (136)                           | Neuromorphic (62) Texture (61) Object stiffness (6) Multimodal (position and tactile) (64) Biomimetic stimulation (62)  | Temperature feedback Proprioception                                                                                       |\n\n| Sensorization    | No skin                         | Force sensors (measuring motor current) Sensorized fingertips (e.g., bebionic)                  | Asynchronously coded electronic skin (125)                                                                              | Soft embedded sensors (115) Bioinspired flexible organic artificial afferent nerve (122)                                  |\n\nAbbreviations: EMG, electromyography; FINE, flat interface nerve electrode; HD-sEMG, high-density surface electromyography; iEMG, implanted EMG; LIFE, longitudinal intrafascicular electrode; sEMG, surface electromyography; TENS, transcutaneous electrical nerve stimulation; TIME; transverse intrafascicular multichannel electrode.\n\na Motor interface.\n\nb Sensory interface.\n\nc Both motor and sensory interface.\n",
    "topic": "Advances in motor decoding techniques from threshold-based sEMG to deep learning approaches for proportional single-finger control.",
    "response": "<document_analysis>\nThe provided context discusses the evolution of technologies related to robotic prosthetic hands (RPHs), emphasizing the shift from rigid to soft architectures and highlighting innovations in actuation, sensorization, and interfaces. Within the comprehensive Table 1, the section on motor decoding succinctly outlines the progression from basic body-powered and threshold-based sEMG control to more advanced methods involving EMG pattern recognition, simultaneous single-finger classification, and linear regression with shared control. At the cutting edge, the text references simultaneous single-finger classification and linear regression, while future directions point toward regenerative peripheral nerve interfaces and deep learning for single-finger proportional control. This transition reflects a move from discrete, binary control signals to continuous, nuanced, and proportional control that can distinguish and independently actuate individual fingers, enhancing dexterity and naturalness of prosthetic movement.\n\nImplicit assumptions include that the integration of deep learning techniques enables higher fidelity decoding of neural or muscular signals for more precise control, and that regenerative peripheral nerve interfaces provide richer, more localized input for these algorithms. The text suggests that while significant progress has been made, these methods are still in research or early clinical stages, emphasizing the need for further validation and integration.\n\nThe difficulty level is high (9/10) because understanding the technical evolution requires knowledge of electrophysiological signal acquisition (sEMG), signal processing (pattern recognition, regression), neural interface technologies, and machine learning applications in biomedical engineering. The question should invite critical reflection on how deep learning fundamentally changes motor decoding capabilities compared to traditional methods, including challenges and implications for prosthetic functionality.\n\nThe question is planned to probe the expert\u2019s understanding of the comparative technical advantages, limitations, and practical impacts of advancing from threshold-based sEMG to deep learning-enabled proportional single-finger control, encouraging synthesis of neuroengineering, signal processing, and clinical application knowledge.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does the application of deep learning techniques to regenerative peripheral nerve interfaces enable proportional single-finger control in prosthetic hands, and in what fundamental ways does this approach overcome the limitations of traditional threshold-based surface electromyography (sEMG) methods?\n\nExplanation: Deep learning applied to regenerative peripheral nerve interfaces can decode complex, high-dimensional neural signals with greater specificity and resolution, enabling continuous, proportional control of individual fingers. This contrasts with traditional threshold-based sEMG methods, which rely on binary or limited multi-state muscle activation signals that cannot discriminate fine finger movements or provide smooth proportional control, thereby limiting dexterity and naturalness in prosthetic hand function.\n\nCorrect Answer: Deep learning with regenerative nerve interfaces decodes complex neural signals for continuous, proportional single-finger control, overcoming threshold-based sEMG\u2019s limited binary activation and poor finger discrimination.\n</output_format>",
    "question": "How does the application of deep learning techniques to regenerative peripheral nerve interfaces enable proportional single-finger control in prosthetic hands, and in what fundamental ways does this approach overcome the limitations of traditional threshold-based surface electromyography (sEMG) methods?",
    "answer": "Deep learning with regenerative nerve interfaces decodes complex neural signals for continuous, proportional single-finger control, overcoming threshold-based sEMG\u2019s limited binary activation and poor finger discrimination.",
    "explanation": "Deep learning applied to regenerative peripheral nerve interfaces can decode complex, high-dimensional neural signals with greater specificity and resolution, enabling continuous, proportional control of individual fingers. This contrasts with traditional threshold-based sEMG methods, which rely on binary or limited multi-state muscle activation signals that cannot discriminate fine finger movements or provide smooth proportional control, thereby limiting dexterity and naturalness in prosthetic hand function.",
    "question_token_count": 51,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 36
  },
  {
    "context": "## Neuroprosthesis:\na device that connects to the nervous system and either replaces missing parts of it or improves it\n\n\n## 1. INTRODUCTION\nDecades of research on robotic prosthetic hands (RPHs) have led to a paradoxical situation: On the one hand, the development of novel RPHs is among the most exciting fields of robotics (1), but on the other hand, the vast majority of amputee patients still use technologies that have changed little in almost half a century. However, this apparent discrepancy might seem less surprising when considering the immense challenge of developing a prosthetic that can mimic the functions of a hand. Indeed, the hand has one of the largest sensory representations in the brain, and grasping is among the most complex coordination tasks (2); the hand has both the highest density of mechanoreceptors in the human body (see the sidebar titled Skin Mechanoreceptors) and the largest number of degrees of freedom (DOFs); and the hand permits people to both experience the surrounding world and shape it.\n\nThe challenges are multiple and intricate, and they can be overcome only by combining advanced mechatronic solutions for dexterous and highly sensorized robotic hands with new approaches for robust and effective interfaces with users' nervous systems to allow seamless naturalartificial integration. As such, several viable solutions can emerge from this multidimensional optimization problem.\n\nTremendous efforts have been made in the past 20 years on the quest for an RPH that is easy to wear, comfortable, and intuitive to control. The design of such a device can be considered a compromise among dexterity, robustness, and usability (3). In the past 5 years, another aspect has been proposed by researchers as an essential milestone: sensorization. Indeed, feedback systems can increase both the acceptability and the performance of the new generation of RPHs (4-6).\n\nThis review summarizes the main achievements in this field. In particular, after providing an overview of the existing neuroprostheses and their characteristics, we focus on four central aspects: ( a ) stable interfaces that enable a new connection with the nervous system to record neural signals and stimulate neural structures, ( b ) algorithmic strategies for decoding motor intentions, ( c ) RPH sensorization plus encoding strategies to convey somatosensory feedback, and ( d ) assessment methods to measure the efficacy of a given strategy or technology. Throughout the review, we keep a patient-centered perspective and ask ourselves, Does a novel approach significantly improve the subjects' quality of life? Is it easy to learn and natural to use? And does it improve their independence? On a technical aspect, our goal is to provide a critical view of the most advanced technologies and a perspective on future implementations of RPHs.\n",
    "topic": "Analyze the paradox between rapid advances in robotic prosthetic hand technology and the limited adoption of these advancements by amputee patients over the past decades.",
    "response": "<document_analysis>\nThe context presents a paradox where despite significant advances in robotic prosthetic hand (RPH) technology, most amputees still use prosthetics that have not changed substantially in decades. This paradox is attributed to the immense complexity of replicating the human hand's functions, which involve a high density of mechanoreceptors, numerous degrees of freedom, and sophisticated sensorimotor integration. The text emphasizes that overcoming these challenges requires integrating advanced mechatronics with robust nervous system interfaces to create intuitive and natural control. It also highlights that beyond dexterity and robustness, sensorization and feedback systems have become essential to improve performance and acceptance. The patient-centered focus considers quality of life, ease of use, and independence as critical measures of success. The difficulty level is high (8/10) because it involves understanding multidisciplinary challenges across robotics, neuroscience, and user experience, reflecting deep technical and practical insight. The question is designed to probe understanding of the multifactorial reasons behind slow clinical adoption despite technological progress, encouraging reflection on the interplay between engineering complexity, interface challenges, and patient-centered considerations.\n</document_analysis>\n\n<output_format>\nQuestion: What are the key technical and practical factors underlying the paradox where rapid advances in robotic prosthetic hand technology have not translated into widespread adoption by amputee patients, and how do these factors collectively impede the development of prosthetics that seamlessly replicate natural hand function?\n\nExplanation: The paradox arises because replicating the human hand\u2019s complex sensorimotor functions demands integrating highly dexterous mechatronic systems with stable, intuitive neural interfaces\u2014challenges that remain unresolved. The hand\u2019s intricate sensory representation, numerous degrees of freedom, and need for natural somatosensory feedback require multidimensional optimization. Additionally, practical considerations such as device wearability, comfort, ease of control, and meaningful improvements in quality of life limit adoption. Thus, despite technological advances, the difficulty in achieving seamless natural-artificial integration and patient-centered usability impedes widespread clinical uptake.\n\nCorrect Answer: The complexity of replicating the hand\u2019s sensorimotor functions, challenges in stable and intuitive neural interfaces, and the need for wearable, comfortable, and easy-to-control devices that meaningfully improve patient quality of life collectively hinder adoption despite technological advances.\n</output_format>",
    "question": "What are the key technical and practical factors underlying the paradox where rapid advances in robotic prosthetic hand technology have not translated into widespread adoption by amputee patients, and how do these factors collectively impede the development of prosthetics that seamlessly replicate natural hand function?",
    "answer": "The complexity of replicating the hand\u2019s sensorimotor functions, challenges in stable and intuitive neural interfaces, and the need for wearable, comfortable, and easy-to-control devices that meaningfully improve patient quality of life collectively hinder adoption despite technological advances.",
    "explanation": "The paradox arises because replicating the human hand\u2019s complex sensorimotor functions demands integrating highly dexterous mechatronic systems with stable, intuitive neural interfaces\u2014challenges that remain unresolved. The hand\u2019s intricate sensory representation, numerous degrees of freedom, and need for natural somatosensory feedback require multidimensional optimization. Additionally, practical considerations such as device wearability, comfort, ease of control, and meaningful improvements in quality of life limit adoption. Thus, despite technological advances, the difficulty in achieving seamless natural-artificial integration and patient-centered usability impedes widespread clinical uptake.",
    "question_token_count": 51,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 50
  },
  {
    "context": "## Figure 3\nExamples of available assessment tools. ( a ) The standardized test equipment for the Box and Block T est includes a box with two compartments separated by a barrier and 150 2.5-cm colored blocks. The subject is asked to transfer as many blocks as possible from one compartment to the other in one minute. Panel adapted with permission from Accsim Instrumentos. ( ) The Clothespin Relocation b Test measures hand function (reaching, grasping, and wrist rotation). The measurement consists of the time it takes for the subject to move three clothespins from a horizontal to a vertical bar and then back (see, e.g., 184). Panel adapted with permission from Reference 184. ( ) The Action Research Arm T est standard box is commercially available and contains different objects to assess grasp, grip pinch, c and gross movement functions. Panel reproduced with permission from Rehab Solutions. ( d ) The Virtual Egg T est is a variation of the Box and Block T est where blocks are replaced by breakable objects. In this example, the plastic cubes have a magnetic fuse that breaks if the grasping force exceeds a certain threshold. Panel adapted with permission from Reference 129. ( ) An audio-tactile interaction task e has been used to measure the brain representation of the peripersonal space (the brain's presentation of the space immediately around the body) (175). The test consists of a looming sound (perceived as coming from far away and moving toward the amputated hand) and a vibrator placed on the subject's stump that is triggered when the sound is perceived to be at different distances from the subject (D1 to D5). The position where the presence of the sound facilitates the perception of the vibrator (reaction time) is used as a proxy for the peripersonal space limit ( dashed line ).\n\nThese evaluations are used in rehabilitation and have been clinically validated ( Table 3 ). Most of them were developed for neurological impairments (such as a stroke), multiple sclerosis, or spinal cord injuries and have been adapted for the evaluation of RPHs. While these wellestablished evaluations are essential, detailed investigation of RPHs-mainly when integrating sensory feedback capabilities-implies specific challenges that have been addressed in a series of tests introduced in recent years. These tests, although not yet clinically validated, are, in our opinion, of great interest.\n\nThe Grasping Relative Index of Performance measures the ability to control the desired force during grasping (139) independently from the control and feedback modalities. This measurement is based on the well-known Fitts' law, which states that the difficulty of a reaching task is given by the log of the ratio between the distance to the target and its size; in other words, the farther away and smaller a target is, the harder it is to reach it. Thumser et al. (162) argued that grasping is similar to pointing with the thumb and finger toward selected positions and defined the index of difficulty for grasping as the ratio of the object's weight to its hardness (where grasping a fragile object is analogous to reaching a small target). Other assessments have been proposed to estimate object stiffness (139) and size discrimination (6); Risso et al. (163) investigated the contribution of vision, tactile feedback via intraneural stimulation, and visuo-tactile integration to estimate the size of a handheld object.\n\nThe magnetic table task (164) and the Virtual Egg T est (129) ( Figure 3 d ) are variations of the Box and Block T est in which the blocks are replaced by magnetic cubes and breakable objects, respectively. Both have been used to evaluate the efficacy of different sensory encoding strategies (see 136 for the magnetic table task and 62 for the Virtual Egg T est). Finally, Prosthesis Efficiency and Profitability is an ad hoc measurement for prosthetics with sensory feedback to assess searching, reaching, grasping, manipulating, and decision-making during a foraging task (139).\n\nUse of cognitive load during a sensorimotor task can give an indirect evaluation of the intuitiveness of a task: Do patients need to give their full attention to a particular movement, or are they able to perform it as part of a dual task? Subjects might be asked, for example, to perform a task while counting backward, finding words that start with a given letter, or visually following a moving target on a screen (for an example with a Virtual Egg T est, see 63). More direct measurement of the cognitive burden via electroencephalographic event-related potentials during human-machine interactions has also been proposed (165). Here, the subject must perform a specific task (the primary task) while detecting an auditory stimulus (the secondary task), and the amplitude of the event-related potentials in response to the auditory stimulus then indicates the amount of dedicated attention to the secondary and primary tasks. Simply put, a small response to the auditory cue suggests more extensive attention to the primary task (166) and therefore a greater cognitive load.\n\nThe prolonged use of prosthetic limbs can reverse some of the effects of post-traumatic maladaptive plasticity, one of the most debilitating of which is phantom limb pain, a condition present in the majority of subjects with amputation (167). Phantom limb pain has a complex etiology that can be elicited by a multitude of factors, including nociceptive (neuroma hyperactivity), neuropathic (cortical reorganization), or psychogenic mechanisms. Numerous studies have shown that the use of prosthetics with sensory feedback significantly reduces phantom limb pain for upperlimb (38, 112, 114) and lower-limb (166) amputees. T ypical measurements of pain are the McGill Pain Questionnaire (168), the Neuropathic Pain Symptom Inventory (169), and the Visual Analog Pain intensity scale, but it can also be measured with the DASH assessment (146) and the physical domain of the WHOQOL test.\n\nLongitudinal experiments with amputee patients have demonstrated changes in body schema representation and embodiment of the prosthetic when tactile (62, 170) or proprioceptive (171) feedback is provided to the subject. A questionnaire-based measurement inspired by the rubber hand illusion (172) is often used. T ools for psychometrical measurement of the embodiment include a visuo-tactile integration task (173) and a cross-modal congruency task (174). A similar protocol using audio-tactile stimuli (175) revealed changes of the peripersonal space around the stump following prolonged use of a prosthetic limb ( Figure 3 e ). In the same study, the authors used a tactile distance perception task in subjects' healthy and amputated arms to measure the perceived length of the remaining part of the upper limb and the homologous region of the healthy limb.\n\nEtiology: the cause, set of causes, or manner of causation of a disease or condition\n\nThere is no single measurement that assesses all aspects of the use of an RPH. T o evaluate the validity of novel technology, the experimenter should consider the multifaceted aspects of the impairment and subjects' biopsychosocial welfare, which is possible only via a series of tools, as presented in this section. In the case of prosthetics with sensory feedback, there is a lack of validated and well-established measurements, but several research groups are working to define adapted measurements, which might become the new norm in the future.\n",
    "topic": "Methods for evaluating object property discrimination (stiffness and size) and the integration of multisensory feedback (vision and tactile) in prosthetic users.",
    "response": "<document_analysis>\nThe provided context discusses various assessment tools used in rehabilitation, particularly for prosthetic hands (RPHs) with sensory feedback. It highlights traditional tools adapted from neurological impairments and newer, specific tests developed to address the challenges of evaluating prosthetic users, especially those integrating sensory feedback. Among these, particular attention is given to methods measuring the discrimination of object properties such as stiffness and size. The Grasping Relative Index of Performance uses an analogy to Fitts' law to quantify grasping difficulty based on object weight and hardness. Other assessments estimate object stiffness and size discrimination, with Risso et al. investigating how vision, tactile feedback via intraneural stimulation, and their integration contribute to size estimation of handheld objects. This indicates a sophisticated approach that probes multisensory integration in prosthetic users. The text also mentions other tests (magnetic table task, Virtual Egg Test) used to evaluate sensory encoding strategies but focuses more on object property discrimination through combined sensory modalities. The complexity lies in understanding how different sensory feedback modalities (vision, tactile, their integration) affect perceptual discrimination, which is critical for prosthetic function and embodiment.\n\nDifficulty rating: 9/10 \u2014 The question must require understanding of sensory feedback modalities, their integration, and the specifics of object property discrimination in prosthetic users, involving knowledge of psychophysical principles and prosthetic evaluation methods.\n\nThe question should invite reflection on how multisensory feedback contributes to object property discrimination, the theoretical basis (like Fitts' law analogy), and how this might translate into assessment and prosthetic design.\n\nThe context is meaningful, detailed, and sufficiently technical to generate a highly challenging question about evaluating object property discrimination and multisensory integration in prosthetic users.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do current evaluation methods quantify the role of multisensory feedback\u2014specifically vision and tactile input via intraneural stimulation\u2014in the discrimination of object size and stiffness by prosthetic users, and what theoretical framework underpins the measurement of grasping difficulty in these assessments?\n\nExplanation: Evaluation methods such as those developed by Risso et al. investigate the contributions of vision, tactile feedback delivered through intraneural stimulation, and their integration in estimating object size, demonstrating the importance of multisensory inputs in prosthetic perception. The Grasping Relative Index of Performance applies an analogy to Fitts' law by defining grasping difficulty as the ratio of object weight to hardness, equating grasping a fragile object to reaching a smaller target, thus providing a theoretical basis for quantifying the challenge in controlling grasp force and feedback integration.\n\nCorrect Answer: By assessing size and stiffness discrimination through combined vision and intraneural tactile feedback integration, using the Grasping Relative Index of Performance based on an adapted Fitts' law framework relating object weight and hardness to grasping difficulty.\n</output_format>",
    "question": "How do current evaluation methods quantify the role of multisensory feedback\u2014specifically vision and tactile input via intraneural stimulation\u2014in the discrimination of object size and stiffness by prosthetic users, and what theoretical framework underpins the measurement of grasping difficulty in these assessments?",
    "answer": "By assessing size and stiffness discrimination through combined vision and intraneural tactile feedback integration, using the Grasping Relative Index of Performance based on an adapted Fitts' law framework relating object weight and hardness to grasping difficulty.",
    "explanation": "Evaluation methods such as those developed by Risso et al. investigate the contributions of vision, tactile feedback delivered through intraneural stimulation, and their integration in estimating object size, demonstrating the importance of multisensory inputs in prosthetic perception. The Grasping Relative Index of Performance applies an analogy to Fitts' law by defining grasping difficulty as the ratio of object weight to hardness, equating grasping a fragile object to reaching a smaller target, thus providing a theoretical basis for quantifying the challenge in controlling grasp force and feedback integration.",
    "question_token_count": 54,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 46
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "The pathophysiology, measurement, and management of phantom limb pain and residual limb pain in amputees, including the use of the McGill Pain Questionnaire and the Neuropathic Pain Symptom Inventory.",
    "response": "<document_analysis>\nThe provided context is a list of references primarily related to prosthetics, sensory feedback, nerve surgery, functional assessment tools, and pain measurement in amputees. Among these, some references specifically address phantom limb pain (Ephraim et al. 2005), the McGill Pain Questionnaire (Melzack 2005), and the Neuropathic Pain Symptom Inventory (Bouhassira et al. 2004). These references indicate measurement tools and surveys used to assess neuropathic pain and phantom limb pain in amputees, suggesting an emphasis on both the pathophysiological mechanisms and clinical evaluation of such pain phenomena. The references point to multidimensional approaches for understanding and managing phantom and residual limb pain, including sensory feedback techniques and pain symptom inventories.\n\nThe key ideas involve:\n- The complex sensory and neurological underpinnings of phantom limb pain and residual limb pain.\n- The use of validated assessment tools such as the McGill Pain Questionnaire and the Neuropathic Pain Symptom Inventory to characterize and quantify pain.\n- The clinical implications of accurate measurement for treatment and rehabilitation.\n- The relationship between sensory feedback restoration and potential reduction of phantom pain.\n\nImplicit assumptions include that phantom limb pain involves neuropathic mechanisms measurable by standardized tools, and that these measurements are crucial for appropriate clinical management. The interplay of sensory feedback and pain perception is also a critical theme.\n\nDifficulty rating is 9/10 because it requires integration of neuropathic pain pathophysiology, clinical pain measurement instruments, and implications for prosthesis-related rehabilitation\u2014topics that require advanced expertise in neurorehabilitation, pain science, and prosthetics.\n\nThe question should prompt reflection on how pain measurement tools capture the complexity of phantom limb pain and how this understanding guides management strategies, encouraging a nuanced grasp of neuroplasticity, pain phenomenology, and clinical application.\n\nThis context is meaningful and educationally valuable, warranting a challenging, technical question.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the McGill Pain Questionnaire and the Neuropathic Pain Symptom Inventory differ in their approach to characterizing phantom limb and residual limb pain in amputees, and what are the implications of these differences for tailoring effective pain management strategies?\n\nExplanation: The McGill Pain Questionnaire assesses the qualitative and multidimensional aspects of pain including sensory, affective, and evaluative components, providing a broad phenomenological profile of phantom limb pain, whereas the Neuropathic Pain Symptom Inventory focuses specifically on neuropathic pain symptoms through a structured symptom checklist. These differences allow clinicians to distinguish neuropathic features from other pain dimensions, enabling more precise diagnosis and individualized treatment plans targeting neuropathic mechanisms or broader pain experiences, thereby improving management outcomes for amputees.\n\nCorrect Answer: The McGill Pain Questionnaire provides a multidimensional qualitative assessment of pain experience, while the Neuropathic Pain Symptom Inventory quantitatively targets neuropathic symptoms specifically, guiding tailored pain management by distinguishing pain types in amputees.\n</output_format>",
    "question": "How do the McGill Pain Questionnaire and the Neuropathic Pain Symptom Inventory differ in their approach to characterizing phantom limb and residual limb pain in amputees, and what are the implications of these differences for tailoring effective pain management strategies?",
    "answer": "The McGill Pain Questionnaire provides a multidimensional qualitative assessment of pain experience, while the Neuropathic Pain Symptom Inventory quantitatively targets neuropathic symptoms specifically, guiding tailored pain management by distinguishing pain types in amputees.",
    "explanation": "The McGill Pain Questionnaire assesses the qualitative and multidimensional aspects of pain including sensory, affective, and evaluative components, providing a broad phenomenological profile of phantom limb pain, whereas the Neuropathic Pain Symptom Inventory focuses specifically on neuropathic pain symptoms through a structured symptom checklist. These differences allow clinicians to distinguish neuropathic features from other pain dimensions, enabling more precise diagnosis and individualized treatment plans targeting neuropathic mechanisms or broader pain experiences, thereby improving management outcomes for amputees.",
    "question_token_count": 50,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 45
  },
  {
    "context": "## 5.3. Sensory Architectures\nTheproblem of handling many sensors at the same time has been addressed successfully in the past by using time-sharing (multiplexing) and space-sharing (matrix arrangement) techniques, minimizing wiring complexity while keeping read latency in an acceptable range. Nevertheless, this approach does not scale well in terms of covering the whole hand with a sensor density comparable to that of the human hand. Additionally, the unavoidable increase in the number of electrical connections makes the system highly susceptible to breakage.\n\nEvent-based architectures rely on the concept of send-on-delta (123), where each sensor (comprising an analog front end and an analog-to-digital converter), instead of signaling its value at a constant rate, does so only when the value changes by more than a certain threshold. These architectures have many advantages owing to the sparsity of the data representation. In other words, the communication line does not need to be capable of handling all the sensors simultaneously (as an interaction where all the sensors are triggered in the same moment is unlikely); instead, single sensors are polled at a high rate, which preserves the time structure of the stimulus.\n\nThe underlying idea of event-based systems is inspired by how neurons communicate information to each other, sending a train of spikes instead of continuous value. In earlier implementations, data flowed from sensors to the central unit through digital communication lines using well-known protocols such as Universal Asynchronous Transmitter Receiver (UART), Ethernet, and the Controller Area Network (CAN) bus. Some groups have designed communication paradigms by mimicking information encoding by the nerves; using pulses of 20 ns, Bartolozzi et al. (124) showed a 94% improvement in data rate over traditional protocols.\n\nAn even more advanced step was made in the work of Lee et al. (125), where the sensors communicate with spikes through the same conductive surface without any flow control, reducing the wires needed to two (data and ground). In this way, at the cost of a decoding stage for sensor value acquisition, the performance of the architecture increased, reaching up to 100,000 sensors sharing the same bus.\n",
    "topic": "The concept and implementation of pulse-based communication mimicking nerve encoding to improve data rates in tactile sensor networks.",
    "response": "<document_analysis>\nThe context discusses sensory architectures for handling many sensors simultaneously, focusing on the evolution from traditional multiplexing and matrix arrangements to event-based architectures inspired by neural spike communication. Traditional methods face scalability issues due to wiring complexity and latency when trying to achieve high sensor density like that of the human hand. Event-based systems mitigate this by sending data only when the sensor value changes beyond a threshold (send-on-delta), capitalizing on sparse data and temporal structure preservation.\n\nA key advanced technique mentioned is the use of pulse-based communication mimicking nerve encoding. Bartolozzi et al. demonstrated that using very short pulses (20 ns) for data transmission can improve data rates by 94% compared to traditional protocols such as UART, Ethernet, or CAN bus. This approach leverages the neural-inspired spike encoding paradigm rather than continuous data streams.\n\nFurthermore, Lee et al. pushed this concept forward by enabling spike communication of sensors over a shared conductive surface with minimal wiring (two wires: data and ground) and no flow control. Although this requires a decoding stage, it allows up to 100,000 sensors to share the same bus, massively increasing scalability and reducing wiring complexity.\n\nThe implicit assumptions include the analogy between neural spike communication and sensor data transmission, the benefits of sparse event-driven data for bandwidth and wiring reduction, and the trade-offs introduced by decoding complexity.\n\nThe question difficulty rates at 9/10 because it requires understanding neural spike encoding principles, communication protocols, and their impact on sensor network scalability and data rates.\n\nThe question should probe understanding of why pulse-based spike communication improves data rates and how it can be practically implemented in tactile sensor networks, including the trade-offs involved.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does pulse-based communication inspired by neural spike encoding enhance data transmission rates in tactile sensor networks compared to traditional protocols, and what are the key trade-offs involved in implementing such systems?\n\nExplanation: Pulse-based communication mimics neurons by sending discrete spikes only when significant changes occur, exploiting data sparsity to reduce bandwidth needs and enabling higher data rates, as shown by a 94% improvement over traditional protocols. Implementing this requires specialized decoding stages and novel wiring strategies, such as using a shared conductive surface with minimal wires, which reduces wiring complexity but adds decoding complexity and challenges like lack of flow control.\n\nCorrect Answer: By transmitting discrete spikes only on significant changes, pulse-based communication reduces bandwidth and improves data rates, but it requires complex decoding and specialized wiring with minimal flow control.\n</output_format>",
    "question": "How does pulse-based communication inspired by neural spike encoding enhance data transmission rates in tactile sensor networks compared to traditional protocols, and what are the key trade-offs involved in implementing such systems?",
    "answer": "By transmitting discrete spikes only on significant changes, pulse-based communication reduces bandwidth and improves data rates, but it requires complex decoding and specialized wiring with minimal flow control.",
    "explanation": "Pulse-based communication mimics neurons by sending discrete spikes only when significant changes occur, exploiting data sparsity to reduce bandwidth needs and enabling higher data rates, as shown by a 94% improvement over traditional protocols. Implementing this requires specialized decoding stages and novel wiring strategies, such as using a shared conductive surface with minimal wires, which reduces wiring complexity but adds decoding complexity and challenges like lack of flow control.",
    "question_token_count": 37,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 33
  },
  {
    "context": "## 4.1. Decoding Algorithms\nThe clinical standard for RPH control is based on the use of two sEMG channels, with the electrodes placed superficially on antagonist muscles. The envelope of the signal is extracted so that the user can control the closing and opening of the RPH by modulating the amplitude of their muscle contraction. When the amplitude exceeds a certain threshold, the RPH will move depending on which muscle was activated. Companies are offering more DOFs, using cocontraction to\n\ncycle through different types of grasps (e.g., Ottobock's Michelangelo hand). However, this type of control is highly nonintuitive and gives only low dexterity to the user. An alternative to this direct control approach is based on pattern recognition methods, extracting hand-crafted features to characterize the signal in a discriminative way (e.g., the signal root mean square, wavelength, and zero crossing) and classify the type of grasp intended by the user. This solution has become robust enough to reach the market (the Coapt system and Ottobock's Myo Plus). Using 2-12 bipolar sEMG electrodes makes it possible to obtain good classification rates for different kinds of grasps, with 90-95% accuracy for 4-12 classes and up to 75% for 50 classes (68-72).\n\nUsing a similar electrode disposition and classification method, other groups showed the possibility of decoding single-finger movement using the classification of flexion or extension (73, 74). Recently, Bhagwat &amp; Mukherji (75) showed single- and multifinger classification of 15 different movements with 99.79% accuracy. Researchers are also working on proportional control instead of classification, which makes it possible to decode several DOFs (e.g., wrist and finger movements) simultaneously and proportionally (76, 77). This type of control offers continuous position control. Several studies have also shown that single-finger proportional control is feasible, with good results (78, 79).\n\nAs an alternative, nonbiomimetic EMG decoders have been developed that rely on the subject learning inverse maps to relate motor outputs to arbitrary control variables (80). Using an abstract decoding cursor control space, subjects can learn to modulate their EMG activity to reach different targets arranged in a center-out task in order to trigger various grasping movements (81). Dyson et al. (82) recently validated these results on amputee participants; they showed that after training, the difficulty of the tasks could be increased, improving the possibilities for robotic hand control.\n\nWith only a few electrodes placed on muscles of interest, the accurate positioning of the electrodes requires anatomical knowledge; indeed, the type of amputation (congenital or traumatic), the surgical procedure, and the time since amputation (83) could influence the muscle anatomy and make the placement of the electrode tedious and specific to individual subjects. Moreover, a small shift in electrode placement can disrupt the pattern recognition algorithm (84). T o tackle these issues, several authors have proposed HD-sEMG, which consists of a grid of closely spaced electrodes, as an alternative solution. The large number of electrodes allows information to be recorded from a large part of the subject's forearm.\n\nHD-sEMG signals offer high spatial resolution, and recorded signals can be interpreted as spatial images of EMG activity. Using this image representation of EMG data, HD-sEMG is robust to small electrode shifts (85). Boschmann &amp; Platzner (85) used a structural similarity index, borrowed from the computer vision field, on HD-sEMG images combined with a simple one-against-one nearest-neighbor classifier to decode wrist and hand motions. Similarly, Stango et al. (86) used a variogram of images (a measure of the degree of spatial correlation, used mainly in geostatistics) to classify wrist movements. Both groups showed that their methods, which use spatial information from the images, performed better or similarly to the classic feature extraction approach. Moreover, their strategies improved the robustness to electrode shift and electrode number. The use of several spatially close electrodes makes it possible to decompose the EMG signal into its constituent motor unit action potential (50, 87). Kapelner et al. (88) investigated this approach, decomposing EMG signals to extract motor unit activity from forearm muscles during wrist motions. Recently, Dai &amp; Hu (89) showed that an approach consisting of finger joint angle estimation, combining classification for finger selection with EMG decomposition into motor unit activity, outperforms a standard amplitude-based approach.\n\nWe observe a paradigm shift from feature engineering to feature learning using raw data as input for deep neural networks. Studies have shown that combining this deep learning approach with HD-sEMG offers better performance than hand-crafted features in both grasp classification\n\n(90) and simultaneous single-finger and wrist movement classification (91). Deep learning has also shown good results with a smaller number of electrodes for grasp classification (72) and regression of arm or wrist motions (92, 93).\n\nThis approach permits both high dexterity and robustness, with unprecedented performance. However,one of the major difficulties of the deep learning approach is that it requires an extensive data set for training. For example, the deep learning used for the ImageNet challenge in 2012 used 1.2 million images for training on 1,000 categories (94). In the context of hand gesture recognition, generating tens of thousands of examples for a subject is not a viable option.\n\nA possible solution could use domain adaptation [often called transfer learning in the EMG literature (95, 96)], by leveraging data acquired from several subjects to enhance and accelerate training for a new user. Indeed, the aim is to use information from a database of several source domains and adapt it to a target domain (the end user) with a small number of samples. Authors generally apply deep domain adaptation (domain adaptation combined with deep learning) by pretraining a deep neural network and fine-tuning it with a few repetitions of movements by a target subject. The main idea is that gathering the recordings of several participants can meet the necessary conditions to learn a general mapping of all users' sEMG signals.\n\nUsing this idea, C\u00f4t\u00e9-Allard et al. (97) showed that their deep model was able to learn the features and significantly enhance the performance of deep networks on out-of-sample gestures. Using HD-sEMG and deep learning, Du et al. (98) also showed an unsupervised deep domain adaptation method that incrementally learns from data during a new session without explicit calibration of gestures. Consequently, deep learning offers a particularly attractive context from which to develop deep domain adaptation algorithms to leverage interuser data. This approach can increase decoding performance, improve robustness to electrode shift, and reduce the number of repetitions needed during training (99).\n\nAs seen in this section, the search for new EMG decoding algorithms that go beyond thresholdbased detection is an active field of research. Phinyomark &amp; Scheme (100) and Khamparia &amp; Singh (101) have reviewed recent research in EMG pattern recognition methods.\n\nMachine learning in the field of computer vision and object recognition has shown outstanding results using deep learning and is already used commercially by many companies. Some deep learning algorithms based on a pretrained network are now usable without any fine-tuning (e.g., self-driving cars). However, bio-signals are intrinsically different from images and need adaptation. More important, the amount of labeled EMG data available to effectively train deep networks might not be sufficient to capture the evolution of the signal over time (electrode displacement, skin impedance changes, etc.). Therefore, if model architectures and data processing are tailored for bio-signal applications and take into consideration signal evolution with time, deep learning can become a solution for more robust motor intention decoding.\n",
    "topic": "The use of unsupervised deep domain adaptation methods to incrementally learn from new data without explicit calibration and its implications for practical prosthetic control.",
    "response": "<document_analysis>\nThe context provides a comprehensive overview of decoding algorithms for robotic prosthetic hand (RPH) control using surface electromyography (sEMG). It discusses traditional threshold-based control, pattern recognition with handcrafted features, proportional control, and emerging approaches including high-density sEMG (HD-sEMG) and deep learning. A particular focus is on the challenges of deep learning, such as the need for large labeled datasets and sensitivity to electrode placement. The text highlights deep domain adaptation as a promising approach to leverage data from multiple users to reduce training effort for new users and improve robustness to electrode shift and signal variability. Notably, Du et al. demonstrated an unsupervised deep domain adaptation method that incrementally learns from new session data without explicit calibration of gestures, which can enhance real-world usability by minimizing user burden during prosthetic control setup.\n\nImplicit in this discussion are key challenges in practical prosthetic control: variability in sEMG signals over time and across subjects, the difficulty of collecting large labeled datasets for each individual user, and the necessity for adaptive algorithms that maintain performance despite these variabilities. Unsupervised deep domain adaptation addresses these by enabling continuous, calibration-free learning that adapts the model to the user\u2019s changing signals, potentially enabling more intuitive and reliable prosthetic control.\n\nThe question should probe deep technical understanding of how unsupervised deep domain adaptation impacts practical prosthetic use, including how it addresses issues of signal variability, training data scarcity, and user calibration burden, and what implications this has for robustness and usability. This requires comprehension of both machine learning methodology and prosthetic application constraints.\n\nDifficulty rating: 9/10 due to the need for integrating knowledge of EMG signal processing, deep learning, domain adaptation, and practical prosthetic control challenges.\n\nThe question will be designed to stimulate reflection on the critical role of unsupervised incremental learning without explicit calibration in advancing prosthetic control systems beyond traditional methods, emphasizing practical implications rather than purely theoretical ones.\n</document_analysis>\n\n<output_format>\nQuestion: How does the use of unsupervised deep domain adaptation methods that incrementally learn from new session data without explicit calibration address key challenges in practical prosthetic hand control, and what are the implications of this approach for robustness and user training requirements?\n\nExplanation: Unsupervised deep domain adaptation methods enable prosthetic control algorithms to adapt continuously to the user\u2019s sEMG signal variations over time and between sessions without requiring explicit gesture calibration. This reduces the burden of collecting large labeled datasets and frequent retraining, improves robustness to electrode shifts and physiological changes, and allows for more seamless and intuitive control, thereby enhancing usability and reducing training time for users.\n\nCorrect Answer: It enables continuous adaptation to signal variability without explicit calibration, improving robustness and reducing user training requirements.\n</output_format>",
    "question": "How does the use of unsupervised deep domain adaptation methods that incrementally learn from new session data without explicit calibration address key challenges in practical prosthetic hand control, and what are the implications of this approach for robustness and user training requirements?",
    "answer": "It enables continuous adaptation to signal variability without explicit calibration, improving robustness and reducing user training requirements.",
    "explanation": "Unsupervised deep domain adaptation methods enable prosthetic control algorithms to adapt continuously to the user\u2019s sEMG signal variations over time and between sessions without requiring explicit gesture calibration. This reduces the burden of collecting large labeled datasets and frequent retraining, improves robustness to electrode shifts and physiological changes, and allows for more seamless and intuitive control, thereby enhancing usability and reducing training time for users.",
    "question_token_count": 47,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 20
  },
  {
    "context": "## ICORR.2013.6650494\n- 159. Kyberd P, Hussaini A, Maillet G. 2018. Characterisation of the Clothespin Relocation T est as a functional assessment tool. J. Rehabil. Assist. T echnol. Eng. 5. https://doi.org/10.1177/2055668317750810\n\n- 160. Yozbatiran N, Der-Yeghiaian L, Cramer SC. 2008. A standardized approach to performing the action research arm test. Neurorehabil. Neural Repair 22:78-90\n\n- 161. Light CM,Chappell PH, Kyberd PJ. 2002. Establishing a standardized clinical assessment tool of pathologic and prosthetic hand function: normative data, reliability, and validity. Arch. Phys. Med. Rehabil. 83:776-83\n\n- 162. Thumser ZC, Slifkin AB, Beckler DT, Marasco PD. 2018. Fitts' law in the control of isometric grip force with naturalistic targets. Front. Psychol. 9:560\n\n- 163. Risso G, Valle G, Iberite F, Strauss I, Stieglitz T, Controzzi M. 2019. Optimal integration of intraneural somatosensory feedback with visual information: a single-case study. Sci. Rep. 9:7916\n\n- 164. Schiefer M, T an D, Sidek SM, Tyler DJ. 2015. Sensory feedback by peripheral nerve stimulation improves task performance in individuals with upper limb loss using a myoelectric prosthesis. J. Neural Eng. 13:016001\n\n- 165. Deeny S, Chicoine C, Hargrove L, Parrish T, Jayaraman A. 2014. A simple ERP method for quantitative analysis of cognitive workload in myoelectric prosthesis control and human-machine interaction. PLOS ONE 9:e112091\n\n- 166. Petrini FM, Bumbasirevic M, Valle G, Ilic V, Mijovi\u00b4 c P, et al. 2019. Sensory feedback restoration in leg amputees improves walking speed, metabolic cost and phantom pain. Nat. Med. 25:1356-63\n\n- 167. Ephraim PL, Wegener ST, MacKenzie EJ, Dillingham TR, Pezzin LE. 2005. Phantom pain, residual limb pain, and back pain in amputees: results of a national survey. Arch. Phys. Med. Rehabil. 86:1910-19\n\n- 168. Melzack R. 2005. The McGill Pain Questionnaire: from description to measurement. Anesthesiology 103:199-202\n\n- 169. Bouhassira D, Attal N, Fermanian J, Alchaar H, Gautron M, et al. 2004. Development and validation of the Neuropathic Pain Symptom Inventory. Pain 108:248-57\n\n- 170. Rognini G, Rossini PM, Strauss I, D'Anna E, Mange R, et al. 2018. Multisensory bionic limb to achieve prosthesis embodiment and reduce distorted phantom limb perceptions. J. Neurol. Neurosurg. Psychiatry 90:833-36\n\n- 171. Marasco PD,Hebert JS,Sensinger JW,Shell CE,Schofield JS,et al.2018.Illusory movement perception improves motor control for prosthetic hands. Sci. Transl. Med. 10:eaao6990\n\n- 172. Botvinick M, Cohen J. 1998. Rubber hands 'feel' touch that eyes see. Nature 391:756\n\n- 173. Di Pino G, Romano D, Spaccasassi C, Mioli A, D'Alonzo M, et al. 2020. Sensory- and action-oriented embodiment of neurally-interfaced robotic hand prostheses. Front. Neurosci. 14:389\n\n- 174. Blustein D, Wilson A, Sensinger J. 2018. Assessing the quality of supplementary sensory feedback using the crossmodal congruency task. Sci. Rep. 8:6203\n\n- 175. Canzoneri E, Marzolla M, Amoresano A, Verni G, Serino A. 2013. Amputation and prosthesis implantation shape body and peripersonal space representations. Sci. Rep. 3:2844\n\n- 176. Lundborg G. 2000. A 25-year perspective of peripheral nerve surgery: evolving neuroscientific concepts and clinical significance. J. Hand. Surg. 25:391-414\n\n- 177. Bernardon L, Gazarian A, Petruzzo P, Packham T, Guillot M, et al. 2015. Bilateral hand transplantation: functional benefits assessment in five patients with a mean follow-up of 7.6 years (range 4-13 years). J. Plast. Reconstr. Aesthet. Surg. 68:1171-83\n\n- 178. Schultz AE, Marasco PD, Kuiken TA. 2009. Vibrotactile detection thresholds for chest skin of amputees following targeted reinnervation surgery. Brain Res . 1251:121-29\n\n- 179. Geng W, Du Y, Jin W, Wei W, Hu Y, Li J. 2016. Gesture recognition by instantaneous surface EMG images. Sci. Rep. 6:36571\n\n- 180. Navarro X, Calvet S, Rodr\u00edguez FJ, Stieglitz T, Blau C, et al. 1998. Stimulation and recording from regenerated peripheral nerves through polyimide sieve electrodes. J. Peripher. Nerv. Syst. 3:91-101\n\n- 181. Valle G, Petrini FM, Strauss I, Iberite F, D'Anna E, et al. 2018. Comparison of linear frequency and amplitude modulation for intraneural sensory feedback in bidirectional hand prostheses. Sci. Rep. 8:16666\n\n- 182. George JA, Davis TS, Brinton MR, Clark GA. 2019. Intuitive neuromyoelectric control of a dexterous bionic arm using a modified Kalman filter. J. Neurosci. Methods 330:108462\n\n- 183. Maravita A, Spence C, Driver J. 2003. Multisensory integration and the body schema: close to hand and within reach. Curr. Biol. 13:R531-39\n\n- 184. Hahne JM, Schweisfurth MA, Koppe M, Farina D. 2018. Simultaneous control of multiple functions of bionic hand prostheses: performance and robustness in end users. Sci. Robot. 3:eaat3630",
    "topic": "The phenomenon of prosthesis embodiment and distorted phantom limb perceptions, with emphasis on multisensory bionic limb approaches and the rubber hand illusion.",
    "response": "<document_analysis>\nThe context is a series of references primarily focusing on advanced prosthetics, sensory feedback, and embodiment phenomena related to limb loss and prosthesis control. Key themes include clinical assessment tools for prosthetic function, integration of sensory feedback (intraneural, peripheral nerve stimulation), cognitive workload during prosthesis use, and the impact of sensory feedback on phantom limb pain and motor control. References 170, 171, 172, and 173 particularly address prosthesis embodiment and distorted phantom limb perceptions through multisensory integration and illusions like the rubber hand illusion. These studies highlight how multisensory feedback can improve the sense of ownership and control of prosthetic limbs, reducing phantom limb distortions.\n\nThe question topic specifically targets the phenomenon of prosthesis embodiment and distorted phantom limb perceptions, focusing on multisensory approaches and the rubber hand illusion. Given the references, the question can probe the mechanisms by which multisensory integration fosters embodiment and alters phantom limb perception, and how the rubber hand illusion paradigm informs prosthetic design.\n\nDifficulty rating: 9/10. The question should demand synthesis of neurophysiological, psychological, and prosthetic design knowledge, requiring an expert-level understanding of embodiment mechanisms, sensory feedback modalities, and their clinical implications.\n\nThe question will invite critical reflection on how multisensory bionic limbs reduce phantom limb distortions by leveraging principles demonstrated by the rubber hand illusion, promoting prosthesis embodiment.\n\nThe content is meaningful, coherent, and highly relevant to the question topic, enabling the creation of a highly challenging and insightful question-answer pair.\n</document_analysis>\n\n<output_format>\nQuestion: How does multisensory integration in bionic limbs reduce distorted phantom limb perceptions and promote embodiment, and what role does the rubber hand illusion paradigm play in informing the design of these prosthetic sensory feedback systems?\n\nExplanation: Multisensory integration in bionic limbs combines somatosensory feedback (e.g., intraneural or peripheral nerve stimulation) with visual information to create congruent sensory experiences that enhance the sense of ownership and control over the prosthesis, thereby reducing distorted phantom limb perceptions. The rubber hand illusion demonstrates that synchronized visual and tactile stimuli can induce a feeling of ownership over an artificial limb, providing a neurophysiological basis for designing multisensory feedback systems in prosthetics that aim to achieve embodiment and alleviate phantom limb distortions.\n\nCorrect Answer: By synchronizing congruent somatosensory and visual feedback to create a coherent multisensory experience, bionic limbs leverage principles from the rubber hand illusion to enhance prosthesis embodiment and reduce phantom limb distortions.\n</output_format>",
    "question": "How does multisensory integration in bionic limbs reduce distorted phantom limb perceptions and promote embodiment, and what role does the rubber hand illusion paradigm play in informing the design of these prosthetic sensory feedback systems?",
    "answer": "By synchronizing congruent somatosensory and visual feedback to create a coherent multisensory experience, bionic limbs leverage principles from the rubber hand illusion to enhance prosthesis embodiment and reduce phantom limb distortions.",
    "explanation": "Multisensory integration in bionic limbs combines somatosensory feedback (e.g., intraneural or peripheral nerve stimulation) with visual information to create congruent sensory experiences that enhance the sense of ownership and control over the prosthesis, thereby reducing distorted phantom limb perceptions. The rubber hand illusion demonstrates that synchronized visual and tactile stimuli can induce a feeling of ownership over an artificial limb, providing a neurophysiological basis for designing multisensory feedback systems in prosthetics that aim to achieve embodiment and alleviate phantom limb distortions.",
    "question_token_count": 41,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 9,
    "question_groundedness_score": 8,
    "avg_answer_token_count": 40
  },
  {
    "context": "## 4.2. Shared Control to Help Motor Decoding\nThe ultimate goal of RPH control is to be as close as possible to controlling a natural hand. Therefore, an ideal control needs to be intuitive and continuous over individual fingers and wrist movements. Increasing the number of DOFs and developing proportional control will increase dexterity for prosthesis users but will inevitably reduce the overall robustness of the decoder. Since reliability is one of the main factors for upper-limb prosthesis users (102), this is a significant issue for the commercialization of more dexterous control schemes.\n\nOne possible solution to improve decoding robustness is to add robotic automation of some portion of the motor command. Shared-control strategies between a subject and a smart robotic hand have been reported for automated preshaping and grasping (103), grip force adjustment\n\n(104), slip detection, and hand closing (105). In the context of single-finger proportional control, Zhuang et al. (79) proposed a shared-control strategy to increase grasp robustness (avoiding accidental drops), by maximizing the number of contacts between the RPH and an object while allowing the user to maintain full autonomy over decisions about grasping and releasing, grasp preshaping, and non-grasp-related motions. These strategies allow both freedom during singlefinger control and robustness during a grasp event (79) and can perform more dexterous movements that cannot be decoded based on EMG alone. However, they necessitate many DOAs (e.g., active control of each phalanx to reposition the fingers around an object), which is still a significant challenge in terms of motor miniaturization, power consumption, and cost.\n",
    "topic": "Investigate the role of intuitive and continuous control across individual fingers and wrist movements in achieving naturalistic prosthetic hand operation.",
    "response": "<document_analysis>\nThe context focuses on the challenges and solutions in achieving naturalistic control of robotic prosthetic hands (RPH), emphasizing that ideal control should be intuitive and continuous over individual fingers and wrist movements to mimic natural hand function. It highlights the trade-off between increasing degrees of freedom (DOFs) and proportional control\u2014which improve dexterity\u2014and the resulting reduction in decoder robustness, critical for prosthesis reliability. The text discusses shared-control strategies combining user input with robotic automation to enhance robustness without sacrificing autonomy, especially during grasping tasks. These strategies enable complex movements beyond EMG decoding capabilities but require many degrees of actuation (DOAs), posing technical challenges related to miniaturization, power, and cost. The topic demands understanding of motor decoding, control theory, and prosthetic design constraints. The difficulty level is high (9/10) due to the integration of neuroprosthetic control, robotic automation, and system design trade-offs. A probing question can explore the implications of intuitive and continuous control on balancing dexterity and robustness, requiring deep insight into the interplay between user control and robotic assistance in advanced prostheses.\n\n</document_analysis>\n\n<output_format>\nQuestion: How does striving for intuitive and continuous control across individual fingers and wrist movements in prosthetic hands impact the balance between dexterity and decoder robustness, and what role do shared-control strategies play in addressing the inherent challenges of this balance?\n\nExplanation: Intuitive and continuous control over many degrees of freedom enhances dexterity to mimic natural hand function but decreases decoder robustness due to complexity and potential signal variability. Shared-control strategies mitigate this by automating parts of the motor command, maintaining user autonomy while improving reliability, especially during complex tasks like grasping, thus addressing the trade-off between fine motor control and system stability.\n\nCorrect Answer: Increasing intuitive, continuous control increases dexterity but reduces robustness; shared-control strategies automate some movements to preserve reliability while maintaining user autonomy.\n</output_format>",
    "question": "How does striving for intuitive and continuous control across individual fingers and wrist movements in prosthetic hands impact the balance between dexterity and decoder robustness, and what role do shared-control strategies play in addressing the inherent challenges of this balance?",
    "answer": "Increasing intuitive, continuous control increases dexterity but reduces robustness; shared-control strategies automate some movements to preserve reliability while maintaining user autonomy.",
    "explanation": "Intuitive and continuous control over many degrees of freedom enhances dexterity to mimic natural hand function but decreases decoder robustness due to complexity and potential signal variability. Shared-control strategies mitigate this by automating parts of the motor command, maintaining user autonomy while improving reliability, especially during complex tasks like grasping, thus addressing the trade-off between fine motor control and system stability.",
    "question_token_count": 46,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 10,
    "avg_answer_token_count": 27
  },
  {
    "context": "## 3.2. Perspectives\nThe challenges for future interfaces that can provide the necessary read/write bandwidth to use RPHs in a natural fashion are immense. We argue that the motor and sensory domains raise different problems. Indeed, the stimulation being close to the target is mandatory with current technologies, and therefore the best solutions are the most invasive ones. In the motor domain, it is possible to decompose the signal if we have enough sources (even noninvasive sources, as with sEMG). As shown in Section 4, machine learning techniques can help infer information from noninvasive interfaces.\n\nOn the sensory level, the currently implantable electrodes are the most promising solution. However, the main advancement so far has been for the tactile modality, while the use of other modalities for proprioception has been obtained via a nonhomologous approach based on intraneural stimulation combined with the delivery of homologous tactile feedback via indirectly targeted intraneural electrical stimulation (64).\n\nTemperature sensation is another limit. T emperature is mediated through A \u03b4 fibers (for cold) and C fibers (for warmth). Given the very small size of these fibers (C fibers are 20-100 times smaller than A \u03b2 fibers), it is not possible to target them using existing state-of-the-art electrodes (42). Future electrodes with even higher levels of selectivity might be able to target A \u03b4 and C fibers. Sensory remapping (65) can be another viable solution to simulate temperature feedback on a different part of the body using a temperature display.\n",
    "topic": "The distinct technical and biological challenges in developing naturalistic read/write bandwidth interfaces for motor versus sensory prosthetic systems.",
    "response": "<document_analysis>\nThe provided context discusses the differing challenges in developing interfaces for motor and sensory prosthetic systems, emphasizing the need for high read/write bandwidth to achieve naturalistic control and feedback. It highlights that motor domain challenges can sometimes be addressed by decomposing signals from multiple sources, including noninvasive methods like sEMG, aided by machine learning. In contrast, sensory domain challenges are more stringent, requiring invasive electrodes near target fibers, especially for modalities like touch and proprioception, with tactile feedback being more advanced than proprioception. A critical biological limitation for sensory feedback is the inability to target very small nerve fibers mediating temperature (A\u03b4 and C fibers) using current electrode technology, which is a fundamental barrier to replicating temperature sensation. The text suggests future electrodes with higher selectivity or sensory remapping strategies might overcome these issues.\n\nThis analysis reveals nuanced technical and biological distinctions between motor and sensory prosthetic interfaces: motor systems can leverage signal decomposition and machine learning with some noninvasive options, whereas sensory systems rely heavily on invasive, highly selective interfacing with small, difficult-to-target nerve fibers. The challenges relate to both the physical scale of neural targets and the fidelity of naturalistic feedback.\n\nDifficulty rating: 9/10 \u2014 The question will require expert-level understanding of neuroprosthetics, neural anatomy, interface technology, and the sensory versus motor domain differences.\n\nThe planned question will probe the expert\u2019s ability to integrate knowledge of the biological constraints (fiber size, modality differences) and technological implications (invasive vs noninvasive, electrode selectivity, machine learning) that differentiate the challenges in motor versus sensory prosthetic interfaces, encouraging reflection on why these differences exist and how they shape future development directions.\n\nThis question will stimulate critical thinking about the interplay between biological factors and engineering constraints and their impact on designing effective neuroprosthetic interfaces.\n\n</document_analysis>\n\n<output_format>\nQuestion: How do the biological characteristics of nerve fibers and current technological limitations create fundamentally different challenges for developing naturalistic read/write bandwidth interfaces in motor prosthetic systems compared to sensory prosthetic systems?\n\nExplanation: Motor prosthetic interfaces can often rely on decomposing signals from multiple sources, including noninvasive methods enhanced by machine learning, because motor commands are accessible via larger or more numerous signals; however, sensory prosthetic interfaces must achieve very high selectivity to stimulate small, modality-specific nerve fibers near the target area, such as the tiny A\u03b4 and C fibers for temperature sensation, which current electrodes cannot reliably target. This biological constraint necessitates invasive solutions and limits the naturalistic feedback achievable, creating a fundamentally different and more difficult challenge for sensory interfaces than for motor ones.\n\nCorrect Answer: The small size and modality specificity of sensory nerve fibers require highly selective invasive electrodes to provide naturalistic feedback, whereas motor interfaces can utilize larger or more accessible signals, sometimes noninvasively, making sensory prosthetics technically and biologically more challenging to implement.\n</output_format>",
    "question": "How do the biological characteristics of nerve fibers and current technological limitations create fundamentally different challenges for developing naturalistic read/write bandwidth interfaces in motor prosthetic systems compared to sensory prosthetic systems?",
    "answer": "The small size and modality specificity of sensory nerve fibers require highly selective invasive electrodes to provide naturalistic feedback, whereas motor interfaces can utilize larger or more accessible signals, sometimes noninvasively, making sensory prosthetics technically and biologically more challenging to implement.",
    "explanation": "Motor prosthetic interfaces can often rely on decomposing signals from multiple sources, including noninvasive methods enhanced by machine learning, because motor commands are accessible via larger or more numerous signals; however, sensory prosthetic interfaces must achieve very high selectivity to stimulate small, modality-specific nerve fibers near the target area, such as the tiny A\u03b4 and C fibers for temperature sensation, which current electrodes cannot reliably target. This biological constraint necessitates invasive solutions and limits the naturalistic feedback achievable, creating a fundamentally different and more difficult challenge for sensory interfaces than for motor ones.",
    "question_token_count": 37,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 6,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 51
  },
  {
    "context": "## Table 3 Clinical assessments for transradial amputees using robotic prosthetic hands\n| Somatosensory feedback   | Implicit                                            | Implicit Implicit           |                      | Explicit                   | Explicit                        | Implicit            | Implicit                         |                          | Explicit                                | Implicit      |                              | Implicit             | Explicit          |               |\n\n|--------------------------|-----------------------------------------------------|-----------------------------|----------------------|----------------------------|---------------------------------|---------------------|----------------------------------|--------------------------|-----------------------------------------|---------------|------------------------------|----------------------|-------------------|---------------|\n\n| Fine movement            |                                                     |                             |                      |                            |                                 | X                   |                                  |                          |                                         |               |                              |                      |                   |               |\n\n| Measurement Reach        |                                                     | X                           |                      |                            | X                               | X                   |                                  |                          | X                                       |               |                              |                      | X                 |               |\n\n| Grasp                    |                                                     | X                           |                      | X                          | X                               |                     |                                  |                          | X                                       |               |                              | X                    |                   |               |\n\n| Embodiment               |                                                     |                             | X                    |                            |                                 |                     |                                  | X                        |                                         |               |                              |                      |                   |               |\n\n| Quality of life          |                                                     |                             |                      |                            |                                 |                     | X                                |                          |                                         | X             |                              |                      |                   | X             |\n\n| Clinically validated     | X X                                                 |                             |                      |                            |                                 | X                   | X                                |                          |                                         | X             | X                            |                      |                   | X             |\n\n| Measurement type         | Handling and manipulation of objects Pick and place | Pick and place              | Psychometric         | Grasping                   | Pick and place                  | Pick and place      | Questionnaire                    | Psychometric             | Pick and place, manipulation            | Questionnaire | Handling and manipulation of | objects              | Pick and place    | Questionnaire |\n\n| Reference(s)             | 160 154, 155                                        | 159                         | 183                  | 139                        | 164                             | 157, 158            | 144, 150                         | 175                      | 139                                     | 147           | 161                          |                      | 129               | 148           |\n\n| Name                     | Action Research Arm Test Box and Block T est        | Clothespin Relocation T est | Cross Congruent Task | Grasping Relative Index of | Performance Magnetic table task | Nine Hole Peg T est | Orthotics and Prosthetics User's | Survey Peripersonal test | Prosthesis Efficiency and Profitability | QuickDASH     | Southampton Hand             | Assessment Procedure | Virtual Egg T est | WHOQOL-BREF   |\n\nAbbreviations: QuickDASH, short version of the Disabilities of the Arm, Shoulder, and Head questionnaire; WHOQOL-BREF, short version of the World Health Organization Quality of Life scale.\n",
    "topic": "The relationship between types of somatosensory feedback and functional domains such as fine movement, reach, and grasp in prosthetic hand evaluation.",
    "response": "<document_analysis>\nThe provided table presents a comprehensive overview of clinical assessments for transradial amputees using robotic prosthetic hands, categorized by the type of somatosensory feedback (implicit or explicit) involved and the functional domains evaluated (fine movement, measurement reach, grasp, embodiment, quality of life). It highlights which assessments incorporate implicit or explicit somatosensory feedback and which functional abilities they measure. The table also distinguishes among measurement types (e.g., pick and place, psychometric tests) and indicates whether the assessments are clinically validated.\n\nCentral ideas include the mapping between the type of somatosensory feedback and the domains of prosthetic hand function evaluated, showing that implicit feedback is more frequently associated with fine movement and reach tasks, while explicit feedback appears in grasping and embodiment domains. Some assessments combine both types of feedback for certain functions, reflecting a nuanced understanding of how sensory feedback modalities impact prosthetic performance.\n\nThe subtlety lies in recognizing that different somatosensory feedback types contribute differently to functional outcomes and that clinical validation varies across tests. The relationship between feedback type and measured domain suggests tailored prosthetic design and evaluation approaches that optimize user interaction.\n\nDifficulty rating: 9/10. The question challenges an expert to synthesize complex relationships between sensory feedback modalities and functional assessments, requiring deep knowledge of prosthetic evaluation methods, somatosensory neuroscience, and clinical measurement techniques.\n\nThe question is designed to provoke critical reflection on how implicit and explicit somatosensory feedback differentially influence fine motor control, reach, and grasp in prosthetic hand use, encouraging integration of neurophysiological principles with clinical assessment strategies.\n\nGiven the meaningful, detailed clinical and technical content, generating a single, highly challenging question-answer pair is justified and valuable.\n</document_analysis>\n\n<output_format>\nQuestion: How do implicit and explicit somatosensory feedback differentially influence the evaluation of fine movement, measurement reach, and grasp domains in transradial amputee prosthetic hand assessments, and what implications does this have for designing clinically validated functional tests?\n\nExplanation: Implicit somatosensory feedback predominantly supports fine movement and measurement reach tasks by facilitating unconscious proprioceptive and tactile cues essential for object handling and manipulation, whereas explicit feedback is more critical in grasp and embodiment assessments that require conscious sensory perception and integration; recognizing this distinction guides the selection and design of clinically validated tests to target the relevant feedback modality that best reflects functional performance in each domain.\n\nCorrect Answer: Implicit feedback mainly enhances fine movement and reach evaluations through unconscious proprioception, while explicit feedback predominantly influences grasp assessments via conscious sensation, informing the design of validated tests tailored to each feedback type\u2019s functional role.\n</output_format>",
    "question": "How do implicit and explicit somatosensory feedback differentially influence the evaluation of fine movement, measurement reach, and grasp domains in transradial amputee prosthetic hand assessments, and what implications does this have for designing clinically validated functional tests?",
    "answer": "Implicit feedback mainly enhances fine movement and reach evaluations through unconscious proprioception, while explicit feedback predominantly influences grasp assessments via conscious sensation, informing the design of validated tests tailored to each feedback type\u2019s functional role.",
    "explanation": "Implicit somatosensory feedback predominantly supports fine movement and measurement reach tasks by facilitating unconscious proprioceptive and tactile cues essential for object handling and manipulation, whereas explicit feedback is more critical in grasp and embodiment assessments that require conscious sensory perception and integration; recognizing this distinction guides the selection and design of clinically validated tests to target the relevant feedback modality that best reflects functional performance in each domain.",
    "question_token_count": 48,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 8,
    "question_difficulty_score": 9,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 41
  },
  {
    "context": "## 4.4. Perspectives\nMotor decoding for RPHs is progressing in two main directions: Noninvasive approaches have seen advances in decoding algorithms using large data sets and increases in the number of recording points, and implanted electrodes (either muscular or intraneural) have seen improvements that enable better recording stability and more robust decoding. There is currently no consensus on which approach is best for transradial amputee patients, as they each have their own strengths and limitations. The need for daily signal and classification recalibration is a weak point of the classic sEMG approach, which is being addressed by several research groups developing, for example, HD-sEMG.And despite iEMG's promising control performance, which is robust to donning and doffing of the prosthesis, its overall performance gain, when compared with sEMG, may not currently be sufficient to justify an invasive surgery. The same reasoning can be applied to intraneural electrodes.\n\nOne can imagine a future where both invasive and noninvasive approaches will continue to progress and will target either patients who prefer a stable decoding setup or those who do not want to undergo surgery and will accept the need to calibrate their prosthesis on a regular basis (118). Another scenario can be a parallel development of invasive technologies for both sensory and motor functions. Indeed, as shown in Section 5, the approach using intraneural implanted electrodes has permitted unprecedented levels of somatosensory restoration; it might, therefore, be reasonable to perform a single surgery to restore both motor and sensory functions. For this reason, motor decoding using the intraneural interface can become a viable solution if these interfaces one day permit both providing sensory feedback and recording discriminative signals for motor decoding in parallel, but online artifact removal remains an important challenge.\n\nPower consumption is another critical issue: RPHs should embed small electronics because the size of the prosthesis limits the space available for batteries, but doing so usually comes at the cost of limited processing resources. Also, the electronics for the HD-sEMG remain cumbersome due to the large number of input channels and should be miniaturized and portable. Moreover, decoding model complexity is also limited by portable processing resources. In practice, an increased number of electrodes is already available in wearable systems (Sessantaquattro, OT Bioelettronica, Italy) and may become available for prostheses in the future.\n\nFinally, low latency is paramount for seamless prosthesis control [ &lt; 300 ms between user intention and real-time decoding (119)]. Among the studies discussed above, only a few performed analyses to show the feasibility of real-time control (without processing resource limitations), and even fewer included embedded electronics that would translate for home use. One possible solution for real-time decoding with complex models is to bypass embedded electronic limitations; this could be achieved by taking advantage of the computational power of cell phones or by relying on cloud computing and the next generations of wireless cellular networks for low-latency communication.\n",
    "topic": "Engineering constraints impacting RPH control systems, focusing on power consumption, miniaturization of electronics, and processing resource limitations.",
    "response": "<document_analysis>\nThe context discusses the engineering challenges related to motor decoding for robotic prosthetic hands (RPHs), particularly focusing on the trade-offs between invasive and noninvasive electrode approaches. It highlights key constraints around power consumption, miniaturization, and processing resources that impact the design and functionality of RPH control systems. The limited space available for batteries in prostheses restricts power capacity, while the need for many input channels in HD-sEMG leads to bulky electronics that must be miniaturized to be wearable and practical. Additionally, complex decoding models are constrained by the limited processing capabilities of embedded electronics, which affects real-time control feasibility. The text also suggests that future solutions might involve offloading computation to external devices like smartphones or cloud services, leveraging wireless low-latency communication. This indicates a multifaceted engineering problem balancing hardware size, energy efficiency, computational power, and latency requirements for effective prosthesis control.\n\nThe question should probe a deep understanding of how these engineering constraints interplay and influence RPH system design choices, encouraging reflection on potential solutions and trade-offs. The difficulty level is high (around 8-9) as it requires integrating knowledge of embedded systems, signal processing, and prosthetic design challenges. The question should be structured to compel the respondent to synthesize this information and consider implications for future development paths.\n\nIrrelevant or extraneous content such as citations, product names, or unrelated sections were excluded from consideration, focusing solely on the engineering and control system constraints discussion.\n\nOverall, the content is rich, coherent, and highly suitable for generating a challenging question-answer pair for domain experts in biomedical engineering or neuroprosthetics.\n</document_analysis>\n\n<output_format>\nQuestion: How do the constraints of limited battery size, required miniaturization of electronics, and processing resource limitations collectively impact the design and real-time control capabilities of RPH systems, and what engineering strategies could be employed to address these challenges without compromising low-latency performance?\n\nExplanation: Limited battery size restricts available power, necessitating small, energy-efficient electronics, which limits processing power and the complexity of decoding algorithms. This in turn challenges the ability to achieve low-latency, real-time control due to computational resource constraints. Miniaturization is further complicated by the need for many input channels in systems like HD-sEMG, making electronics bulky unless optimized. To overcome these, strategies include offloading computation to external devices such as smartphones or cloud computing platforms, leveraging advanced wireless networks for low-latency data transmission, and developing more efficient embedded processing hardware and algorithms. These approaches help maintain responsiveness and usability without enlarging prosthetic size or increasing power consumption excessively.\n\nCorrect Answer: Limited battery size and miniaturization restrict processing power and complexity of decoding algorithms, challenging real-time control; engineering strategies include computation offloading to smartphones or cloud and wireless low-latency communication to maintain performance.\n</output_format>",
    "question": "How do the constraints of limited battery size, required miniaturization of electronics, and processing resource limitations collectively impact the design and real-time control capabilities of RPH systems, and what engineering strategies could be employed to address these challenges without compromising low-latency performance?",
    "answer": "Limited battery size and miniaturization restrict processing power and complexity of decoding algorithms, challenging real-time control; engineering strategies include computation offloading to smartphones or cloud and wireless low-latency communication to maintain performance.",
    "explanation": "Limited battery size restricts available power, necessitating small, energy-efficient electronics, which limits processing power and the complexity of decoding algorithms. This in turn challenges the ability to achieve low-latency, real-time control due to computational resource constraints. Miniaturization is further complicated by the need for many input channels in systems like HD-sEMG, making electronics bulky unless optimized. To overcome these, strategies include offloading computation to external devices such as smartphones or cloud computing platforms, leveraging advanced wireless networks for low-latency data transmission, and developing more efficient embedded processing hardware and algorithms. These approaches help maintain responsiveness and usability without enlarging prosthetic size or increasing power consumption excessively.",
    "question_token_count": 53,
    "answer_correctness_score": 9,
    "explanation_validity_score": 9,
    "question_clarity_score": 7,
    "question_difficulty_score": 8,
    "question_groundedness_score": 9,
    "avg_answer_token_count": 42
  }
]